[
  {
    "library_name": "NumPy",
    "url": "https://github.com/numpy/numpy/releases/tag/v1.25.0",
    "version": "v1.25.0",
    "title": "Release v1.25.0 路 numpy/numpy 路 GitHub",
    "release_date": "2023-06-17T15:21:07Z",
    "content": "NumPy 1.25.0 Release Notes\nThe NumPy 1.25.0 release continues the ongoing work to improve the\nhandling and promotion of dtypes, increase the execution speed, and\nclarify the documentation. There has also been work to prepare for the\nfuture NumPy 2.0.0 release, resulting in a large number of new and\nexpired deprecation. Highlights are:\nSupport for MUSL, there are now MUSL wheels.\nSupport the Fujitsu C/C++ compiler.\nObject arrays are now supported in einsum\nSupport for inplace matrix multiplication (\n@=\n).\nWe will be releasing a NumPy 1.26 when Python 3.12 comes out. That is\nneeded because distutils has been dropped by Python 3.12 and we will be\nswitching to using meson for future builds. The next mainline release\nwill be NumPy 2.0.0. We plan that the 2.0 series will still support\ndownstream projects built against earlier versions of NumPy.\nThe Python versions supported in this release are 3.9-3.11.\nDeprecations\nnp.core.MachAr\nis deprecated. It is private API. In names defined\nin\nnp.core\nshould generally be considered private.\n(\ngh-22638\n)\nnp.finfo(None)\nis deprecated.\n(\ngh-23011\n)\nnp.round_\nis deprecated. Use\nnp.round\ninstead.\n(\ngh-23302\n)\nnp.product\nis deprecated. Use\nnp.prod\ninstead.\n(\ngh-23314\n)\nnp.cumproduct\nis deprecated. Use\nnp.cumprod\ninstead.\n(\ngh-23314\n)\nnp.sometrue\nis deprecated. Use\nnp.any\ninstead.\n(\ngh-23314\n)\nnp.alltrue\nis deprecated. Use\nnp.all\ninstead.\n(\ngh-23314\n)\nOnly ndim-0 arrays are treated as scalars. NumPy used to treat all\narrays of size 1 (e.g.,\nnp.array([3.14])\n) as scalars. In the\nfuture, this will be limited to arrays of ndim 0 (e.g.,\nnp.array(3.14)\n). The following expressions will report a\ndeprecation warning:\na\n=\nnp\n.\narray\n([\n3.14\n])\nfloat\n(\na\n)\n# better: a[0] to get the numpy.float or a.item()\nb\n=\nnp\n.\narray\n([[\n3.14\n]])\nc\n=\nnumpy\n.\nrandom\n.\nrand\n(\n10\n)\nc\n[\n0\n]\n=\nb\n# better: c[0] = b[0, 0]\n(\ngh-10615\n)\nnumpy.find_common_type\nis now deprecated and its use\nshould be replaced with either\nnumpy.result_type\nor\nnumpy.promote_types\n. Most users leave the second\nscalar_types\nargument to\nfind_common_type\nas\n[]\nin which case\nnp.result_type\nand\nnp.promote_types\nare both faster and more\nrobust. When not using\nscalar_types\nthe main difference is that\nthe replacement intentionally converts non-native byte-order to\nnative byte order. Further,\nfind_common_type\nreturns\nobject\ndtype rather than failing promotion. This leads to differences when\nthe inputs are not all numeric. Importantly, this also happens for\ne.g. timedelta/datetime for which NumPy promotion rules are\ncurrently sometimes surprising.\nWhen the\nscalar_types\nargument is not\n[]\nthings are more\ncomplicated. In most cases, using\nnp.result_type\nand passing the\nPython values\n0\n,\n0.0\n, or\n0j\nhas the same result as using\nint\n,\nfloat\n, or\ncomplex\nin\nscalar_types\n.\nWhen\nscalar_types\nis constructed,\nnp.result_type\nis the correct\nreplacement and it may be passed scalar values like\nnp.float32(0.0)\n. Passing values other than 0, may lead to\nvalue-inspecting behavior (which\nnp.find_common_type\nnever used\nand NEP 50 may change in the future). The main possible change in\nbehavior in this case, is when the array types are signed integers\nand scalar types are unsigned.\nIf you are unsure about how to replace a use of\nscalar_types\nor\nwhen non-numeric dtypes are likely, please do not hesitate to open a\nNumPy issue to ask for help.\n(\ngh-22539\n)\nExpired deprecations\nnp.core.machar\nand\nnp.finfo.machar\nhave been removed.\n(\ngh-22638\n)\n+arr\nwill now raise an error when the dtype is not numeric (and\npositive is undefined).\n(\ngh-22998\n)\nA sequence must now be passed into the stacking family of functions\n(\nstack\n,\nvstack\n,\nhstack\n,\ndstack\nand\ncolumn_stack\n).\n(\ngh-23019\n)\nnp.clip\nnow defaults to same-kind casting. Falling back to unsafe\ncasting was deprecated in NumPy 1.17.\n(\ngh-23403\n)\nnp.clip\nwill now propagate\nnp.nan\nvalues passed as\nmin\nor\nmax\n. Previously, a scalar NaN was usually ignored. This was\ndeprecated in NumPy 1.17.\n(\ngh-23403\n)\nThe\nnp.dual\nsubmodule has been removed.\n(\ngh-23480\n)\nNumPy now always ignores sequence behavior for an array-like\n(defining one of the array protocols). (Deprecation started NumPy\n1.20)\n(\ngh-23660\n)\nThe niche\nFutureWarning\nwhen casting to a subarray dtype in\nastype\nor the array creation functions such as\nasarray\nis now\nfinalized. The behavior is now always the same as if the subarray\ndtype was wrapped into a single field (which was the workaround,\npreviously). (FutureWarning since NumPy 1.20)\n(\ngh-23666\n)\n==\nand\n!=\nwarnings have been finalized. The\n==\nand\n!=\noperators on arrays now always:\nraise errors that occur during comparisons such as when the\narrays have incompatible shapes\n(\nnp.array([1, 2]) == np.array([1, 2, 3])\n).\nreturn an array of all\nTrue\nor all\nFalse\nwhen values are\nfundamentally not comparable (e.g. have different dtypes). An\nexample is\nnp.array([\"a\"]) == np.array([1])\n.\nThis mimics the Python behavior of returning\nFalse\nand\nTrue\nwhen comparing incompatible types like\n\"a\" == 1\nand\n\"a\" != 1\n. For a long time these gave\nDeprecationWarning\nor\nFutureWarning\n.\n(\ngh-22707\n)\nNose support has been removed. NumPy switched to using pytest in\n2018 and nose has been unmaintained for many years. We have kept\nNumPy's nose support to avoid breaking downstream projects who\nmight have been using it and not yet switched to pytest or some\nother testing framework. With the arrival of Python 3.12, unpatched\nnose will raise an error. It is time to move on.\nDecorators removed\n:\nraises\nslow\nsetastest\nskipif\nknownfailif\ndeprecated\nparametrize\n_needs_refcount\nThese are not to be confused with pytest versions with similar\nnames, e.g., pytest.mark.slow, pytest.mark.skipif,\npytest.mark.parametrize.\nFunctions removed\n:\nTester\nimport_nose\nrun_module_suite\n(\ngh-23041\n)\nThe\nnumpy.testing.utils\nshim has been removed. Importing from the\nnumpy.testing.utils\nshim has been deprecated since 2019, the shim\nhas now been removed. All imports should be made directly from\nnumpy.testing\n.\n(\ngh-23060\n)\nThe environment variable to disable dispatching has been removed.\nSupport for the\nNUMPY_EXPERIMENTAL_ARRAY_FUNCTION\nenvironment\nvariable has been removed. This variable disabled dispatching with\n__array_function__\n.\n(\ngh-23376\n)\nSupport for\ny=\nas an alias of\nout=\nhas been removed. The\nfix\n,\nisposinf\nand\nisneginf\nfunctions allowed using\ny=\nas a\n(deprecated) alias for\nout=\n. This is no longer supported.\n(\ngh-23376\n)\nCompatibility notes\nThe\nbusday_count\nmethod now correctly handles cases where the\nbegindates\nis later in time than the\nenddates\n. Previously, the\nenddates\nwas included, even though the documentation states it is\nalways excluded.\n(\ngh-23229\n)\nWhen comparing datetimes and timedelta using\nnp.equal\nor\nnp.not_equal\nnumpy previously allowed the comparison with\ncasting=\"unsafe\"\n. This operation now fails. Forcing the output\ndtype using the\ndtype\nkwarg can make the operation succeed, but we\ndo not recommend it.\n(\ngh-22707\n)\nWhen loading data from a file handle using\nnp.load\n, if the handle\nis at the end of file, as can happen when reading multiple arrays by\ncalling\nnp.load\nrepeatedly, numpy previously raised\nValueError\nif\nallow_pickle=False\n, and\nOSError\nif\nallow_pickle=True\n. Now\nit raises\nEOFError\ninstead, in both cases.\n(\ngh-23105\n)\nnp.pad\nwith\nmode=wrap\npads with strict multiples of original data\nCode based on earlier version of\npad\nthat uses\nmode=\"wrap\"\nwill\nreturn different results when the padding size is larger than initial\narray.\nnp.pad\nwith\nmode=wrap\nnow always fills the space with strict\nmultiples of original data even if the padding size is larger than the\ninitial array.\n(\ngh-22575\n)\nCython\nlong_t\nand\nulong_t\nremoved\nlong_t\nand\nulong_t\nwere aliases for\nlonglong_t\nand\nulonglong_t\nand confusing (a remainder from of Python 2). This change may lead to\nthe errors:\n'long_t' is not a type identifier\n'ulong_t' is not a type identifier\nWe recommend use of bit-sized types such as\ncnp.int64_t\nor the use of\ncnp.intp_t\nwhich is 32 bits on 32 bit systems and 64 bits on 64 bit\nsystems (this is most compatible with indexing). If C\nlong\nis desired,\nuse plain\nlong\nor\nnpy_long\n.\ncnp.int_t\nis also\nlong\n(NumPy's\ndefault integer). However,\nlong\nis 32 bit on 64 bit windows and we may\nwish to adjust this even in NumPy. (Please do not hesitate to contact\nNumPy developers if you are curious about this.)\n(\ngh-22637\n)\nChanged error message and type for bad\naxes\nargument to\nufunc\nThe error message and type when a wrong\naxes\nvalue is passed to\nufunc(..., axes=[...])\nhas changed. The message is now more\nindicative of the problem, and if the value is mismatched an\nAxisError\nwill be raised. A\nTypeError\nwill still be raised for\ninvalidinput types.\n(\ngh-22675\n)\nArray-likes that define\n__array_ufunc__\ncan now override ufuncs if used as\nwhere\nIf the\nwhere\nkeyword argument of a\nnumpy.ufunc\n{.interpreted-text\nrole=\"class\"} is a subclass of\nnumpy.ndarray\n{.interpreted-text\nrole=\"class\"} or is a duck type that defines\nnumpy.class.__array_ufunc__\n{.interpreted-text role=\"func\"} it can\noverride the behavior of the ufunc using the same mechanism as the input\nand output arguments. Note that for this to work properly, the\nwhere.__array_ufunc__\nimplementation will have to unwrap the\nwhere\nargument to pass it into the default implementation of the\nufunc\nor,\nfor\nnumpy.ndarray\n{.interpreted-text role=\"class\"} subclasses before\nusing\nsuper().__array_ufunc__\n.\n(\ngh-23240\n)\nCompiling against the NumPy C API is now backwards compatible by default\nNumPy now defaults to exposing a backwards compatible subset of the\nC-API. This makes the use of\noldest-supported-numpy\nunnecessary.\nLibraries can override the default minimal version to be compatible with\nusing:\n#define NPY_TARGET_VERSION NPY_1_22_API_VERSION\nbefore including NumPy or by passing the equivalent\n-D\noption to the\ncompiler. The NumPy 1.25 default is\nNPY_1_19_API_VERSION\n. Because the\nNumPy 1.19 C API was identical to the NumPy 1.16 one resulting programs\nwill be compatible with NumPy 1.16 (from a C-API perspective). This\ndefault will be increased in future non-bugfix releases. You can still\ncompile against an older NumPy version and run on a newer one.\nFor more details please see\nfor-downstream-package-authors\n{.interpreted-text role=\"ref\"}.\n(\ngh-23528\n)\nNew Features\nnp.einsum\nnow accepts arrays with\nobject\ndtype\nThe code path will call python operators on object dtype arrays, much\nlike\nnp.dot\nand\nnp.matmul\n.\n(\ngh-18053\n)\nAdd support for inplace matrix multiplication\nIt is now possible to perform inplace matrix multiplication via the\n@=\noperator.\n>\n>>\nimport\nnumpy\nas\nnp\n>\n>>\na\n=\nnp\n.\narange\n(\n6\n).\nreshape\n(\n3\n,\n2\n)\n>\n>>\nprint\n(\na\n)\n[[\n0\n1\n]\n [\n2\n3\n]\n [\n4\n5\n]]\n>\n>>\nb\n=\nnp\n.\nones\n((\n2\n,\n2\n),\ndtype\n=\nint\n)\n>\n>>\na\n@=\nb\n>\n>>\nprint\n(\na\n)\n[[\n1\n1\n]\n [\n5\n5\n]\n [\n9\n9\n]]\n(\ngh-21120\n)\nAdded\nNPY_ENABLE_CPU_FEATURES\nenvironment variable\nUsers may now choose to enable only a subset of the built CPU features\nat runtime by specifying the\nNPY_ENABLE_CPU_FEATURES\nenvironment variable. Note that these specified features must be outside\nthe baseline, since those are always assumed. Errors will be raised if\nattempting to enable a feature that is either not supported by your CPU,\nor that NumPy was not built with.\n(\ngh-22137\n)\nNumPy now has an\nnp.exceptions\nnamespace\nNumPy now has a dedicated namespace making most exceptions and warnings\navailable. All of these remain available in the main namespace, although\nsome may be moved slowly in the future. The main reason for this is to\nincrease discoverability and add future exceptions.\n(\ngh-22644\n)\nnp.linalg\nfunctions return NamedTuples\nnp.linalg\nfunctions that return tuples now return namedtuples. These\nfunctions are\neig()\n,\neigh()\n,\nqr()\n,\nslogdet()\n, and\nsvd()\n. The\nreturn type is unchanged in instances where these functions return\nnon-tuples with certain keyword arguments (like\nsvd(compute_uv=False)\n).\n(\ngh-22786\n)\nString functions in\nnp.char\nare compatible with NEP 42 custom dtypes\nCustom dtypes that represent unicode strings or byte strings can now be\npassed to the string functions in\nnp.char\n.\n(\ngh-22863\n)\nString dtype instances can be created from the string abstract dtype classes\nIt is now possible to create a string dtype instance with a size without\nusing the string name of the dtype. For example,\ntype(np.dtype('U'))(8)\nwill create a dtype that is equivalent to\nnp.dtype('U8')\n. This feature is most useful when writing generic code\ndealing with string dtype classes.\n(\ngh-22963\n)\nFujitsu C/C++ compiler is now supported\nSupport for Fujitsu compiler has been added. To build with Fujitsu\ncompiler, run:\npython setup.py build -c fujitsu\nSSL2 is now supported\nSupport for SSL2 has been added. SSL2 is a library that provides\nOpenBLAS compatible GEMM functions. To enable SSL2, it need to edit\nsite.cfg and build with Fujitsu compiler. See site.cfg.example.\n(\ngh-22982\n)\nImprovements\nNDArrayOperatorsMixin\nspecifies that it has no\n__slots__\nThe\nNDArrayOperatorsMixin\nclass now specifies that it contains no\n__slots__\n, ensuring that subclasses can now make use of this feature\nin Python.\n(\ngh-23113\n)\nFix power of complex zero\nnp.power\nnow returns a different result for\n0^{non-zero}\nfor complex\nnumbers. Note that the value is only defined when the real part of the\nexponent is larger than zero. Previously, NaN was returned unless the\nimaginary part was strictly zero. The return value is either\n0+0j\nor\n0-0j\n.\n(\ngh-18535\n)\nNew\nDTypePromotionError\nNumPy now has a new\nDTypePromotionError\nwhich is used when two dtypes\ncannot be promoted to a common one, for example:\nnp.result_type(\"M8[s]\", np.complex128)\nraises this new exception.\n(\ngh-22707\n)\nnp.show_config\nuses information from Meson\nBuild and system information now contains information from Meson.\nnp.show_config\nnow has a new optional parameter\nmode\nto\nhelp customize the output.\n(\ngh-22769\n)\nFix\nnp.ma.diff\nnot preserving the mask when called with arguments prepend/append.\nCalling\nnp.ma.diff\nwith arguments prepend and/or append now returns a\nMaskedArray\nwith the input mask preserved.\nPreviously, a\nMaskedArray\nwithout the mask was returned.\n(\ngh-22776\n)\nCorrected error handling for NumPy C-API in Cython\nMany NumPy C functions defined for use in Cython were lacking the\ncorrect error indicator like\nexcept -1\nor\nexcept *\n. These have now\nbeen added.\n(\ngh-22997\n)\nAbility to directly spawn random number generators\nnumpy.random.Generator.spawn\nnow allows to directly spawn new independent\nchild generators via the\nnumpy.random.SeedSequence.spawn\nmechanism.\nnumpy.random.BitGenerator.spawn\ndoes the same for the underlying bit\ngenerator.\nAdditionally,\nnumpy.random.BitGenerator.seed_seq\nnow gives\ndirect access to the seed sequence used for initializing the bit\ngenerator. This allows for example:\nseed = 0x2e09b90939db40c400f8f22dae617151\nrng = np.random.default_rng(seed)\nchild_rng1, child_rng2 = rng.spawn(2)\n\n# safely use rng, child_rng1, and child_rng2\nPreviously, this was hard to do without passing the\nSeedSequence\nexplicitly. Please see\nnumpy.random.SeedSequence\nfor more\ninformation.\n(\ngh-23195\n)\nnumpy.logspace\nnow supports a non-scalar\nbase\nargument\nThe\nbase\nargument of\nnumpy.logspace\ncan now be array-like if it is\nbroadcastable against the\nstart\nand\nstop\narguments.\n(\ngh-23275\n)\nnp.ma.dot()\nnow supports for non-2d arrays\nPreviously\nnp.ma.dot()\nonly worked if\na\nand\nb\nwere both 2d. Now it\nworks for non-2d arrays as well as\nnp.dot()\n.\n(\ngh-23322\n)\nExplicitly show keys of .npz file in repr\nNpzFile\nshows keys of loaded .npz file when printed.\n>\n>>\nnpzfile\n=\nnp\n.\nload\n(\n'arr.npz'\n)\n>\n>>\nnpzfile\nNpzFile\n'arr.npz'\nwith\nkeys\narr_0\n,\narr_1\n,\narr_2\n,\narr_3\n,\narr_4\n...\n(\ngh-23357\n)\nNumPy now exposes DType classes in\nnp.dtypes\nThe new\nnumpy.dtypes\nmodule now exposes DType classes and will contain\nfuture dtype related functionality. Most users should have no need to\nuse these classes directly.\n(\ngh-23358\n)\nDrop dtype metadata before saving in .npy or .npz files\nCurrently, a\n*.npy\nfile containing a table with a dtype with metadata cannot\nbe read back. Now,\nnp.save\nand\nnp.savez\ndrop metadata before saving.\n(\ngh-23371\n)\nnumpy.lib.recfunctions.structured_to_unstructured\nreturns views in more cases\nstructured_to_unstructured\nnow returns a view, if the stride between\nthe fields is constant. Prior, padding between the fields or a reversed\nfield would lead to a copy. This change only applies to\nndarray\n,\nmemmap\nand\nrecarray\n. For all other array subclasses, the behavior\nremains unchanged.\n(\ngh-23652\n)\nSigned and unsigned integers always compare correctly\nWhen\nuint64\nand\nint64\nare mixed in NumPy, NumPy typically promotes\nboth to\nfloat64\n. This behavior may be argued about but is confusing\nfor comparisons\n==\n,\n<=\n, since the results returned can be incorrect\nbut the conversion is hidden since the result is a boolean. NumPy will\nnow return the correct results for these by avoiding the cast to float.\n(\ngh-23713\n)\nPerformance improvements and changes\nFaster\nnp.argsort\non AVX-512 enabled processors\n32-bit and 64-bit quicksort algorithm for np.argsort gain up to 6x speed\nup on processors that support AVX-512 instruction set.\nThanks to\nIntel corporation\nfor sponsoring\nthis work.\n(\ngh-23707\n)\nFaster\nnp.sort\non AVX-512 enabled processors\nQuicksort for 16-bit and 64-bit dtypes gain up to 15x and 9x speed up on\nprocessors that support AVX-512 instruction set.\nThanks to\nIntel corporation\nfor sponsoring\nthis work.\n(\ngh-22315\n)\n__array_function__\nmachinery is now much faster\nThe overhead of the majority of functions in NumPy is now smaller\nespecially when keyword arguments are used. This change significantly\nspeeds up many simple function calls.\n(\ngh-23020\n)\nufunc.at\ncan be much faster\nGeneric\nufunc.at\ncan be up to 9x faster. The conditions for this\nspeedup:\noperands are aligned\nno casting\nIf ufuncs with appropriate indexed loops on 1d arguments with the above\nconditions,\nufunc.at\ncan be up to 60x faster (an additional 7x\nspeedup). Appropriate indexed loops have been added to\nadd\n,\nsubtract\n,\nmultiply\n,\nfloor_divide\n,\nmaximum\n,\nminimum\n,\nfmax\n,\nand\nfmin\n.\nThe internal logic is similar to the logic used for regular ufuncs,\nwhich also have fast paths.\nThanks to the\nD. E. Shaw group\nfor sponsoring\nthis work.\n(\ngh-23136\n)\nFaster membership test on\nNpzFile\nMembership test on\nNpzFile\nwill no longer decompress the archive if it\nis successful.\n(\ngh-23661\n)\nChanges\nnp.r_[]\nand\nnp.c_[]\nwith certain scalar values\nIn rare cases, using mainly\nnp.r_\nwith scalars can lead to different\nresults. The main potential changes are highlighted by the following:\n>>> np.r_[np.arange(5, dtype=np.uint8), -1].dtype\nint16  # rather than the default integer (int64 or int32)\n>>> np.r_[np.arange(5, dtype=np.int8), 255]\narray([  0,   1,   2,   3,   4, 255], dtype=int16)\nWhere the second example returned:\narray([ 0,  1,  2,  3,  4, -1], dtype=int8)\nThe first one is due to a signed integer scalar with an unsigned integer\narray, while the second is due to\n255\nnot fitting into\nint8\nand\nNumPy currently inspecting values to make this work. (Note that the\nsecond example is expected to change in the future due to\nNEP 50 <NEP50>\n{.interpreted-text role=\"ref\"}; it will then raise an\nerror.)\n(\ngh-22539\n)\nMost NumPy functions are wrapped into a C-callable\nTo speed up the\n__array_function__\ndispatching, most NumPy functions\nare now wrapped into C-callables and are not proper Python functions or\nC methods. They still look and feel the same as before (like a Python\nfunction), and this should only improve performance and user experience\n(cleaner tracebacks). However, please inform the NumPy developers if\nthis change confuses your program for some reason.\n(\ngh-23020\n)\nC++ standard library usage\nNumPy builds now depend on the C++ standard library, because the\nnumpy.core._multiarray_umath\nextension is linked with the C++ linker.\n(\ngh-23601\n)\nChecksums\nMD5\n4657f046d9d9d62e4baeae9b2cc1b4ea  numpy-1.25.0-cp310-cp310-macosx_10_9_x86_64.whl\nf57f98fee3da2d98f752f755a880a508  numpy-1.25.0-cp310-cp310-macosx_11_0_arm64.whl\n72b0ad52f96a41a7a82f511cb35c7ef1  numpy-1.25.0-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\na61227341b8903fa66ab0e0fdaa15430  numpy-1.25.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\nbfccabfbd866c59545ce11ecdac60701  numpy-1.25.0-cp310-cp310-musllinux_1_1_x86_64.whl\n22402904f194376b8d2de01481f04b03  numpy-1.25.0-cp310-cp310-win32.whl\ne983b193f7d63568eac85d8bda8be62e  numpy-1.25.0-cp310-cp310-win_amd64.whl\n5f6477db172f59a4fd7f591e1007e632  numpy-1.25.0-cp311-cp311-macosx_10_9_x86_64.whl\n6a85cca47af69e3d45b4efab9490af4d  numpy-1.25.0-cp311-cp311-macosx_11_0_arm64.whl\nad1c0b4b406c9a2f1b42792502bc456b  numpy-1.25.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n39e241f265611a9c1e89499054ead1c9  numpy-1.25.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\ne36b37acf1acfbc185face67c67bfe09  numpy-1.25.0-cp311-cp311-musllinux_1_1_x86_64.whl\n67862d7849b4f0f943760142f1628aed  numpy-1.25.0-cp311-cp311-win32.whl\n6e8ed7865792246cac2213bad404f4da  numpy-1.25.0-cp311-cp311-win_amd64.whl\n25e843425697364f50dd7288ff9d2ce1  numpy-1.25.0-cp39-cp39-macosx_10_9_x86_64.whl\n58641e53bcb1e13dfed1f5af1aff94bc  numpy-1.25.0-cp39-cp39-macosx_11_0_arm64.whl\nce15327793c39beecee8401356bc6c9b  numpy-1.25.0-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n34b734a2c7698d59954c29fe7c0536f3  numpy-1.25.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n6652d9df23c84e54466b10f4a2a290be  numpy-1.25.0-cp39-cp39-musllinux_1_1_x86_64.whl\nc228105e3c4c8887823d99e35eea9d2b  numpy-1.25.0-cp39-cp39-win32.whl\n1322210ae6a874293d13c4bb3abf24ee  numpy-1.25.0-cp39-cp39-win_amd64.whl\ndc36096628e65077c2a44c493606c668  numpy-1.25.0-pp39-pypy39_pp73-macosx_10_9_x86_64.whl\n942b4276f8d563efb111921d5995834c  numpy-1.25.0-pp39-pypy39_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n0fa0734a8ff952dd643e7b9826168099  numpy-1.25.0-pp39-pypy39_pp73-win_amd64.whl\nb236497153bc19b4a560ac485e4c2754  numpy-1.25.0.tar.gz\nSHA256\n8aa130c3042052d656751df5e81f6d61edff3e289b5994edcf77f54118a8d9f4  numpy-1.25.0-cp310-cp310-macosx_10_9_x86_64.whl\n9e3f2b96e3b63c978bc29daaa3700c028fe3f049ea3031b58aa33fe2a5809d24  numpy-1.25.0-cp310-cp310-macosx_11_0_arm64.whl\nd6b267f349a99d3908b56645eebf340cb58f01bd1e773b4eea1a905b3f0e4208  numpy-1.25.0-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n4aedd08f15d3045a4e9c648f1e04daca2ab1044256959f1f95aafeeb3d794c16  numpy-1.25.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n6d183b5c58513f74225c376643234c369468e02947b47942eacbb23c1671f25d  numpy-1.25.0-cp310-cp310-musllinux_1_1_x86_64.whl\nd76a84998c51b8b68b40448ddd02bd1081bb33abcdc28beee6cd284fe11036c6  numpy-1.25.0-cp310-cp310-win32.whl\nc0dc071017bc00abb7d7201bac06fa80333c6314477b3d10b52b58fa6a6e38f6  numpy-1.25.0-cp310-cp310-win_amd64.whl\n4c69fe5f05eea336b7a740e114dec995e2f927003c30702d896892403df6dbf0  numpy-1.25.0-cp311-cp311-macosx_10_9_x86_64.whl\n9c7211d7920b97aeca7b3773a6783492b5b93baba39e7c36054f6e749fc7490c  numpy-1.25.0-cp311-cp311-macosx_11_0_arm64.whl\necc68f11404930e9c7ecfc937aa423e1e50158317bf67ca91736a9864eae0232  numpy-1.25.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\ne559c6afbca484072a98a51b6fa466aae785cfe89b69e8b856c3191bc8872a82  numpy-1.25.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n6c284907e37f5e04d2412950960894b143a648dea3f79290757eb878b91acbd1  numpy-1.25.0-cp311-cp311-musllinux_1_1_x86_64.whl\n95367ccd88c07af21b379be1725b5322362bb83679d36691f124a16357390153  numpy-1.25.0-cp311-cp311-win32.whl\nb76aa836a952059d70a2788a2d98cb2a533ccd46222558b6970348939e55fc24  numpy-1.25.0-cp311-cp311-win_amd64.whl\nb792164e539d99d93e4e5e09ae10f8cbe5466de7d759fc155e075237e0c274e4  numpy-1.25.0-cp39-cp39-macosx_10_9_x86_64.whl\n7cd981ccc0afe49b9883f14761bb57c964df71124dcd155b0cba2b591f0d64b9  numpy-1.25.0-cp39-cp39-macosx_11_0_arm64.whl\n5aa48bebfb41f93043a796128854b84407d4df730d3fb6e5dc36402f5cd594c0  numpy-1.25.0-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n5177310ac2e63d6603f659fadc1e7bab33dd5a8db4e0596df34214eeab0fee3b  numpy-1.25.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n0ac6edfb35d2a99aaf102b509c8e9319c499ebd4978df4971b94419a116d0790  numpy-1.25.0-cp39-cp39-musllinux_1_1_x86_64.whl\n7412125b4f18aeddca2ecd7219ea2d2708f697943e6f624be41aa5f8a9852cc4  numpy-1.25.0-cp39-cp39-win32.whl\n26815c6c8498dc49d81faa76d61078c4f9f0859ce7817919021b9eba72b425e3  numpy-1.25.0-cp39-cp39-win_amd64.whl\n5b1b90860bf7d8a8c313b372d4f27343a54f415b20fb69dd601b7efe1029c91e  numpy-1.25.0-pp39-pypy39_pp73-macosx_10_9_x86_64.whl\n85cdae87d8c136fd4da4dad1e48064d700f63e923d5af6c8c782ac0df8044542  numpy-1.25.0-pp39-pypy39_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\ncc3fda2b36482891db1060f00f881c77f9423eead4c3579629940a3e12095fe8  numpy-1.25.0-pp39-pypy39_pp73-win_amd64.whl\nf1accae9a28dc3cda46a91de86acf69de0d1b5f4edd44a9b0c3ceb8036dfff19  numpy-1.25.0.tar.gz",
    "crawl_status": "success"
  },
  {
    "library_name": "NumPy",
    "url": "https://github.com/numpy/numpy/releases/tag/v2.3.0",
    "version": "v2.3.0",
    "title": "Release v2.3.0 (June 7, 2025) 路 numpy/numpy 路 GitHub",
    "release_date": "2025-06-07T15:08:03Z",
    "content": "NumPy 2.3.0 Release Notes\nThe NumPy 2.3.0 release continues the work to improve free threaded\nPython support and annotations together with the usual set of bug fixes.\nIt is unusual in the number of expired deprecations, code\nmodernizations, and style cleanups. The latter may not be visible to\nusers, but is important for code maintenance over the long term. Note\nthat we have also upgraded from manylinux2014 to manylinux_2_28.\nUsers running on a Mac having an M4 cpu might see various warnings about\ninvalid values and such. The warnings are a known problem with\nAccelerate. They are annoying, but otherwise harmless. Apple promises to\nfix them.\nThis release supports Python versions 3.11-3.13, Python 3.14 will be\nsupported when it is released.\nHighlights\nInteractive examples in the NumPy documentation.\nBuilding NumPy with OpenMP Parallelization.\nPreliminary support for Windows on ARM.\nImproved support for free threaded Python.\nImproved annotations.\nNew functions\nNew function\nnumpy.strings.slice\nThe new function\nnumpy.strings.slice\nwas added, which implements fast\nnative slicing of string arrays. It supports the full slicing API\nincluding negative slice offsets and steps.\n(\ngh-27789\n)\nDeprecations\nThe\nnumpy.typing.mypy_plugin\nhas been deprecated in favor of\nplatform-agnostic static type inference. Please remove\nnumpy.typing.mypy_plugin\nfrom the\nplugins\nsection of your mypy\nconfiguration. If this change results in new errors being reported,\nkindly open an issue.\n(\ngh-28129\n)\nThe\nnumpy.typing.NBitBase\ntype has been deprecated and will be\nremoved in a future version.\nThis type was previously intended to be used as a generic upper\nbound for type-parameters, for example:\nimport\nnumpy\nas\nnp\nimport\nnumpy\n.\ntyping\nas\nnpt\ndef\nf\n[\nNT\n:\nnpt\n.\nNBitBase\n](\nx\n:\nnp\n.\ncomplexfloating\n[\nNT\n])\n->\nnp\n.\nfloating\n[\nNT\n]: ...\nBut in NumPy 2.2.0,\nfloat64\nand\ncomplex128\nwere changed to\nconcrete subtypes, causing static type-checkers to reject\nx: np.float64 = f(np.complex128(42j))\n.\nSo instead, the better approach is to use\ntyping.overload\n:\nimport\nnumpy\nas\nnp\nfrom\ntyping\nimport\noverload\n@\noverload\ndef\nf\n(\nx\n:\nnp\n.\ncomplex64\n)\n->\nnp\n.\nfloat32\n: ...\n@\noverload\ndef\nf\n(\nx\n:\nnp\n.\ncomplex128\n)\n->\nnp\n.\nfloat64\n: ...\n@\noverload\ndef\nf\n(\nx\n:\nnp\n.\nclongdouble\n)\n->\nnp\n.\nlongdouble\n: ...\n(\ngh-28884\n)\nExpired deprecations\nRemove deprecated macros like\nNPY_OWNDATA\nfrom Cython interfaces\nin favor of\nNPY_ARRAY_OWNDATA\n(deprecated since 1.7)\n(\ngh-28254\n)\nRemove\nnumpy/npy_1_7_deprecated_api.h\nand C macros like\nNPY_OWNDATA\nin favor of\nNPY_ARRAY_OWNDATA\n(deprecated since 1.7)\n(\ngh-28254\n)\nRemove alias\ngenerate_divbyzero_error\nto\nnpy_set_floatstatus_divbyzero\nand\ngenerate_overflow_error\nto\nnpy_set_floatstatus_overflow\n(deprecated since 1.10)\n(\ngh-28254\n)\nRemove\nnp.tostring\n(deprecated since 1.19)\n(\ngh-28254\n)\nRaise on\nnp.conjugate\nof non-numeric types (deprecated since 1.13)\n(\ngh-28254\n)\nRaise when using\nnp.bincount(...minlength=None)\n, use 0 instead\n(deprecated since 1.14)\n(\ngh-28254\n)\nPassing\nshape=None\nto functions with a non-optional shape argument\nerrors, use\n()\ninstead (deprecated since 1.20)\n(\ngh-28254\n)\nInexact matches for\nmode\nand\nsearchside\nraise (deprecated since\n1.20)\n(\ngh-28254\n)\nSetting\n__array_finalize__ = None\nerrors (deprecated since 1.23)\n(\ngh-28254\n)\nnp.fromfile\nand\nnp.fromstring\nerror on bad data, previously they\nwould guess (deprecated since 1.18)\n(\ngh-28254\n)\ndatetime64\nand\ntimedelta64\nconstruction with a tuple no longer\naccepts an\nevent\nvalue, either use a two-tuple of (unit, num) or a\n4-tuple of (unit, num, den, 1) (deprecated since 1.14)\n(\ngh-28254\n)\nWhen constructing a\ndtype\nfrom a class with a\ndtype\nattribute,\nthat attribute must be a dtype-instance rather than a thing that can\nbe parsed as a dtype instance (deprecated in 1.19). At some point\nthe whole construct of using a dtype attribute will be deprecated\n(see\n#25306\n)\n(\ngh-28254\n)\nPassing booleans as partition index errors (deprecated since 1.23)\n(\ngh-28254\n)\nOut-of-bounds indexes error even on empty arrays (deprecated since\n1.20)\n(\ngh-28254\n)\nnp.tostring\nhas been removed, use\ntobytes\ninstead (deprecated\nsince 1.19)\n(\ngh-28254\n)\nDisallow make a non-writeable array writeable for arrays with a base\nthat do not own their data (deprecated since 1.17)\n(\ngh-28254\n)\nconcatenate()\nwith\naxis=None\nuses\nsame-kind\ncasting by\ndefault, not\nunsafe\n(deprecated since 1.20)\n(\ngh-28254\n)\nUnpickling a scalar with object dtype errors (deprecated since 1.20)\n(\ngh-28254\n)\nThe binary mode of\nfromstring\nnow errors, use\nfrombuffer\ninstead\n(deprecated since 1.14)\n(\ngh-28254\n)\nConverting\nnp.inexact\nor\nnp.floating\nto a dtype errors\n(deprecated since 1.19)\n(\ngh-28254\n)\nConverting\nnp.complex\n,\nnp.integer\n,\nnp.signedinteger\n,\nnp.unsignedinteger\n,\nnp.generic\nto a dtype errors (deprecated\nsince 1.19)\n(\ngh-28254\n)\nThe Python built-in\nround\nerrors for complex scalars. Use\nnp.round\nor\nscalar.round\ninstead (deprecated since 1.19)\n(\ngh-28254\n)\n'np.bool' scalars can no longer be interpreted as an index\n(deprecated since 1.19)\n(\ngh-28254\n)\nParsing an integer via a float string is no longer supported.\n(deprecated since 1.23) To avoid this error you can\nmake sure the original data is stored as integers.\nuse the\nconverters=float\nkeyword argument.\nUse\nnp.loadtxt(...).astype(np.int64)\n(\ngh-28254\n)\nThe use of a length 1 tuple for the ufunc\nsignature\nerrors. Use\ndtype\nor fill the tuple with\nNone\n(deprecated since 1.19)\n(\ngh-28254\n)\nSpecial handling of matrix is in np.outer is removed. Convert to a\nndarray via\nmatrix.A\n(deprecated since 1.20)\n(\ngh-28254\n)\nRemoved the\nnp.compat\npackage source code (removed in 2.0)\n(\ngh-28961\n)\nC API changes\nNpyIter_GetTransferFlags\nis now available to check if the iterator\nneeds the Python API or if casts may cause floating point errors\n(FPE). FPEs can for example be set when casting\nfloat64(1e300)\nto\nfloat32\n(overflow to infinity) or a NaN to an integer (invalid\nvalue).\n(\ngh-27883\n)\nNpyIter\nnow has no limit on the number of operands it supports.\n(\ngh-28080\n)\nNew\nNpyIter_GetTransferFlags\nand\nNpyIter_IterationNeedsAPI\nchange\nNumPy now has the new\nNpyIter_GetTransferFlags\nfunction as a more\nprecise way checking of iterator/buffering needs. I.e. whether the\nPython API/GIL is required or floating point errors may occur. This\nfunction is also faster if you already know your needs without\nbuffering.\nThe\nNpyIter_IterationNeedsAPI\nfunction now performs all the checks\nthat were previously performed at setup time. While it was never\nnecessary to call it multiple times, doing so will now have a larger\ncost.\n(\ngh-27998\n)\nNew Features\nThe type parameter of\nnp.dtype\nnow defaults to\ntyping.Any\n. This\nway, static type-checkers will infer\ndtype: np.dtype\nas\ndtype: np.dtype[Any]\n, without reporting an error.\n(\ngh-28669\n)\nStatic type-checkers now interpret:\n_: np.ndarray\nas\n_: npt.NDArray[typing.Any]\n.\n_: np.flatiter\nas\n_: np.flatiter[np.ndarray]\n.\nThis is because their type parameters now have default values.\n(\ngh-28940\n)\nNumPy now registers its pkg-config paths with the\npkgconf\nPyPI package\nThe\npkgconf\nPyPI\npackage provides an interface for projects like NumPy to register their\nown paths to be added to the pkg-config search path. This means that\nwhen using\npkgconf\nfrom PyPI, NumPy will be discoverable without needing for any custom\nenvironment configuration.\nNote\nThis only applies when using the\npkgconf\npackage from\nPyPI\n,\nor put another way, this only applies when installing\npkgconf\nvia a\nPython package manager.\nIf you are using\npkg-config\nor\npkgconf\nprovided by your system,\nor any other source that does not use the\npkgconf-pypi\nproject, the NumPy pkg-config directory will not be automatically added\nto the search path. In these situations, you might want to use\nnumpy-config\n.\n(\ngh-28214\n)\nAllow\nout=...\nin ufuncs to ensure array result\nNumPy has the sometimes difficult behavior that it currently usually\nreturns scalars rather than 0-D arrays (even if the inputs were 0-D\narrays). This is especially problematic for non-numerical dtypes (e.g.\nobject\n).\nFor ufuncs (i.e. most simple math functions) it is now possible to use\nout=...\n(literally `...`, e.g.\nout=Ellipsis\n) which is identical\nin behavior to\nout\nnot being passed, but will ensure a non-scalar\nreturn. This spelling is borrowed from\narr1d[0, ...]\nwhere the\n...\nalso ensures a non-scalar return.\nOther functions with an\nout=\nkwarg should gain support eventually.\nDownstream libraries that interoperate via\n__array_ufunc__\nor\n__array_function__\nmay need to adapt to support this.\n(\ngh-28576\n)\nBuilding NumPy with OpenMP Parallelization\nNumPy now supports OpenMP parallel processing capabilities when built\nwith the\n-Denable_openmp=true\nMeson build flag. This feature is\ndisabled by default. When enabled,\nnp.sort\nand\nnp.argsort\nfunctions\ncan utilize OpenMP for parallel thread execution, improving performance\nfor these operations.\n(\ngh-28619\n)\nInteractive examples in the NumPy documentation\nThe NumPy documentation includes a number of examples that can now be\nrun interactively in your browser using WebAssembly and Pyodide.\nPlease note that the examples are currently experimental in nature and\nmay not work as expected for all methods in the public API.\n(\ngh-26745\n)\nImprovements\nScalar comparisons between non-comparable dtypes such as\nnp.array(1) == np.array('s')\nnow return a NumPy bool instead of a\nPython bool.\n(\ngh-27288\n)\nnp.nditer\nnow has no limit on the number of supported operands\n(C-integer).\n(\ngh-28080\n)\nNo-copy pickling is now supported for any array that can be\ntransposed to a C-contiguous array.\n(\ngh-28105\n)\nThe\n__repr__\nfor user-defined dtypes now prefers the\n__name__\nof\nthe custom dtype over a more generic name constructed from its\nkind\nand\nitemsize\n.\n(\ngh-28250\n)\nnp.dot\nnow reports floating point exceptions.\n(\ngh-28442\n)\nnp.dtypes.StringDType\nis now a\ngeneric\ntype\nwhich\naccepts a type argument for\nna_object\nthat defaults to\ntyping.Never\n. For example,\nStringDType(na_object=None)\nreturns a\nStringDType[None]\n, and\nStringDType()\nreturns a\nStringDType[typing.Never]\n.\n(\ngh-28856\n)\nAdded warnings to\nnp.isclose\nAdded warning messages if at least one of atol or rtol are either\nnp.nan\nor\nnp.inf\nwithin\nnp.isclose\n.\nWarnings follow the user's\nnp.seterr\nsettings\n(\ngh-28205\n)\nPerformance improvements and changes\nPerformance improvements to\nnp.unique\nnp.unique\nnow tries to use a hash table to find unique values instead\nof sorting values before finding unique values. This is limited to\ncertain dtypes for now, and the function is now faster for those dtypes.\nThe function now also exposes a\nsorted\nparameter to allow returning\nunique values as they were found, instead of sorting them afterwards.\n(\ngh-26018\n)\nPerformance improvements to\nnp.sort\nand\nnp.argsort\nnp.sort\nand\nnp.argsort\nfunctions now can leverage OpenMP for\nparallel thread execution, resulting in up to 3.5x speedups on x86\narchitectures with AVX2 or AVX-512 instructions. This opt-in feature\nrequires NumPy to be built with the -Denable_openmp Meson flag. Users\ncan control the number of threads used by setting the OMP_NUM_THREADS\nenvironment variable.\n(\ngh-28619\n)\nPerformance improvements for\nnp.float16\ncasts\nEarlier, floating point casts to and from\nnp.float16\ntypes were\nemulated in software on all platforms.\nNow, on ARM devices that support Neon float16 intrinsics (such as recent\nApple Silicon), the native float16 path is used to achieve the best\nperformance.\n(\ngh-28769\n)\nChanges\nThe vector norm\nord=inf\nand the matrix norms\nord={1, 2, inf, 'nuc'}\nnow always returns zero for empty arrays.\nEmpty arrays have at least one axis of size zero. This affects\nnp.linalg.norm\n,\nnp.linalg.vector_norm\n, and\nnp.linalg.matrix_norm\n. Previously, NumPy would raises errors or\nreturn zero depending on the shape of the array.\n(\ngh-28343\n)\nA spelling error in the error message returned when converting a\nstring to a float with the method\nnp.format_float_positional\nhas\nbeen fixed.\n(\ngh-28569\n)\nNumPy's\n__array_api_version__\nwas upgraded from\n2023.12\nto\n2024.12\n.\nnumpy.count_nonzero\nfor\naxis=None\n(default) now returns a NumPy\nscalar instead of a Python integer.\nThe parameter\naxis\nin\nnumpy.take_along_axis\nfunction has now a\ndefault value of\n-1\n.\n(\ngh-28615\n)\nPrinting of\nnp.float16\nand\nnp.float32\nscalars and arrays have\nbeen improved by adjusting the transition to scientific notation\nbased on the floating point precision. A new legacy\nnp.printoptions\nmode\n'2.2'\nhas been added for backwards\ncompatibility.\n(\ngh-28703\n)\nMultiplication between a string and integer now raises OverflowError\ninstead of MemoryError if the result of the multiplication would\ncreate a string that is too large to be represented. This follows\nPython's behavior.\n(\ngh-29060\n)\nunique_values\nmay return unsorted data\nThe relatively new function (added in NumPy 2.0)\nunique_values\nmay now\nreturn unsorted results. Just as\nunique_counts\nand\nunique_all\nthese\nnever guaranteed a sorted result, however, the result was sorted until\nnow. In cases where these do return a sorted result, this may change in\nfuture releases to improve performance.\n(\ngh-26018\n)\nChanges to the main iterator and potential numerical changes\nThe main iterator, used in math functions and via\nnp.nditer\nfrom\nPython and\nNpyIter\nin C, now behaves differently for some buffered\niterations. This means that:\nThe buffer size used will often be smaller than the maximum buffer\nsized allowed by the\nbuffersize\nparameter.\nThe \"growinner\" flag is now honored with buffered reductions when\nno operand requires buffering.\nFor\nnp.sum()\nsuch changes in buffersize may slightly change numerical\nresults of floating point operations. Users who use \"growinner\" for\ncustom reductions could notice changes in precision (for example, in\nNumPy we removed it from\neinsum\nto avoid most precision changes and\nimprove precision for some 64bit floating point inputs).\n(\ngh-27883\n)\nThe minimum supported GCC version is now 9.3.0\nThe minimum supported version was updated from 8.4.0 to 9.3.0, primarily\nin order to reduce the chance of platform-specific bugs in old GCC\nversions from causing issues.\n(\ngh-28102\n)\nChanges to automatic bin selection in numpy.histogram\nThe automatic bin selection algorithm in\nnumpy.histogram\nhas been\nmodified to avoid out-of-memory errors for samples with low variation.\nFor full control over the selected bins the user can use set the\nbin\nor\nrange\nparameters of\nnumpy.histogram\n.\n(\ngh-28426\n)\nBuild manylinux_2_28 wheels\nWheels for linux systems will use the\nmanylinux_2_28\ntag (instead of\nthe\nmanylinux2014\ntag), which means dropping support for\nredhat7/centos7, amazonlinux2, debian9, ubuntu18.04, and other\npre-glibc2.28 operating system versions, as per the\nPEP 600 support\ntable\n.\n(\ngh-28436\n)\nRemove use of -Wl,-ld_classic on macOS\nRemove use of -Wl,-ld_classic on macOS. This hack is no longer needed by\nSpack, and results in libraries that cannot link to other libraries\nbuilt with ld (new).\n(\ngh-28713\n)\nRe-enable overriding functions in the\nnumpy.strings\nRe-enable overriding functions in the\nnumpy.strings\nmodule.\n(\ngh-28741\n)\nChecksums\nMD5\ncf552b6b6390343c24bf60365950c91c  numpy-2.3.0-cp311-cp311-macosx_10_9_x86_64.whl\nd3c377f49f84b36297cfc2fc30c6a288  numpy-2.3.0-cp311-cp311-macosx_11_0_arm64.whl\n4e12cd2aea876c09fdc3aaac2d0f4bac  numpy-2.3.0-cp311-cp311-macosx_14_0_arm64.whl\na33af1d4e1f0ee5ed82d7933c5df9f84  numpy-2.3.0-cp311-cp311-macosx_14_0_x86_64.whl\ncd5cf04cb8b40e65aac8264c7bf3d7c9  numpy-2.3.0-cp311-cp311-manylinux_2_28_aarch64.whl\n6a45424beb8f4f23e7b2b853bc18aefa  numpy-2.3.0-cp311-cp311-manylinux_2_28_x86_64.whl\n2dc1c1d1b9deb8c0626af68c0c00660a  numpy-2.3.0-cp311-cp311-musllinux_1_2_aarch64.whl\n9ff8ea227afce090dea3b4dac4653fa6  numpy-2.3.0-cp311-cp311-musllinux_1_2_x86_64.whl\na1e9e40a20187e1f5ae2f8ba165e291b  numpy-2.3.0-cp311-cp311-win32.whl\n819e4ac62a3449c79818ff5aa0e6b276  numpy-2.3.0-cp311-cp311-win_amd64.whl\n347260edfd35535b15b8133280793080  numpy-2.3.0-cp311-cp311-win_arm64.whl\n9c1ad46e637b876a0535de60f5b604bc  numpy-2.3.0-cp312-cp312-macosx_10_13_x86_64.whl\n5b656fbed339bcac1af6de73b15e5dba  numpy-2.3.0-cp312-cp312-macosx_11_0_arm64.whl\n5b86d6d0cab79d0cd381bb2e912e7e23  numpy-2.3.0-cp312-cp312-macosx_14_0_arm64.whl\nea83ef5cd00d5e42bb745eee1ee0ad3f  numpy-2.3.0-cp312-cp312-macosx_14_0_x86_64.whl\n15a5f57cb51d3d957c1b387c4bc54830  numpy-2.3.0-cp312-cp312-manylinux_2_28_aarch64.whl\nb5fa92d1093dab4c3ca0622c29c4a241  numpy-2.3.0-cp312-cp312-manylinux_2_28_x86_64.whl\n666cad26086ee212047e5ea0e8906480  numpy-2.3.0-cp312-cp312-musllinux_1_2_aarch64.whl\n6263705622ca89ccadc6f458effde281  numpy-2.3.0-cp312-cp312-musllinux_1_2_x86_64.whl\nbf1bf83eca701ff70351c2d7b308e181  numpy-2.3.0-cp312-cp312-win32.whl\n0707b427c1102bb904994289e1555c3d  numpy-2.3.0-cp312-cp312-win_amd64.whl\n097bd498f8333d383db61105044906dc  numpy-2.3.0-cp312-cp312-win_arm64.whl\n54eb5fa0444ff5dd078bb1aa30d9533f  numpy-2.3.0-cp313-cp313-macosx_10_13_x86_64.whl\n004b4c3650562bd851e31fb925863acb  numpy-2.3.0-cp313-cp313-macosx_11_0_arm64.whl\ncd4e31304e51cc5dacd355730be25e4e  numpy-2.3.0-cp313-cp313-macosx_14_0_arm64.whl\n0ed70aa071f35060ee68d6ab407159e5  numpy-2.3.0-cp313-cp313-macosx_14_0_x86_64.whl\na89b304bbb52268b233ab9652fee8142  numpy-2.3.0-cp313-cp313-manylinux_2_28_aarch64.whl\n4b55cf791be482e8d8e5aaba0c10b6f2  numpy-2.3.0-cp313-cp313-manylinux_2_28_x86_64.whl\nd3a1b81da2f2cba4743d1ee5385cb4d6  numpy-2.3.0-cp313-cp313-musllinux_1_2_aarch64.whl\nfcaacdedcd8cfec7a6cb430fba7a5553  numpy-2.3.0-cp313-cp313-musllinux_1_2_x86_64.whl\n7d0deec2ad395fda48b80be59612db22  numpy-2.3.0-cp313-cp313-win32.whl\n7386a22b0ef219ba043f6e085933dbd6  numpy-2.3.0-cp313-cp313-win_amd64.whl\nf4559038276d0e2bfb19601484d4cdff  numpy-2.3.0-cp313-cp313-win_arm64.whl\n6c586985db2e888876aa96ceaf99ee66  numpy-2.3.0-cp313-cp313t-macosx_10_13_x86_64.whl\n9726de30cce2b36940225a7ea086c824  numpy-2.3.0-cp313-cp313t-macosx_11_0_arm64.whl\nea021092cbb7b1e7d0984dc774bb288d  numpy-2.3.0-cp313-cp313t-macosx_14_0_arm64.whl\n6f8261bc789eed1d3f6f7ea9ff3c2a2c  numpy-2.3.0-cp313-cp313t-macosx_14_0_x86_64.whl\nab624ddc1425d44412541aad1f012fd9  numpy-2.3.0-cp313-cp313t-manylinux_2_28_aarch64.whl\naf55bc7a8f46ec8d413eb1fbe2c200e9  numpy-2.3.0-cp313-cp313t-manylinux_2_28_x86_64.whl\n830eecf7c372aa0d7d746ad031ff0ba1  numpy-2.3.0-cp313-cp313t-musllinux_1_2_aarch64.whl\n28870039fde4fec369185e185bf0077e  numpy-2.3.0-cp313-cp313t-musllinux_1_2_x86_64.whl\n4510373c08383787c263a4b5a21a24ef  numpy-2.3.0-cp313-cp313t-win32.whl\nde883c4313f4dc984045a51b8edb4084  numpy-2.3.0-cp313-cp313t-win_amd64.whl\n334f5c275a6aad46e5f46436572d3dc1  numpy-2.3.0-cp313-cp313t-win_arm64.whl\n05b86d4a21a832e20e4ebdc6febf298d  numpy-2.3.0-pp311-pypy311_pp73-macosx_10_15_x86_64.whl\n4589038edf55f085252f194e880d7454  numpy-2.3.0-pp311-pypy311_pp73-macosx_14_0_arm64.whl\n7d8f0554035717dc396de7d77c696377  numpy-2.3.0-pp311-pypy311_pp73-macosx_14_0_x86_64.whl\nc0cb89f0dca94446e6aa472ec6874c22  numpy-2.3.0-pp311-pypy311_pp73-manylinux_2_28_aarch64.whl\n14e43315dea5eddffe888986e47d8584  numpy-2.3.0-pp311-pypy311_pp73-manylinux_2_28_x86_64.whl\ne3688182f8551c3c99b559c1696d41dc  numpy-2.3.0-pp311-pypy311_pp73-win_amd64.whl\n19a5470a37d066bd3e9385918d7760e7  numpy-2.3.0.tar.gz\nSHA256\nc3c9fdde0fa18afa1099d6257eb82890ea4f3102847e692193b54e00312a9ae9  numpy-2.3.0-cp311-cp311-macosx_10_9_x86_64.whl\n46d16f72c2192da7b83984aa5455baee640e33a9f1e61e656f29adf55e406c2b  numpy-2.3.0-cp311-cp311-macosx_11_0_arm64.whl\na0be278be9307c4ab06b788f2a077f05e180aea817b3e41cebbd5aaf7bd85ed3  numpy-2.3.0-cp311-cp311-macosx_14_0_arm64.whl\n99224862d1412d2562248d4710126355d3a8db7672170a39d6909ac47687a8a4  numpy-2.3.0-cp311-cp311-macosx_14_0_x86_64.whl\n2393a914db64b0ead0ab80c962e42d09d5f385802006a6c87835acb1f58adb96  numpy-2.3.0-cp311-cp311-manylinux_2_28_aarch64.whl\n7729c8008d55e80784bd113787ce876ca117185c579c0d626f59b87d433ea779  numpy-2.3.0-cp311-cp311-manylinux_2_28_x86_64.whl\n06d4fb37a8d383b769281714897420c5cc3545c79dc427df57fc9b852ee0bf58  numpy-2.3.0-cp311-cp311-musllinux_1_2_aarch64.whl\nc39ec392b5db5088259c68250e342612db82dc80ce044cf16496cf14cf6bc6f8  numpy-2.3.0-cp311-cp311-musllinux_1_2_x86_64.whl\nee9d3ee70d62827bc91f3ea5eee33153212c41f639918550ac0475e3588da59f  numpy-2.3.0-cp311-cp311-win32.whl\n43c55b6a860b0eb44d42341438b03513cf3879cb3617afb749ad49307e164edd  numpy-2.3.0-cp311-cp311-win_amd64.whl\n2e6a1409eee0cb0316cb64640a49a49ca44deb1a537e6b1121dc7c458a1299a8  numpy-2.3.0-cp311-cp311-win_arm64.whl\n389b85335838155a9076e9ad7f8fdba0827496ec2d2dc32ce69ce7898bde03ba  numpy-2.3.0-cp312-cp312-macosx_10_13_x86_64.whl\n9498f60cd6bb8238d8eaf468a3d5bb031d34cd12556af53510f05fcf581c1b7e  numpy-2.3.0-cp312-cp312-macosx_11_0_arm64.whl\n622a65d40d8eb427d8e722fd410ac3ad4958002f109230bc714fa551044ebae2  numpy-2.3.0-cp312-cp312-macosx_14_0_arm64.whl\nb9446d9d8505aadadb686d51d838f2b6688c9e85636a0c3abaeb55ed54756459  numpy-2.3.0-cp312-cp312-macosx_14_0_x86_64.whl\n50080245365d75137a2bf46151e975de63146ae6d79f7e6bd5c0e85c9931d06a  numpy-2.3.0-cp312-cp312-manylinux_2_28_aarch64.whl\nc24bb4113c66936eeaa0dc1e47c74770453d34f46ee07ae4efd853a2ed1ad10a  numpy-2.3.0-cp312-cp312-manylinux_2_28_x86_64.whl\n4d8d294287fdf685281e671886c6dcdf0291a7c19db3e5cb4178d07ccf6ecc67  numpy-2.3.0-cp312-cp312-musllinux_1_2_aarch64.whl\n6295f81f093b7f5769d1728a6bd8bf7466de2adfa771ede944ce6711382b89dc  numpy-2.3.0-cp312-cp312-musllinux_1_2_x86_64.whl\ne6648078bdd974ef5d15cecc31b0c410e2e24178a6e10bf511e0557eed0f2570  numpy-2.3.0-cp312-cp312-win32.whl\n0898c67a58cdaaf29994bc0e2c65230fd4de0ac40afaf1584ed0b02cd74c6fdd  numpy-2.3.0-cp312-cp312-win_amd64.whl\nbd8df082b6c4695753ad6193018c05aac465d634834dca47a3ae06d4bb22d9ea  numpy-2.3.0-cp312-cp312-win_arm64.whl\n5754ab5595bfa2c2387d241296e0381c21f44a4b90a776c3c1d39eede13a746a  numpy-2.3.0-cp313-cp313-macosx_10_13_x86_64.whl\nd11fa02f77752d8099573d64e5fe33de3229b6632036ec08f7080f46b6649959  numpy-2.3.0-cp313-cp313-macosx_11_0_arm64.whl\naba48d17e87688a765ab1cd557882052f238e2f36545dfa8e29e6a91aef77afe  numpy-2.3.0-cp313-cp313-macosx_14_0_arm64.whl\n4dc58865623023b63b10d52f18abaac3729346a7a46a778381e0e3af4b7f3beb  numpy-2.3.0-cp313-cp313-macosx_14_0_x86_64.whl\ndf470d376f54e052c76517393fa443758fefcdd634645bc9c1f84eafc67087f0  numpy-2.3.0-cp313-cp313-manylinux_2_28_aarch64.whl\n87717eb24d4a8a64683b7a4e91ace04e2f5c7c77872f823f02a94feee186168f  numpy-2.3.0-cp313-cp313-manylinux_2_28_x86_64.whl\nd8fa264d56882b59dcb5ea4d6ab6f31d0c58a57b41aec605848b6eb2ef4a43e8  numpy-2.3.0-cp313-cp313-musllinux_1_2_aarch64.whl\ne651756066a0eaf900916497e20e02fe1ae544187cb0fe88de981671ee7f6270  numpy-2.3.0-cp313-cp313-musllinux_1_2_x86_64.whl\ne43c3cce3b6ae5f94696669ff2a6eafd9a6b9332008bafa4117af70f4b88be6f  numpy-2.3.0-cp313-cp313-win32.whl\n81ae0bf2564cf475f94be4a27ef7bcf8af0c3e28da46770fc904da9abd5279b5  numpy-2.3.0-cp313-cp313-win_amd64.whl\nc8738baa52505fa6e82778580b23f945e3578412554d937093eac9205e845e6e  numpy-2.3.0-cp313-cp313-win_arm64.whl\n39b27d8b38942a647f048b675f134dd5a567f95bfff481f9109ec308515c51d8  numpy-2.3.0-cp313-cp313t-macosx_10_13_x86_64.whl\n0eba4a1ea88f9a6f30f56fdafdeb8da3774349eacddab9581a21234b8535d3d3  numpy-2.3.0-cp313-cp313t-macosx_11_0_arm64.whl\nb0f1f11d0a1da54927436505a5a7670b154eac27f5672afc389661013dfe3d4f  numpy-2.3.0-cp313-cp313t-macosx_14_0_arm64.whl\n690d0a5b60a47e1f9dcec7b77750a4854c0d690e9058b7bef3106e3ae9117808  numpy-2.3.0-cp313-cp313t-macosx_14_0_x86_64.whl\n8b51ead2b258284458e570942137155978583e407babc22e3d0ed7af33ce06f8  numpy-2.3.0-cp313-cp313t-manylinux_2_28_aarch64.whl\naaf81c7b82c73bd9b45e79cfb9476cb9c29e937494bfe9092c26aece812818ad  numpy-2.3.0-cp313-cp313t-manylinux_2_28_x86_64.whl\nf420033a20b4f6a2a11f585f93c843ac40686a7c3fa514060a97d9de93e5e72b  numpy-2.3.0-cp313-cp313t-musllinux_1_2_aarch64.whl\nd344ca32ab482bcf8735d8f95091ad081f97120546f3d250240868430ce52555  numpy-2.3.0-cp313-cp313t-musllinux_1_2_x86_64.whl\n48a2e8eaf76364c32a1feaa60d6925eaf32ed7a040183b807e02674305beef61  numpy-2.3.0-cp313-cp313t-win32.whl\nba17f93a94e503551f154de210e4d50c5e3ee20f7e7a1b5f6ce3f22d419b93bb  numpy-2.3.0-cp313-cp313t-win_amd64.whl\nf14e016d9409680959691c109be98c436c6249eaf7f118b424679793607b5944  numpy-2.3.0-cp313-cp313t-win_arm64.whl\n80b46117c7359de8167cc00a2c7d823bdd505e8c7727ae0871025a86d668283b  numpy-2.3.0-pp311-pypy311_pp73-macosx_10_15_x86_64.whl\n5814a0f43e70c061f47abd5857d120179609ddc32a613138cbb6c4e9e2dbdda5  numpy-2.3.0-pp311-pypy311_pp73-macosx_14_0_arm64.whl\nef6c1e88fd6b81ac6d215ed71dc8cd027e54d4bf1d2682d362449097156267a2  numpy-2.3.0-pp311-pypy311_pp73-macosx_14_0_x86_64.whl\n33a5a12a45bb82d9997e2c0b12adae97507ad7c347546190a18ff14c28bbca12  numpy-2.3.0-pp311-pypy311_pp73-manylinux_2_28_aarch64.whl\n54dfc8681c1906d239e95ab1508d0a533c4a9505e52ee2d71a5472b04437ef97  numpy-2.3.0-pp311-pypy311_pp73-manylinux_2_28_x86_64.whl\ne017a8a251ff4d18d71f139e28bdc7c31edba7a507f72b1414ed902cbe48c74d  numpy-2.3.0-pp311-pypy311_pp73-win_amd64.whl\n581f87f9e9e9db2cba2141400e160e9dd644ee248788d6f90636eeb8fd9260a6  numpy-2.3.0.tar.gz",
    "crawl_status": "success"
  },
  {
    "library_name": "NumPy",
    "url": "https://github.com/numpy/numpy/releases/tag/v2.0.0",
    "version": "v2.0.0",
    "title": "Release v2.0.0 路 numpy/numpy 路 GitHub",
    "release_date": "2024-06-16T14:06:53Z",
    "content": "NumPy 2.0.0 Release Notes\nNumPy 2.0.0 is the first major release since 2006. It is the result of\n11 months of development since the last feature release and is the work\nof 212 contributors spread over 1078 pull requests. It contains a large\nnumber of exciting new features as well as changes to both the Python\nand C APIs.\nThis major release includes breaking changes that could not happen in a\nregular minor (feature) release - including an ABI break, changes to\ntype promotion rules, and API changes which may not have been emitting\ndeprecation warnings in 1.26.x. Key documents related to how to adapt to\nchanges in NumPy 2.0, in addition to these release notes, include:\nThe\nnumpy-2-migration-guide\nThe Numpy 2.0-specific advice in\nfor downstream package authors\nHighlights\nHighlights of this release include:\nNew features:\nA new variable-length string dtype,\nnumpy.dtypes.StringDType\nand a new\nnumpy.strings\nnamespace with performant ufuncs for string operations,\nSupport for\nfloat32\nand\nlongdouble\nin all\nnumpy.fft\nfunctions,\nSupport for the array API standard in the main\nnumpy\nnamespace.\nPerformance improvements:\nSorting functions\nsort\n,\nargsort\n,\npartition\n,\nargpartition\nhave been\naccelerated through the use of the Intel x86-simd-sort and\nGoogle Highway libraries, and may see large (hardware-specific)\nspeedups,\nmacOS Accelerate support and binary wheels for macOS >=14, with\nsignificant performance improvements for linear algebra\noperations on macOS, and wheels that are about 3 times smaller,\nnumpy.char\nfixed-length string operations have\nbeen accelerated by implementing ufuncs that also support\nnumpy.dtypes.StringDType\nin addition to the\nfixed-length string dtypes,\nA new tracing and introspection API,\nnumpy.lib.introspect.opt_func_info\n, to determine\nwhich hardware-specific kernels are available and will be\ndispatched to.\nnumpy.save\nnow uses pickle protocol version 4 for saving\narrays with object dtype, which allows for pickle objects larger\nthan 4GB and improves saving speed by about 5% for large arrays.\nPython API improvements:\nA clear split between public and private API, with a new module\nstructure and each public function now available in a single place.\nMany removals of non-recommended functions and aliases. This\nshould make it easier to learn and use NumPy. The number of\nobjects in the main namespace decreased by ~10% and in\nnumpy.lib\nby ~80%.\nCanonical dtype names and a new\nnumpy.isdtype` introspection\nfunction,\nC API improvements:\nA new public C API for creating custom dtypes,\nMany outdated functions and macros removed, and private\ninternals hidden to ease future extensibility,\nNew, easier to use, initialization functions:\nPyArray_ImportNumPyAPI\nand\nPyUFunc_ImportUFuncAPI\n.\nImproved behavior:\nImprovements to type promotion behavior was changed by adopting NEP 50.\nThis fixes many user surprises about promotions which previously often\ndepended on data values of input arrays rather than only their dtypes.\nPlease see the NEP and the numpy-2-migration-guide for details as this\nchange can lead to changes in output dtypes and lower precision results\nfor mixed-dtype operations.\nThe default integer type on Windows is now\nint64\nrather than\nint32\n, matching the behavior on other platforms,\nThe maximum number of array dimensions is changed from 32 to 64\nDocumentation:\nThe reference guide navigation was significantly improved, and\nthere is now documentation on NumPy's\nmodule structure,\nThe building from source documentation was completely rewritten,\nFurthermore there are many changes to NumPy internals, including\ncontinuing to migrate code from C to C++, that will make it easier to\nimprove and maintain NumPy in the future.\nThe \"no free lunch\" theorem dictates that there is a price to pay for\nall these API and behavior improvements and better future extensibility.\nThis price is:\nBackwards compatibility. There are a significant number of breaking\nchanges to both the Python and C APIs. In the majority of cases,\nthere are clear error messages that will inform the user how to\nadapt their code. However, there are also changes in behavior for\nwhich it was not possible to give such an error message - these\ncases are all covered in the Deprecation and Compatibility sections\nbelow, and in the numpy-2-migration-guide.\nNote that there is a\nruff\nmode to auto-fix many things in Python\ncode.\nBreaking changes to the NumPy ABI. As a result, binaries of packages\nthat use the NumPy C API and were built against a NumPy 1.xx release\nwill not work with NumPy 2.0. On import, such packages will see an\nImportError\nwith a message about binary incompatibility.\nIt is possible to build binaries against NumPy 2.0 that will work at\nruntime with both NumPy 2.0 and 1.x. See numpy-2-abi-handling for more\ndetails.\nAll downstream packages that depend on the NumPy ABI are advised\nto do a new release built against NumPy 2.0 and verify that that\nrelease works with both 2.0 and 1.26 - ideally in the period between\n2.0.0rc1 (which will be ABI-stable) and the final 2.0.0 release to\navoid problems for their users.\nThe Python versions supported by this release are 3.9-3.12.\nNumPy 2.0 Python API removals\nnp.geterrobj\n,\nnp.seterrobj\nand the related ufunc keyword\nargument\nextobj=\nhave been removed. The preferred replacement for\nall of these is using the context manager\nwith np.errstate():\n.\n(\ngh-23922\n)\nnp.cast\nhas been removed. The literal replacement for\nnp.cast[dtype](arg)\nis\nnp.asarray(arg, dtype=dtype)\n.\nnp.source\nhas been removed. The preferred replacement is\ninspect.getsource\n.\nnp.lookfor\nhas been removed.\n(\ngh-24144\n)\nnumpy.who\nhas been removed. As an alternative for the removed\nfunctionality, one can use a variable explorer that is available in\nIDEs such as Spyder or Jupyter Notebook.\n(\ngh-24321\n)\nWarnings and exceptions present in\nnumpy.exceptions\n,\ne.g,\nnumpy.exceptions.ComplexWarning\n,\nnumpy.exceptions.VisibleDeprecationWarning\n, are no\nlonger exposed in the main namespace.\nMultiple niche enums, expired members and functions have been\nremoved from the main namespace, such as:\nERR_*\n,\nSHIFT_*\n,\nnp.fastCopyAndTranspose\n,\nnp.kernel_version\n,\nnp.numarray\n,\nnp.oldnumeric\nand\nnp.set_numeric_ops\n.\n(\ngh-24316\n)\nReplaced\nfrom ... import *\nin the\nnumpy/__init__.py\nwith\nexplicit imports. As a result, these main namespace members got\nremoved:\nnp.FLOATING_POINT_SUPPORT\n,\nnp.FPE_*\n,\nnp.NINF\n,\nnp.PINF\n,\nnp.NZERO\n,\nnp.PZERO\n,\nnp.CLIP\n,\nnp.WRAP\n,\nnp.WRAP\n,\nnp.RAISE\n,\nnp.BUFSIZE\n,\nnp.UFUNC_BUFSIZE_DEFAULT\n,\nnp.UFUNC_PYVALS_NAME\n,\nnp.ALLOW_THREADS\n,\nnp.MAXDIMS\n,\nnp.MAY_SHARE_EXACT\n,\nnp.MAY_SHARE_BOUNDS\n,\nadd_newdoc\n,\nnp.add_docstring\nand\nnp.add_newdoc_ufunc\n.\n(\ngh-24357\n)\nAlias\nnp.float_\nhas been removed. Use\nnp.float64\ninstead.\nAlias\nnp.complex_\nhas been removed. Use\nnp.complex128\ninstead.\nAlias\nnp.longfloat\nhas been removed. Use\nnp.longdouble\ninstead.\nAlias\nnp.singlecomplex\nhas been removed. Use\nnp.complex64\ninstead.\nAlias\nnp.cfloat\nhas been removed. Use\nnp.complex128\ninstead.\nAlias\nnp.longcomplex\nhas been removed. Use\nnp.clongdouble\ninstead.\nAlias\nnp.clongfloat\nhas been removed. Use\nnp.clongdouble\ninstead.\nAlias\nnp.string_\nhas been removed. Use\nnp.bytes_\ninstead.\nAlias\nnp.unicode_\nhas been removed. Use\nnp.str_\ninstead.\nAlias\nnp.Inf\nhas been removed. Use\nnp.inf\ninstead.\nAlias\nnp.Infinity\nhas been removed. Use\nnp.inf\ninstead.\nAlias\nnp.NaN\nhas been removed. Use\nnp.nan\ninstead.\nAlias\nnp.infty\nhas been removed. Use\nnp.inf\ninstead.\nAlias\nnp.mat\nhas been removed. Use\nnp.asmatrix\ninstead.\nnp.issubclass_\nhas been removed. Use the\nissubclass\nbuiltin\ninstead.\nnp.asfarray\nhas been removed. Use\nnp.asarray\nwith a proper dtype\ninstead.\nnp.set_string_function\nhas been removed. Use\nnp.set_printoptions\ninstead with a formatter for custom printing of NumPy objects.\nnp.tracemalloc_domain\nis now only available from\nnp.lib\n.\nnp.recfromcsv\nand\nrecfromtxt\nare now only available from\nnp.lib.npyio\n.\nnp.issctype\n,\nnp.maximum_sctype\n,\nnp.obj2sctype\n,\nnp.sctype2char\n,\nnp.sctypes\n,\nnp.issubsctype\nwere all removed\nfrom the main namespace without replacement, as they where niche\nmembers.\nDeprecated\nnp.deprecate\nand\nnp.deprecate_with_doc\nhas been\nremoved from the main namespace. Use\nDeprecationWarning\ninstead.\nDeprecated\nnp.safe_eval\nhas been removed from the main namespace.\nUse\nast.literal_eval\ninstead.\n(\ngh-24376\n)\nnp.find_common_type\nhas been removed. Use\nnumpy.promote_types\nor\nnumpy.result_type\ninstead. To achieve semantics for the\nscalar_types\nargument, use\nnumpy.result_type\nand pass\n0\n,\n0.0\n, or\n0j\nas a Python scalar instead.\nnp.round_\nhas been removed. Use\nnp.round\ninstead.\nnp.nbytes\nhas been removed. Use\nnp.dtype(<dtype>).itemsize\ninstead.\n(\ngh-24477\n)\nnp.compare_chararrays\nhas been removed from the main namespace.\nUse\nnp.char.compare_chararrays\ninstead.\nThe\ncharrarray\nin the main namespace has been deprecated. It can\nbe imported without a deprecation warning from\nnp.char.chararray\nfor now, but we are planning to fully deprecate and remove\nchararray\nin the future.\nnp.format_parser\nhas been removed from the main namespace. Use\nnp.rec.format_parser\ninstead.\n(\ngh-24587\n)\nSupport for seven data type string aliases has been removed from\nnp.dtype\n:\nint0\n,\nuint0\n,\nvoid0\n,\nobject0\n,\nstr0\n,\nbytes0\nand\nbool8\n.\n(\ngh-24807\n)\nThe experimental\nnumpy.array_api\nsubmodule has been removed. Use\nthe main\nnumpy\nnamespace for regular usage instead, or the\nseparate\narray-api-strict\npackage for the compliance testing use\ncase for which\nnumpy.array_api\nwas mostly used.\n(\ngh-25911\n)\n__array_prepare__\nis removed\nUFuncs called\n__array_prepare__\nbefore running computations for normal\nufunc calls (not generalized ufuncs, reductions, etc.). The function was\nalso called instead of\n__array_wrap__\non the results of some linear\nalgebra functions.\nIt is now removed. If you use it, migrate to\n__array_ufunc__\nor rely\non\n__array_wrap__\nwhich is called with a context in all cases,\nalthough only after the result array is filled. In those code paths,\n__array_wrap__\nwill now be passed a base class, rather than a subclass\narray.\n(\ngh-25105\n)\nDeprecations\nnp.compat\nhas been deprecated, as Python 2 is no longer supported.\nnumpy.int8\nand similar classes will no longer support conversion\nof out of bounds python integers to integer arrays. For example,\nconversion of 255 to int8 will not return -1.\nnumpy.iinfo(dtype)\ncan be used to check the machine limits for data types. For example,\nnp.iinfo(np.uint16)\nreturns min = 0 and max = 65535.\nnp.array(value).astype(dtype)\nwill give the desired result.\nnp.safe_eval\nhas been deprecated.\nast.literal_eval\nshould be\nused instead.\n(\ngh-23830\n)\nnp.recfromcsv\n,\nnp.recfromtxt\n,\nnp.disp\n,\nnp.get_array_wrap\n,\nnp.maximum_sctype\n,\nnp.deprecate\nand\nnp.deprecate_with_doc\nhave\nbeen deprecated.\n(\ngh-24154\n)\nnp.trapz\nhas been deprecated. Use\nnp.trapezoid\nor a\nscipy.integrate\nfunction instead.\nnp.in1d\nhas been deprecated. Use\nnp.isin\ninstead.\nAlias\nnp.row_stack\nhas been deprecated. Use\nnp.vstack\ndirectly.\n(\ngh-24445\n)\n__array_wrap__\nis now passed\narr, context, return_scalar\nand\nsupport for implementations not accepting all three are deprecated.\nIts signature should be\n__array_wrap__(self, arr, context=None, return_scalar=False)\n(\ngh-25409\n)\nArrays of 2-dimensional vectors for\nnp.cross\nhave been deprecated.\nUse arrays of 3-dimensional vectors instead.\n(\ngh-24818\n)\nnp.dtype(\"a\")\nalias for\nnp.dtype(np.bytes_)\nwas deprecated. Use\nnp.dtype(\"S\")\nalias instead.\n(\ngh-24854\n)\nUse of keyword arguments\nx\nand\ny\nwith functions\nassert_array_equal\nand\nassert_array_almost_equal\nhas been\ndeprecated. Pass the first two arguments as positional arguments\ninstead.\n(\ngh-24978\n)\nnumpy.fft\ndeprecations for n-D transforms with None values in arguments\nUsing\nfftn\n,\nifftn\n,\nrfftn\n,\nirfftn\n,\nfft2\n,\nifft2\n,\nrfft2\nor\nirfft2\nwith the\ns\nparameter set to a value that is not\nNone\nand\nthe\naxes\nparameter set to\nNone\nhas been deprecated, in line with the\narray API standard. To retain current behaviour, pass a sequence [0,\n..., k-1] to\naxes\nfor an array of dimension k.\nFurthermore, passing an array to\ns\nwhich contains\nNone\nvalues is\ndeprecated as the parameter is documented to accept a sequence of\nintegers in both the NumPy docs and the array API specification. To use\nthe default behaviour of the corresponding 1-D transform, pass the value\nmatching the default for its\nn\nparameter. To use the default behaviour\nfor every axis, the\ns\nargument can be omitted.\n(\ngh-25495\n)\nnp.linalg.lstsq\nnow defaults to a new\nrcond\nvalue\nnumpy.linalg.lstsq\nnow uses the new rcond value of the\nmachine precision times\nmax(M, N)\n. Previously, the machine precision\nwas used but a FutureWarning was given to notify that this change will\nhappen eventually. That old behavior can still be achieved by passing\nrcond=-1\n.\n(\ngh-25721\n)\nExpired deprecations\nThe\nnp.core.umath_tests\nsubmodule has been removed from the public\nAPI. (Deprecated in NumPy 1.15)\n(\ngh-23809\n)\nThe\nPyDataMem_SetEventHook\ndeprecation has expired and it is\nremoved. Use\ntracemalloc\nand the\nnp.lib.tracemalloc_domain\ndomain. (Deprecated in NumPy 1.23)\n(\ngh-23921\n)\nThe deprecation of\nset_numeric_ops\nand the C functions\nPyArray_SetNumericOps\nand\nPyArray_GetNumericOps\nhas been expired\nand the functions removed. (Deprecated in NumPy 1.16)\n(\ngh-23998\n)\nThe\nfasttake\n,\nfastclip\n, and\nfastputmask\nArrFuncs\ndeprecation\nis now finalized.\nThe deprecated function\nfastCopyAndTranspose\nand its C counterpart\nare now removed.\nThe deprecation of\nPyArray_ScalarFromObject\nis now finalized.\n(\ngh-24312\n)\nnp.msort\nhas been removed. For a replacement,\nnp.sort(a, axis=0)\nshould be used instead.\n(\ngh-24494\n)\nnp.dtype((\"f8\", 1)\nwill now return a shape 1 subarray dtype rather\nthan a non-subarray one.\n(\ngh-25761\n)\nAssigning to the\n.data\nattribute of an ndarray is disallowed and\nwill raise.\nnp.binary_repr(a, width)\nwill raise if width is too small.\nUsing\nNPY_CHAR\nin\nPyArray_DescrFromType()\nwill raise, use\nNPY_STRING\nNPY_UNICODE\n, or\nNPY_VSTRING\ninstead.\n(\ngh-25794\n)\nCompatibility notes\nloadtxt\nand\ngenfromtxt\ndefault encoding changed\nloadtxt\nand\ngenfromtxt\nnow both default to\nencoding=None\nwhich may\nmainly modify how\nconverters\nwork. These will now be passed\nstr\nrather than\nbytes\n. Pass the encoding explicitly to always get the new\nor old behavior. For\ngenfromtxt\nthe change also means that returned\nvalues will now be unicode strings rather than bytes.\n(\ngh-25158\n)\nf2py\ncompatibility notes\nf2py\nwill no longer accept ambiguous\n-m\nand\n.pyf\nCLI\ncombinations. When more than one\n.pyf\nfile is passed, an error is\nraised. When both\n-m\nand a\n.pyf\nis passed, a warning is emitted\nand the\n-m\nprovided name is ignored.\n(\ngh-25181\n)\nThe\nf2py.compile()\nhelper has been removed because it leaked\nmemory, has been marked as experimental for several years now, and\nwas implemented as a thin\nsubprocess.run\nwrapper. It was also one\nof the test bottlenecks. See\ngh-25122\nfor the full\nrationale. It also used several\nnp.distutils\nfeatures which are\ntoo fragile to be ported to work with\nmeson\n.\nUsers are urged to replace calls to\nf2py.compile\nwith calls to\nsubprocess.run(\"python\", \"-m\", \"numpy.f2py\",...\ninstead, and to\nuse environment variables to interact with\nmeson\n.\nNative\nfiles\nare also an\noption.\n(\ngh-25193\n)\nMinor changes in behavior of sorting functions\nDue to algorithmic changes and use of SIMD code, sorting functions with\nmethods that aren't stable may return slightly different results in\n2.0.0 compared to 1.26.x. This includes the default method of\nnumpy.argsort\nand\nnumpy.argpartition\n.\nRemoved ambiguity when broadcasting in\nnp.solve\nThe broadcasting rules for\nnp.solve(a, b)\nwere ambiguous when\nb\nhad\n1 fewer dimensions than\na\n. This has been resolved in a\nbackward-incompatible way and is now compliant with the Array API. The\nold behaviour can be reconstructed by using\nnp.solve(a, b[..., None])[..., 0]\n.\n(\ngh-25914\n)\nModified representation for\nPolynomial\nThe representation method for\nnumpy.polynomial.polynomial.Polynomial\nwas updated to\ninclude the domain in the representation. The plain text and latex\nrepresentations are now consistent. For example the output of\nstr(np.polynomial.Polynomial([1, 1], domain=[.1, .2]))\nused to be\n1.0 + 1.0 x\n, but now is\n1.0 + 1.0 (-3.0000000000000004 + 20.0 x)\n.\n(\ngh-21760\n)\nC API changes\nThe\nPyArray_CGT\n,\nPyArray_CLT\n,\nPyArray_CGE\n,\nPyArray_CLE\n,\nPyArray_CEQ\n,\nPyArray_CNE\nmacros have been removed.\nPyArray_MIN\nand\nPyArray_MAX\nhave been moved from\nndarraytypes.h\nto\nnpy_math.h\n.\n(\ngh-24258\n)\nA C API for working with\nnumpy.dtypes.StringDType\narrays has been exposed. This includes functions for acquiring and\nreleasing mutexes which lock access to the string data, as well as\npacking and unpacking UTF-8 bytestreams from array entries.\nNPY_NTYPES\nhas been renamed to\nNPY_NTYPES_LEGACY\nas it does not\ninclude new NumPy built-in DTypes. In particular the new string\nDType will likely not work correctly with code that handles legacy\nDTypes.\n(\ngh-25347\n)\nThe C-API now only exports the static inline function versions of\nthe array accessors (previously this depended on using \"deprecated\nAPI\"). While we discourage it, the struct fields can still be used\ndirectly.\n(\ngh-25789\n)\nNumPy now defines\nPyArray_Pack\nto set an individual memory address.\nUnlike\nPyArray_SETITEM\nthis function is equivalent to setting an\nindividual array item and does not require a NumPy array input.\n(\ngh-25954\n)\nThe\n->f\nslot has been removed from\nPyArray_Descr\n. If you use this slot,\nreplace accessing it with\nPyDataType_GetArrFuncs\n(see its documentation\nand the\nnumpy-2-migration-guide\n). In some cases using other functions\nlike\nPyArray_GETITEM\nmay be an alternatives.\nPyArray_GETITEM\nand\nPyArray_SETITEM\nnow require the import of\nthe NumPy API table to be used and are no longer defined in\nndarraytypes.h\n.\n(\ngh-25812\n)\nDue to runtime dependencies, the definition for functionality\naccessing the dtype flags was moved from\nnumpy/ndarraytypes.h\nand\nis only available after including\nnumpy/ndarrayobject.h\nas it\nrequires\nimport_array()\n. This includes\nPyDataType_FLAGCHK\n,\nPyDataType_REFCHK\nand\nNPY_BEGIN_THREADS_DESCR\n.\nThe dtype flags on\nPyArray_Descr\nmust now be accessed through the\nPyDataType_FLAGS\ninline function to be compatible with both 1.x\nand 2.x. This function is defined in\nnpy_2_compat.h\nto allow\nbackporting. Most or all users should use\nPyDataType_FLAGCHK\nwhich\nis available on 1.x and does not require backporting. Cython users\nshould use Cython 3. Otherwise access will go through Python unless\nthey use\nPyDataType_FLAGCHK\ninstead.\n(\ngh-25816\n)\nDatetime functionality exposed in the C API and Cython bindings\nThe functions\nNpyDatetime_ConvertDatetime64ToDatetimeStruct\n,\nNpyDatetime_ConvertDatetimeStructToDatetime64\n,\nNpyDatetime_ConvertPyDateTimeToDatetimeStruct\n,\nNpyDatetime_GetDatetimeISO8601StrLen\n,\nNpyDatetime_MakeISO8601Datetime\n, and\nNpyDatetime_ParseISO8601Datetime\nhave been added to the C API to\nfacilitate converting between strings, Python datetimes, and NumPy\ndatetimes in external libraries.\n(\ngh-21199\n)\nConst correctness for the generalized ufunc C API\nThe NumPy C API's functions for constructing generalized ufuncs\n(\nPyUFunc_FromFuncAndData\n,\nPyUFunc_FromFuncAndDataAndSignature\n,\nPyUFunc_FromFuncAndDataAndSignatureAndIdentity\n) take\ntypes\nand\ndata\narguments that are not modified by NumPy's internals. Like the\nname\nand\ndoc\narguments, third-party Python extension modules are\nlikely to supply these arguments from static constants. The\ntypes\nand\ndata\narguments are now const-correct: they are declared as\nconst char *types\nand\nvoid *const *data\n, respectively. C code should\nnot be affected, but C++ code may be.\n(\ngh-23847\n)\nLarger\nNPY_MAXDIMS\nand\nNPY_MAXARGS\n,\nNPY_RAVEL_AXIS\nintroduced\nNPY_MAXDIMS\nis now 64, you may want to review its use. This is usually\nused in a stack allocation, where the increase should be safe. However,\nwe do encourage generally to remove any use of\nNPY_MAXDIMS\nand\nNPY_MAXARGS\nto eventually allow removing the constraint completely.\nFor the conversion helper and C-API functions mirroring Python ones such as\ntake\n,\nNPY_MAXDIMS\nwas used to mean\naxis=None\n. Such usage must be replaced\nwith\nNPY_RAVEL_AXIS\n. See also\nmigration_maxdims\n.\n(\ngh-25149\n)\nNPY_MAXARGS\nnot constant and\nPyArrayMultiIterObject\nsize change\nSince\nNPY_MAXARGS\nwas increased, it is now a runtime constant and not\ncompile-time constant anymore. We expect almost no users to notice this.\nBut if used for stack allocations it now must be replaced with a custom\nconstant using\nNPY_MAXARGS\nas an additional runtime check.\nThe\nsizeof(PyArrayMultiIterObject)\nno longer includes the full size of\nthe object. We expect nobody to notice this change. It was necessary to\navoid issues with Cython.\n(\ngh-25271\n)\nRequired changes for custom legacy user dtypes\nIn order to improve our DTypes it is unfortunately necessary to break\nthe ABI, which requires some changes for dtypes registered with\nPyArray_RegisterDataType\n. Please see the documentation of\nPyArray_RegisterDataType\nfor how to adapt your code and achieve\ncompatibility with both 1.x and 2.x.\n(\ngh-25792\n)\nNew Public DType API\nThe C implementation of the NEP 42 DType API is now public. While the\nDType API has shipped in NumPy for a few versions, it was only usable in\nsessions with a special environment variable set. It is now possible to\nwrite custom DTypes outside of NumPy using the new DType API and the\nnormal\nimport_array()\nmechanism for importing the numpy C API.\nSee\ndtype-api\nfor more details about the API. As always with a new feature,\nplease report any bugs you run into implementing or using a new DType. It is\nlikely that downstream C code that works with dtypes will need to be updated to\nwork correctly with new DTypes.\n(\ngh-25754\n)\nNew C-API import functions\nWe have now added\nPyArray_ImportNumPyAPI\nand\nPyUFunc_ImportUFuncAPI\nas static inline functions to import the NumPy C-API tables. The new\nfunctions have two advantages over\nimport_array\nand\nimport_ufunc\n:\nThey check whether the import was already performed and are\nlight-weight if not, allowing to add them judiciously (although this\nis not preferable in most cases).\nThe old mechanisms were macros rather than functions which included\na\nreturn\nstatement.\nThe\nPyArray_ImportNumPyAPI()\nfunction is included in\nnpy_2_compat.h\nfor simpler backporting.\n(\ngh-25866\n)\nStructured dtype information access through functions\nThe dtype structures fields\nc_metadata\n,\nnames\n,\nfields\n, and\nsubarray\nmust now be accessed through new functions following the same\nnames, such as\nPyDataType_NAMES\n. Direct access of the fields is not\nvalid as they do not exist for all\nPyArray_Descr\ninstances. The\nmetadata\nfield is kept, but the macro version should also be\npreferred.\n(\ngh-25802\n)\nDescriptor\nelsize\nand\nalignment\naccess\nUnless compiling only with NumPy 2 support, the\nelsize\nand\naligment\nfields must now be accessed via\nPyDataType_ELSIZE\n,\nPyDataType_SET_ELSIZE\n, and\nPyDataType_ALIGNMENT\n. In cases where the\ndescriptor is attached to an array, we advise using\nPyArray_ITEMSIZE\nas it exists on all NumPy versions. Please see\nmigration_c_descr\nfor more information.\n(\ngh-25943\n)\nNumPy 2.0 C API removals\nnpy_interrupt.h\nand the corresponding macros like\nNPY_SIGINT_ON\nhave been removed. We recommend querying\nPyErr_CheckSignals()\nor\nPyOS_InterruptOccurred()\nperiodically (these do currently require\nholding the GIL though).\nThe\nnoprefix.h\nheader has been removed. Replace missing symbols\nwith their prefixed counterparts (usually an added\nNPY_\nor\nnpy_\n).\n(\ngh-23919\n)\nPyUFunc_GetPyVals\n,\nPyUFunc_handlefperr\n, and\nPyUFunc_checkfperr\nhave been removed. If needed, a new backwards compatible function to\nraise floating point errors could be restored. Reason for removal:\nthere are no known users and the functions would have made\nwith np.errstate()\nfixes much more difficult).\n(\ngh-23922\n)\nThe\nnumpy/old_defines.h\nwhich was part of the API deprecated since\nNumPy 1.7 has been removed. This removes macros of the form\nPyArray_CONSTANT\n. The\nreplace_old_macros.sed\nscript may be useful to convert them to the\nNPY_CONSTANT\nversion.\n(\ngh-24011\n)\nThe\nlegacy_inner_loop_selector\nmember of the ufunc struct is\nremoved to simplify improvements to the dispatching system. There\nare no known users overriding or directly accessing this member.\n(\ngh-24271\n)\nNPY_INTPLTR\nhas been removed to avoid confusion (see\nintp\nredefinition).\n(\ngh-24888\n)\nThe advanced indexing\nMapIter\nand related API has been removed.\nThe (truly) public part of it was not well tested and had only one\nknown user (Theano). Making it private will simplify improvements to\nspeed up\nufunc.at\n, make advanced indexing more maintainable, and\nwas important for increasing the maximum number of dimensions of\narrays to 64. Please let us know if this API is important to you so\nwe can find a solution together.\n(\ngh-25138\n)\nThe\nNPY_MAX_ELSIZE\nmacro has been removed, as it only ever\nreflected builtin numeric types and served no internal purpose.\n(\ngh-25149\n)\nPyArray_REFCNT\nand\nNPY_REFCOUNT\nare removed. Use\nPy_REFCNT\ninstead.\n(\ngh-25156\n)\nPyArrayFlags_Type\nand\nPyArray_NewFlagsObject\nas well as\nPyArrayFlagsObject\nare private now. There is no known use-case;\nuse the Python API if needed.\nPyArray_MoveInto\n,\nPyArray_CastTo\n,\nPyArray_CastAnyTo\nare\nremoved use\nPyArray_CopyInto\nand if absolutely needed\nPyArray_CopyAnyInto\n(the latter does a flat copy).\nPyArray_FillObjectArray\nis removed, its only true use was for\nimplementing\nnp.empty\n. Create a new empty array or use\nPyArray_FillWithScalar()\n(decrefs existing objects).\nPyArray_CompareUCS4\nand\nPyArray_CompareString\nare removed. Use\nthe standard C string comparison functions.\nPyArray_ISPYTHON\nis removed as it is misleading, has no known\nuse-cases, and is easy to replace.\nPyArray_FieldNames\nis removed, as it is unclear what it would be\nuseful for. It also has incorrect semantics in some possible\nuse-cases.\nPyArray_TypestrConvert\nis removed, since it seems a misnomer and\nunlikely to be used by anyone. If you know the size or are limited\nto few types, just use it explicitly, otherwise go via Python\nstrings.\n(\ngh-25292\n)\nPyDataType_GetDatetimeMetaData\nis removed, it did not actually do\nanything since at least NumPy 1.7.\n(\ngh-25802\n)\nPyArray_GetCastFunc\nis removed. Note that custom legacy user\ndtypes can still provide a castfunc as their implementation, but any\naccess to them is now removed. The reason for this is that NumPy\nnever used these internally for many years. If you use simple\nnumeric types, please just use C casts directly. In case you require\nan alternative, please let us know so we can create new API such as\nPyArray_CastBuffer()\nwhich could use old or new cast functions\ndepending on the NumPy version.\n(\ngh-25161\n)\nNew Features\nnp.add\nwas extended to work with\nunicode\nand\nbytes\ndtypes.\n(\ngh-24858\n)\nA new\nbitwise_count\nfunction\nThis new function counts the number of 1-bits in a number.\nnumpy.bitwise_count\nworks on all the numpy integer types\nand integer-like objects.\n>\n>>\na\n=\nnp\n.\narray\n([\n2\n**\ni\n-\n1\nfor\ni\nin\nrange\n(\n16\n)])\n>\n>>\nnp\n.\nbitwise_count\n(\na\n)\narray\n([\n0\n,\n1\n,\n2\n,\n3\n,\n4\n,\n5\n,\n6\n,\n7\n,\n8\n,\n9\n,\n10\n,\n11\n,\n12\n,\n13\n,\n14\n,\n15\n],\ndtype\n=\nuint8\n)\n(\ngh-19355\n)\nmacOS Accelerate support, including the ILP64\nSupport for the updated Accelerate BLAS/LAPACK library, including ILP64\n(64-bit integer) support, in macOS 13.3 has been added. This brings\narm64 support, and significant performance improvements of up to 10x for\ncommonly used linear algebra operations. When Accelerate is selected at\nbuild time, or if no explicit BLAS library selection is done, the 13.3+\nversion will automatically be used if available.\n(\ngh-24053\n)\nBinary wheels are also available. On macOS >=14.0, users who install\nNumPy from PyPI will get wheels built against Accelerate rather than\nOpenBLAS.\n(\ngh-25255\n)\nOption to use weights for quantile and percentile functions\nA\nweights\nkeyword is now available for\nnumpy.quantile\n,\nnumpy.percentile\n,\nnumpy.nanquantile\nand\nnumpy.nanpercentile\n. Only\nmethod=\"inverted_cdf\"\nsupports weights.\n(\ngh-24254\n)\nImproved CPU optimization tracking\nA new tracer mechanism is available which enables tracking of the\nenabled targets for each optimized function (i.e., that uses\nhardware-specific SIMD instructions) in the NumPy library. With this\nenhancement, it becomes possible to precisely monitor the enabled CPU\ndispatch targets for the dispatched functions.\nA new function named\nopt_func_info\nhas been added to the new namespace\nnumpy.lib.introspect\n, offering this tracing capability.  This function allows\nyou to retrieve information about the enabled targets based on function names\nand data type signatures.\n(\ngh-24420\n)\nA new Meson backend for\nf2py\nf2py\nin compile mode (i.e.\nf2py -c\n) now accepts the\n--backend meson\noption. This is the default option for Python >=3.12.\nFor older Python versions,\nf2py\nwill still default to\n--backend distutils\n.\nTo support this in realistic use-cases, in compile mode\nf2py\ntakes a\n--dep\nflag one or many times which maps to\ndependency()\ncalls in the\nmeson\nbackend, and does nothing in the\ndistutils\nbackend.\nThere are no changes for users of\nf2py\nonly as a code generator, i.e.\nwithout\n-c\n.\n(\ngh-24532\n)\nbind(c)\nsupport for\nf2py\nBoth functions and subroutines can be annotated with\nbind(c)\n.\nf2py\nwill handle both the correct type mapping, and preserve the unique label\nfor other C interfaces.\nNote:\nbind(c, name = 'routine_name_other_than_fortran_routine')\nis\nnot honored by the\nf2py\nbindings by design, since\nbind(c)\nwith the\nname\nis meant to guarantee only the same name in C and Fortran, not in\nPython and Fortran.\n(\ngh-24555\n)\nA new\nstrict\noption for several testing functions\nThe\nstrict\nkeyword is now available for\nnumpy.testing.assert_allclose\n,\nnumpy.testing.assert_equal\n, and\nnumpy.testing.assert_array_less\n. Setting\nstrict=True\nwill disable the broadcasting behaviour for scalars and ensure\nthat input arrays have the same data type.\n(\ngh-24680\n,\ngh-24770\n,\ngh-24775\n)\nAdd\nnp.core.umath.find\nand\nnp.core.umath.rfind\nUFuncs\nAdd two\nfind\nand\nrfind\nUFuncs that operate on unicode or byte\nstrings and are used in\nnp.char\n. They operate similar to\nstr.find\nand\nstr.rfind\n.\n(\ngh-24868\n)\ndiagonal\nand\ntrace\nfor\nnumpy.linalg\nnumpy.linalg.diagonal\nand\nnumpy.linalg.trace\nhave been added, which are\narray API standard-compatible variants of\nnumpy.diagonal\nand\nnumpy.trace\n.\nThey differ in the default axis selection which define 2-D sub-arrays.\n(\ngh-24887\n)\nNew\nlong\nand\nulong\ndtypes\nnumpy.long\nand\nnumpy.ulong\nhave been added as NumPy integers mapping to\nC's\nlong\nand\nunsigned long\n. Prior to NumPy 1.24,\nnumpy.long\nwas an alias\nto Python's\nint\n.\n(\ngh-24922\n)\nsvdvals\nfor\nnumpy.linalg\nnumpy.linalg.svdvals\nhas been added. It computes singular values for (a stack\nof) matrices. Executing\nnp.svdvals(x)\nis the same as calling\nnp.svd(x, compute_uv=False, hermitian=False)\n. This function is compatible with the array\nAPI standard.\n(\ngh-24940\n)\nA new\nisdtype\nfunction\nnumpy.isdtype\nwas added to provide a canonical way to classify NumPy's\ndtypes in compliance with the array API standard.\n(\ngh-25054\n)\nA new\nastype\nfunction\nnumpy.astype\nwas added to provide an array API standard-compatible\nalternative to the\nnumpy.ndarray.astype\nmethod.\n(\ngh-25079\n)\nArray API compatible functions' aliases\n13 aliases for existing functions were added to improve compatibility\nwith the array API standard:\nTrigonometry:\nacos\n,\nacosh\n,\nasin\n,\nasinh\n,\natan\n,\natanh\n,\natan2\n.\nBitwise:\nbitwise_left_shift\n,\nbitwise_invert\n,\nbitwise_right_shift\n.\nMisc:\nconcat\n,\npermute_dims\n,\npow\n.\nIn\nnumpy.linalg\n:\ntensordot\n,\nmatmul\n.\n(\ngh-25086\n)\nNew\nunique_*\nfunctions\nThe\nnumpy.unique_all\n,\nnumpy.unique_counts\n,\nnumpy.unique_inverse\n, and\nnumpy.unique_values\nfunctions have been added. They provide functionality of\nnumpy.unique\nwith different sets of flags. They are array API\nstandard-compatible, and because the number of arrays they return does not\ndepend on the values of input arguments, they are easier to target for JIT\ncompilation.\n(\ngh-25088\n)\nMatrix transpose support for ndarrays\nNumPy now offers support for calculating the matrix transpose of an\narray (or stack of arrays). The matrix transpose is equivalent to\nswapping the last two axes of an array. Both\nnp.ndarray\nand\nnp.ma.MaskedArray\nnow expose a\n.mT\nattribute, and there is a\nmatching new\nnumpy.matrix_transpose\nfunction.\n(\ngh-23762\n)\nArray API compatible functions for\nnumpy.linalg\nSix new functions and two aliases were added to improve compatibility\nwith the Array API standard for `numpy.linalg`:\nnumpy.linalg.matrix_norm\n- Computes the matrix norm of\na matrix (or a stack of matrices).\nnumpy.linalg.vector_norm\n- Computes the vector norm of\na vector (or batch of vectors).\nnumpy.vecdot\n- Computes the (vector) dot product of\ntwo arrays.\nnumpy.linalg.vecdot\n- An alias for\nnumpy.vecdot\n.\nnumpy.linalg.matrix_transpose\n- An alias for\nnumpy.matrix_transpose\n.\n(\ngh-25155\n)\nnumpy.linalg.outer\nhas been added. It computes the\nouter product of two vectors. It differs from\nnumpy.outer\nby accepting one-dimensional arrays only.\nThis function is compatible with the array API standard.\n(\ngh-25101\n)\nnumpy.linalg.cross\nhas been added. It computes the\ncross product of two (arrays of) 3-dimensional vectors. It differs\nfrom\nnumpy.cross\nby accepting three-dimensional\nvectors only. This function is compatible with the array API\nstandard.\n(\ngh-25145\n)\nA\ncorrection\nargument for\nvar\nand\nstd\nA\ncorrection\nargument was added to\nnumpy.var\nand\nnumpy.std\n, which is an\narray API standard compatible alternative to\nddof\n. As both arguments serve a\nsimilar purpose, only one of them can be provided at the same time.\n(\ngh-25169\n)\nndarray.device\nand\nndarray.to_device\nAn\nndarray.device\nattribute and\nndarray.to_device\nmethod were added\nto\nnumpy.ndarray\nfor array API standard compatibility.\nAdditionally,\ndevice\nkeyword-only arguments were added to:\nnumpy.asarray\n,\nnumpy.arange\n,\nnumpy.empty\n,\nnumpy.empty_like\n,\nnumpy.eye\n,\nnumpy.full\n,\nnumpy.full_like\n,\nnumpy.linspace\n,\nnumpy.ones\n,\nnumpy.ones_like\n,\nnumpy.zeros\n, and\nnumpy.zeros_like\n.\nFor all these new arguments, only\ndevice=\"cpu\"\nis supported.\n(\ngh-25233\n)\nStringDType has been added to NumPy\nWe have added a new variable-width UTF-8 encoded string data type, implementing\na \"NumPy array of Python strings\", including support for a user-provided\nmissing data sentinel. It is intended as a drop-in replacement for arrays of\nPython strings and missing data sentinels using the object dtype. See\nNEP 55\nand the documentation\nof stringdtype for more details.\n(\ngh-25347\n)\nNew keywords for\ncholesky\nand\npinv\nThe\nupper\nand\nrtol\nkeywords were added to\nnumpy.linalg.cholesky\nand\nnumpy.linalg.pinv\n,\nrespectively, to improve array API standard compatibility.\nFor\nnumpy.linalg.pinv\n, if neither\nrcond\nnor\nrtol\nis\nspecified, the\nrcond\n's default is used. We plan to deprecate and\nremove\nrcond\nin the future.\n(\ngh-25388\n)\nNew keywords for\nsort\n,\nargsort\nand\nlinalg.matrix_rank\nNew keyword parameters were added to improve array API standard\ncompatibility:\nrtol\nwas added to\nnumpy.linalg.matrix_rank\n.\nstable\nwas added to\nnumpy.sort\nand\nnumpy.argsort\n.\n(\ngh-25437\n)\nNew\nnumpy.strings\nnamespace for string ufuncs\nNumPy now implements some string operations as ufuncs. The old\nnp.char\nnamespace is still available, and where possible the string manipulation\nfunctions in that namespace have been updated to use the new ufuncs,\nsubstantially improving their performance.\nWhere possible, we suggest updating code to use functions in\nnp.strings\ninstead of\nnp.char\n. In the future we may deprecate\nnp.char\nin favor of\nnp.strings\n.\n(\ngh-25463\n)\nnumpy.fft\nsupport for different precisions and in-place calculations\nThe various FFT routines in\nnumpy.fft\nnow do their\ncalculations natively in float, double, or long double precision,\ndepending on the input precision, instead of always calculating in\ndouble precision. Hence, the calculation will now be less precise for\nsingle and more precise for long double precision. The data type of the\noutput array will now be adjusted accordingly.\nFurthermore, all FFT routines have gained an\nout\nargument that can be\nused for in-place calculations.\n(\ngh-25536\n)\nconfigtool and pkg-config support\nA new\nnumpy-config\nCLI script is available that can be queried for the\nNumPy version and for compile flags needed to use the NumPy C API. This\nwill allow build systems to better support the use of NumPy as a\ndependency. Also, a\nnumpy.pc\npkg-config file is now included with\nNumpy. In order to find its location for use with\nPKG_CONFIG_PATH\n, use\nnumpy-config --pkgconfigdir\n.\n(\ngh-25730\n)\nArray API standard support in the main namespace\nThe main\nnumpy\nnamespace now supports the array API standard. See\narray-api-standard-compatibility\nfor\ndetails.\n(\ngh-25911\n)\nImprovements\nStrings are now supported by\nany\n,\nall\n, and the logical ufuncs.\n(\ngh-25651\n)\nInteger sequences as the shape argument for\nmemmap\nnumpy.memmap\ncan now be created with any integer sequence\nas the\nshape\nargument, such as a list or numpy array of integers.\nPreviously, only the types of tuple and int could be used without\nraising an error.\n(\ngh-23729\n)\nerrstate\nis now faster and context safe\nThe\nnumpy.errstate\ncontext manager/decorator is now faster\nand safer. Previously, it was not context safe and had (rare) issues\nwith thread-safety.\n(\ngh-23936\n)\nAArch64 quicksort speed improved by using Highway's VQSort\nThe first introduction of the Google Highway library, using VQSort on\nAArch64. Execution time is improved by up to 16x in some cases, see the\nPR for benchmark results. Extensions to other platforms will be done in\nthe future.\n(\ngh-24018\n)\nComplex types - underlying C type changes\nThe underlying C types for all of NumPy's complex types have been\nchanged to use C99 complex types.\nWhile this change does not affect the memory layout of complex\ntypes, it changes the API to be used to directly retrieve or write\nthe real or complex part of the complex number, since direct field\naccess (as in\nc.real\nor\nc.imag\n) is no longer an option. You can\nnow use utilities provided in\nnumpy/npy_math.h\nto do these\noperations, like this:\nnpy_cdouble\nc\n;\nnpy_csetreal\n(\n&\nc\n,\n1.0\n);\nnpy_csetimag\n(\n&\nc\n,\n0.0\n);\nprintf\n(\n\"%d + %di\\n\"\n,\nnpy_creal\n(\nc\n),\nnpy_cimag\n(\nc\n));\nTo ease cross-version compatibility, equivalent macros and a\ncompatibility layer have been added which can be used by downstream\npackages to continue to support both NumPy 1.x and 2.x. See\ncomplex-numbers\nfor more info.\nnumpy/npy_common.h\nnow includes\ncomplex.h\n, which means that\ncomplex\nis now a reserved keyword.\n(\ngh-24085\n)\niso_c_binding\nsupport and improved common blocks for\nf2py\nPreviously, users would have to define their own custom\nf2cmap\nfile to\nuse type mappings defined by the Fortran2003\niso_c_binding\nintrinsic\nmodule. These type maps are now natively supported by\nf2py\n(\ngh-24555\n)\nf2py\nnow handles\ncommon\nblocks which have\nkind\nspecifications from\nmodules. This further expands the usability of intrinsics like\niso_fortran_env\nand\niso_c_binding\n.\n(\ngh-25186\n)\nCall\nstr\nautomatically on third argument to functions like\nassert_equal\nThe third argument to functions like\nnumpy.testing.assert_equal\nnow has\nstr\ncalled on it\nautomatically. This way it mimics the built-in\nassert\nstatement, where\nassert_equal(a, b, obj)\nworks like\nassert a == b, obj\n.\n(\ngh-24877\n)\nSupport for array-like\natol\n/\nrtol\nin\nisclose\n,\nallclose\nThe keywords\natol\nand\nrtol\nin\nnumpy.isclose\nand\nnumpy.allclose\nnow accept both scalars and arrays. An\narray, if given, must broadcast to the shapes of the first two array\narguments.\n(\ngh-24878\n)\nConsistent failure messages in test functions\nPreviously, some\nnumpy.testing\nassertions printed messages\nthat referred to the actual and desired results as\nx\nand\ny\n. Now,\nthese values are consistently referred to as\nACTUAL\nand\nDESIRED\n.\n(\ngh-24931\n)\nn-D FFT transforms allow\ns[i] == -1\nThe\nnumpy.fft.fftn\n,\nnumpy.fft.ifftn\n,\nnumpy.fft.rfftn\n,\nnumpy.fft.irfftn\n,\nnumpy.fft.fft2\n,\nnumpy.fft.ifft2\n,\nnumpy.fft.rfft2\nand\nnumpy.fft.irfft2\nfunctions now use the whole input array along the axis\ni\nif\ns[i] == -1\n, in line with the array API standard.\n(\ngh-25495\n)\nGuard PyArrayScalar_VAL and PyUnicodeScalarObject for the limited API\nPyUnicodeScalarObject\nholds a\nPyUnicodeObject\n, which is not\navailable when using\nPy_LIMITED_API\n. Add guards to hide it and\nconsequently also make the\nPyArrayScalar_VAL\nmacro hidden.\n(\ngh-25531\n)\nChanges\nnp.gradient()\nnow returns a tuple rather than a list making the\nreturn value immutable.\n(\ngh-23861\n)\nBeing fully context and thread-safe,\nnp.errstate\ncan only be\nentered once now.\nnp.setbufsize\nis now tied to\nnp.errstate()\n: leaving an\nnp.errstate\ncontext will also reset the\nbufsize\n.\n(\ngh-23936\n)\nA new public\nnp.lib.array_utils\nsubmodule has been introduced and\nit currently contains three functions:\nbyte_bounds\n(moved from\nnp.lib.utils\n),\nnormalize_axis_tuple\nand\nnormalize_axis_index\n.\n(\ngh-24540\n)\nIntroduce\nnumpy.bool\nas the new canonical name for\nNumPy's boolean dtype, and make\nnumpy.bool\\_\nan alias\nto it. Note that until NumPy 1.24,\nnp.bool\nwas an alias to\nPython's builtin\nbool\n. The new name helps with array API standard\ncompatibility and is a more intuitive name.\n(\ngh-25080\n)\nThe\ndtype.flags\nvalue was previously stored as a signed integer.\nThis means that the aligned dtype struct flag lead to negative flags\nbeing set (-128 rather than 128). This flag is now stored unsigned\n(positive). Code which checks flags manually may need to adapt. This\nmay include code compiled with Cython 0.29.x.\n(\ngh-25816\n)\nRepresentation of NumPy scalars changed\nAs per NEP 51, the scalar representation has been updated to include the type\ninformation to avoid confusion with Python scalars.\nScalars are now printed as\nnp.float64(3.0)\nrather than just\n3.0\n.\nThis may disrupt workflows that store representations of numbers (e.g.,\nto files) making it harder to read them. They should be stored as\nexplicit strings, for example by using\nstr()\nor\nf\"{scalar!s}\"\n. For\nthe time being, affected users can use\nnp.set_printoptions(legacy=\"1.25\")\nto get the old behavior (with\npossibly a few exceptions). Documentation of downstream projects may\nrequire larger updates, if code snippets are tested. We are working on\ntooling for\ndoctest-plus\nto facilitate updates.\n(\ngh-22449\n)\nTruthiness of NumPy strings changed\nNumPy strings previously were inconsistent about how they defined if the\nstring is\nTrue\nor\nFalse\nand the definition did not match the one\nused by Python. Strings are now considered\nTrue\nwhen they are\nnon-empty and\nFalse\nwhen they are empty. This changes the following\ndistinct cases:\nCasts from string to boolean were previously roughly equivalent to\nstring_array.astype(np.int64).astype(bool)\n, meaning that only\nvalid integers could be cast. Now a string of\n\"0\"\nwill be\nconsidered\nTrue\nsince it is not empty. If you need the old\nbehavior, you may use the above step (casting to integer first) or\nstring_array == \"0\"\n(if the input is only ever\n0\nor\n1\n). To get\nthe new result on old NumPy versions use\nstring_array != \"\"\n.\nnp.nonzero(string_array)\npreviously ignored whitespace so that a\nstring only containing whitespace was considered\nFalse\n. Whitespace\nis now considered\nTrue\n.\nThis change does not affect\nnp.loadtxt\n,\nnp.fromstring\n, or\nnp.genfromtxt\n. The first two still use the integer definition, while\ngenfromtxt\ncontinues to match for\n\"true\"\n(ignoring case). However,\nif\nnp.bool_\nis used as a converter the result will change.\nThe change does affect\nnp.fromregex\nas it uses direct assignments.\n(\ngh-23871\n)\nA\nmean\nkeyword was added to var and std function\nOften when the standard deviation is needed the mean is also needed. The\nsame holds for the variance and the mean. Until now the mean is then\ncalculated twice, the change introduced here for the\nnumpy.var\nand\nnumpy.std\nfunctions allows for passing in a precalculated mean as an keyword\nargument. See the docstrings for details and an example illustrating the\nspeed-up.\n(\ngh-24126\n)\nRemove datetime64 deprecation warning when constructing with timezone\nThe\nnumpy.datetime64\nmethod now issues a UserWarning rather than a\nDeprecationWarning whenever a timezone is included in the datetime string that\nis provided.\n(\ngh-24193\n)\nDefault integer dtype is now 64-bit on 64-bit Windows\nThe default NumPy integer is now 64-bit on all 64-bit systems as the\nhistoric 32-bit default on Windows was a common source of issues. Most\nusers should not notice this. The main issues may occur with code\ninterfacing with libraries written in a compiled language like C. For\nmore information see\nmigration_windows_int64\n.\n(\ngh-24224\n)\nRenamed\nnumpy.core\nto\nnumpy._core\nAccessing\nnumpy.core\nnow emits a DeprecationWarning. In practice we\nhave found that most downstream usage of\nnumpy.core\nwas to access\nfunctionality that is available in the main\nnumpy\nnamespace. If for\nsome reason you are using functionality in\nnumpy.core\nthat is not\navailable in the main\nnumpy\nnamespace, this means you are likely using\nprivate NumPy internals. You can still access these internals via\nnumpy._core\nwithout a deprecation warning but we do not provide any\nbackward compatibility guarantees for NumPy internals. Please open an\nissue if you think a mistake was made and something needs to be made\npublic.\n(\ngh-24634\n)\nThe \"relaxed strides\" debug build option, which was previously enabled\nthrough the\nNPY_RELAXED_STRIDES_DEBUG\nenvironment variable or the\n-Drelaxed-strides-debug\nconfig-settings flag has been removed.\n(\ngh-24717\n)\nRedefinition of\nnp.intp\n/\nnp.uintp\n(almost never a change)\nDue to the actual use of these types almost always matching the use of\nsize_t\n/\nPy_ssize_t\nthis is now the definition in C. Previously, it\nmatched\nintptr_t\nand\nuintptr_t\nwhich would often have been subtly\nincorrect. This has no effect on the vast majority of machines since the\nsize of these types only differ on extremely niche platforms.\nHowever, it means that:\nPointers may not necessarily fit into an\nintp\ntyped array anymore.\nThe\np\nand\nP\ncharacter codes can still be used, however.\nCreating\nintptr_t\nor\nuintptr_t\ntyped arrays in C remains\npossible in a cross-platform way via\nPyArray_DescrFromType('p')\n.\nThe new character codes\nnN\nwere introduced.\nIt is now correct to use the Python C-API functions when parsing to\nnpy_intp\ntyped arguments.\n(\ngh-24888\n)\nnumpy.fft.helper\nmade private\nnumpy.fft.helper\nwas renamed to\nnumpy.fft._helper\nto indicate that\nit is a private submodule. All public functions exported by it should be\naccessed from\nnumpy.fft\n.\n(\ngh-24945\n)\nnumpy.linalg.linalg\nmade private\nnumpy.linalg.linalg\nwas renamed to\nnumpy.linalg._linalg\nto indicate\nthat it is a private submodule. All public functions exported by it\nshould be accessed from\nnumpy.linalg\n.\n(\ngh-24946\n)\nOut-of-bound axis not the same as\naxis=None\nIn some cases\naxis=32\nor for concatenate any large value was the same\nas\naxis=None\n. Except for\nconcatenate\nthis was deprecate. Any out of\nbound axis value will now error, make sure to use\naxis=None\n.\n(\ngh-25149\n)\nNew\ncopy\nkeyword meaning for\narray\nand\nasarray\nconstructors\nNow\nnumpy.array\nand\nnumpy.asarray\nsupport\nthree values for\ncopy\nparameter:\nNone\n- A copy will only be made if it is necessary.\nTrue\n- Always make a copy.\nFalse\n- Never make a copy. If a copy is required a\nValueError\nis\nraised.\nThe meaning of\nFalse\nchanged as it now raises an exception if a copy\nis needed.\n(\ngh-25168\n)\nThe\n__array__\nspecial method now takes a\ncopy\nkeyword argument.\nNumPy will pass\ncopy\nto the\n__array__\nspecial method in situations\nwhere it would be set to a non-default value (e.g. in a call to\nnp.asarray(some_object, copy=False)\n). Currently, if an unexpected\nkeyword argument error is raised after this, NumPy will print a warning\nand re-try without the\ncopy\nkeyword argument. Implementations of\nobjects implementing the\n__array__\nprotocol should accept a\ncopy\nkeyword argument with the same meaning as when passed to\nnumpy.array\nor\nnumpy.asarray\n.\n(\ngh-25168\n)\nCleanup of initialization of\nnumpy.dtype\nwith strings with commas\nThe interpretation of strings with commas is changed slightly, in that a\ntrailing comma will now always create a structured dtype. E.g., where\npreviously\nnp.dtype(\"i\")\nand\nnp.dtype(\"i,\")\nwere treated as\nidentical, now\nnp.dtype(\"i,\")\nwill create a structured dtype, with a\nsingle field. This is analogous to\nnp.dtype(\"i,i\")\ncreating a\nstructured dtype with two fields, and makes the behaviour consistent\nwith that expected of tuples.\nAt the same time, the use of single number surrounded by parenthesis to\nindicate a sub-array shape, like in\nnp.dtype(\"(2)i,\")\n, is deprecated.\nInstead; one should use\nnp.dtype(\"(2,)i\")\nor\nnp.dtype(\"2i\")\n.\nEventually, using a number in parentheses will raise an exception, like\nis the case for initializations without a comma, like\nnp.dtype(\"(2)i\")\n.\n(\ngh-25434\n)\nChange in how complex sign is calculated\nFollowing the array API standard, the complex sign is now calculated as\nz / |z|\n(instead of the rather less logical case where the sign of the\nreal part was taken, unless the real part was zero, in which case the\nsign of the imaginary part was returned). Like for real numbers, zero is\nreturned if\nz==0\n.\n(\ngh-25441\n)\nReturn types of functions that returned a list of arrays\nFunctions that returned a list of ndarrays have been changed to return a\ntuple of ndarrays instead. Returning tuples consistently whenever a\nsequence of arrays is returned makes it easier for JIT compilers like\nNumba, as well as for static type checkers in some cases, to support\nthese functions. Changed functions are:\nnumpy.atleast_1d\n,\nnumpy.atleast_2d\n,\nnumpy.atleast_3d\n,\nnumpy.broadcast_arrays\n,\nnumpy.meshgrid\n,\nnumpy.ogrid\n,\nnumpy.histogramdd\n.\nnp.unique\nreturn_inverse\nshape for multi-dimensional inputs\nWhen multi-dimensional inputs are passed to\nnp.unique\nwith\nreturn_inverse=True\n, the\nunique_inverse\noutput is now shaped such\nthat the input can be reconstructed directly using\nnp.take(unique, unique_inverse)\nwhen\naxis=None\n, and\nnp.take_along_axis(unique, unique_inverse, axis=axis)\notherwise.\n(\ngh-25553\n,\ngh-25570\n)\nany\nand\nall\nreturn booleans for object arrays\nThe\nany\nand\nall\nfunctions and methods now return booleans also for\nobject arrays. Previously, they did a reduction which behaved like the\nPython\nor\nand\nand\noperators which evaluates to one of the arguments.\nYou can use\nnp.logical_or.reduce\nand\nnp.logical_and.reduce\nto\nachieve the previous behavior.\n(\ngh-25712\n)\nnp.can_cast\ncannot be called on Python int, float, or complex\nnp.can_cast\ncannot be called with Python int, float, or complex\ninstances anymore. This is because NEP 50 means that the result of\ncan_cast\nmust not depend on the value passed in. Unfortunately, for\nPython scalars whether a cast should be considered\n\"same_kind\"\nor\n\"safe\"\nmay depend on the context and value so that this is currently\nnot implemented. In some cases, this means you may have to add a\nspecific path for:\nif type(obj) in (int, float, complex): ...\n.\n(\ngh-26393\n)\nChecksums\nMD5\nfcda027f9735771088e607161c913094  numpy-2.0.0-cp310-cp310-macosx_10_9_x86_64.whl\n1c381a5af3e6b945c6937ab3c6e2de09  numpy-2.0.0-cp310-cp310-macosx_11_0_arm64.whl\n6258de3c0599f8e3674e11898f2dd71c  numpy-2.0.0-cp310-cp310-macosx_14_0_arm64.whl\naa4d28b404566dc9f5c34a31c6cd7b23  numpy-2.0.0-cp310-cp310-macosx_14_0_x86_64.whl\n6b83ba81bdc750ef9924e3dc6f7c93be  numpy-2.0.0-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n3d129fe67d99e0aad451742abb963ffa  numpy-2.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n24a060577965bd2a573ed87cbd207b4c  numpy-2.0.0-cp310-cp310-musllinux_1_1_x86_64.whl\nb00832f558669aacf855c4f5e9cf31d1  numpy-2.0.0-cp310-cp310-musllinux_1_2_aarch64.whl\ncfe7420d294c583b90cfe07b730136dc  numpy-2.0.0-cp310-cp310-win32.whl\ncff9da6b9fe5ad3b05dd3526dff00ac2  numpy-2.0.0-cp310-cp310-win_amd64.whl\nf390e03564df5ea37a97ac10cf0cbb00  numpy-2.0.0-cp311-cp311-macosx_10_9_x86_64.whl\na006b081decba286a321de67a1abe246  numpy-2.0.0-cp311-cp311-macosx_11_0_arm64.whl\n6aea3e8589e33349b8170524af5a2e44  numpy-2.0.0-cp311-cp311-macosx_14_0_arm64.whl\neea8146c5dc2a306333bfea1f01f7a37  numpy-2.0.0-cp311-cp311-macosx_14_0_x86_64.whl\ne96c2af477c970c8ff50ecb5d1cf754f  numpy-2.0.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\nd065256e02a1d410d0db2577bb8fd9a4  numpy-2.0.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n98c570b79459342c219590c5af38d527  numpy-2.0.0-cp311-cp311-musllinux_1_1_x86_64.whl\ndc435751cb926f53a9fc457f35146527  numpy-2.0.0-cp311-cp311-musllinux_1_2_aarch64.whl\naaa4b435d29022ceacb4e3dcbd43d11a  numpy-2.0.0-cp311-cp311-win32.whl\n9ff8be4f581d86b2f181fe905491b19b  numpy-2.0.0-cp311-cp311-win_amd64.whl\n1c9519c5e6a0c5a99715e51ac3b7c932  numpy-2.0.0-cp312-cp312-macosx_10_9_x86_64.whl\nb0f26e8728523d716f5165953b35244f  numpy-2.0.0-cp312-cp312-macosx_11_0_arm64.whl\n029703d0ff0e96c603c91f611926ef17  numpy-2.0.0-cp312-cp312-macosx_14_0_arm64.whl\n2231ecbb380c70ddf462e9671d06612c  numpy-2.0.0-cp312-cp312-macosx_14_0_x86_64.whl\n4153b50c1a3647ca58f1084fcaf3e4c6  numpy-2.0.0-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n82cba3915234f8018fd754ffc45e95b0  numpy-2.0.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n249047dd7255a5fcf5c45614ba211e10  numpy-2.0.0-cp312-cp312-musllinux_1_1_x86_64.whl\nf7581ebfe0c9d4ae4f3b6ea09c19eea7  numpy-2.0.0-cp312-cp312-musllinux_1_2_aarch64.whl\n8a0dbcd919d1d959f1846a00ebb05162  numpy-2.0.0-cp312-cp312-win32.whl\n22aabdfd85ed34f02a7cdacff399c5d9  numpy-2.0.0-cp312-cp312-win_amd64.whl\n1fce84122c393e05b69e2ec53ecd1137  numpy-2.0.0-cp39-cp39-macosx_10_9_x86_64.whl\n81e4c1152274d85813bf14814ad4d359  numpy-2.0.0-cp39-cp39-macosx_11_0_arm64.whl\n5eab1a2b427b590d2bc9d8ecd330fc21  numpy-2.0.0-cp39-cp39-macosx_14_0_arm64.whl\nab967929693baf2d2bfb00c53413ad2b  numpy-2.0.0-cp39-cp39-macosx_14_0_x86_64.whl\n85d2971cd78800663766f46ba312d356  numpy-2.0.0-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n7e831fcf9cff5317429786a3bd123671  numpy-2.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n03a6426ca86ad53567e3ef61bc766013  numpy-2.0.0-cp39-cp39-musllinux_1_1_x86_64.whl\nb30af2d2b99468538f45e6769f9fee2b  numpy-2.0.0-cp39-cp39-musllinux_1_2_aarch64.whl\ncc9a8db8d131fb5a387e2c1342ab0065  numpy-2.0.0-cp39-cp39-win32.whl\n9843951308fa31c5e36c4c6a0b090308  numpy-2.0.0-cp39-cp39-win_amd64.whl\n5021eb5e225bff3e05a38a565daf8852  numpy-2.0.0-pp39-pypy39_pp73-macosx_10_9_x86_64.whl\n99186fe49ac7931d3e92e8993c2faa92  numpy-2.0.0-pp39-pypy39_pp73-macosx_14_0_x86_64.whl\nc39f0ab6e07d42708550899951b852b8  numpy-2.0.0-pp39-pypy39_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\ncbf151633948e90c93dd988777750961  numpy-2.0.0-pp39-pypy39_pp73-win_amd64.whl\na180aaba9982c6e15da6db62dab5eb4e  numpy-2.0.0.tar.gz\nSHA256\n04494f6ec467ccb5369d1808570ae55f6ed9b5809d7f035059000a37b8d7e86f  numpy-2.0.0-cp310-cp310-macosx_10_9_x86_64.whl\n2635dbd200c2d6faf2ef9a0d04f0ecc6b13b3cad54f7c67c61155138835515d2  numpy-2.0.0-cp310-cp310-macosx_11_0_arm64.whl\n0a43f0974d501842866cc83471bdb0116ba0dffdbaac33ec05e6afed5b615238  numpy-2.0.0-cp310-cp310-macosx_14_0_arm64.whl\n8d83bb187fb647643bd56e1ae43f273c7f4dbcdf94550d7938cfc32566756514  numpy-2.0.0-cp310-cp310-macosx_14_0_x86_64.whl\n79e843d186c8fb1b102bef3e2bc35ef81160ffef3194646a7fdd6a73c6b97196  numpy-2.0.0-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n6d7696c615765091cc5093f76fd1fa069870304beaccfd58b5dcc69e55ef49c1  numpy-2.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\nb4c76e3d4c56f145d41b7b6751255feefae92edbc9a61e1758a98204200f30fc  numpy-2.0.0-cp310-cp310-musllinux_1_1_x86_64.whl\nacd3a644e4807e73b4e1867b769fbf1ce8c5d80e7caaef0d90dcdc640dfc9787  numpy-2.0.0-cp310-cp310-musllinux_1_2_aarch64.whl\ncee6cc0584f71adefe2c908856ccc98702baf95ff80092e4ca46061538a2ba98  numpy-2.0.0-cp310-cp310-win32.whl\ned08d2703b5972ec736451b818c2eb9da80d66c3e84aed1deeb0c345fefe461b  numpy-2.0.0-cp310-cp310-win_amd64.whl\nad0c86f3455fbd0de6c31a3056eb822fc939f81b1618f10ff3406971893b62a5  numpy-2.0.0-cp311-cp311-macosx_10_9_x86_64.whl\ne7f387600d424f91576af20518334df3d97bc76a300a755f9a8d6e4f5cadd289  numpy-2.0.0-cp311-cp311-macosx_11_0_arm64.whl\n34f003cb88b1ba38cb9a9a4a3161c1604973d7f9d5552c38bc2f04f829536609  numpy-2.0.0-cp311-cp311-macosx_14_0_arm64.whl\nb6f6a8f45d0313db07d6d1d37bd0b112f887e1369758a5419c0370ba915b3871  numpy-2.0.0-cp311-cp311-macosx_14_0_x86_64.whl\n5f64641b42b2429f56ee08b4f427a4d2daf916ec59686061de751a55aafa22e4  numpy-2.0.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\na7039a136017eaa92c1848152827e1424701532ca8e8967fe480fe1569dae581  numpy-2.0.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n46e161722e0f619749d1cd892167039015b2c2817296104487cd03ed4a955995  numpy-2.0.0-cp311-cp311-musllinux_1_1_x86_64.whl\n0e50842b2295ba8414c8c1d9d957083d5dfe9e16828b37de883f51fc53c4016f  numpy-2.0.0-cp311-cp311-musllinux_1_2_aarch64.whl\n2ce46fd0b8a0c947ae047d222f7136fc4d55538741373107574271bc00e20e8f  numpy-2.0.0-cp311-cp311-win32.whl\nfbd6acc766814ea6443628f4e6751d0da6593dae29c08c0b2606164db026970c  numpy-2.0.0-cp311-cp311-win_amd64.whl\n354f373279768fa5a584bac997de6a6c9bc535c482592d7a813bb0c09be6c76f  numpy-2.0.0-cp312-cp312-macosx_10_9_x86_64.whl\n4d2f62e55a4cd9c58c1d9a1c9edaedcd857a73cb6fda875bf79093f9d9086f85  numpy-2.0.0-cp312-cp312-macosx_11_0_arm64.whl\n1e72728e7501a450288fc8e1f9ebc73d90cfd4671ebbd631f3e7857c39bd16f2  numpy-2.0.0-cp312-cp312-macosx_14_0_arm64.whl\n84554fc53daa8f6abf8e8a66e076aff6ece62de68523d9f665f32d2fc50fd66e  numpy-2.0.0-cp312-cp312-macosx_14_0_x86_64.whl\nc73aafd1afca80afecb22718f8700b40ac7cab927b8abab3c3e337d70e10e5a2  numpy-2.0.0-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n49d9f7d256fbc804391a7f72d4a617302b1afac1112fac19b6c6cec63fe7fe8a  numpy-2.0.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n0ec84b9ba0654f3b962802edc91424331f423dcf5d5f926676e0150789cb3d95  numpy-2.0.0-cp312-cp312-musllinux_1_1_x86_64.whl\nfeff59f27338135776f6d4e2ec7aeeac5d5f7a08a83e80869121ef8164b74af9  numpy-2.0.0-cp312-cp312-musllinux_1_2_aarch64.whl\nc5a59996dc61835133b56a32ebe4ef3740ea5bc19b3983ac60cc32be5a665d54  numpy-2.0.0-cp312-cp312-win32.whl\na356364941fb0593bb899a1076b92dfa2029f6f5b8ba88a14fd0984aaf76d0df  numpy-2.0.0-cp312-cp312-win_amd64.whl\ne61155fae27570692ad1d327e81c6cf27d535a5d7ef97648a17d922224b216de  numpy-2.0.0-cp39-cp39-macosx_10_9_x86_64.whl\n4554eb96f0fd263041baf16cf0881b3f5dafae7a59b1049acb9540c4d57bc8cb  numpy-2.0.0-cp39-cp39-macosx_11_0_arm64.whl\n903703372d46bce88b6920a0cd86c3ad82dae2dbef157b5fc01b70ea1cfc430f  numpy-2.0.0-cp39-cp39-macosx_14_0_arm64.whl\n3e8e01233d57639b2e30966c63d36fcea099d17c53bf424d77f088b0f4babd86  numpy-2.0.0-cp39-cp39-macosx_14_0_x86_64.whl\n1cde1753efe513705a0c6d28f5884e22bdc30438bf0085c5c486cdaff40cd67a  numpy-2.0.0-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n821eedb7165ead9eebdb569986968b541f9908979c2da8a4967ecac4439bae3d  numpy-2.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n9a1712c015831da583b21c5bfe15e8684137097969c6d22e8316ba66b5baabe4  numpy-2.0.0-cp39-cp39-musllinux_1_1_x86_64.whl\n9c27f0946a3536403efb0e1c28def1ae6730a72cd0d5878db38824855e3afc44  numpy-2.0.0-cp39-cp39-musllinux_1_2_aarch64.whl\n63b92c512d9dbcc37f9d81b123dec99fdb318ba38c8059afc78086fe73820275  numpy-2.0.0-cp39-cp39-win32.whl\n3f6bed7f840d44c08ebdb73b1825282b801799e325bcbdfa6bc5c370e5aecc65  numpy-2.0.0-cp39-cp39-win_amd64.whl\n9416a5c2e92ace094e9f0082c5fd473502c91651fb896bc17690d6fc475128d6  numpy-2.0.0-pp39-pypy39_pp73-macosx_10_9_x86_64.whl\n17067d097ed036636fa79f6a869ac26df7db1ba22039d962422506640314933a  numpy-2.0.0-pp39-pypy39_pp73-macosx_14_0_x86_64.whl\n38ecb5b0582cd125f67a629072fed6f83562d9dd04d7e03256c9829bdec027ad  numpy-2.0.0-pp39-pypy39_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\ncef04d068f5fb0518a77857953193b6bb94809a806bd0a14983a8f12ada060c9  numpy-2.0.0-pp39-pypy39_pp73-win_amd64.whl\ncf5d1c9e6837f8af9f92b6bd3e86d513cdc11f60fd62185cc49ec7d1aba34864  numpy-2.0.0.tar.gz",
    "crawl_status": "success"
  },
  {
    "library_name": "Requests",
    "url": "https://github.com/psf/requests/releases/tag/v2.31.0",
    "version": "v2.31.0",
    "title": "Release v2.31.0 路 psf/requests 路 GitHub",
    "release_date": "2023-05-22T15:26:23Z",
    "content": "2.31.0 (2023-05-22)\nSecurity\nVersions of Requests between v2.3.0 and v2.30.0 are vulnerable to potential\nforwarding of\nProxy-Authorization\nheaders to destination servers when\nfollowing HTTPS redirects.\nWhen proxies are defined with user info (\nhttps://user:pass@proxy:8080\n), Requests\nwill construct a\nProxy-Authorization\nheader that is attached to the request to\nauthenticate with the proxy.\nIn cases where Requests receives a redirect response, it previously reattached\nthe\nProxy-Authorization\nheader incorrectly, resulting in the value being\nsent through the tunneled connection to the destination server. Users who rely on\ndefining their proxy credentials in the URL are\nstrongly\nencouraged to upgrade\nto Requests 2.31.0+ to prevent unintentional leakage and rotate their proxy\ncredentials once the change has been fully deployed.\nUsers who do not use a proxy or do not supply their proxy credentials through\nthe user information portion of their proxy URL are not subject to this\nvulnerability.\nFull details can be read in our\nGithub Security Advisory\nand\nCVE-2023-32681\n.",
    "crawl_status": "success"
  },
  {
    "library_name": "Requests",
    "url": "https://github.com/psf/requests/releases/tag/v2.32.0",
    "version": "v2.32.0",
    "title": "Release v2.32.0 路 psf/requests 路 GitHub",
    "release_date": "2024-05-20T16:19:14Z",
    "content": "2.32.0 (2024-05-20)\n PYCON US 2024 EDITION \nSecurity\nFixed an issue where setting\nverify=False\non the first request from a\nSession will cause subsequent requests to the\nsame origin\nto also ignore\ncert verification, regardless of the value of\nverify\n.\n(\nGHSA-9wx4-h78v-vm56\n)\nImprovements\nverify=True\nnow reuses a global SSLContext which should improve\nrequest time variance between first and subsequent requests. It should\nalso minimize certificate load time on Windows systems when using a Python\nversion built with OpenSSL 3.x. (\n#6667\n)\nRequests now supports optional use of character detection\n(\nchardet\nor\ncharset_normalizer\n) when repackaged or vendored.\nThis enables\npip\nand other projects to minimize their vendoring\nsurface area. The\nResponse.text()\nand\napparent_encoding\nAPIs\nwill default to\nutf-8\nif neither library is present. (\n#6702\n)\nBugfixes\nFixed bug in length detection where emoji length was incorrectly\ncalculated in the request content-length. (\n#6589\n)\nFixed deserialization bug in JSONDecodeError. (\n#6629\n)\nFixed bug where an extra leading\n/\n(path separator) could lead\nurllib3 to unnecessarily reparse the request URI. (\n#6644\n)\nDeprecations\nRequests has officially added support for CPython 3.12 (\n#6503\n)\nRequests has officially added support for PyPy 3.9 and 3.10 (\n#6641\n)\nRequests has officially dropped support for CPython 3.7 (\n#6642\n)\nRequests has officially dropped support for PyPy 3.7 and 3.8 (\n#6641\n)\nDocumentation\nVarious typo fixes and doc improvements.\nPackaging\nRequests has started adopting some modern packaging practices.\nThe source files for the projects (formerly\nrequests\n) is now located\nin\nsrc/requests\nin the Requests sdist. (\n#6506\n)\nStarting in Requests 2.33.0, Requests will migrate to a PEP 517 build system\nusing\nhatchling\n. This should not impact the average user, but extremely old\nversions of packaging utilities may have issues with the new packaging format.\nNew Contributors\n@matthewarmand\nmade their first contribution in\n#6258\n@cpzt\nmade their first contribution in\n#6456\n@ittner\nmade their first contribution in\n#6214\n@ZetaTwo\nmade their first contribution in\n#6465\n@joren485\nmade their first contribution in\n#6475\n@elprimato\nmade their first contribution in\n#6266\n@dependabot\nmade their first contribution in\n#6499\n@Ocupe\nmade their first contribution in\n#6507\n@13steinj\nmade their first contribution in\n#6508\n@jnhyperion\nmade their first contribution in\n#6517\n@swims-hjkl\nmade their first contribution in\n#6552\n@msea1\nmade their first contribution in\n#6574\n@EFord36\nmade their first contribution in\n#6581\n@MestreLion\nmade their first contribution in\n#6600\n@atatuzuner61\nmade their first contribution in\n#6592\n@jaikishpai\nmade their first contribution in\n#6605\n@miketheman\nmade their first contribution in\n#6613\n@Tarty\nmade their first contribution in\n#6629\n@bruceadams\nmade their first contribution in\n#6589\n@amkarn258\nmade their first contribution in\n#6562\n@flysee\nmade their first contribution in\n#6302\n@mbeijen\nmade their first contribution in\n#6680\n@franekmagiera\nmade their first contribution in\n#6700\n@agubelu\nmade their first contribution in\n#6667\nFull Changelog\n:\nhttps://github.com/psf/requests/blob/main/HISTORY.md#2320-2024-05-20",
    "crawl_status": "success"
  },
  {
    "library_name": "Requests",
    "url": "https://github.com/psf/requests/releases/tag/v2.32.5",
    "version": "v2.32.5",
    "title": "Release v2.32.5 路 psf/requests 路 GitHub",
    "release_date": "2025-08-18T20:33:27Z",
    "content": "2.32.5 (2025-08-18)\nBugfixes\nThe SSLContext caching feature originally introduced in 2.32.0 has created\na new class of issues in Requests that have had negative impact across a number\nof use cases. The Requests team has decided to revert this feature as long term\nmaintenance of it is proving to be unsustainable in its current iteration.\nDeprecations\nAdded support for Python 3.14.\nDropped support for Python 3.8 following its end of support.",
    "crawl_status": "success"
  },
  {
    "library_name": "PyTorch",
    "url": "https://github.com/pytorch/pytorch/releases/tag/v2.9.0",
    "version": "v2.9.0",
    "title": "Release 2.9 Release Notes 路 pytorch/pytorch 路 GitHub",
    "release_date": "2025-10-15T17:12:27Z",
    "content": "PyTorch 2.9.0 Release Notes\nHighlights\nBackwards Incompatible Changes\nDeprecations\nNew Features\nImprovements\nBug fixes\nPerformance\nDocumentation\nDevelopers\nSecurity\nHighlights\nUnstable (API-Unstable)\nUpdates to the stable libtorch ABI for third-party C++/CUDA extensions\nSymmetric memory that enables easy programming of multi-GPU kernels\nThe ability to arbitrarily toggle error or resume on graph breaks in torch.compile\nExpanded wheel variant support  to include ROCm,  XPU and CUDA 13\nFlexAttention enablement on Intel GPUs\nFlash decoding optimization based on FlexAttention on X86 CPU\nARM Platform improvements and optimizations\nEnablement of Linux aarch64 binary wheel builds across all supported CUDA versions\nFor more details about these highlighted features, you can look at the\nrelease blogpost\n. Below are the full release notes for this release.\nBackwards Incompatible Changes\nMin supported Python version is now 3.10 (\n#162310\n)\nThe minimum version of Python required for PyTorch 2.9.0 is 3.10. We also have 3.14 and 3.14t available as preview with this release.\nUndefined behavior when an output of a custom operator shares storage with an input\nThis is a reminder that outputs of PyTorch custom operators (that are registered using the\ntorch.library\nor\nTORCH_LIBRARY\nAPIs) are not allowed to return Tensors that share storage with input tensors. The violation of this condition leads to undefined behavior: sometimes the result will be correct, sometimes it will be garbage.\nAfter\n#163227\n, custom operators that violated this condition that previously returned correct results under\ntorch.compile\nmay now return silently incorrect results under\ntorch.compile\n. Because this is changing the behavior of undefined behavior, we do not consider this to be a bug, but we are still documenting it in this section as a \"potentially unexpected behavior change\".\nThis is one of the conditions checked for by\ntorch.library.opcheck\nand is mentioned in\nThe Custom Operators Manual\nMore details\nOutputs of PyTorch custom operators are not allowed to return Tensors that share storage with input tensors\nFor example, the following two custom operators are not valid custom operators:\n@\ntorch\n.\nlibrary\n.\ncustom_op\n(\n\"mylib::foo\"\n,\nmutates_args\n=\n())\ndef\nfoo\n(\nx\n:\ntorch\n.\nTensor\n)\n->\ntorch\n.\nTensor\n:\n# the result of `foo` must not directly be an input to foo.\nreturn\nx\n@\ntorch\n.\nlibrary\n.\ncustom_op\n(\n\"mylib::bar\"\n,\nmutates_args\n=\n())\ndef\nbar\n(\nx\n:\ntorch\n.\nTensor\n)\n->\ntorch\n.\nTensor\n:\n# the result of bar must not be a view of an input of bar\nreturn\nx\n.\nview\n(\n-\n1\n)\nThe easiest workaround is to add an extra\n.clone()\nto the outputs:\n@\ntorch\n.\nlibrary\n.\ncustom_op\n(\n\"mylib::foo\"\n,\nmutates_args\n=\n())\ndef\nfoo\n(\nx\n:\ntorch\n.\nTensor\n)\n->\ntorch\n.\nTensor\n:\nreturn\nx\n.\nclone\n()\n@\ntorch\n.\nlibrary\n.\ncustom_op\n(\n\"mylib::bar\"\n,\nmutates_args\n=\n())\ndef\nbar\n(\nx\n:\ntorch\n.\nTensor\n)\n->\ntorch\n.\nTensor\n:\nreturn\nx\n.\nview\n(\n-\n1\n).\nclone\n()\nA common way to get into this situation is for a user to want to create a custom operator that sometimes mutates the input in-place and sometimes returns a new Tensor, like in the following example.\n@\ntorch\n.\nlibrary\n.\ncustom_op\n(\n\"mylib::baz\"\n,\nmutates_args\n=\n[\n\"x\"\n])\ndef\nbaz\n(\nx\n:\ntorch\n.\nTensor\n)\n->\ntorch\n.\nTensor\n:\nif\ninplace\n:\nx\n.\nsin_\n()\nreturn\nx\nelse\n:\nreturn\nx\n.\nsin\n()\nThis dynamism is not supported and leads to undefined behavior. The workaround is to split the custom operator into two custom operators, one that always mutates the input in-place, and another that always returns a new Tensor.\n@\ntorch\n.\nlibrary\n.\ncustom_op\n(\n\"mylib::baz_outplace\"\n,\nmutates_args\n=\n())\ndef\nbaz_outplace\n(\nx\n:\ntorch\n.\nTensor\n)\n->\ntorch\n.\nTensor\n:\nreturn\nx\n.\nsin\n()\n@\ntorch\n.\nlibrary\n.\ncustom_op\n(\n\"mylib::baz_inplace\"\n,\nmutates_args\n=\n[\n\"x\"\n])\ndef\nbaz_inplace\n(\nx\n:\ntorch\n.\nTensor\n)\n->\ntorch\n.\nTensor\n:\nx\n.\nsin_\n()\ndef\nbaz\n(\nx\n):\nif\ninplace\n:\nbaz_inplace\n(\nx\n)\nreturn\nx\nelse\n:\nreturn\nbaz_outplace\n(\nx\n)\nBuild metal kernels of MacOS-14+ and remove all pre-MacOS-14 specific logic, requires MacOS-14+ going forward (\n#159733\n,\n#159912\n)\nPyTorch MPS is only supported on MacOS-14 or later. If you need to use MPS on MacOS Ventura, please avoid updating to Python-3.9 or above\nUpgrade to DLPack 1.0 (\n#145000\n)\nThis upgrade is doing the same BC-breaking changes as the DLPack release. Objects in\ntorch.utils.dlpack\nhave been updated to reflect these changes, such as\nDLDeviceType\n.\nSee the PR for details on the exact changes and how to update your code.\nRaise appropriate errors in\ntorch.cat\n(\n#158249\n)\ntorch.cat\nnow raises\nValueError\n,\nIndexError\nor\nTypeError\nwhere appropriate instead of the generic\nRuntimeError\n. If you code was catching these errors, you can update to catch the new error type.\nDefault to\ndynamo=True\nfor ONNX exporter (\n#159646\n,\n#162726\n)\nPreviously\ntorch.onnx.export(...)\nused the legacy TorchScript exporter if no arguments were provied. The ONNX exporter now uses the newer\ntorch.export.export\npipeline by default (\ndynamo=True\n). This change improves graph fidelity and future-proofs exports, but may surface graph capture errors that were previously masked or handled differently.\nPreviously in torch 2.8.0:\n# API calls the legacy exporter with dynamo=False\ntorch\n.\nonnx\n.\nexport\n(...)\nNow in torch 2.9.0:\n# To preserve the original behavior\ntorch\n.\nonnx\n.\nexport\n(...,\ndynamo\n=\nFalse\n)\n# Export onnx model through torch.export.export\ntorch\n.\nonnx\n.\nexport\n(...)\nRecommendation: first try the new default; only fall back if you hit blocking issues and report them upstream.\nLong term solution: fix the root cause instead of relying on fallback or TorchScript exporter.\nSwitch off runtime asserts by default in Export in favor of a shape guards function (\n#160111\n,\n#161178\n,\n#161794\n)\nTo enable runtime asserts, use\nexport(..., prefer_deferred_runtime_asserts_over_guards=True)\n. Also kills the\nallow_complex_guards_as_runtime_asserts\nflag, merging it into the former option.\nAdditionally,\nexported_program.module()\nwill generate a call to a\n_guards_fn\nsubmodule that will run additional checks on inputs. Users who do not want this behavior can either remove this call in the graph, or do\nexported_program.module(check_guards=False)\nto avoid the generation.\nSet default opset to 20 in ONNX (\n#158802\n)\nOpset 20 enables newer operator definitions. If your tooling or downstream runtime only supports opset 18, pin it explicitly. For the latest ONNX operators, you can experiment with opset 23.\nPreviously in torch 2.8.0:\n# opset_version=18\ntorch\n.\nonnx\n.\nexport\n(...)\nNow in torch 2.9.0:\n# To preserve the original behavior\ntorch\n.\nonnx\n.\nexport\n(...,\nopset_version\n=\n18\n)\n# New: opset_version=20\ntorch\n.\nonnx\n.\nexport\n(...)\n# Use the latest supported opset: opset_version=23\ntorch\n.\nonnx\n.\nexport\n(...,\nopset_version\n=\n23\n)\nDrop\ndraft_export\nin exporter API (\n#161454\n,\n#162225\n)\nRemove implicit draft tracing from the default exporter path, achieving clearer behaviour and faster failures.\nThe expensive\ntorch.export.draft_export\ndiagnostic path is no longer auto-invoked (which could take hours on large models). You can still opt in for deep diagnostics:\nPreviously in torch 2.8.0:\n#\nIf both torch.export.export(..., strict=False) and\n#\ntorch.export.export(..., strict=True) fail to capture\n#\nthe model graph, torch.export.draft_export(...) will be triggered,\n#\nand uses real tensor to trace/export the model.\n#\n#\nInside export_to_onnx.py:\n#\n... torch.onnx.export(..., dynamo=True)\npython export_to_onnx.py\nNow in torch 2.9.0:\n#\nTo trigger torch.export.draft_export once\n#\ntorch.export.export strict=False/True both\n#\nfail:\nTORCH_ONNX_ENABLE_DRAFT_EXPORT=True python export_to_onnx.py\nRemove\ntorch.onnx.dynamo_export\nand the\nonnxrt\ntorch compile backend (\n#158130\n,\n#158258\n)\ntorch.onnx.dynamo_export\nis removed. Please use\ntorch.onnx.export\ninstead.\nThe experimental ONNX Runtime compile backend (\ntorch.compile(backend=\"onnxrt\")\n) is no longer supported.\nRemove\ntorch.onnx.enable_fake_mode\n(\n#161222\n)\nThe\ndynamo=True\nmode uses\nFakeTensor\ns by default which is memory efficient.\nSome public facing ONNX utility APIs for the TorchScript based exporter are now private (\n#161323\n)\nDeprecated members in\ntorch.onnx.verification\nare removed. Previously private\ntorch.onnx.symbolic_opsets*\nfunctions will no longer be accessible. Consider making a copy of the source code if you need to access any private functions for compatibility with the TorchScript based exporter.\nRemove\ntorch.onnx.symbolic_caffe2\n(\n#157102\n)\nSupport for\ncaffe2\nin the ONNX exporter has ended and is removed.\nRemove\n/d2implyavx512upperregs\nflag that slows build (\n#159431\n)\nRe-introduced AVX512 optimizations for Windows VS2022 builds, may cause issues with specific versions of VS2022, see\n#145702\nAdd\nScalarType\nto shim conversion and\nstable::Tensor.scalar_type\n(\n#160557\n)\nBefore, user extensions could only in abstract pass around obfuscated dtypes appearing as\nint32_ts\n. Now, users can confidently use\ntorch::headeronly::ScalarType\nin their extensions for major scalar types. This PR enables ABI stability by adding a translation layer through the shim, so that even if the\nScalarType\nenum values change in the future, user extensions need not fear.\nThis change adds ScalarType support for user extensions and is only narrowly BC breaking for unpopular dtypes:\nquint*\ns,\nqint*\ns,\nBits*\n,\ndummy_uint*\ns,\ndummy_int*\ns,\nFloat8_e8m0fnu\n, and\nFloat4_e2m1fn_x2\nin the use case where an extension retrieves a Tensor dtype of the above and passes it into\naoti_torch_call_dispatcher\n.\nDeprecations\nDeprecate\npin_memory_device\nparam in\ntorch.utils.data.DataLoader\n(\n#158323\n)\nWe move enabling\npin_memory\nback inside\nBaseDataLoaderIter\n. This is required for\nStatefulDataloader\nwhich leveraged\nBaseDataLoaderIter\ndireclty rather than the\nDataloader\nclass init\nDeprecate\ntorch.export.export_for_training\nAPI in favor of equivalent\ntorch.export.export\nAPI (\n#158203\n)\ntorch.export.export_for_training\nexists because we couldn't migrate internal usages of export to the final IR. Now that we have completed the migration, we deprecated and deleted this API.\nNew Features\nPython Frontend\nAdd utility to get the kernel currently registered on the dispatcher (\n#158393\n)\nExtend\n__torch_function__\nhandler to be triggered by elements within a list (\n#160256\n)\nAdd\ntorch.hash_tensor\nreduction function (\n#154149\n)\nFX\nExtend torch function support to ALL arguments instead of just scalar type (but not inside of list,\n#145089\n)\nAdd\nis_fx_symbolic_tracing\nflag (\n#161385\n)\nDynamo\nExperimental API for ahead-of-time compiling models in fullgraph mode (\n#161383\n)\nAdd a hook for recompilations (\n#157961\n)\nDynamicInts prototype (\n#162194\n)\nIntroduces an API for annotating dynamic integer inputs & attributes for\ntorch.compile\n, by wrapping plain ints with\nDynamicInt()\n.\nDynamicInt objects also work in eager mode, acting as their underlying values when passed as scalar inputs.\na\n=\nDynamicInt\n(\n4\n)\ny\n=\na\n+\n2\n# DynamicInt(6)\nz\n=\ntorch\n.\nones\n(\na\n)\n# torch.ones(4)\nfn\n=\ntorch\n.\ncompile\n(\ntorch\n.\nones\n)\nfn\n(\na\n)\n# compiled fn takes a dynamic integer input\nfn\n(\n2\n)\n# returns torch.ones(2) without recompiling\nOptimizer\nIntroduce Muon optimizer to PyTorch (\n#160213\n)\nProfiler\nAdd GC Events to Python Stack Tracer (\n#161209\n)\nAdd a custom profiler configuration option (\n#151656\n)\nInductor\nAllow user to pass in custom partitioner function (\n#157580\n)\nExport\nAdd support for param mutation under inference mode (\n#159661\n)\nAOTDispatcher\nAdd AOTDispatcher config to set backward autocast behavior (\n#156356\n)\nQuantization\nEnable cpu fp8 qlinear and cpu fp8 qconv (\n#155678\n,\n#157076\n)\nONNX\nRMS Norm support in opset 23 (\n#159377\n)\nC++ Extensions\nBuild out a stable set of ATen ops in\ntorch/csrc/stable/ops.h\n:\namax\n,\nnarrow\n,\nnew_empty\n+\nnew_zeros\ndtype variant,\npad\n, (\n#159328\n,\n#158974\n,\n#159508\n,\n#161597\n,\n#160214\n)\nAdd\ntorch::stable::Tensor()\ndefault constructor,\nis_cpu\n, and\nget_device_index\n(\n#159507\n,\n#160212\n,\n#160143\n)\nAdd beginnings of\ntorch::stable::accelerator\nwith support for DeviceGuard and Stream (\n#159679\n,\n#160453\n)\nStart building out\ntorch/headeronly\n: c10 Macros, STD_TORCH_CHECK, ScalarTypes (like BFloat16 and Half,\n#158035\n,\n#158365\n,\n#157912\n,\n#158377\n,\n#159302\n,\n#159414\n,\n#159412\n,\n#159415\n,\n#159411\n,\n#159911\n)\nRemove cmake cache and reconfigure again if it is invalid (\n#156958\n)\nCut a version of\nTORCH_ERROR_CODE_CHECK\nin\nheaderonly\nfrom AOTI (\n#159604\n)\nRemove\nwheel\nfrom build requirements (\n#158027\n)\nError when\nTORCH_STABLE_ONLY\nis defined in\nTensorBase.h\n(\n#161658\n)\nBuild Frontend\nAdd transpose to\ntorch/csrc/stable\n(\n#158160\n)\nAdd\nzero_()\nand\nempty_like(t)\nto\ntorch/csrc/stable/ops.h\n(\n#158866\n)\nRelease Engineering\nAdd support for CUDA 13.0 in CI/CD builds. Enable CUDA compression mode for binary size reduction for CUDA 13.0 builds (\n#160956\n,\n#161073\n,\n#161257\n,\n#161663\n,\n#161316\n,\n#160201\n,\n#160770\n,\n#161013\n,\n#161916\n,\n#162268\n,\n#162322\n,\n#162383\n,\n#161833\n)\nEnable CUDA 12.6, 12.8 and 13.0 support for Linux ARM64 CD builds (\n#162364\n,\n#160720\n,\n#159481\n)\nAdd support for Python 3.14 in CI/CD builds (\n#156889\n,\n#157559\n,\n#159261\n,\n#159869\n,\n#160593\n,\n#160788\n,\n#161255\n,\n#159725\n)\nEnable NVSHMEM integration (\n#151261\n,\n#153010\n,\n#154538\n,\n#155506\n,\n#156685\n,\n#158938\n,\n#161321\n,\n#160778\n,\n#159907\n,\n#160465\n)\nCUDA\nAdd getter for CUDA graph exec to allow mutation of captured kernel params (\n#161294\n)\nImplement support for\ncudnn_batch_norm_out\nkernel to replace the autogen approach (\n#123020\n)\nCPU\nSupport GQA for flash attention (\n#157893\n)\nMPS\nPartial sparse support for MPS backend (\n#159729\n,\n#160254\n,\n#160223\n,\n#161846\n,\n#162007\n,\n#157238\n)\nAdd\navg_pool3d\n,\nmax_unpool1d/2d/3d\n,\nmax_pool3d\n,\nmax_pool3d\nbwd pass, and\navg_pool3d\nbwd pass for MPS (\n#158877\n,\n#159789\n,\n#156467\n,\n#157498\n,\n#159089\n)\nROCm\nOCP Micro-scaling Format (mx-fp8/mx-fp4) Support (\n#151360\n)\nXPU\nEnable\nFlexAttention\non Intel GPU (\n#143553\n)\nImprovements\nPython Frontend\nSpeed up\ntorch.load\nunder\nFakeTensorMode\nby reducing random reads (\n#157931\n)\nMake\ntorch.utils.benchmark.utils.timer\naccelerator agnostic (\n#157131\n)\nImprove error message for weight-only load errors (\n#159935\n)\ntorch.nn\nAllow\nregister_buffer\nwith\nTensor\n-like objects (\n#159455\n)\nImprove error message for unsupported padding configurations (\n#160866\n)\nValidate target is 0D when input is 1D in\nNLLLoss\n(\n#161412\n)\nOptimizer\nResolve warning in LBFGS when converting a tensor with\nrequires_grad=True\nto a scalar (\n#160389\n)\nResolve\nSequentialLR\ndeprecation warning about invoking\nstep(epoch)\n(\n#149392\n)\nAutograd\nSupport deterministic\ntorch.nn.Upsample\nmode=\"trilinear\"\nbackward (\n#154239\n)\nDistributed\nc10d\nAdd improvements to eager init of\nProcessGroupNCCL\n(\n#156748\n)\nSimplify unique hash management of\nProcessGroupNCCL\n(\n#156790\n)\nSupport per operation timeouts in\nProcessGroupGloo\n(\n#158128\n)\nAllow ping to be retried in\nTCPStore\n(\n#159165\n)\nSupport scalar tensor for functional\nall_gather\n(\n#149913\n)\nExpos\nunsafe_get_ptr\nfor dist.ProcessGroupNCCL.NCCLConfig (\n#161136\n)\nAdd batch option for\nsend/recv_object_list\n(\n#160342\n)\nMake FakeStore optional to be passed into fake backend (\n#162164\n)\nEnable complex datatype support in\nProcessGroupGloo\n(\n#156633\n)\nMove thread-local capture mode guard to include\nwork.isStarted\n(\n#160398\n)\nDistributedDataParallel (DDP)\nSupport ddp zero hook XCCL path (\n#159240\n)\nDTensor\nRelax\ndevice_mesh\nargument constraint in\nlocal_map\n(\n#157049\n)\nSupport complex numbers in DTensor redistribute (\n#157329\n)\nRework partial propagation in point-wise op and support mul (\n#157340\n)\nAllow dynamic shapes for\nDTensor\nslice (\n#157953\n)\nImplement\nhistc\nop (\n#158298\n)\nMade dispatch to sharding prop over decomps (\n#159324\n)\nSupport user-supplied Generator for random ops (\n#159933\n)\nAdd\npropagate_tensor_meta\nfunction that skips cache if\n_are_we_tracing\n(\n#161334\n)\nSupport\nlocal_map\nas a decorator (\n#161353\n)\nDevice Mesh\nEnable the use of user set backend and pg option even for the global mesh (\n#157501\n)\nEnable slicing a submesh with warnings (\n#158899\n)\nAllow controlling PG backend and options via\ninit_device_mesh\n(\n#159371\n)\nFullyShardedDataParallel2 (FSDP2)\nSupport custom\nall_gather\nand\nreduce_scatter\ncomms (\n#155189\n)\nMade it fail\nset_allocate_memory_from_process_group\nif used together with custom comm hooks (\n#157487\n)\nUse\nreduceOpSum\nwhen world size is 1 (\n#157529\n)\nSkipp\nallgather\nwhen world size is 1 (\n#160135\n)\nUse\npost_reduce_stream.record_event()\non hsdp+cpuoffload (\n#160481\n)\nTensor Parallel (TP)\nImprove\nparallelize_module\nAPI to support more cases (\n#157182\n)\nTensorPipe\nUpdate TensorPipe pinned dependency version (\n#159834\n)\nTorchElastic\nEnable NUMA binding integration with elastic agent and\ntorchrun\n(\n#149334\n)\nSupport NUMA Binding for Callable Entrypoints (\n#160163\n,\n#161183\n)\nPipeline Parallelism (PP)\nAdd\neval()\nAPI to schedule (\n#157795\n)\nAllow intermediate nodes in zero bubble to have multiple grads (\n#159084\n)\nSupport\nOVERLAP_F_B\ncomputation type (\n#158978\n)\nInitializ P2P communicators on first step (\n#160210\n)\nAdd\nDualPipeV\nschedule (\n#159591\n)\nLinear Algebra Frontend\nUse rocSOLVER for Cholesky inversion on AMD. (\n#157154\n)\nAdd option for using TF32 as fp32 internal precision for matmul/linear/conv on MKLDNN (\n#157520\n)\nMake einsum produce contiguous outputs in more cases (\n#161755\n)\nProfiler\nAdd more CUDA API for kernel launcher (\n#156016\n)\nAllow Custom Time Unit When Printing Profiler Table (\n#157913\n)\nUpdate CUDA runtime kernel identification logic (\n#157890\n)\nFX\nFix DCE eliminating random operations by improving\nis_impure()\n(\n#151524\n,\n#157981\n)\nSupport converting a float32 tensor to a scalar in FX trace. (\n#158216\n)\nCorrectly copy\nself.module_stack\nin ModuleStackTracer (\n#159956\n)\nAdd tool to track events in graph split (\n#159795\n)\nAdd\nnode_name_match\nto subgraph rewriter (\n#157574\n)\nDynamo\nImprove tracing support for various Python builtin data structures/modules:\nlist\ns (e.g.\n#153969\n)\nset\ns (e.g.\n#153150\n)\ndict\ns (e.g.\n#154794\n)\niter\n(e.g.\n#156371\n)\nitertools\n(e.g.\n#159693\n)\ncollections\n(e.g.\n#159365\n)\ncollections.NamedTuple\n(\n#159367\n)\nfrozen\ndataclasses.dataclass\n(\n#159529\n)\nGraph break error messages link to a website with more information (\n#159011\n)\nAdd option for\nTorchDispatchMode\nto ignore\ntorch.compile\ninternals (\n#161648\n)\nInductor\nAdd Inductor support for MTIA backend (\n#159211\n)\nShare default device context when all graph partitions and cudagraph-unsafe ops are on the same device(\n#162873\n)\nAhead-Of-Time Inductor (AOTI)\nEnable AOTI for CPU on Windows (\n#158915\n)\nRe-enable TMA templates w/ AOTI (\n#157819\n)\nDon't allow int32 indices if\n{non-inf, > int32_max}\nupper bound is provided (\n#159433\n)\nAdd RecordFunction to C shim so that profiling works with AOTI (\n#159842\n)\nAdd AOTI C shim functions for collective ops (\n#154492\n)\nAdd missing ops to set of C-shim ops which can have nullptr returns (\n#158073\n)\nExport\nHandle\nNone\n& ellipsis slicing/select in non-strict (\n#157821\n)\nExtend FP8 types in serialization (\n#158430\n)\nImprove error messages for deserialization (\n#159881\n)\nSupport serialization for\ntriton_kernel_wrapper_functional\nHOP (\n#161314\n)\nSupport serialization for complex constants (\n#161517\n)\nAdd runtime asserts to\nwhile_loop\nHOP subgraphs (\n#158467\n)\nWarn on side-effectful code in strict mode (\n#160060\n)\nSupport for vmap in pre-dispatch export (\n#154650\n)\nSupport vmap and custom autograd function/improve DTensor constructor inefficiency (\n#162240\n)\nAOTDispatcher\nSkip logging in fp8 activation quantization if there are no nodes to be quantized (\n#158129\n)\nAdd\naot_export_joint_with_descriptors\nand\naot_compile_joint_with_descriptors\n(\n#158715\n)\nExtract out\nprepare_aot_module_simplified\nfor use in next PR (\n#158319\n)\nRename modules in AOTAutograd (\n#158449\n)\nTrack descriptors for all inputs/outputs of AOTAutograd traced graph (\n#158624\n)\nImprove graph output alias with subclass error message (\n#159619\n)\nPass fw/bw compilers to\naot_export_joint_with_descriptors\n(\n#159814\n)\nComposability\nMeta implementation for\naten.add.Scalar\n(\n#161332\n)\naten.expand_copy\ndecomp (\n#161688\n)\nFix result dtype cast in decomp for\naten.linalg_vector_norm\n(\n#155111\n)\nAdd dtype checks in meta implementation for several ordering ops (\n#159556\n)\nFix meta function for\naten.complex\n(\n#160894\n)\nImprove unbacked symint (dynamic shape) support for several decompositions (\n#148815\n,\n#156902\n,\n#157008\n,\n#158894\n,\n#159184\n,\n#160683\n,\n#160253\n,\n#162084\n,\n#162099\n,\n#162109\n,\n#160462\n)\nQuantization\nAvoid getting model device once per node for pt2e quantization flow (\n#159901\n)\nFixes bug in implementation of\nHistogramObserver\n(\n#156457\n)\nSupport\nbias=None\nfor\nfbgemm_linear_fp16_weight\nCPU op (\n#158535\n)\nAdd Static Dispatch Kernel for\nwrapped_fbgemm_linear_fp16_weight\nfor Sigmoid (\n#160451\n)\nNested Tensor (NJT)\nAdded initial\nlog_softmax()\nsupport (\n#159662\n)\nForeach\nInvoke\nvector.reserve()\nconsistently for non-inplace foreach operations (\n#161128\n)\nFaster and safer lambda expression capture in\nhas_integral_tensor()\n(\n#161042\n)\nONNX\nSupport symbolic arguments in ONNX exporter (\n#157734\n)\nFix\ntorch.tensor\nwarning in ONNX\nsymbolic_opset10\nexport  (\n#158835\n)\nC++ Frontend\nGeneralized\nAllocatorConfig\nto be device-agnostic via new\nAcceleratorAllocatorConfig\n(\n#149601\n,\n#150312\n)\nAdded\nScalar::isUnsigned()\nmethod (\n#159877\n)\nExposed\nModelRunner\nfrom nativert as public (\n#159989\n)\nImprove error message for\ntorch.binomial\nenforcing float inputs (\n#157658\n)\nBuild Frontend\nFix dev warning in\nDependencies.cmake\n(\n#159702\n)\nFix building system gloo with CUDA/HIP (\n#146637\n)\nBuild\nlibtorch\nwithout NVSHMEM (\n#160910\n)\nImprove BLAS feature detection (\n#143846\n)\nRelease Engineering\nEnable vLLM testing workflow (\n#160583\n,\n#161565\n,\n#162292\n,\n#162000\n,\n#161797\n)\nEnable Windows ARM64 CI testing (\n#148753\n,\n#161504\n)\nEnable PyTorch ROCm CI for MI355X testing. (\n#158889\n)\nCUDA\nMake cublaslt/hipblaslt workspaces persistent (\n#156495\n)\nRemove unnecessary warnings during the ATen compilation process (\n#157703\n)\nSlightly improve error message from\nrepeat_interleave\nkernel (\n#157996\n)\nAdd framework for explanations for common CUDA errors (\n#158395\n)\nUpgrade KernelLauncher\nkernelLaunchCheck\nto print help string (\n#158896\n)\nPrep for cutlass upgrade by ignoring\nWunused-but-set-variable\n(\n#159276\n)\nWorkaround ATen SFINAE under\nlibc++\n(\n#161101\n)\nImplement changes to CCCL (CUB/Thrust/LibCUDACXX) usage in ATen (\n#153373\n)\nAdd maybe unused flag to remove warning (\n#157655\n)\nUse new CCCL API in v2.8 (\n#160554\n)\nImprove cupy device placement when device is provided with explicit index (\n#158529\n)\nCPU (AArch64)\nMade PyTorch compilable with gcc-14 on ARM (\n#157867\n)\nMPS\nAdd\nshifted_chebyshev_polynomial_[tuvw]\n,\nigamma/igammac,grid_sampler_3d, native_dropout\n/\nnative_dropout_backward\n(\n#157488\n,\n#161927\n,\n#160541\n,\n#162108\n)\nExtend atomic operations to all int types (\n#158179\n)\nExtend\nindex_put\nto complex types (\n#160159\n)\nExtend\naddmm\nto integral types (\n#160270\n)\nAdd support for unsigned types (\n#159094\n)\nAdd API to query GPU core count (\n#160414\n)\nAdd\nkthvalue\n(\n#161817\n)\nType-promote tensor-iterator common dtype (\n#160334\n)\nImplement\nlogcumsumexp\nmetal kernel (\n#156858\n)\nEnable\ndlpack\nintegration (\n#158888\n)\nDynamic reductions (\n#159355\n)\nUpdate\navg_pool2d\nto use Metal kernel when\nceil_mode=True\n(\n#161011\n)\nROCm\nAdditional hipify mappings (\n#158056\n,\n#158352\n,\n#161992\n)\nRefactor\ncomposable_kernel\n(CK) backend user interface to improve user experience (\n#152951\n)\nAllow use of\nrocSOLVER\nfor Cholesky inversion. (\n#157154\n)\nAOT Inductor enable gfx950 for max autotune using CK (\n#159195\n)\nAdd flag\ntorch.backends.miopen.immediate\nto toggle MIOpen Immediate Mode instead of relying on\ndeterministic=True\nand\nbenchmark=False\n(\n#158951\n)\nMIOpen convolutions no longer call\nreshape_\nor unexpectedly change memory formats (\n#161687\n)\nXPU\nSupport Intel GPU quantization ops in AOTInductor (\n#156572\n)\nAdd\ndevice_id\nto Intel GPU properties to distinguish iGPUs with identical names (\n#156481\n)\nBug Fixes\nPython Frontend\nAdd option in\ntorch.utils.cpp_extension.load_inline\nto override gencode (\n#156850\n)\nFix\nmax_width\ncomputation in Tensor printing (\n#126859\n)\nImprove\npin_memory\nerror message on CPU-only systems (\n#159994\n)\nMaking batching rule for\nF.embedding\nDTensor-aware (\n#162117\n)\nAutograd\nFix\ntorch.autograd.Function\nmemory leak due to\ntorch.utils.checkpiont\nearly stopping (\n#161171\n)\nFix\ntorch.autograd.graph.GradientEdge\nfor\ntorch.autograd.Function\n(\n#160098\n)\nMatch 0-dim gradients device type regardless of subclass-ness (\n#160165\n)\nDistributed\nc10d\nFix slow init due to repeated dns resolution failure in socket (\n#159596\n)\nFix\nsetGroupName\nand\nsetGroupDesc\nin\ngroup_split\nand\nmerge_remote_group\n(\n#159429\n)\nFix a bug of distributed 'gather' with noncontiguous tensors on the Gloo backend (\n#158903\n)\nFix a bug of distributed 'gather' with noncontiguous tensors on the NCCL backend (\n#159549\n)\nFix data inconsistencies when using\nbatch_isend_irecv\nwith 2D tensor views by making P2P tensors dense (\n#163719\n)\nHandle discontiguous\nallgather\n/\nreducescatter\ninputs (\n#163712\n)\nDevice Mesh\nFix the not incorrectly chained each of the strings as iterables (\n#160709\n)\nDistributedDataParallel (DDP)\nFix incorrect interaction between\nDDPOptimizer\nand donated buffers (\n#160745\n)\nDTensor\nFix DTensor handling of conjugate bit (\n#158030\n)\nFix\nOpSchema\nequality check (\n#161231\n)\nFix\ngrouped_mm\nstrategy for invalid stride cases (\n#158245\n)\nFix\nF.one_hot\nin DTensor (\n#162307\n)\nAlways disabled\nShardingPropagation\ncache if compiling (\n#156868\n)\nFullyShardedDataParallel (FSDP)\nFix the bug in FSDP offload\npin_memory\n(\n#157147\n)\nFix to ensure writeback handles\nNO_SHARD\ncorrectly by flattening tensors before copying (\n#154369\n)\nFullyShardedDataParallel2 (FSDP2)\nFix error message for\nfsdp_pre_all_gather\n(\n#160817\n)\nFix the issue with\nset_reduce_scatter_divide_factor\nerrors and\nMixedPrecisionPolicy\n(\n#155964\n)\nPipeline Parallelism (PP)\nFix eval step under\nno_grad()\n(\n#159293\n)\nFix zero bubble schedules for\neval()\n(\n#159475\n)\nTensorPipe\nFix\nimport torch\nif compiled without\nTensorPipe\n(\n#159461\n)\nTorchElastic\nFix wrong log file name in the docs of\ntorch.distributed.elastic.multiprocessing.start_processes()\n(\n#160396\n)\nLinear Algebra Frontend\nAvoid downcasts for fp16 matmul on the BLAS backend (\n#161999\n)\nProfiler\nFix Linter for Global Annotations flag in Snapshot (\n#157858\n)\nFX\nFix\nsplit_module\nwith symint (\n#160093\n)\nFix\ngetattr_recursive\nwith ModuleList (\n#161204\n)\nSkip const folding with symbolic expression (\n#161437\n)\nFix qualified name for methods of\ntorch.Tensor\n(\n#162224\n)\nDynamo\nFix segfault due to interaction between Dynamo backends and\ntorch.compiler.reset()\n(\n#156527\n)\nFix crash due to bad interaction with recompilations and with blocks in Python 3.11+ (\n#162318\n)\ntorch.nn\nFix silent correctness w/ backpropping grads for\nFlexAttention\n(\n#163677\n)\nFix\nreturn_lse\nwarning message in\nFlexAttention\n(\n#163578\n)\nFix\nFlexAttention\nhead broadcast (\n#163426\n)\nInductor\nFix wrong meta function for\nconstant_pad_nd\n(\n#159878\n)\nFix learnable bias assertion error in Inductor (\n#161170\n)\nFix int64 from\nMutationOutput\nBuffer (\n#162020\n)\nFix Inductor CUDA sort\nNaN\nbehavior (\n#159308\n)\nFix layout for local buf in outer loop fusion (\n#160857\n)\nFix slice scatter\ndtype\nconsistency (\n#160851\n)\nFix 3d tiled online softmax (\n#162341\n)\nFix unsafe collective reorder past wait in Inductor (\n#157489\n)\nFix\nFallbackKernel\nalias function to avoid incorrect aliasing for custom ops (\n#163227\n)\nAhead-Of-Time Inductor (AOTI)\nFix a bug from\nload_constants\n(\n#161887\n)\nFix wrong propagation of fallback_ops_dict in\ngen_aoti_c_shim\n(\n#159904\n)\nFix unbacked symint and memory leak in Inductor memory planning (\n#159839\n)\nFix memory leak in AOTI when calling\naoti_torch_as_strided\n(\n#162118\n)\nExplicitly delete\nwait_tensor\nreturned tensor (\n#159502\n)\nFix memory leak from\nall_reduce\n(\n#159818\n)\nComposability\nMake functionalization ViewMeta serializable with pickle (\n#163769\n)\nExport\nFix bug in constants lifting pass (\n#157719\n)\nFix\nfrom_node\nprovenance in unlift pass (\n#157943\n)\nFix\nNaN\nserialization (\n#155359\n)\nFix deserialization for unbacked symbol ranges (\n#158681\n)\nFix runtime assert handling in deserialization (\n#159060\n)\nFix for FQN handling in unflattener (\n#159418\n)\nFix\nnn_module_stack\nfor\nassert_tensor_metadata\nnodes (\n#159625\n)\nFix usage for\nmove_to_device_pass\n(\n#159992\n,\n#160528\n,\n#162301\n)\nAvoid name overwrites for aliased exported module parameters (\n#160600\n)\nAvoid inling\ndynamo.disables\nin unflattening (\n#161306\n)\nFix deserialization issue for storage offset (\n#162172\n)\nRemove\n.contiguous()\nwhen saving weights to raw bytes to preserve original storage size of tensor (\n#163587\n)\nQuantization\nAvoid\nNaN\nin fp8 output of CPU\nqlinear\nand\nqconv\nops (\n#160957\n)\nFix segmentation fault when\nchoose_qparams_optimized\n(\n#161966\n)\nForeach\nchunk_size\nshould always be\nint64_t\nfor Foreach functors (\n#156872\n)\nONNX\nMake onnx export SDPA match ATen behavior (\n#159973\n)\nFix\nrotary_embedding_23\nimplementation (\n#162865\n)\nFix export behavior when model has\nNone\nas output (\n#160200\n)\nFix lower opset version support in\ndynamo=True\n(\n#161056\n)\nFix\nindex_put_\nusage (\n#161263\n)\nC++ Extensions\nFix CPP extension distributed warning for\nTORCH_CUDA_ARCH_LIST\nto only log when running on non-distributed or on rank 0 (\n#162764\n)\nC++ Frontend\nFix\ntorch.utils.cpp_extension\nparser for clang version 20.1.7+libcxx (\n#157666\n)\nFix\nMakeTensor::computeStorageSize()\ncalculation (\n#158690\n)\nFix static initialization order issue with\nAllocatorConfig\n(\n#159629\n)\nBuild Frontend\nTurn on\nBUILD_BUNDLEPTXAS=1\nto allow compile on newer GPUs(\n#163988\n)\nCUDA\nHandle uninitialized\ntorch.backends.cuda.matmul.fp32_precision\n(\n#161102\n)\nFix nansum in non-JIT build (\n#158633\n)\nDecrease launch bounds of CTCLoss backward for blackwell to avoid crash (\n#159522\n)\nImplement workaround for\ncudaErrorNotSupported\n(\n#162412\n)\nFix missing\n__syncthreads\nin MultiMarginLoss backward (\n#158994\n)\nRoll-back cuDNN frontend upgrade and update Meta registration due to compile issues (\n#163104\n)\nDisable cuDNN for 3D convolutions with\nkernel size != 1\nfor cuDNN 9.8+ (\n#163581\n)\nCPU\nAdd check so non-aarch64 platforms can hit\nMKLDNN\npath (\n#162168\n)\nMPS\nFix batch norm incorrect gradient (\n#156867\n)\nDo not crash if\ntensor dim > INT_MAX\n(\n#158824\n)\nAvoid outputing zeros from\nexponential_\nfor MPS (\n#159386\n)\nFix MPS autocast for\nConvTranspose3d\n(\n#160345\n)\nFix MPS\nconv3d\nautocast bias dtype mismatch (\n#160423\n)\nFix error check for\ntorch.var\non scalar (\n#160889\n)\nFix\nindex_add\nfor complex + int64, int64 input + zerodim index (\n#160926\n,\n#161511\n)\nFix\nconstant_pad_nd_mps\nbug when pad is empty (\n#161149\n)\nFix\nindex_select\nfor\nscalar_types\n(\n#161206\n)\nFix\nindex_copy\nfor scalars and\nindex_copy\nfor strided indices (\n#161267\n,\n#161333\n)\nEnsure that tensors are contiguous before using MPS linear kernel (\n#161641\n)\nAddress\nNaN\ns if SDPA is called with all values masked from query (\n#157727\n)\nFix invalid formatting (\n#158436\n)\nFix empty input in posneg functions (\n#161824\n)\nMigrate round unary op to Metal (\n#161712\n)\nType-promote tensor-iterator common dtype (\n#160334\n)\nFix regression in 2.8.0 for\nscaled_dot_product_attention\nusing MPS (\n#163598\n)\nChunk\nfillBuffer\ninto 4Gb slices to avoid regression on MacOS 26 (\n#164108\n)\nFix latent bug that can result in segfault in CPP extensions (\n#164093\n)\nROCm\nFix Inductor with cudagraph trees\nhip:0\ndevice error (\n#161221\n)\nFix some build failures and support some BLAS calls on Windows (\n#161981\n)\nFix undefined symbol linker error after exposing MIOpen symbols on Windows (\n#156479\n)\nFix finding ROCm/HIP version on Windows (\n#156486\n)\nFix LoadHIP handling of environment variable paths on Windows (\n#159080\n)\nAdd hipcc compatibility flags to\ncpp_extension.py\non Windows (\n#159790\n)\nIn SDPA via AOTriton,\nlogsumexp\nneeds scaling back to natural base (\n#156903\n)\nCheck stream graph capture status in\nmemcpy_and_sync\ninline function (\n#158165\n)\nXPU\nFix\ncpp_extension\ncompatibility with\nintel-deep-learning-essentials-2025.2\n(\n#161012\n)\nJIT\nMake\nErrorReport::CallStack\nthread-safe (\n#160386\n)\nFix\nRemoveProfileNodesAndSpecializeTypes\nhandling for\nTensor?\nthat is resolved to\nNone\n(\n#161538\n)\nPerformance\nOptimizer\nUse\naddmm\nto improve NewtonSchulz orthogonalization in Muon (\n#161379\n)\nAvoid stream sync in SWA\nAveragedModel.update_parameters()\n(\n#157705\n)\nAutograd\nFix SVD forward-mode AD multiplication priority (\n#161027\n)\nDynamo\nRecursive\ndict\ntag optimization for faster guard evaluation (\n#159183\n)\nInductor\nImprove performance of A16W4 and A16W8\nGEMM\ntemplate (\n#159127\n,\n#161148\n)\nMore aggressive persistent reduction (\n#161055\n)\nAdd a few outer dimension reduction cases for LOAF (\n#162028\n)\nFuse two RoPE kernels into a single kernel and improving runtime efficiency (\n#161420\n)\nExport\nCaching optimizations for placeholder naming pass (\n#158594\n)\nAdd Static Dispatch Kernel for\nfmod.Scalar\nand\nscale_gradient\n(\n#160654\n,\n#160454\n)\nCUDA\nUse a nonblocking copy to avoid stream synchronization for GPU tensor indexing with CPU mask (\n#156384\n)\nDisable cudagraph GCs by default to improve capture performance (\n#158649\n)\nRelease Engineering\nUpgrade to ROCm 6.4.1 and 6.4.2 patch releases (\n#156636\n,\n#158887\n,\n#158886\n,\n#158651\n,\n#159001\n)\nMigrate RPyTorch ROCm CI to MI325 capacity (\n#159059\n,\n#159649\n,\n#161184\n)\nEnable B200 PyTorch benchmark testing (\n#158011\n,\n#157341\n)\nMPS\nOptimize cummin/cummax metal kernels (\n#156794\n)\nSpeedup\ntorch.full\nfor 1-byte types (\n#158874\n)\nSpeedup\nargmax\n/\nargmin\n(\n#159524\n)\nImprove performance of\nmax_pool3d\n(\n#157875\n)\nAvoid calling tensor ops in\nmax_pool3d\nimpl (\n#157874\n)\nMove\nmax_pool2d\nto Metal for\nstride != 1\n(\n#157876\n)\nROCm\nSDPA now uses AOTriton to 0.11b (\n#161754\n)\nhipblaslt\nis used by default on gfx908 for ROCm >= 6.3 (\n#159092\n)\nEnable miopen channels last 3d for conv and batchnorm (\n#160529\n)\nRemove extra transposes in NHWC convolutions on MIOpen (\n#160435\n)\nRemove extra sync in\ntensor.item()\n(\n#158486\n)\nElementwise and reduction kernel perf improvements (\n#159430\n,\n#159652\n,\n#160444\n,\n#160466\n,\n#161054\n,\n#161180\n,\n#161181\n)\nEnable build of\nfbgemm_gpu genai\nsources for grouped GEMM support (\n#160676\n)\nXPU\nEnable tensor memory descriptor Triton template for Intel GPU (\n#161600\n)\nDocumentation\nPython Frontend\nImprove documentation for\ntorch.lobpcg\n,\ntorch.clone\n,\ntorch.matmul\n,\ntorch.max\n,\ntorch.gather\n,\ntorch.Tensor.scatter_\n,\ntorch.empty_like\n,\ntorch.randint\n,\ntorch.mul\n,\ntorch.min\n,\ntorch.max\n.\ntorch.sort\n,\ntorch.full_like\n,\ntorch.histogramdd\n,\ntorch.hamming_window\n(\n#156139\n,\n#157007\n,\n#161424\n,\n#156153\n,\n#157929\n,\n#157920\n,\n#158050\n,\n#158731\n,\n#160312\n,\n#161539\n,\n#162051\n,\n#158275\n,\n#152682\n)\nRemove torchscript related sections in serialization docs (\n#156648\n)\nFix typo in\ntorch.set_float32_matmul_precision\ndocs (\n#158191\n)\nFix docstring for\ntorch.nn.utils.clip_grads_with_norm_\nto reflect clamping behavior (\n#158200\n)\nFix the Doc issue on the description of edge_order in\ntorch.gradient\n(\n#159130\n)\nAdd\ntorch.segment_reduce\ndocs (\n#154352\n)\nAdd examples to\ntorch.is_floating_point\nand\ntorch.is_complex\ndocs (\n#161951\n)\ntorch.nn\nImprove description of\npadding\nfor\navg_poolnd\n(\n#159142\n)\nImprove\nCrossEntropyLoss\ndocs with example of incorrect target specification (\n#155649\n)\nRemove redundant dtype conversion in\nscaled_dot_product_attention\nexample (\n#161613\n)\nOptimizer\nDocument specific optimizer modules APIs e.g.,\ntorch.optim.adam.Adam\n, properly (\n#158483\n,\n#158669\n,\n#160194\n)\nAdd note for clarity in Adafactor doc\n#154862\n(\n#155248\n)\nMinorly improve\nzero_grad\ndescription (\n#161239\n)\nAutograd\nImprove\ntorch.inference_mode\ndocs and error message (\n#161164\n)\nDistributed\nc10d\nDocumented barrier collective's interaction with\ndevice_id\n(\n#159389\n)\nFix comment to match logic in\ndistributed_c10d.py\n(\n#162158\n)\nDTensor\nRewrote doc of\nTupleStrategy\n(\n#158132\n)\nDocumented\nredistribute_costs\n(\n#158495\n)\nFullyShardedDataParallel (FSDP)\nRemoved FSDP1 developer note (\n#158991\n)\nProfiler\nUpdate PT2 Profiler Torch-Compiled Region Image (\n#158066\n)\nFix Experimental Config Documentatation(\n#156586\n)\nUpdate README (\n#159816\n)\nFX\nFix typos in\ntorch/\n(\ntorch/fx/\n,\n#156604\n)\nAdd typing (\n#158450\n)\nFix typo in FX interpreter class docs (\n#162055\n)\nRemove allow-untyped-defs from\ntorch/fx/experimental/migrate_gradual_types/util.py\n(\n#157236\n)\nInductor\nAdd documentation for CUDAGraph partition (\n#159450\n)\nExport\nUpdate docs around draft export, dynamism, and PT2 Archive (\n#157750\n)\nONNX\nUpdate export docstring (\n#162622\n)\nDelete deprecated tutorial page link (\n#157310\n)\nFilter out torchscript sentences (#158850)\nFix doc typo for\nsymbolic_multi_out\n(#160702)\nonnx.md\nto simplify deprecated entities (#159312)\nUpdate export docstring and set\nfallback=False\nby default (\n#162622\n,\n#162726\n)\nFix typo in error message: summit -> submit (#162587)\nRelease Engineering\nAdd decorator to create deprecation warnings (#155127)\nAdd runnable code examples to export documentation (#158506)\nAdd developer notes for integrating new backends into PyTorch (#158644)\nXPU\nUpdate supported OS to Windows 11 & Ubuntu 24.04/25.04 for Intel client GPU (#161699)\nSecurity\nPython Frontend\nDon't store flamegraph to tmp folder (#157374)\nDevelopers\nPython Frontend\nBetter sample inputs for addmm OpInfo (#160234)\nDistributed\nc10d\nAdd\nwaitcounter\nfor watchdog and heartbeat monitoring thread (#157480)\nMade\ntorch.distributed.breakpoint\nset a long timeout (#158481)\nAdd\ncheck_rng_sync\nutil (#160283)\nAdd\nFlightRecorder\nsupport for\nProcessGroupXCCL\n(#158568)\nAdd\nearly_stop\nkwarg to\ntorch.utils.checkpoint\n(#160781)\nDTensor\nWrap sharding prop error with contextual exception (#161574)\nAdd check if tracing for sharding propagation to handle un-hashable keys in DTensor (#160798)\nDevice Mesh\nAdd error when users try to slice non contiguous flattened dim submesh (#157523)\nMake the repr shorter when debug ENV not set (#158822)\nShardedTensor\nMake error message descriptive in ShardedTensor creation (#150627, #159423)\nPipeline Parallelism (PP)\nAdd profiling to schedule execution (#160753)\nFX\nConsolidate stack trace in Tracer (#156257, #157302, #158266)\nSeparate provenance tracking to different levels (#160383, #158399, #158796, #159484)\nFix\nregister_foward_pre_hook not supported on ScriptModule\nerror (#156904)\nAdd\n__eq__\nfunction to NodeSource (#158170)\nAdd\n__hash__\nfunction to NodeSource (#158322)\nCache dict and string rep for better perf in NodeSource (#158372)\nRecover node source from dict (#158373, #158473)\nInclude error stacktrace and graph module in\ntlparse\nerror (#158469)\nAdd\nexpanded_def\noption for FX printing, render descriptor, update tests (#158708)\nRemove\nco_lnotab\nin favor of\nco_linetable\n(#159227)\nRemove duplicate imports (#161685)\nInclude Output tensor metadata for\nCompiledFxGraph\n(#159311)\nInductor\nDeprecate\nallow_tf32\nin\ntl.dot(..., allow_tf32=...)\n, use\ntl.dot(..., input_precision=...)\n(#160711)\nLog autotune choices and benchmark result to scuba/chrome trace (#159496)\nAdd TLParse artifact for logging runtime of collective and compute ops (#159730)\nCall\njit_post_compile_hook\nwithin Inductor Triton Kernel compile path (#161443)\nPrune configs that require more shared memory than the hardware limit (#161996)\nRuntime estimations using nccl estimator on mm only benchmark mode (#161405)\nDon't use\ntorch.backends.cuda.matmul.allow_tf32\nin Inductor cache key (#159480)\nAhead-Of-Time Inductor (AOTI)\nBetter error message when no .so/cpp files are found (#156863)\nClean up old APIs in AOTI c shim (#158400)\nAdd Inductor provenance mapping for cpp extern kernel (#161656, #162069)\nPrint out error msg when nvcc compiler fails (#157203)\nAdd kernel information JSON generation for AOTI packages (#160540)\nComposability\nStop suggesting to use\nguard_size_oblivious\non data dependent errors (#160510)\nAvoid unnecessary slices resulting in data-dependent errors (#157528)\nQuantization\nRevamp dtype documentation (#156087)\nUse new type statement to fix public API of types (#158487)\nDataloader Frontend\nAdd\ntorch.utils.data\nsamplers benchmark script (#156974)\nAdd\ntorch.utils.data.Dataloader\nbenchmark script (#159432)\nRelease Engineering\nReplace\nsetup.py develop\nwith\npip install -e\nfor development builds (#155998, #156027, #156710)  (#156709)\nXPU\nUpgrade Intel GPU software stack package to intel-deep-learning-essentials-2025.2 (#158733)",
    "crawl_status": "success"
  },
  {
    "library_name": "PyTorch",
    "url": "https://github.com/pytorch/pytorch/releases/tag/v2.4.0",
    "version": "v2.4.0",
    "title": "Release PyTorch 2.4: Python 3.12, AOTInductor freezing, libuv backend for TCPStore 路 pytorch/pytorch 路 GitHub",
    "release_date": "2024-07-24T18:39:28Z",
    "content": "PyTorch 2.4 Release Notes\nHighlights\nTracked Regressions\nBackward incompatible changes\nDeprecations\nNew features\nImprovements\nBug Fixes\nPerformance\nDocumentation\nDevelopers\nSecurity\nHighlights\nWe are excited to announce the release of PyTorch庐 2.4!\nPyTorch 2.4 adds support for the latest version of Python (3.12) for\ntorch.compile\n.\nAOTInductor freezing gives developers running AOTInductor more performance based optimizations by allowing the\nserialization of MKLDNN weights. As well, a new default TCPStore server backend utilizing\nlibuv\nhas been introduced\nwhich should significantly reduce initialization times for users running large-scale jobs.\nFinally, a new Python Custom Operator API makes it easier than before to integrate custom kernels\ninto PyTorch, especially for\ntorch.compile\n.\nThis release is composed of 3661 commits and 475 contributors since PyTorch 2.3. We want to sincerely thank our\ndedicated community for your contributions. As always, we encourage you to try these out and report any issues as we\nimprove 2.4. More information about how to get started with the PyTorch 2-series can be found at our\nGetting Started\npage.\nBeta\nPrototype\nPerformance Improvements\nPython 3.12 support for torch.compile\nFSDP2: DTensor-based per-parameter-sharding FSDP\ntorch.compile optimizations for AWS Graviton (aarch64-linux) processors\nAOTInductor Freezing for CPU\ntorch.distributed.pipelining, simplified pipeline parallelism\nBF16 symbolic shape optimization in TorchInductor\nNew Higher-level Python Custom Operator API\nIntel GPU is available through source build\nPerformance optimizations for GenAI projects utilizing CPU devices\nSwitching TCPStores default server backend to libuv\n*To see a full list of public feature submissions click\nhere\n.\nTracked Regressions\nSubproc exception with torch.compile and onnxruntime-training\nThere is a reported issue (\n#131070\n) when using\ntorch.compile\nif\nonnxruntime-training\nlib is\ninstalled. The issue will be fixed (\n#131194\n) in v2.4.1. It can be solved locally by setting the environment variable\nTORCHINDUCTOR_WORKER_START=fork\nbefore executing the script.\ncu118 wheels will not work with pre-cuda12 drivers\nIt was also reported (\n#130684\n) that the new version of triton uses cuda features that are not compatible with pre-cuda12 drivers.\nIn this case, the\nworkaround\nis to set\nTRITON_PTXAS_PATH\nmanually as follows (adapt the code according to the local installation path):\nTRITON_PTXAS_PATH=/usr/local/lib/python3.10/site-packages/torch/bin/ptxas  python script.py\nBackwards Incompatible Change\nPython frontend\nDefault\nTreadPool\nsize to number of physical cores  (\n#125963\n)\nChanged the default number of threads used for intra-op parallelism from the number of logical cores to the number of\nphysical cores. This should reduce core oversubscribing when running CPU workload and improve performance.\nPrevious behavior can be recovered by using torch.set_num_threads to set the number of threads to the desired value.\nFix\ntorch.quasirandom.SobolEngine.draw\ndefault dtype handling (\n#126781\n)\nThe default dtype value has been changed from\ntorch.float32\nto the current default dtype as given by\ntorch.get_default_dtype()\nto be consistent with other APIs.\nForbid subclassing\ntorch._C._TensorBase\ndirectly (\n#125558\n)\nThis is an internal subclass that a user used to be able to create an object that is almost a Tensor in Python and was\nadvertised as such in some tutorials. This is not allowed anymore to improve consistency and all users should\nsubclass torch.Tensor directly.\nComposability\nNon-compositional usages of as_strided + mutation under\ntorch.compile\nwill raise an error (\n#122502\n)\nThe\ntorch.compile\nflow involves functionalizing any mutations inside the region being compiled. Torch.as_strided is\nan existing view op that can be used non-compositionally: meaning when you call x.as_strided(...), as_strided will only\nconsider the underlying storage size of x, and ignore its current size/stride/storage_offset when creating a new view.\nThis makes it difficult to safely functionalize mutations on views of as_strided that are created non-compositionally,\nso we ban them rather than risking silent correctness issues under torch.compile.\nAn example of a non-compositional usage of as_strided followed by mutation that we will error on is below. You can avoid\nthis issue by re-writing your usage of as_strided so that it is compositional (for example: either use a different set\nof view ops instead of as_strided, or call as_strided directly on the base tensor instead of an existing view of it).\n@\ntorch\n.\ncompile\ndef\nfoo\n(\na\n):\ne\n=\na\n.\ndiagonal\n()\n# as_strided is being called on an existing view (e),\n# making it non-compositional. mutations to f under torch.compile\n# are not allowed, as we cannot easily functionalize them safely\nf\n=\ne\n.\nas_strided\n((\n2\n,), (\n1\n,),\n0\n)\nf\n.\nadd_\n(\n1.0\n)\nreturn\na\nWe now verify schemas of custom ops at registration time (\n#124520\n)\nPreviously, you could register a custom op through the operator registration APIs, but give it a schema that contained\ntypes unknown to the PyTorch Dispatcher. This behavior came from TorchScript, where unknown types were implicitly\ntreated by the TorchScript interpreter as type variables. However, calling such a custom op through regular pytorch\nwould result in an error later. As of 2.4, we will raise an error at registration time, when you first register the\ncustom operator. You can get the old behavior by constructing the schema with allow_typevars=true.\nTORCH_LIBRARY(my_ns, m) {\n  // this now raises an error at registration time: bar/baz are unknown types\n  m.def(\"my_ns::foo(bar t) -> baz\");\n  // you can get back the old behavior with the below flag\n  m.def(torch::schema(\"my_ns::foo(bar t) -> baz\", /*allow_typevars*/ true));\n}\nAutograd frontend\nDelete torch.autograd.function.traceable APIs (\n#122817\n)\nThe torch.autograd.function.traceable(...) API, which sets the is_traceable class attribute\non a torch.autograd.Function class was deprecated in 2.3 and is now being deleted.\nThis API does not do anything and was only meant for internal purposes.\nThe following raised an warning in 2.3, and now errors because the API has been deleted:\n@\ntorch\n.\nautograd\n.\nfunction\n.\ntraceable\nclass\nFunc\n(\ntorch\n.\nautograd\n.\nFunction\n):\n    ...\nRelease engineering\nRemove caffe2 db and distributed from build system (\n#125092\n)\nOptim\nRemove\nSparseAdam\nweird allowance of raw Tensor input (\n#127081\n).\nDistributed\nDeviceMesh\nUpdate get_group and add get_all_groups (\n#128097\n)\nIn 2.3 and before, users can do:\nmesh_2d\n=\ninit_device_mesh\n(\n\"cuda\"\n, (\n2\n,\n2\n),\nmesh_dim_names\n=\n(\n\"dp\"\n,\n\"tp\"\n)\n)\nmesh_2d\n.\nget_group\n()\n# This will return all sub-pgs within the mesh\nassert\nmesh_2d\n.\nget_group\n()[\n0\n]\n==\nmesh_2d\n.\nget_group\n(\n0\n)\nassert\nmesh_2d\n.\nget_group\n()[\n1\n]\n==\nmesh_2d\n.\nget_group\n(\n1\n)\nBut from 2.4 forward, if users call\nget_group\nwithout passing in the dim, users will get a\nRuntimeError\n.\nInstead, they should use\nget_all_groups\n:\nmesh_2d\n=\ninit_device_mesh\n(\n\"cuda\"\n, (\n2\n,\n2\n),\nmesh_dim_names\n=\n(\n\"dp\"\n,\n\"tp\"\n)\n)\nmesh_2d\n.\nget_group\n()\n# This will throw a RuntimeError\nassert\nmesh_2d\n.\nget_all_groups\n()[\n0\n]\n==\nmesh_2d\n.\nget_group\n(\n0\n)\nassert\nmesh_2d\n.\nget_all_groups\n()[\n1\n]\n==\nmesh_2d\n.\nget_group\n(\n1\n)\nPipelining\nRetire torch.distributed.pipeline (\n#127354\n)\nIn 2.3 and before, users can do:\nimport\ntorch\n.\ndistributed\n.\npipeline\n# warning saying that this will be removed and users need to migrate to torch.distributed.pipelining\nBut from 2.4 forward, if users write the code above, users will get a\nModuleNotFound\nerror.\nInstead, they should use\ntorch.distributed.pipelining\n:\nimport\ntorch\n.\ndistributed\n.\npipeline\n# -> ModuleNotFoundError\nimport\ntorch\n.\ndistributed\n.\npipelining\njit\nFix serialization/deepcopy behavior for tensors that are aliasing but not equal (\n#126126\n)\nFx\nComplete revamp of float/promotion sympy handling (\n#126905\n)\nONNX\nRemove caffe2 contrib and experiments (\n#125038\n)\nDeprecations\nPython frontend\nUser warning when using\ntorch.load\nwith default\nweights_only=False\nvalue (\n#129239\n,\n#129396\n,\n#129509\n).\nA warning is now raised if the weights_only value is not specified during a call to torch.load, encouraging users to\nadopt the safest practice when loading weights.\nDeprecate device-specific autocast API (\n#126062\n)\nAll the autocast APIs are unified under torch.amp and it can be used as a drop-in replacement for torch.{device}.amp APIs\n(passing a device argument where applicable)..\nExport torch.newaxis=None for Python Array API/Numpy consistency (\n#125026\n)\nComposability\nDeprecate calling FakeTensor.data_ptr in eager-mode. FakeTensors are tensors without a valid data pointer, so in\ngeneral their data pointer is not safe to access. This makes it easier for\ntorch.compile\nto provide a nice error\nmessage when tracing custom ops into a graph that are not written in a PT2-friendly way (because, for example, they\ntry to directly access a tensors data pointer from a region of code being traced). More details on integrating custom\nops with\ntorch.compile\ncan be found\nhere\n(\n#123292\n)\nDynamic shapes:\nSymInt-ify mem-efficient attention forward op signature (\n#125418\n)\nDon't call item() into torch.scalar_tensor uselessly (\n#125373\n)\nFix scalar type for constraint_range to Long (\n#121752\n)\nGuard oblivious on meta registrations (\n#122216\n), vector_norm (\n#126772\n), and unbind (\n#124959\n)\nMake expected stride test in torch._prims_common size oblivious (\n#122370\n)\nUse torch._check for safety assert in _reshape_view_helper (\n#125187\n)\nAdd a code comment about torch._check_is_size in tensor_split (\n#125292\n)\nMake min(stride, strides[idx]) in collapse_view_helper size oblivious (\n#125301\n)\nDon't short circuit if shape is same (\n#125188\n)\nCPP\nRefactor autocast C++ APIs to be device-agnostic (\n#124359\n)\nRelease Engineering\nRemove of QNNPACK third-party module (\n#126941\n)\nOptim\nDeprecate LRScheduler.print_lr (\n#126105\n)\nnn\ntorch.nn.hardtahn\nallowed\nmin_val\nto be greater than max_val (\n#121627\n)\nDistributed\nDistributed Checkpointing (DCP)\nDeprecated submodules feature for distributed_state_dict (\n#127793\n)\nIn 2.3 and before, users can do:\nmodel\n=\nAnyModel\n(\ndevice\n=\ntorch\n.\ndevice\n(\n\"cuda\"\n))\nmodel_state_dict\n=\nget_model_state_dict\n(\nmodel\n)\nset_model_state_dict\n(\nmodel\n,\nmodel_state_dict\n=\nnew_model_state_dict\n,\noptions\n=\nStateDictOptions\n(\nstrict\n=\nFalse\n),\n)\n# Below way of calling API is also legit\nmodel_state_dict2\n=\nget_model_state_dict\n(\nmodel\n,\nsubmodules\n=\n{\nmodel\n.\nsubmodule\n})\nset_model_state_dict\n(\nmodel\n,\nmodel_state_dict\n=\n{\nmodel\n.\nsubmodule\n:\nnew_submodel_state_dict\n},\noptions\n=\nStateDictOptions\n(\nstrict\n=\nFalse\n),\n)\nBut from 2.4 forward, if users call\nget_model_state_dict\nor\nset_model_state_dict\nwith a submodule path or\nstate_dict, users will see a warning about the feature. To achieve the same functionality, users can manually\nfilter out the\nstate_dict\nreturned from\nget_state_dict\nAPI and preprocess the model_state_dict before\ncalling\nset_state_dict\nAPI:\nmodel\n=\nAnyModel\n(\ndevice\n=\ntorch\n.\ndevice\n(\n\"cuda\"\n))\nmodel_state_dict\n=\nget_model_state_dict\n(\nmodel\n)\nset_model_state_dict\n(\nmodel\n,\nmodel_state_dict\n=\nnew_model_state_dict\n,\noptions\n=\nStateDictOptions\n(\nstrict\n=\nFalse\n),\n)\n# Deprecating warnings thrown for the below way of calling API\nmodel_state_dict2\n=\nget_model_state_dict\n(\nmodel\n,\nsubmodules\n=\n{\nmodel\n.\nsubmodule\n})\nset_model_state_dict\n(\nmodel\n,\nmodel_state_dict\n=\n{\nmodel\n.\nsubmodule\n:\nnew_submodel_state_dict\n},\noptions\n=\nStateDictOptions\n(\nstrict\n=\nFalse\n),\n)\nFullyShardedDataParallel (FSDP)\nDeprecate FSDP.state_dict_type and redirect users to distributed_state_dict (\n#127794\n)\nIn 2.3 and before, users can do:\nmodel\n=\nAnyModel\n(\ndevice\n=\ntorch\n.\ndevice\n(\n\"cuda\"\n))\nfsdp_model\n=\nFSDP\n(\nmodel\n)\n# Users can do both ways below\nget_model_state_dict\n(\nmodel\n)\nwith\nFSDP\n.\nstate_dict_type\n(\nfsdp_model\n,\nStateDictType\n.\nFULL_STATE_DICT\n):\nfsdp_model\n.\nstate_dict\n()\nBut from 2.4 forward, if users call\nstate_dict\nor set\nstate_dict\nwith the FSDP.state_dict_type, users will see warnings. And the recommended solution now is to use\nget_model_state_dict\nand\nset_model_state_dict\ndirectly:\nmodel\n=\nAnyModel\n(\ndevice\n=\ntorch\n.\ndevice\n(\n\"cuda\"\n))\nfsdp_model\n=\nFSDP\n(\nmodel\n)\nget_model_state_dict\n(\nmodel\n)\n# Deprecating warnings thrown for the below way of calling API\nwith\nFSDP\n.\nstate_dict_type\n(\nfsdp_model\n,\nStateDictType\n.\nFULL_STATE_DICT\n):\nfsdp_model\n.\nstate_dict\n()\nProfiler\nRemove FlameGraph usage steps from export_stacks docstring (\n#123102\n)\nThe export_stacks API will continue to work as before, however weve removed the docstring to use FrameGraph.\nPyTorch doesnt own FrameGraph, and cannot guarantee that it functions properly.\nQuantization\nRemove deprecated\ntorch._aminmax\noperator (\n#125995\n).\ntorch._aminmax\n->\ntorch.aminmax\ninstead\nExport\nStart deprecation of capture_pre_autograd_graph (\n#125848\n,\n#126403\n)\nXPU\nRefactor autocast C++ APIs to be device-agnostic(\n#124359\n)\nat::autocast::get_autocast_gpu_dtype()\n->\nat::autocast::get_autocast_dtype(at::kCUDA)\nat::autocast::get_autocast_cpu_dtype()\n->\nat::autocast::get_autocast_dtype(at::kCPU)\nRefactor autocast Python APIs(\n#124479\n)\ntorch.get_autocast_gpu_dtype()\n->\ntorch.get_autocast_dtype(cuda)\n,\ntorch.set_autocast_gpu_dtype(dtype)\n->\ntorch.set_autocast_dtype(cuda, dtype)\n,\ntorch.is_autocast_enabled()\n->\ntorch.is_autocast_enabled(cuda)\n,\ntorch.set_autocast_enabled(enabled)\n->\ntorch.set_autocast_enabled(cuda, enabled)\n,\ntorch.get_autocast_cpu_dtype()\n->\ntorch.get_autocast_dtype(cpu)\nMake torch.amp.autocast more generic (\n#125103\n)\ntorch.cuda.amp.autocast(args)\n->\ntorch.amp.autocast(cuda,args)\n,\ntorch.cpu.amp.autocast(args)\n->\ntorch.amp.autocast(cpu, args)\n,\nDeprecate device-specific GradScaler autocast API(\n#126527\n)\ntorch.cuda.amp.GradScaler(args)\n->\ntorch.amp.GradScaler(cuda, args)\n,\ntorch.cuda.amp.GradScaler(args)\n->\ntorch.amp.GradScaler(cpu, args)\n,\nGeneralize custom_fwd&custom_bwd to be device-agnostic (\n#126531\n)\ntorch.cuda.amp.custom_fwd(args)\n->\ntorch.amp.custom_fwd(args, device_type=cuda)\n,\nONNX\nRemove more caffe2 files (\n#126628\n)\nNew Features\nPython frontend\nAdd\nsupport for unsigned int sizes for torch.unique (\n#123643\n)\ntorch.OutOfMemoryError to signify out of memory error from any device (\n#121702\n)\nnew device-agnostic API for autocast in torch.amp.* (\n#124938\n)\nnew device-agnostic API for Stream/Event in torch.{Stream,Event} (\n#125757\n)\nchannels last support to max, average and adaptive pooling functions (\n#116305\n)\ntorch.serialization.add_safe_globals that allows users to allowlist classes for weights_only\nload (\n#124331\n,\n#124330\n,\n#127808\n)\npickling support for torch.Generator (\n#126271\n)\ntorch.utils.module_tracker to track position within torch.nn.Module hierarchy (\n#125352\n)\nComposability\nAdd\nOpOverload.redispatch; use it in new custom ops API (\n#124089\n)\nmutated_args field to custom_op (\n#123129\n)\nnew Python Custom Operators API\nregister_autograd to register backward formulas for custom ops (\n#123110\n)\ntorch.library.opcheck (\n#124496\n), torch.library.register_autograd (\n#124071\n), torch.library.register_kernel (\n#124299\n)\nBlanket ban kwarg-only Tensors (\n#124805\n)\nChange register_autograd to reflect ordering of setup_context and backward (\n#124403\n)\nEnsure torch.library doctests runs under xdoctest (\n#123282\n)\nFix torch.library.register_fake's module reporting (\n#125037\n)\nNew Custom Ops Documentation landing page (\n#127400\n)\nRefresh OpOverloadPacket if a new OpOverload gets added (\n#126863\n,\n#128000\n)\nRename\nimpl_abstract to register_fake, part 1/2 (\n#123937\n)\nregister_impl to register_kernel (\n#124200\n)\nSchema inference now includes default values (\n#123453\n)\nStop requiring a pystub for register_fake by default (\n#124064\n)\nSupport TensorList inputs/outputs (\n#123615\n)\nUpdate the functionalization error message (\n#123261\n)\nadd ability to provide manual schema (\n#124180\n)\nfix schema inference for kwarg-only args (\n#124637\n)\nmutated_args -> mutates_args (\n#123437\n)\nregister_autograd supports non-tensor kwargonly-args (\n#124806\n)\nset some tags when constructing the op (\n#124414\n)\nsetup_context fills in default values (\n#124852\n)\ntorch.library.register_fake accepts more types (\n#124066\n)\nuse new python custom ops API on prims ops (\n#124665\n)\nOptim\nEnable\ntorch.compile\nsupport for LRScheduler with Tensor LRs (\n#123751\n,\n#123752\n,\n#123753\n,\n#127190\n)\nnn frontend\nAdd RMSNorm module (\n#121364\n)\nlinalg\nImplement svd_lowrank and pca_lowrank for complex numbers (\n#125580\n)\nExtend\npreferred_backend\non ROCm backend.\nAdd cuBLASLt\ngemm\nimplementation (\n#122106\n)\nDistributed\nc10d\nImplemented IntraNodeComm primitives for\nallgather_matmul\n(\n#118038\n)\nAdd first differentiable collective\nall_to_all_single_grad\n(\n#123599\n)\nAdd P2P versions of\nsend/recv_object_list\noperations (\n#124379\n)\nAdd a new Collectives API for doing distributed collectives operations in the Elastic\nstore with more performant and debuggable primitives (\n#126695\n)\nFullyShardedDataParallel v2 (FSDP2)\nFSDP2 is a new fully sharded data parallel implementation that uses DTensor-based dim-0 per-parameter\nsharding for improved flexibility (e.g. mixed-dtype all-gather, no constraints on requires_grad) without\nsignificant cost to performance.\nSee the\ndocument\nfor more details and a\ncomparison with FSDP1 (\n#122888\n,\n#122907\n,\n#123142\n,\n#123362\n,\n#123491\n,\n#123857\n,\n#119302\n,\n#122908\n,\n#123953\n,\n#120952\n,\n#123988\n,\n#124293\n,\n#124318\n,\n#124319\n,\n#120256\n,\n#124513\n,\n#124955\n,\n#125191\n,\n#125269\n,\n#125394\n,\n#126070\n,\n#126267\n,\n#126305\n,\n#126166\n,\n#127585\n,\n#127776\n,\n#127832\n,\n#128138\n,\n#128117\n,\n#128242\n)\nPipelining\nPyTorch Distributed pipeline parallelism APIs were upstreamed from the\nPiPPy project\nand are available as a prototype release in\nPyTorch 2.4.\nThe package is under\ntorch.distributed.pipelining\nand consists of two parts: a splitting frontend and a distributed runtime.\nThe splitting frontend takes your model code as-is, splits it up into model partitions, and captures the data-flow relationship.\nThe distributed runtime executes the pipeline stages on different devices in parallel, handling things like micro-batch splitting,\nscheduling, communication, and gradient propagation.\nFor more information please check out the\ndocumentation\nand\ntutorial\n(\n#126322\n,\n#124776\n,\n#125273\n,\n#125729\n,\n#125975\n,\n#126123\n,\n#126419\n,\n#126539\n,\n#126582\n,\n#126732\n,\n#126653\n,\n#127418\n,\n#127084\n,\n#127673\n,\n#127332\n,\n#127946\n,\n#128157\n,\n#128163\n,\n#127796\n,\n#128201\n,\n#128228\n,\n#128240\n,\n#128236\n,\n#128273\n,\n#128279\n,\n#128276\n,\n#128278\n,\n#127066\n)\nProfiler\nAdd profiler support for\nPrivateUse1\n(\n#124818\n)\nDynamo\ntorch.compile\nis compatible with Python 3.12.\nGuarding on nn modules attributes (\n#125202\n) - TorchDynamo guards on nn module attributes. This was a frequently raised\nissue in the past (examples (\n#111785\n,\n#120248\n,\n#120958\n,\n#117758\n,\n#124357\n,\n#124717\n,\n#124817\n)).\nThis increases TorchDynamo soundness with minimal perf impact.\nHardened the recently introduced tracing rules infrastructure. This allows\ntorch.compile\nusers to easily control TorchDynamo tracing of PyTorch internal code.\nExtended\ntorch.compile\nsupport for RAdam and Adamax optimizer. Compiler optimizers now demonstrate SOTA performance.\nExperimental feature - We introduced a new experimental flag torch._dynamo.config.inline_inbuilt_nn_modules to enable\ntorch.compile\nto reuse compiled\nartifacts on repeated blocks in the models. This gives another point in the tradeoff space of compilation time and performance speedup.\nBy moving\ntorch.compile\nfrom full model to a repeated block (e.g. moving\ntorch.compile\nfrom full LLM to a repeated Transformer block),\nwe can now achieve faster compilation time with some performance dip compared to full model.\nWe plan to make this flag default to True in the 2.5 release.\nExport\nIntroduce ShapesCollection, a dynamic shapes builder API (\n#124898\n)\nInductor\nAdd higher order associative scan operator (\n#119430\n)\njit\nAdd aten::sort.any op for sorting lists of arbitrary elements (\n#123982\n)\nMPS\nConform torch.mps to device module interface (\n#124676\n)\nXPU\nInductor Intel GPU backend (\n#121895\n)\na new autocast API torch.amp.is_autocast_available(\n#124938\n)\nattributes to xpu device prop (\n#121898\n)\nXPU implementation for PyTorch ATen operators (\n#120891\n)\ngeneric stream/event on XPU backend (\n#125751\n)\ngpu trace on XPU (\n#121795\n)\nSwitch to torch.float16 on XPU AMP mode (\n#127741\n)\nONNX\nquantized layer norm op to opset 17 (\n#127640\n)\nsymbolic_opset19.py and symbolic_opset20.py to support opset 19/20, extend opset 18 support (\n#118828\n)\nSupport for Some Bitwise Ops in Onnx Exporter (\n#126229\n)\nAllow ONNX models without parameters (\n#121904\n)\nIntegrate onnxscript optimizer (\n#123379\n)\nVulkan\nquantized transposed 2D convolutions (\n#120151\n,\n#122547\n)\nthe quantized ReLU operator (\n#123004\n)\nImprovements\nPython frontend\nbfloat16 support for torch.binary_cross_entropy on CPU (\n#123823\n)\nMAP_SHARED option for torch.load when mmap=True (\n#124889\n)\ndefault value when printing function signature (\n#127059\n)\nall variants of upsampling functions to be done in high precision in autocast (\n#121324\n)\nComposability\nFakeTensors, meta tensors and python decompositions are used to perform shape propagation when tracing out a graph in\ntorch.compile. There were much coverage improvements this release:\nNew metas / fake tensor rules:\naten._embedding_bag_dense_backward, aten._embedding_bag_per_sample_weights_backward (\n#125785\n), aten.randint.out,\naten.rand.out (\n#122375\n), aten.unique2 (\n#124306\n), aten.histc (\n#124548\n), aten.channel_shuffle (\n#123033\n),\naten._masked_scale (\n#127389\n), aten.addcdiv.ScalarList, aten.addcmul.ScalarList (\n#123486\n)\nNew decomps:\nAten.resize_as (\n#122317\n), several out= variants of ops with existing decomps (\n#122979\n,\n#115437\n)\nAutograd frontend\nnn.functional.batch_norm\n: add forward AD rule for miopen backend (\n#125069\n)\nnn.functional.scaled_dot_product_attention\n: add backward rule for cuDNN backend (\n#122510\n)\nRelease Engineering\nAdd CI support for aarch64 linux. The CI is triggered when the ciflow/linux-aarch64 label is added.\n(\n#120931\n,\n#121284\n,\n#125255\n,\n#121136\n,\n#124781\n,\n#125599\n)\nAdd experimental CUDA pip wheels for ARM architectures supporting the NVIDIA Hopper architecture as nightly binaries\nand a prototype for the PyTorch 2.4.0 release. (\n#126174\n,\n#127514\n)\nAdd support for CUDA 12.4 in CI/CD (\n#121684\n,\n#121956\n,\n#127825\n,\n#125944\n,\n#128250\n)\nAdd support for numpy 2.0.0rc1 in CI and CD (\n#123286\n,\n#122157\n)\nEnable support for\ntorch.compile\nand triton with Python 3.12 CI/CD (\n#127547\n,\n#123307\n,\n#126218\n)\nIntel GPU enablement in CI (\n#122254\n,\n#123920\n,\n#125655\n)\nMigrated CI/CD jobs to macOS 14 (\n#127582\n,\n#127853\n,\n#125801\n)\nROCM: upgrade CI/CD to 6.1 (\n#124811\n,\n#118216\n,\n#124300\n,\n#125646\n)\nCUDNN version 9.1.0.70 for CUDA 11.8, 12.1, 12.4 builds (\n#123475\n)\nNCCL submodule v2.20.5 (\n#121635\n)\nsubmodule oneDNN v3.4.2 (\n#126137\n)\nWrapped deprecated function/class with typing_extensions.deprecated (\n#127689\n)\nnn frontend\nAdd\nswap_tensors\npath to nn parametrizations (\n#124130\n)\nRelax\nuse_count\nconstraints for\nswap_tensors\nwhen\nAccumulateGrad\nnode holds a reference (\n#127313\n)\nIncrease numel limit to 2^63 for replicatepad1d (\n#122199\n)\nUse\nint64_t\nindexing for\nUpsample2d\nbackwards (\n#123682\n)\nRemove warning from\nLazyModuleMixin\nconstructor (\n#123968\n)\nOptim\nRadam and Nadam support the flag for \"maximize\" (\n#126765\n,\n#127214\n)\nInclude scheduler_on_plateau in optim.h (\n#121722\n)\nForeach\nAllow foreach ops to run for any backend, not just CPU (\n#127412\n)\ncuda\nUpdate CUDA out of memory message with private pool info (\n#124673\n)\nAdd autocast rule for torch.vdot (\n#125697\n)\nFix type hint for cuda.get_device_name() and cuda. get_device_capability() (\n#126743\n)\nQuantization\nX86 Inductor backend\nEnable linear and linear-unary post-op gelu quant recipe for\nX86InductorQuantizer\n(\n#114853\n)\nAdd Quantization recipe filter per operator type for\nX86InductorQuantizer\n(\n#122775\n)\nAdd Matmul recipe into\nX86InductorQuantizer\n(\n#122776\n)\nImprove performance of\nqconv\nby reducing integration overhead (\n#123240\n)\nPT2E quantization flow\nAdd support for conv transpose + bn + {relu} weights fusion in PTQ and QAT (\n#122046\n,\n#123652\n)\nSimplify\nfake_quant_per_channel\n(\n#123186\n)\nSupport fp8 quantization (\n#123161\n)\nPropagate get_attr meta through known ops only (\n#124415\n)\nFix issue of lowering nn.linear ops with kwargs (\n#126331\n)\nDistributed\nc10d\nTORCH_NCCL_HIGH_PRIORITY\noption for ProcessGroupNCCL (\n#122830\n)\n__repr__\nto P2POp class (\n#126538\n)\ncommCreateFromRanks\nto c10d (\n#127421\n,\n#127982\n)\ndist.get_node_local_rank\nhelper (\n#123992\n)\nan option to enable TCPStore libuv backed for c10d rendezvous  (\n#124684\n)\nCaptured dtype in Flight Recorder (\n#126581\n)\nEnable ncclCommDevIdxMap unconditionally (\n#122049\n)\nExtended the flight recorder dump from timeout to any exception (\n#123023\n)\nMake TCPStore server use libuv by default (\n#127957\n)\nMake\nget_node_local_rank()\naccept fallback_rank (\n#126737\n)\nMake abort communicators in destroy_process_group call on default and code cleanup (\n#124334\n)\nMapped float8 types to uint8 for allgather (\n#126556\n)\nOptionally avoided rethrowing CUDA Errors in NCCL Watchdog (\n#126587\n)\nWrapped TCPStore check in a try/catch (\n#127030\n)\nProcessGroupWrapper\nsupport custom backend (\n#124447\n)\nncclComm is not aborted before checking exception (\n#124466\n)\nDeviceMesh\nAdd a private init backend option (\n#124780\n)\nInitialized mesh tensor with CPU context (\n#124767\n)\nAdd\nDeviceMesh.from_group()\n(\n#124787\n)\nMake\n_validate_tp_mesh_dim\nsupport 3D (\n#125763\n)\nSupported N groups in from_group (\n#126258\n)\nMake sure device mesh can be imported from torch.distributed (\n#126119\n)\nDistributed quantization\nUsed BFloat16 in distributed quantization when supported by NCCL (\n#125113\n)\nDistributedDataParallel (DDP)\nAdd a mode to avoid clone() in DDPSink (\n#122927\n)\nDistributed Checkpointing (DCP)\nAdd\ntype_check\nparam to copy state dict utils (\n#127417\n)\nAdd strict option to\nDefaultPlanner\n(\n#123869\n)\nAlways created requests for non-tensor objects (\n#125334\n)\nAlways flattened mapping even if no tensors present (\n#125335\n)\nCorrectly handle\n_extra_state\n(\n#125336\n)\nImplement\nbroadcast_from_rank0\noption for model/optim\nstate_dict\n(\n#125338\n,\n#125339\n)\nIntroduced async staging extension points (\n#122965\n)\nMake distributed\nstate_dict\nsupport\ntorch.distributed\nis not initialized case (\n#127385\n)\nMake param name consistent with overridden function (\n#124770\n)\nRemove the support of Dict[nn.Module, Dict[str, Any]] state_dict (\n#127070\n)\nSupported flattening the optimizer\nstate_dict\nwhen saving and unflattening when loading (\n#127071\n)\nUnified the API signatures of\nset_model_state_dict\nand\nset_optimizer_state_dict\n(\n#127384\n)\nDTensor\nbackward support for\nscaled_dot_product_attention\n(flash-attention) (\n#122541\n)\nmore foreach ops (\n#123214\n)\nop support for\nview_as_complex\nand\nview_as_real\n(\n#122569\n)\nop support for memory efficient attention (\n#122996\n)\nsupport for\nfused_adam\nand\nfused_adamw\nwhen lr is a tensor (\n#126750\n)\nASGD foreach optimizer with associated unit tests (\n#121942\n)\nthe handle of DTensor.device_mesh.device_type in dynamo (\n#118803\n)\nthe support of placement kwargs for DTensor.to_local() in dynamo (\n#119947\n)\nscatter op with simple replication (\n#126713\n)\ndistributed topk operator (\n#126711\n)\nMake Partial placement public (\n#127338\n,\n#127420\n)\nensure expected input spec have correct tensor meta (\n#122949\n)\nensure meta tensor random op does not alternate rng state (\n#125693\n)\nMove early return check into redistribute autograd function (\n#121653\n)\nMove some modules to private namespace (\n#127339\n)\nStandardized multi mesh-dim strategy with utils (\n#126712\n)\n2D clip_grad_norm_ (\n#121945\n)\nsimple replicate strategy for SVD (\n#127004\n)\nTurned on foreach implementation for (1)\nclip_grad_norm_\nfor DTensor by default (\n#126423\n), (2) optimizer for DTensor by default (\n#123394\n)\nFullyShardedDataParallel (FSDP)\ndevice in\npin_memory\nargument (\n#119878\n)\nprivate _unshard API (\n#124304\n)\nprivateuse1 in FSDP's sharded grad scaler (\n#126971\n)\nAvoided CPU sync in\nclip_grad_norm_\n(\n#122001\n)\nMarked\npre_backward_hook\nunserializable (\n#125464\n)\nSkipped FSDP hooks base on dynamo config (\n#123021\n)\nUsed generic device handle instead of cuda (\n#121620\n)\nShardedTensor\nSupported non-contiguous rank validation in sharded tensor (\n#123230\n)\nTorchElastic\ndebug info logging interface for expired timers (\n#123883\n)\nhealth check server hook in torch elastic (\n#122750\n,\n#123504\n)\noption for sharing TCPStore created by rendezvous handlers (\n#125743\n)\nsupport for binding to TCP in WorkerServer (\n#127986\n)\nApplied \"distributed debug handlers\" (\n#127805\n)\nCleared timer for already terminated process (\n#122324\n)\nSkipped expired timer logging for empty expired timers (\n#125039\n)\nTensor Parallel\nwildcard support for Tensor Parallel\nparallelize_plan\n(\n#122968\n)\nkwargs support to\nprepare_module_input\n(\n#124114\n)\nProfiler\nProfiler\ntorch.profiler\n:\nmetrics for performance timing and other statistics collection (\n#123412\n)\nKineto traces will export ns granularity for finer timestamps (\n#122425\n,\n#123650\n)\nUnified the device (CUDA, XPU, PrivateUse1) in profilers post processing (\n#123247\n)\nImprove profiler post processing by iterating frontend function events rather than all function events (\n#124596\n)\nReport strides in json traces (\n#125851\n)\nRegister COLLECTIVE_COMM profiler activity type when available (\n#121461\n)\nSupport third-party devices emit a range for each autograd operator (\n#125822\n)\nMemory Snapshot\ntorch.cuda.memory._dump_snapshot\n:\nImprove the description of blocks with missing frames in the Memory Visualizer (\n#124784\n)\nAdd recordAnnotations to capture record_function annotations (\n#124179\n)\nProfiler\nrecord_function\n:\nFor with_effects, skip over profiler.record_function_exit (\n#121829\n)\nsupport for RecordFunctionFast to take inputs (\n#123208\n)\nsupport for kwargs in RecordFunctionFast (\n#123600\n)\nCollecting autograd sequence numbers on PythonTLSSnapshot dispatch keys for Nested Tensor (\n#123304\n)\nExport\na printer to the unflattened module (\n#124315\n)\ndisable_forced_specializations flag (\n#124949\n,\n#126925\n)\nexport support for auto_functionalize (\n#121990\n,\n#122177\n,\n#122246\n)\nreadable placeholder names to ExportedProgram nodes (\n#123587\n,\n#123590\n,\n#124765\n)\nset_grad_enabled higher order operator (\n#123391\n,\n#125066\n,\n#121736\n)\nstack_trace for non-strict export (\n#121034\n)\ntorch_fn, a more consistent metadata across strict and non-strict export (\n#122693\n)\ntorchbind tracing support (\n#122619\n,\n#123370\n,\n#122622\n,\n#125490\n)\nAllow static constraints in dynamic_shapes (\n#121860\n)\nIgnore logging.Logger.* calls during dynamo export (\n#123402\n)\nMake metadata serialization more strict (\n#124411\n)\nPopulate ShapeEnv's var_to_val during deserialization (\n#121759\n)\nPrototype TorchScript 2 ExportedProgram Converter (\n#126920\n,\n#127466\n)\nProvide refine function for automatically accepting dynamic shapes suggested fixes (\n#127436\n)\nSave/load example inputs in the ExportedProgram (\n#122618\n)\nSuggest constant dim values in dynamic shapes fixes (\n#125458\n)\nSupport map in pre-dispatch functionalization (\n#121444\n)\nWe introduced the concept of effect tokens, which is how we allow side-effectful operators in torch.compile/export (\n#121552\n,\n#122357\n)\nFx\nshape inference tool (\n#120097\n)\ndevice_ordinal to Subgraph in splitter_base (\n#125616\n)\nexclusion function to minimizer base (\n#124504\n)\nmissing forbidden mutation methods in immutable collections (\n#125468\n)\noption to turn on return_tuple in _SplitterBase (\n#123868\n)\nprefix option to CapabilityBasedPartitioner (\n#126382\n)\nCreate block traverse mode in minimizer for graph aware debugging (\n#125613\n)\nImplement Graph Transform Observer (\n#127427\n)\nOption to include stride and device annotation in gm.print_readable() (\n#123690\n)\nRegister create_node_hook (\n#126671\n)\nDynamo\nWe performed a careful audit and fixed all known memory leaks in TorchDynamo.\nWe hardened\ntorch.compile\n+\n__torch_function__\nsupport by onboarding Scaled Dot Product Attention (SDPA) and TensorDict.\nInductor\n0 initialization to Triton masked loads (\n#127311\n)\nHalideCodeCache (\n#126416\n)\nclone if output is a view from constant (\n#123200\n)\nconfig to allow buffer mutation (\n#126584\n)\ndecompose_mem_bound_mm to the customization pre and post grad passes (\n#123376\n)\ninductor support (\n#123709\n)\nkernel_code logging artifact (\n#126631\n)\nlowering for avg_pool{1, 3}d (\n#116085\n), cummax, cummin (\n#120429\n)\nmissing files to torch_key (\n#128230\n)\nmode to MemoryDep to track atomic accumulates (\n#123223\n)\npybind for tensor_converter util functions (\n#121744\n)\nqlinear_pointwise.binary op for X86Inductor backend (\n#123144\n)\nsupport for multiple flexattention calls in a single compile (\n#125516\n)\ntensor_constantX to pass constant buffer update's check (\n#122562\n,\n#122690\n)\nthe quant lift up pass in convert phase (\n#122777\n)\na decomposition for select_scatter (\n#124426\n)\nAllow multiple cudagraph recordings per compiled graph (\n#126822\n)\nAutomatic detection for buffer mutation and binary linking (\n#126706\n)\nChange\nOverridesData to take callables instead of strings (\n#123397\n)\naot_compile callsites (\n#122225\n)\nClean up for removing 2 decompose patterns (\n#123422\n)\nCodegen runtime asserts in Inductor (\n#124874\n)\nCustomize pre grad and post grad patterns (\n#121915\n)\nDisallow fusions of foreach and reductions (\n#127048\n)\nEnable\nlowering of qlinear-binary(-unary) fusion for X86Inductor (\n#122593\n)\nmmaped weights when CUDA is used (\n#124346\n)\nmeta internal AOTInductor compilation on ROCM (\n#124123\n)\nEnhance RecordFunctionFast input args and use input args in triton_heuristics.py (\n#123459\n)\nFilter non input symexprs from codecache guards (\n#128052\n)\nGet PT2 Cutlass backend working under fbcode (\n#125688\n)\nHipifying aoti code_wrapper (\n#124241\n)\nImprove group batch fusion with same parent/users fusion enablement (\n#127648\n)\nInductor respects strides for custom ops by default (\n#126986\n)\nInitial implementation of Inductor FX Graph Remote Cache (\n#124669\n)\nMake\ntorch._inductor.dependencies.Dep a proper class (\n#124407\n)\nc10/util ostream function implementations to their headers (\n#123847\n)\nsome cudagraphs checks into C++ (\n#122251\n)\nPass triton kernel info to record function (\n#123871\n)\nRead the patterns from the config instead of hard-code passes (\n#125136\n)\nRemove\nAPI that allows for extra deferred runtime asserts during lowering (\n#124864\n)\nassertion for cat target_func (\n#125540\n)\nSerialize large weights (\n#123002\n)\nSpecialize on unguarded alignment of example inputs (\n#123319\n)\nSplit cat customization (\n#123045\n)\nSupport\nCUDA_INC_PATH env variable when compiling extensions (\n#126808\n)\ncustom op in JIT with cpp wrapper (\n#122554\n)\npytrees as associative_scan input (\n#122137\n)\nuse_runtime_constant_folding for CPU (\n#122563\n)\nTry to reuse old symbol name rather than new symbol name when renaming (\n#124782\n)\nUpdate the cpp_wrapper entry function signature (\n#121745\n)\nUse source code hash instead of torch version (\n#126092\n)\nVarious improvements to error handling during autotuning (\n#126847\n)\nbatch pointwise op + unbind stack pass in post grad (\n#126959\n)\nconfig target platform (\n#126306\n)\ndisable comprehensive padding in fbcode (\n#124191\n)\nenable software pipelining on AMD devices (\n#125858\n)\nepilogue support for gemm template (\n#126019\n)\nmake mask_rcnn inference work in max-autotune mode (\n#123008\n)\npt2 dper passes: run shape prop before each pass (\n#122451\n)\nremove 2 decompose patterns (\n#123371\n)\nswitch assume_aligned_inputs to False (\n#124336\n)\nunified the vectorized conversion with at::vec::convert for all data types (\n#119979\n)\njit\nShape function fix for _batch_norm_with_update (\n#122430\n)\nAttach target function to OSError when source can't be found (\n#125248\n)\nSupport getattr/hasattr on NamedTuple (\n#121863\n)\nONNX\nAllow fake models to run with ONNXProgram.\ncall\n(\n#122230\n)\nFix ONNX export with print (\n#123368\n)\nImprove torch.onnx.export runtime from O(n^2) to O(n) (\n#123025\n,\n#123027\n,\n#123063\n,\n#124909\n,\n#123028\n,\n#123028\n,\n#123029\n,\n#123026\n,\n#124912\n)\nMake ONNXProgram.model_proto and disk file the same (\n#122196\n)\nSkip optimizer when it fails (\n#127349\n)\nUpdate decomposition table to core ATen ops (\n#127353\n)\nbeartype to emit warning instead of error by default (\n#123205\n)\nMPS\nAdd naive quantized int4_mm, int8_mm and .gputrace capture hooks (\n#125163\n)\nBetter error-check for linear op (\n#124952\n)\nEnable\nindex_select for complex types (\n#122590\n)\ntorch.mm and other ops for complex dtypes (\n#127241\n)\nImplemented isin_Tensor_Tensor_out for MPS backend (\n#124896\n)\nImprove F.adaptive_avg_pool2d error messages on MPS backend (\n#124143\n)\nNative non-zero op implementation (\n#125355\n)\nXPU\nGeneralize host allocator to be device-agnostic(\n#123079\n)\nMake macro with AMP more generic(\n#124050\n)\nRefactor\nCUDAs AMP autocast policy to be generic(\n#124051\n)\ngpu trace to be device-agnostic(\n#121794\n)\nSupport generic Stream/Event on CUDA/HIP backend(\n#125757\n)\nBug fixes\nPython frontend fixes\nDtoH sync in torch.index_put_ (\n#125952\n)\ntorch.load\nmap_location for wrapper subclass and device being serialized through numpy (\n#126728\n)\nmemory leak in torch.dtype.to_complex() (\n#125154\n)\nnn.Parameter constructor type hint (\n#125106\n)\nparameter name in torch.can_cast to from_ (\n#126030\n)\nsupport of paths with space in torch.utils.cpp_extensions (\n#122974\n)\nSupport numpy array in Tensor.\neq\n(\n#122249\n)\nComposability fixes\nFakeTensors, meta tensors and python decompositions are used to perform shape propagation when tracing out a graph in\ntorch.compile. There were a number of bug fixes improvements this release:\nFakeTensor fixes:\nHandle symbolic size access in FakeTensor (\n#124760\n)\nAvoid cuda init in FakeTensorMode (\n#124413\n)\nDo not run CUDA lazy init if it is triggered with fake mode on (\n#122636\n)\nRefactor faketensor ops that produce unbacked symints to memoize (\n#125623\n)\nMeta device fixes:\nfix meta tensor set_() incorrectly modifying nbytes of the storage (\n#123880\n)\nFix aten._weight_int4pack_mm meta registration for float16 inputs (\n#124136\n)\nFixes to python decompositions:\naten.upsample_bicubic2d: support for uint8 (\n#120411\n)\naten.upsample_nearest* ops: properly registered decomp to dispatch keys (\n#122782\n), (\n#122783\n)\n_refs.masked_fill: support privateuse1 device when value.device.type is cpu (\n#124835\n)\n_refs._reshape_view_helper: specialization shortcut for converting n-d to 1-d and 1-d to 2-d views (\n#127641\n)\nFix decomp for torch.tensor(...) constructor with nested python lists(\n#125639\n)\nAten.rrellu_\n: fix decomp when default values are missing (\n#126978\n)\nAOTDispatcher is the component of the\ntorch.compile\nstack that functionalizes and normalizes the graph, and adds\nsupport for compiling the backward during training. There were several bugfixes and improvements to AOTDispatcher:\nFix\ntorch.compile\nused with triton kernels under inference_mode (\n#124489\n)\nFix incorrect graph when functionalizing aten.expand followed by mutation (#122114)\nProperly keep input mutations in the graph when they are under torch.no_grad, even if there are outstanding aliases (#122433)\nReplay original views from the user code instead of falling back to as_strided in a few cases, which can improve\nperformance of the backward pass in cases where\ntorch.compile\ncaptures small graphs with outputs that alias graph inputs (#121007)\nFor\n__torch_dispatch__\n-based tensor subclasses, support custom layout overrides under torch dispatch mode (#125379)\ncuda fixes\ncuda array for empty arrays (#121458)\na perf regression in kernel launcher for the foreach_* family of ops (#123566)\nCUDA out of memory error message formatting (#123984)\nCUblasLt compilation on windows (#125792)\nAutograd frontend fixes\ntorch.utils.checkpoint\n: Use pytrees to improve determination of what RNG state to stash (#121462)\nFix error message of autograd (#123154)\nRelease Engineering fixes\nFix mypy issues in fake_tensor.py (#124428)\nFix running of: lintrunner --all-files --take FLAKE8 (#124771)\nFix libc and libstdcxx installation on conda environments (#121556)\nRelease engineering tooling and CI fixes. Workflows, Trymerge, Bot Labeler, Mergebot (#125042, #121762, #121920, #124965, #122155, #123301, #121733, #127567, #128080)\nnn frontend fixes\naccess to unitialized memory in VSX vector functions for quantized values (#122399)\nswap_tensors\npath in\nnn.Module._apply\nfor modules that inherit from\nRNNBase\n(\nRNN\n,\nGRU\n,\nLSTM\n) (#122800)\nctc_loss\nzero/negative length corner cases (#123193)\n_LazyConvXdMixin.initialize_parameters\nand add related tests (#123756)\nload_state_dict\nwith unexpected key whose prefix matches a valid key (#124385)\nrequires_grad\npropagation in\nnn.utils.parametrize\n(#124888)\nnan\nwith large\nbfloat16\nvalues for\nFlashAttention\nbackend of\nnn.functional.scaled_dot_product_attention\nissue in\naffine_grid_backward\nwhen\ngrad_grid\nis non-contiguous (#124370)\nAdd error checks for invalid inputs on\nthnn_conv2d\n(#121906)(#122135)\nOptim fixes fixes\nWrong ASGD implementation (#125440, #126375)\nloading optimizer options from archive (#125215)\nlinalg fixes\nsvd_lowrank(..., M)\nin the presence of broadcasting (#122681)\nlinalg.vector_norm\nwhen used with\nautocast(cuda)\n(#125175)\nCPP fixes\nHandle all types c10::isSigned (#125637)\ncrash for AVX512 int4 matrix multiplication if weights are unaligned (#124128)\nloading custom C++ extension within DataParallel-ized model (#125404)\nDistributed fixes\nc10d\ncoalescedCollective\nop Flight Recording (#120430)\ngroup_name/group_desc\nset up in eager initialization (#127053)\nbug in\n_update_process_group\nAPI (#128262)\nbug in update_process_group DDP API (#128092)\nexcepthook crash on exit after destroy_process_group (#126739)\nvarious errors in\nTCPStoreLibUvBackend.cpp\n(#127230)\nwork handle for coalescing manager (#122849)\nAdd check gloo availability when doing\n_ProcessGroupWrapper\ncheck (#124233)\nAdd initialize lastEnqueuedSeq_ and lastCompletedSeq_ in ProcessGroupNCCL (#121980)\nEnsured gil is not released when calling to PyBytes (#128212)\nGuarded gpu context during abort (#127363)\nMake monitorThread sleep when we try to dump flight recorder (#123788)\nOnly included NCCL related header file with macro\nUSE_C10D_NCCL\n(#127501)\nPrevented\nwait_tensor()\ncalls on graph inputs from getting DCEd for AsyncCollectiveTensor (#125677)\nDeviceMesh\nhash and eq not match (#123572)\ndevice type issue in\n_get_device_handle\n(#124390)\nEnable cache and reuse of sliced result to prevent funky behaviors and NCCL deadlock at large scale (#122975)\nMake dtype of mesh tensor from\ninit_device_mesh()\nconsistent with directly calling\nDeviceMesh()\n(#123677)\nDistributedDataParallel (DDP)\nDDP\nno_sync\nwhen\nfind_unused_parameters\nis True (#124193)\nDistributed Checkpointing (DCP)\nto remove non_persistent buffer in distributed state dict (#125337)\nset_optimizer_state_dict()\nchanges the parameters with some optimizers (#125708)\nvarious bugs for\nbroadcast_from_rank0\n(#127635)\nRemove the check of FSDP has root (#121544)\nKept params in torch.distributed.checkpoint.state_dict.set_optimizer_state_dict (#127644)\nFullyShardedDataParallel (FSDP)\nFSDP 2D state_dict to use run_check=False (#123802)\nHSDP: sharding placement (#123778), validation error msg (#123019)\nsummon_full_params on submodule (#123290)\nTorchElastic\nMake\ntorch.multiprocessing.ProcessContext.join()\nwait for all child procs to exit before return (#125969)\nProfiler fixes\nan asynchronous trace bug where end timestamp overflows and events are years in the future (#124080)\ntorch.profiler Schedule Function (Function Event only) to accumulate events (#125510)\nAdd a sanity test to the unit testing (#124773)\nAdd missing field device_resource_id in profiler events (#121480)\nCleaned up deprecated use_cuda by default (#126180)\nDo not emit a warning when using CPU profiler only (#125654)\nHandle more cases of symbolic sizes/strides detection (#123696)\nReduced warning msg in torch.profiler when using AMD (#124469)\nRelease gil in prepareProfiler (#121949)\nRemove a redundant *1000 to timestamp since we already have ns precision (#124374)\nSplit up profiler test file (#124856)\nDynamo fixes\n'Could not infer dtype of SymBool' on torch.tensor call (#125656)\n'get_attr' call in dynamo 'run_node' (#127696)\n'get_real_value' on placeholder nodes (#127698)\nassume_constant_result for UnspecializedNNModuleVariable methods (#127695)\nguard_size_oblivious on non-symbolic expression (#123743)\ntvm backend interface (#126529)\nAdd support for tensor's is_complex method (#124927)\nAllow asserts to fail (#126661)\nForward OptimizedModule.\nsetattr\nto the wrapped module (#122098)\nInitial exception handling support in dynamo (#126923)\nKeep track of ViewMeta with symbolic inputs (#125876)\nSupport macOS and Linux/aarch64 platforms (#128124)\nExport fixes\nGraphModuleDeserializer handling of signature (#122342)\nbug in get_update_constraint (#125194)\nconv decomp when decomposing to core-aten (#123283)\nmode not on stack error for while loop (#122323)\nruntime assertions to add call_function (#125878)\nto_copy to be inserted in the exported graph (#125628)\nunflattening with duplicate tensors (#125192)\nup nn_module_stack for nodes occurred around tracepoint ops (#124457)\nleaky fake tensor on attribute assignment, support buffer assignment (#122337)\nAllow Dim(1,2) for export dynamic shapes (v2 after revert) (#121910)\nAllow modules to be created in the forward (#125725)\nCorrectly serialize empty list based on argument type (#123748)\nForward fix failures for torch.export switch to predispatch (#126081)\nHandle param aliasing (#127471, #125509, #125758)\nMake error name private (#126715)\nMore strictly respect scope when removing inputs in unflattener (#127607)\nSkip nn_module_stack verifier for non-fx.GraphModule modules  (#122210)\nFx fixes\nfx graph triton import bug (#122041)\ngraph partitioner and make runtime assertion work with submodules in export (#125793)\ninfinite recursion in API BC test (#125706)\nmem size mismatch from split/chunk in const folding (#125199)\ntriton import time cycles (#122059)\nDon't intersect when clamping for size oblivious (#123675)\nDon't use Proxy torch function in the sym size calls (#121981)\nFakeTensorProp assert consistency of sizes when metadata previously existed (#124059)\nKeep set_() input mutations in the AOTDispatcher graph, ban other cases (#122981)\nMake\ncheck_is_size clamp to sys.maxsize - 1, so sys.maxsize comparison returns False (#122372)\ntorch._check understand Eq commutativity (#125629)\nPreserve\nnode.meta when fusing subgraph (#125261)\npartitioner order (#122111)\nunbacked SymInt on SymNode (#120816)\nRemove\nduplicated nodes in dfs_iter_find_cycle (#125585)\nincorrect check (#123616)\nSkip index_put_ in dce (#122683)\nInductor fixes\nAFOC QPS Regression (#122944)\nC++ compilation error for tensor array in abi_compatible mode\nFakeTensorUpdater logic for updating fake tensors (#116168)\na bool value codegen issue when calling custom ops (#127398)\na bug when mutated buffer meets .to (#127671)\na codegen issue when .item() is used for kernel arg (#126575)\na dynamic shape problem when lowering diagonal (#121881)\nan internal test regression (#123481)\nanother out-of-bounds access (#122580)\ncat backwards wrapping on symints (#121527)\ncompilation_latency regression caused by #127060 (#127326)\nconstant propagation pass (#114471)\ncuda compilation under fbcode remote execution (#126408)\ncummax and cummin lowering for empty case (#126461)\ncutlass path in inductor (#125463)\nedge case in JIT vs. AOT fusion after finalizing MultiTemplateBuffer (#126622)\nincludes to system Python (#125285)\nissue with randint + symbolic shapes (#122428)\nissues in pre_grad passes  (#123181)\nmask propagation in the presence of where (#125574)\nmemory planning compile error (#123867)\nmissing unbacked def for unbacked in input expr (#127770)\nnextafter in inductor CPP codegen (#126876)\nops.scan for non-commutative operators (#126633)\nout-of-bounds read/write in cvt_int64_to_[fp32|int32] (#122511)\nscheduler typehints (#127769)\ntest with inlining flag (#128200)\nto #126656 (#127050)\ntriton codegen main do_bench_gpu import error (#126213)\nunbacked symbol in stride when using item() (#122298)\nunsupported type of output=s1 (#126797)\nScatterFallback codegen (#124580)\na constant tensor device move issue (#128265)\nan assertion for node debug str (#127021)\ngrid z bug for large grid (#127448)\ninvalid call to aoti_torch_tensor_copy_ (#126668)\nlinear_add_bias path (#127597)\nloop ordering test (#127807)\nmiss isa bool check (#128274)\npost_grad pattern (#127457)\nredis-related env vars in remote_cache.py (#127583)\nAdd missing acosh op to vec256_float_neon.h (#122513)\nBack out\n\"Added a check in register_lowering to avoid decomposed ops (#117632)\" (#122709)\n\"Precompile triton templates (#121998)\" (#123305)\nBackport\nhttps://github.com/openai/triton/pull/3433\n(#122470)\nCorrectly calculate the numel with symint in DDP fusion (#124422)\nDisable stack allocation when there is a fallback op (#122367)\nDo not forward parent's value range to CSE variable for variables created within codegen (#123099)\nDo not propogate (#124769)\nDon't clamp slices generated from cat kernel (#124139)\nEnable B019 - flags memory leaks through LRU cache on method (#127686)\nFX graph cache: Fix bug handling constants (#121925)\nFall back to eager mode when viewing with differing bitwidths (#120998, #121786)\nImplement masked_load for integral types (#122608)\nImprove unbacked SymInt input support in Inductor (#124739)\nInductor: fix Conv output stride for dynamic shapes (#121400)\nRemove symbol exports in C shim for Windows (#125472)\nRevert \"Inductor respects strides for custom ops by default (\n#126986\n)\" (#127923)\nUse pexpr, not texpr in Triton launch codegen (#128038)\nturn off triton memcache for amd devices (#122560)\ntyping scheduler.py [1/2]: Bug fix (#126610)\nuse two pass reduction for deterministic reduction order (#115620)\nForward fixes\nfor D56289438 (#124882)\nfor templates + views (#127446)\nONNX fixes\nFix list dtype finding bug in dispatcher (#122327)\nRename ort to maia in dynamo's ort backend (#124967)\nCast checkpoint weights to match model parameter's dtype (#122100)\nReduce excessive warning to info (#122442)\nPrevent dup initializers when ONNXProgram.save is called many times (#122435)\nMPS fixes\nFFT descriptor fields to resolve precision issue (#125328)\nFFT implementation bug dropping negative frequency components (#123274)\nGELU, LeakyRELU and MISH on non-contiguous tensors (#123049)\nabs for complex types (#125662)\ncopies larger than 4GB (#124635)\ncrash with binary_cross_entropy is invoked for half dtypes (#124258)\nfor MPS regression in scalar creation (#123234)\nfor addcdiv contiguous problem (#124442)\nnaive matmul for BFloat16 (#121731)\nnextafter for negative values (#125029)\noverflow in cumsum when dtype is bool (#125318)\nstrided ELU op correctness issue (#125692) and mse_loss correctness issue (#125696)\nFwd-fix for clamp regression (#122148)\nRemove in place views fixing various crashes (#124895)\nXPU fixes\nrecord issue on XPUGuardImpl (#123523)\nPerformance\nPython frontend\nUse sleef on macOS Apple silicon by default (#126509)\ncuda\nSpeed up torch.softmax kernel (#122970)\nnn frontend\nParallelize upsampling ops across the batch/channel dimension (#127082)\nOptim\nAdd fast fused kernels for Adam, AdamW, SGD, and Adagrad on CPU (#123074, #123629, #124905)\nlinalg\nImprovements\nthe CPU performance of\nlinalg.vector_norm\nwhen reducing over a dimension of length 1 (#122143)\nperformance of FP16\ngemv\non ARM (#126297, #126745, #126746, #126877, #127033) and BF16\ngemm\nfallback on ARM (#126592)\nautotuning through\nTunableOp\non ROCm (#124362)\nForeach\nAllow int vals to go down the fastpath for _foreach_max (#127303)\n_foreach_copy\nnow supports different source/dest dtypes on the fast path (#127186)\nDistributed\nC10d\nDisable compute of collective duration by default (#122138)\nDTensor\nUsed str for reduce_op instead of c10d enum (#125172)\nMake early return for\n_split_tensor\n(#125810)\nMake directly return\nlocal_tensor\nunder\nno_grad\n(#128145)\nDistributed Checkpointing (DCP)\nImprove the performance of distributed state_dict (#125501)\nTorchElastic\nChanged\nmonitor_interval\nfor torchelastic default value to 0.1 sec (#124692)\nAdd timing events to different stages of rendezvous (#125636)\njit\nFix exponential memory usage when TorchScript types share the same name (#121874), (#121928)\nFx\nAdd side table to FX Graph for O(1) op/target query (#121565)\nApply guard knowledge to all simplifications (#123342)\nDo not calculate hint in advice_is_size (#124472)\nEnable FX graph and symbolic shape caching (#121697, #125258, #123724, #124610)\nFlatten/Unflatten micro optimization in proxy_tensor.py (#121993)\nMinor compile time optimization in has_free_symbols (#122144)\nSkip assert in check_is_size (#124209)\nTeach ShapeEnv that a <= b => a < b + 1 (#123436)\nUse sympy xreplace instead of subs (#124208)\n_find\nnot update unchanged replacements (#124274)\neval_static: guards, unbacked compute once (#124217)\nInductor\nSpeedup\nconvert<float>(Vectorized<half>::loadu(ptr, 8))\non ARM (#125889)\nAdd more mm kernel choices (#125000)\nAdd NEON ISA support on\narm64 Macs (#122217)\naarch64 (#123584)\nMPS\nImprovements to perf of int4pack_mm (#125983, #127135, #125704)\nMaking copy_cast, softmax and cat_out unranked (#123191)\nXPU\nIntel GPU\nConvolution&Deconvolution aten operators(#117529)\nMatmul aten operators(addmm, badbmm, etc.)(#117202)\nSupport xpu host allocator (#123080)\noneDNN\nConv primitive integration (#117512)\nMatmul primitive integration (#117112)\nlibrary compilation for Intel GPU support (#117098)\nDocumentation\nPython frontend\nAdd doc for\ntorch.distributions.utils.clamp_probs (#128136)\nthe legacy constructor for Tensor (#122625)\ntorch.Size.numel (#124186)\ntorch.utils.benchmark.utils.compare.Compare (#125009)\ntorch.utils.collect_env.get_env_info (#128021)\nClarify Security Policy (#120531)\nFixes doc\nexample of torch.masked_scatter (#123664)\nfor torch.load map_location (#125473)\nImprove doc for\ntorch.set_default_dtype (#121730)\ntorch.load weights_only argument (#127575)\nUpdate doc for\nfunctions in torch.multinomial (#125495)\nfunctions in torch.random (#125265)\ntorch.dot (#125908)\nComposability\nAdd extended debugging options for troubleshooting\ntorch.compile\nissues (#122028)\ncuda\nAdd doc for torch.cuda.nccl.version (#128022)\nAdd documentation for nvtx.range (#121699)\nAutograd frontend\ntorch.autograd.Function\n: update docs for separate context and forward functions (#121955)\ntorch.utils.checkpoint\n: Improve error message when use_reentrant=True is used with .grad() (#125155)\nImprove the clarity of the\ntorch.Tensor.backward\ndoc (#127201)\nFix typing for\ntorch.autograd.Function\nwith ctx-less forward (#122167)\nRelease Engineering\nFix torch and\ntorch.compile\nlinks (#121823, #121824)\nAdd\nfuzzer instructions to pt2 bug template (#123156)\nbetter instructions for pytorchbot merge command on cancel (#124947)\ninstructions on how to run doc coverage locally (#123688)\nnn frontend\nFixes\nKLDiv\nexample (#126857)\ntorch.nn.TripletMarginLoss\nallowing margin less or equal to 0 (#121978)\nexample and typo in\nnn.ChannelShuffle\nand\nnn.PReLU\ndocs (#123959)\nredundant tensor in\nnn.MaxUnpool2d\nexample (#127850)\nwording in\nnn.Linear\ndocstring (#127240)\nImprovements\nNLLLoss\ndocumentation (#127346)\ndocumentation of\ntorch.nn.utils.rnn\n(#123559)\nreturn value documentation for\nnn.Module.load_state_dict\n(#123637)\nthe example description for\ntorch.nn.utils.rnn.pad_sequence\n(#123183)\nUpdate the\nis_causal\nexplanation in the\nnn.functional.scaled_dot_product_attention\ndoc (#127209)\nWarn SDPA users about dropout behavior (#126294)\nOptim\nDocument complex optimizer semantic behavior (#121667)\nAdd missing parameter doc of Adagrad (#125886)\nlinalg\nImprove docs on the sorting of\neig\n/\neigvals\n(#127492)\nDistributed\nc10d\nAdd\na doc page for NCCL ENVs (#128235)\nmigration notes for --local-rank option style change for torchrun for PyTorch 2.0 onwards (#109480)\nDocuments\n'tag' limitation for nccl send/recv (#125278)\ndestroy_process_group\nusage (#122358)\nFixes\nexample in\ntorch.distributed.new_subgroups\ndocstring (#123492)\nthe document of\ndistributed.new_group()\n(#122703)\nDistributed Checkpointing (DCP)\nCorrected typos in assert (#122633)\nDTensor\nAdd comment on replicate -> partial for _NormPartial (#121976)\nUpdated public API docs for DTensor (#127340)\nFullyShardedDataParallel (FSDP)\nRemove excessive warnings and rewrite FSDP docstrings (#123281)\nFix docs for inter/intra node PG helpers (#126288)\nUpdated docstring to include\ndevice_mesh\narg (#126589)\nProfiler\nUpdated PT2+Profiler docs (#122272)\nExport\nFix documentation for register_fake_class (#126422)\nFx\nDocument for add_var_to_val (#121850)\nDynamo\nAdd a Dynamo deepdive to documentation (#122305)\nUpdate compile doc to suggest Module.compile (#123951)\nFixes\nlinks rendering when surrounding code in Dynamo deepdive (#123427)\nthe link to torch.compiler_custom_backends (#125865)\ntypos in torch._dynamo.config.py (#126150)\nNumPy + backward example (#126872)\nInductor\nFix aoti doc to avoid cannot bind non-const lvalue reference error (#121672)\ndocumentation for pattern_matcher.py (#127459)\nONNX\nFix pytorch version for onnx in doc (#124182)\nAdd docstring to masked_fill, expand, select, unsqueeze, cat fns (#128055)\nDocumenting torch.onnx.operator.shape_as_tensor (#128051)\nInit sigmoid comments (#127983) (edited)\nXPU\nPyTorch 2.4 XPU Getting Started (#127872)\nUpdate Intel GPU Support on README (#126001)\nTensor (#126383 #127280)\nStream (#121398)\nAMP (#127276 #127278)\ntorch.compile\nwith XPU support (#127879)\nDevelopers\nComposability\ncpu_fallback for aten::triu_indices on custom device crash (#121306)\nAPI to check whether running in torch_dispatch mode (#122339)\nclarify c10::Dispatcher kernel static asserts (#124519)\nRelease Engineering\nTD (target determination) reorders tests in CI based on heuristics and\nremoves tests it believes to be irrelevant to the changes in the PR.\n(#121835, #121836, #122279, #122615, #122901, #124082, #122976, #125931)\ntorchbench on-demand test workflow (#122624).\nBE: Ruff lint improvements (#124743, #124570)\nability to save TORCH_COMPILE_DEBUG logs for CI failures (#124408)\nfreezing option for cpu inductor accuracy test in inductor CI (#124715)\nOptim\nModify device check in capturable optimizer to support more devices (#124919)\nImprove typing and error messages in LRScheduler (#125556, #127943, #121633, #125161)\nOnly initialize state if needed in SGD (#123757)\nExempt\ntorch.compile\nfrom more checks in Adamax (#123498)\nMerged the pyi files into py files of optimizer (#125153, #125452)\nTighten fallback conditions for compiled optimizer (#125825)\nDistributed\nc10d\nUpdated error message for sparse all-reduce (#121644)\nAdd\ngeneric scuba logging capability into c10d (#121859)\nlog the target of Flight Recorder dump (#122345)\nthe source rank in the logs when detecting the timeout (#122850)\nmore fields for periodic logging (#123860)\npg_name\nand\npg_desc\nto logger (#126409)\nWork's numel to logger for debugging purposes (#127468)\nAllow user to pass process group description for ProcessGroupNCCL (#123472)\nPrint the duration of the broadcast  of\nncclunique_id\n(#123963)\nPass and recorded\nprocess_group_name\nwhen creating ProcessGroupNCCL (#123117)\nPass pg name and desc to NCCL communicator (#124149)\nMake only PG0 should dump when monitoring thread timed out (#125356)\nsplit seq_id to\ncollective_seq_id\nand\np2p_seq_id\n(#125727)\nPrint certain logs only on the head rank of each node (#125432)\nMake warn env vars only once during program (#127046)\nDTensor\nAdd some initial c10d ops to\nCommDebugMode\n(#125475)\nRemove unused failed_reason (#126710)\nAdd\nall_reduce_coalesced\ntracing to CommDebugMode (#127025)\nDistributed Checkpointing (DCP)\nadditional logging for improved observability in DCP (#121352)\nFullyShardedDataParallel (FSDP)\nRemove unnecessary warnings (#126365)\nwarnings on wrapping\nModuleList\n/\nModuleDict\n(#124764)\nMiscellaneous\nRemove dist_ prefix from TORCH_LOGS shortcuts (#126499)\nMake torch.distributed.breakpoint() to work under Python/Meta contexts (#118645)\nTorchElastic\nMake log directory creation idempotent (#126496)\nFx\nSuggest TORCHDYNAMO_EXTENDED_DEBUG_ envvars when appropriate (#122473)\nInductor\naoti_torch_item\nas a util function (#126352)\nmodel_type and global_rank for the scuba log for the dashboard Optimus pattern frequency monitor (#123398)\nChange the log for the group batch fusion (#122245)\nDo not use\nimportlib.load_module\n(#122542)\nEnable FX graph caching on another round of inductor tests (#121994)\nImproves\nexception typing. Remove NOQAs (#125535)\ngenerate_extern_kernel_out's signature (#123351)\nlogging (#122932)\nthe optimus scuba log (#122361)\nMisc refactors (#126945)\nOnly print bw result for the first time we benchmark a kernel (#123568)\nRefactor\nMultiOutput. codegen_list_tuple_access to use subclass type checks (#121662)\nindexing() into triton.py\npart of\nIterationRangesEntry\ninto triton.py (#126944)\nsome fallback op util functions (#126182)\nis_legacy_abi_kernel and abi_compatible_kernel (#121523)\nRenamed\nmutationlayout\n/\naliasedlayout\n(#122474)\nUnify val_to_arg_str and val_to_cpp_arg_str (#126916)\nUpdate\nDTYPE_TO_CPP\nmapping (#126915)\nopinfo\ntests (flattened diff) (#124657)\ntensor_converter util functions (#121743)\ntriton pin (#121268)\nUse C++17 helper templates (#122607)\ndelete inductor\nconfig.trace.compile_profile\n(#127143)\nlog pt2 config dict to signpost from inductor post grad (#124593)\nrefactor\ncode to use define_kernel and call_kernel similar to CUDA (#123704)\ndevice dispatch inside\ndo_bench\n(#125736)\nMPS\nReorganize logics and naming in copy.mm (#123310)\nPointer to the non-zero limit ticket#124244\nIntroduce MetalShaderLibrary class (#125550)\nInclude MPSGraphVenturaOps.h for complex types on macOS12 (#127859)\nDefine _compute_tolerances  (#121754)\nXPU\nSupport general device runtime Interface for Intel GPU (#121883)\nEnable triton installation for Intel GPU (\n#122254\n)\nReuse inductor test for Intel GPU  (#122866, #124147)\nUpdate Intel triton for Pytorch 2.4 release (#128615)\nSupport reduction split for Intel GPU (#129337)\ncall empty_cache for dynamo tests (#126377)\nSupport xpu autocast policy (#124052)\nSecurity\nPython frontend\nwarning for weights_only (\n#129239\n,\n#129396\n,\n#129509\n) (see Deprecations section)\nRelease Engineering\nVulnerability related updates of packages used in CI (#124614, #124675, #124976, #124983, #125698, #126805, #126989)",
    "crawl_status": "success"
  },
  {
    "library_name": "PyTorch",
    "url": "https://github.com/pytorch/pytorch/releases/tag/v2.0.0",
    "version": "v2.0.0",
    "title": "Release PyTorch 2.0: Our next generation release that is faster, more Pythonic and Dynamic as ever 路 pytorch/pytorch 路 GitHub",
    "release_date": "2023-03-15T19:38:58Z",
    "content": "PyTorch 2.0 Release notes\nHighlights\nBackwards Incompatible Changes\nDeprecations\nNew Features\nImprovements\nBug fixes\nPerformance\nDocumentation\nHighlights\nWe are excited to announce the release of PyTorch庐 2.0 (\nrelease note\n) which we highlighted during the\nPyTorch Conference\non 12/2/22! PyTorch 2.0 offers the same eager-mode development and user experience, while fundamentally changing and supercharging how PyTorch operates at compiler level under the hood with faster performance and support for Dynamic Shapes and Distributed.\nThis next-generation release includes a Stable version of Accelerated Transformers (formerly called Better Transformers); Beta includes torch.compile as the main API for PyTorch 2.0, the scaled_dot_product_attention function as part of torch.nn.functional, the MPS backend, functorch APIs in the torch.func module; and other Beta/Prototype improvements across various inferences, performance and training optimization features on GPUs and CPUs. For a comprehensive introduction and technical overview of torch.compile, please visit the 2.0\nGet Started page\n.\nAlong with 2.0, we are also releasing a series of beta updates to the PyTorch domain libraries, including those that are in-tree, and separate libraries including TorchAudio, TorchVision, and TorchText. An update for TorchX is also being released as it moves to community supported mode. More details can be found in this\nlibrary blog\n.\nThis release is composed of over 4,541 commits and 428 contributors since 1.13.1. We want to sincerely thank our dedicated community for your contributions. As always, we encourage you to try these out and report any issues as we improve 2.0 and the overall 2-series this year.\nSummary:\ntorch.compile is the main API for PyTorch 2.0, which wraps your model and returns a compiled model. It is a fully additive (and optional) feature and hence 2.0 is 100% backward compatible by definition.\nAs an underpinning technology of torch.compile, TorchInductor with Nvidia and AMD GPUs will rely on OpenAI Triton deep learning compiler to generate performant code and hide low level hardware details. OpenAI Triton-generated kernels achieve performance that's on par with hand-written kernels and specialized cuda libraries such as cublas.\nAccelerated Transformers introduce high-performance support for training and inference using a custom kernel architecture for scaled dot product attention (SPDA). The API is integrated with torch.compile() and model developers may also use the\nscaled dot product attention\nkernels directly by calling the new scaled_dot_product_attention() operator.\nMetal Performance Shaders (MPS) backend provides GPU accelerated PyTorch training on Mac platforms with added support for Top 60 most used ops, bringing coverage to over 300 operators.\nAmazon AWS optimize the PyTorch CPU inference on AWS Graviton3 based\nC7g instances\n. PyTorch 2.0 improves inference performance on Graviton compared to the previous releases, including improvements for Resnet50 and Bert.\nNew prototype features and technologies across TensorParallel, DTensor, 2D parallel, TorchDynamo, AOTAutograd, PrimTorch and TorchInductor.\nStable\nBeta\nPrototype\nPlatform Changes\nAccelerated PT 2 Transformers\ntorch.compile\nDTensor\nCUDA support for 11.7 & 11.8 (deprecating CUDA 11.6)\nPyTorch MPS Backend\nTensorParallel\nPython 3.8 (deprecating Python 3.7)\nScaled dot product attention\n2D Parallel\nAWS Graviton3\nFunctorch\nTorch.compile (dynamic=True)\nDispatchable Collectives\ntorch.set_default_device and torch.device as context manager\nX86 quantization backend\nGNN inference and training performance\n*To see a full list of public 2.0, 1.13 and 1.12 feature submissions click\nhere\nBackwards Incompatible Changes\nDrop support for Python versions <= 3.7 (\n#93155\n)\nPreviously the minimum supported version of Python for PyTorch was 3.7. This PR updates the minimum version to require 3.8 in order to install PyTorch. See\nHardware / Software Support\nfor more information.\nDrop support for CUDA 10 (\n#89582\n)\nThis PR updates the minimum CUDA version to 11.0. See the\ngetting-started\nfor installation or\nbuilding from source\nfor more information.\nGradients are now set to\nNone\ninstead of zeros by default in\ntorch.optim.*.zero_grad()\nand\ntorch.nn.Module.zero_grad()\n(\n#92731\n)\nThis changes the default behavior of\nzero_grad()\nto zero out the grads by setting them to\nNone\ninstead of zero tensors. In other words, the\nset_to_none\nkwarg is now\nTrue\nby default instead of\nFalse\n. Setting grads to\nNone\nreduces peak memory usage and increases performance. This will break code that directly accesses data or does computation on the grads after calling\nzero_grad()\nas they will now be\nNone\n. To revert to the old behavior, pass in\nzero_grad(set_to_none=False)\n.\n1.13\n2.0\n>\n>>\nimport\ntorch\n>\n>>\nfrom\ntorch\nimport\nnn\n>\n>>\nmodule\n=\nnn\n.\nLinear\n(\n2\n,\n22\n)\n>\n>>\ni\n=\ntorch\n.\nrandn\n(\n2\n,\n2\n,\nrequires_grad\n=\nTrue\n)\n>\n>>\nmodule\n(\ni\n).\nsum\n().\nbackward\n()\n>\n>>\nmodule\n.\nzero_grad\n()\n>\n>>\nmodule\n.\nweight\n.\ngrad\n==\nNone\nFalse\n>\n>>\nmodule\n.\nweight\n.\ngrad\n.\ndata\ntensor\n([[\n0.\n,\n0.\n],\n        [\n0.\n,\n0.\n]])\n>\n>>\nmodule\n.\nweight\n.\ngrad\n+\n1.0\ntensor\n([[\n1.\n,\n1.\n],\n        [\n1.\n,\n1.\n]])\n>\n>>\nimport\ntorch\n>\n>>\nfrom\ntorch\nimport\nnn\n>\n>>\nmodule\n=\nnn\n.\nLinear\n(\n5\n,\n5\n)\n>\n>>\ni\n=\ntorch\n.\nrandn\n(\n2\n,\n5\n,\nrequires_grad\n=\nTrue\n)\n>\n>>\nmodule\n(\ni\n).\nsum\n().\nbackward\n()\n>\n>>\nmodule\n.\nzero_grad\n()\n>\n>>\nmodule\n.\nweight\n.\ngrad\n==\nNone\nTrue\n>\n>>\nmodule\n.\nweight\n.\ngrad\n.\ndata\nAttributeError\n:\n'NoneType'\nobject\nhas\nno\nattribute\n'data'\n>\n>>\nmodule\n.\nweight\n.\ngrad\n+\n1.0\nTypeError\n:\nunsupported\noperand\ntype(\ns\n)\nfor\n+\n:\n'NoneType'\nand\n'float'\nUpdate\ntorch.tensor\nand\nnn.Parameter\nto serialize all their attributes (\n#88913\n)\nAny attribute stored on\ntorch.tensor\nand\ntorch.nn.Parameter\nwill now be serialized. This aligns the serialization behavior of\ntorch.nn.Parameter\n,\ntorch.Tensor\nand other tensor subclasses\n1.13\n2.0\n# torch.Tensor behavior\n>\n>>\na\n=\ntorch\n.\nTensor\n()\n>\n>>\na\n.\nfoo\n=\n'hey'\n>\n>>\nbuffer\n=\nio\n.\nBytesIO\n()\n>\n>>\ntorch\n.\nsave\n(\na\n,\nbuffer\n)\n>\n>>\nbuffer\n.\nseek\n(\n0\n)\n>\n>>\nb\n=\ntorch\n.\nload\n(\nbuffer\n)\n>\n>>\nprint\n(\na\n.\nfoo\n)\nhey\n>\n>>\nprint\n(\nb\n.\nfoo\n)\nAttributeError\n:\n'Tensor'\nobject\nhas\nno\nattribute\n'foo'\n# torch.nn.Parameter behavior\n>\n>>\na\n=\nnn\n.\nParameter\n()\n>\n>>\na\n.\nfoo\n=\n'hey'\n>\n>>\nbuffer\n=\nio\n.\nBytesIO\n()\n>\n>>\ntorch\n.\nsave\n(\na\n,\nbuffer\n)\n>\n>>\nbuffer\n.\nseek\n(\n0\n)\n>\n>>\nb\n=\ntorch\n.\nload\n(\nbuffer\n)\n>\n>>\nprint\n(\na\n.\nfoo\n)\nhey\n>\n>>\nprint\n(\nb\n.\nfoo\n)\nAttributeError\n:\n'Parameter'\nobject\nhas\nno\nattribute\n'foo'\n# torch.Tensor subclass behavior\n>\n>>\nclass\nMyTensor\n(\ntorch\n.\nTensor\n):\n...\npass\n>>\n>\na\n=\nMyTensor\n()\n>\n>>\na\n.\nfoo\n=\n'hey'\n>\n>>\nprint\n(\na\n.\nfoo\n)\nhey\n>\n>>\nbuffer\n=\nio\n.\nBytesIO\n()\n>\n>>\ntorch\n.\nsave\n(\na\n,\nbuffer\n)\n>\n>>\nbuffer\n.\nseek\n(\n0\n)\n>\n>>\nb\n=\ntorch\n.\nload\n(\nbuffer\n)\n>\n>>\nprint\n(\nb\n.\nfoo\n)\nhey\n# torch.Tensor behavior\na\n=\ntorch\n.\nTensor\n()\na\n.\nfoo\n=\n'hey'\n>\n>>\nbuffer\n=\nio\n.\nBytesIO\n()\n>\n>>\ntorch\n.\nsave\n(\na\n,\nbuffer\n)\n>\n>>\nbuffer\n.\nseek\n(\n0\n)\n>\n>>\nb\n=\ntorch\n.\nload\n(\nbuffer\n)\n>\n>>\nprint\n(\na\n.\nfoo\n)\nhey\n>\n>>\nprint\n(\nb\n.\nfoo\n)\nhey\n# torch.nn.Parameter behavior\n>\n>>\na\n=\nnn\n.\nParameter\n()\n>\n>>\na\n.\nfoo\n=\n'hey'\n>\n>>\nbuffer\n=\nio\n.\nBytesIO\n()\n>\n>>\ntorch\n.\nsave\n(\na\n,\nbuffer\n)\n>\n>>\nbuffer\n.\nseek\n(\n0\n)\n>\n>>\nb\n=\ntorch\n.\nload\n(\nbuffer\n)\n>\n>>\nprint\n(\na\n.\nfoo\n)\nhey\n>\n>>\nprint\n(\nb\n.\nfoo\n)\nhey\n# torch.Tensor subclass behavior\n>\n>>\nclass\nMyTensor\n(\ntorch\n.\nTensor\n):\n...\npass\n>>\n>\na\n=\nMyTensor\n()\n>\n>>\na\n.\nfoo\n=\n'hey'\n>\n>>\nprint\n(\na\n.\nfoo\n)\nhey\n>\n>>\nbuffer\n=\nio\n.\nBytesIO\n()\n>\n>>\ntorch\n.\nsave\n(\na\n,\nbuffer\n)\n>\n>>\nbuffer\n.\nseek\n(\n0\n)\n>\n>>\nb\n=\ntorch\n.\nload\n(\nbuffer\n)\n>\n>>\nprint\n(\nb\n.\nfoo\n)\nhey\nIf you have an attribute that you don't want to be serialized you should not store it as an attribute on tensor or Parameter but instead it is recommended to use\ntorch.utils.weak.WeakTensorKeyDictionary\n>\n>>\nfoo_dict\n=\nweak\n.\nWeakTensorKeyDictionary\n()\n>\n>>\nfoo_dict\n[\na\n]\n=\n'hey'\n>\n>>\nprint\n(\nfoo_dict\n[\na\n])\nhey\nAlgorithms\n{Adadelta, Adagrad, Adam, Adamax, AdamW, ASGD, NAdam, RAdam, RMSProp, RProp, SGD}\ndefault to faster\nforeach\nimplementation when on CUDA + differentiable=\nFalse\nWhen applicable, this changes the default behavior of\nstep()\nand anything that calls into\nadadelta(...)\n,\nadagrad(...)\n,\nadam(...)\n,\nadamax(...)\n,\nadamw(...)\n,\nasgd(...)\n,\nnadam(...)\n,\nradam(...)\n,\nrmsprop(...)\n,\nrprop(...)\n,\nsgd(...)\ndirectly to use the\nforeach\nimplementation instead of the for-loop for better performance. However, this change can potentially be backward incompatible since there may be small numerical differences between the results computed with the\nforeach\nimplementation and the previous default. The foreach implementation will be the default only if the following conditions are met.\nThe user has not specified kwargs relating to implementation (\nforeach\n,\nfused\n, or\ndifferentiable\n),\nAll tensors are native tensors (not subclasses) and on CUDA,\ntorch.jit.is_scripting\nis\nFalse\n.\nWhen these conditions are satisfied, the implementation used will match the implementation used when one passes\nforeach=True\n. The user defined flag for\nforeach\nwill NOT be overwritten in order to preserve user selections. For more details, check the\ndocumentation\n. There should be no significant differences between the results returned by these optimizers. To revert to the old behavior, say, for\nadam\n, pass in\nadam(..., foreach=False, ...)\nor initialize\nAdam\nwith\nAdam(..., foreach=False, ...)\n.\nPull Requests:\n#92306\n,\n#92716\n,\n#92723\n,\n#92724\n,\n#92726\n,\n#92727\n,\n#92728\n,\n#92715\n,\n#91896\n,\n#92730\n,\n#90865\n,\n#93184\n,\n#92181\n,\n#92923\n,\n#95415\n,\n#95818\n,\n#95811\ntorch.nn.utils.stateless.functional_call\nnow respects tied weights (\n#90477\n)\nAssume a module has two tied weights, x and x_tied. Previously, invoking\nfunctional_call(module, parameters_and_buffers, args, kwargs=None, *, strict=False)\nwith a parameter dictionary of only one of the tied weights would result in the other one(s) not being updated.\nWeve changed the behavior so that providing one of the tied weights in the parameter dictionary will update all other tied weights. If you would like the behavior in previous versions of PyTorch, please set\ntie_weights=False\n.\nPlease also see the related deprecation section \"torch.nn.stateless.functional_call in favor of torch.func.functional_call\".\n1.13\n2.0\n>\n>>\nclass\nFoo\n(\nnn\n.\nModule\n):\n...\ndef\n__init__\n(\nself\n):\n...\nsuper\n().\n__init__\n()\n...\nself\n.\nx\n=\nnn\n.\nParameter\n(\ntorch\n.\nzeros\n([]))\n...\nself\n.\nx_tied\n=\nself\n.\nx\n...\n...\ndef\nforward\n(\nself\n,\ninp\n):\n...\nreturn\nself\n.\nx\n+\nself\n.\nx_tied\n>\n>>\nfoo\n=\nFoo\n()\n>\n>>\nparams\n=\n{\n'x'\n:\ntorch\n.\nones\n([])}\n>\n>>\nresult\n=\nfunctional_call\n(\nfoo\n,\nparams\n,\ntorch\n.\nrandn\n([]))\n>\n>>\nprint\n(\nresult\n)\n1.0\n>\n>>\nclass\nFoo\n(\nnn\n.\nModule\n):\n...\ndef\n__init__\n(\nself\n):\n...\nsuper\n().\n__init__\n()\n...\nself\n.\nx\n=\nnn\n.\nParameter\n(\ntorch\n.\nzeros\n([]))\n...\nself\n.\nx_tied\n=\nself\n.\nx\n...\n...\ndef\nforward\n(\nself\n,\ninp\n):\n...\nreturn\nself\n.\nx\n+\nself\n.\nx_tied\n>\n>>\nfoo\n=\nFoo\n()\n>\n>>\nparams\n=\n{\n'x'\n:\ntorch\n.\nones\n([])}\n>\n>>\nresult\n=\nfunctional_call\n(\nfoo\n,\n...\nparams\n,\n...\ntorch\n.\nrandn\n([]),\n...\ntie_weights\n=\nFalse\n)\n>\n>>\nprint\n(\nresult\n)\n1.0\nRequire\nreturn_complex\nto be passed explicitly to\ntorch.stft\nfor real input (\n#86724\n)\ntorch.stft\ntakes an optional return_complex parameter that indicates whether the output should be a floating point tensor or a complex tensor.\nreturn_complex\npreviously defaulted to False for real input tensors. This PR removes the default and makes\nreturn_complex\na required argument for real inputs. However, complex inputs will continue to default to\nreturn_complex=True\n.\n1.13\n2.0\n>\n>>\na\n=\ntorch\n.\nrand\n(\n1024\n)\n>\n>>\n_\n=\ntorch\n.\nstft\n(\na\n,\nn_fft\n=\n128\n)\n>\n>>\nt\n=\ntorch\n.\nrand\n(\n1024\n)\n>\n>>\n_\n=\ntorch\n.\nstft\n(\nt\n,\nn_fft\n=\n128\n,\nreturn_complex\n=\nFalse\n)\nRequire inputs to\ntorch.istft\nto be complex valued\ntorch.istft\nno longer supports input in the form of real tensors\nwith shape\n(..., 2)\nto mimic complex tensors. Instead, convert\ninputs to a complex tensor first before calling\ntorch.istft\n.\n1.13\n2.0\n>\n>>\nt\n=\ntorch\n.\nrand\n(\n65\n,\n33\n,\n2\n)\n>\n>>\n_\n=\ntorch\n.\nistft\n(\nt\n,\nn_fft\n=\n128\n,\nlength\n=\n1024\n)\n>\n>>\nt\n=\ntorch\n.\nrand\n(\n65\n,\n33\n,\n2\n)\n>\n>>\n_\n=\ntorch\n.\nistft\n(\nt\n,\nn_fft\n=\n128\n,\nlength\n=\n1024\n)\nRuntimeError\n:\nistft\nrequires\na\ncomplex\n-\nvalued\ninput\ntensor\nmatching\nthe\noutput\nfrom\nstft\nwith\nreturn_complex\n=\nTrue\n.\n>\n>>\nt_complex\n=\ntorch\n.\nview_as_complex\n(\nt\n)\n>\n>>\n_\n=\ntorch\n.\nistft\n(\nt_complex\n,\nn_fft\n=\n128\n,\nlength\n=\n1024\n)\nChange default behavior of sparse tensor construction to not do component verification(\n#92094\n)\nWe now disable the costly component verification of torch.sparse_coo/csr/csc/bsr/bsc/compressed_tensor by default. The user can use the new\ncheck_invariants\nflag or\ntorch.sparse.check_sparse_tensor_invariants\nto locally enable component verification. This allows users to constrain these costly checks to specific regions of their code and enables better overall performance. Previously users had no access to public constructors that disable these checks.\n1.13\n2.0\n>\n>>\ni\n=\n[[\n0\n,\n1\n,\n1\n],\n         [\n2\n,\n0\n,\n5\n]]\n>\n>>\nv\n=\n[\n3\n,\n4\n,\n5\n]\n>\n>>\ns\n=\ntorch\n.\nsparse_coo_tensor\n(\ni\n,\nv\n, (\n2\n,\n3\n))\nRuntimeError\n:\nsize\nis\ninconsistent\nwith\nindices\n:\nfor\ndim\n1\n,\nsize\nis\n3\nbut\nfound\nindex\n5\n>\n>>\ni\n=\n[[\n0\n,\n1\n,\n1\n],\n         [\n2\n,\n0\n,\n5\n]]\n>\n>>\nv\n=\n[\n3\n,\n4\n,\n5\n]\n>\n>>\ns\n=\ntorch\n.\nsparse_coo_tensor\n(\ni\n,\n...\nv\n,\n...                            (\n2\n,\n3\n),\n...\ncheck_invariants\n=\nTrue\n)\nRuntimeError\n:\nsize\nis\ninconsistent\nwith\nindices\n:\nfor\ndim\n1\n,\nsize\nis\n3\nbut\nfound\nindex\n5\n>\n>>\nwith\ntorch\n.\nsparse\n.\ncheck_sparse_tensor_invariants\n():\n...\ns\n=\ntorch\n.\nsparse_coo_tensor\n(\ni\n,\nv\n, (\n2\n,\n3\n))\n...\nRuntimeError\n:\nsize\nis\ninconsistent\nwith\nindices\n:\nfor\ndim\n1\n,\nsize\nis\n3\nbut\nfound\nindex\n5\nRemove deprecated functionality from\ntorch.testing\nHistorically,\ntorch.testing\nexposed a lot of private and undocumented functionality publicly. The 2.0 release completes the deprecation cycle for the following items and removes them:\nrand\nand\nrandn\n(\n#87970\n)\nget_all_device_types\n(\n#87971\n)\nmultiple dtype getters (\n#87972\n)\nmake_non_contiguous\n(\n#87973\n)\nHooks registered on tensor to always run, even if they are the inputs to\n.grad()\n(\n#85849\n)\nThis is a bug fix. Per the docs, hooks registered to Tensor should fire any time gradients are computed w.r.t. to that tensor. This change corrects the behavior to be consistent with the documentation. See\ndocumentation\nfor more details about backward hooks execution..\n2.0\na\n=\ntorch\n.\ntensor\n(\n1.\n,\nrequires_grad\n=\nTrue\n)\nb\n=\na\n.\nclone\n()\nb\n.\nregister_hook\n(\nhook\n)\n# the hook registered here didn't fire before!\ntorch\n.\nautograd\n.\ngrad\n(\nb\n.\nclone\n(),\ninputs\n=\n(\nb\n,))\ngrad_fn\npost-hooks can always observe the modifications to gradient by any grad_fn pre-hooks or hooks registered to Tensor, even if this is a leaf tensor (\n#85849\n)\nThis corrects the behavior of hooks to be consistent with the documentation in the case where the tensor is a leaf tensor, i.e. the node is a grad accumulator node. See\ndocumentation\nfor more details about backward hooks execution.\n2.0\ndef\nhook\n(\ngrad\n):\n# updates grad\nreturn\ngrad\n*\n3\ndef\nhook2\n(\ngrad_input\n,\ngrad_output\n):\n# Before this change, grad_output would NOT see the x3\nprint\n(\ngrad_output\n)\na\n=\ntorch\n.\ntensor\n(\n1.\n,\nrequires_grad\n=\nTrue\n)\nb\n=\na\n.\nclone\n()\nacc_grad\n=\nb\n.\ngrad_fn\n.\nnext_functions\n[\n0\n][\n0\n]\nacc_grad\n.\nregister_hook\n(\nhook2\n)\nb\n.\nregister_hook\n(\nhook\n)\ntorch\n.\nautograd\n.\nbackward\n(\nb\n.\nclone\n(),\ninputs\n=\n(\na\n,))\n# hook fire\nRemove FSDP\nparams_with_grad\n(\n#87480\n)\nIn FSDP, we used to have an API\nparams_with_grad\nfor users to get parameters which have gradients from the FSDP module. We decided not to expose this helper because it is not a common paradigm.\n1.13\n2.0\nm\n=\nFullyShardedDataParallel\n(\nmodule\n)\nm\n.\nparams_with_grad\n()\nm\n=\nFullyShardedDataParallel\n(\nmodule\n)\nm\n.\nparams_with_grad\n()\n# Runtime error thrown\n# For work-around, users can still do\n[\np\nfor\np\nin\nself\n.\nparameters\n()\nif\np\n.\ngrad\nis\nnot\nNone\n]\nUsers doing wildcard import of torch.distributed.fsdp.fully_sharded_data_parallel will no longer get non-public symbols (\n#87917\n)\nUsers could previously import both public and non-public symbols:\n1.13\n2.0\nfrom\ntorch\n.\ndistributed\n.\nfsdp\n.\nfully_sharded_data_parallel\nimport\n*\nShardingStrategy\n.\nFULL_SHARD\n# Non-public API\nFullyShardedDataParallel\n(\nmodule\n)\n# public API\nfrom\ntorch\n.\ndistributed\n.\nfsdp\n.\nfully_sharded_data_parallel\nimport\n*\nShardingStrategy\n.\nFULL_SHARD\n# Non-public API, this will fail now\nFully\n`Sharded`\nDataParallel\n(\nmodule\n)\n# public API\n...\n# Users can instead\nfrom\ntorch\n.\ndistributed\n.\nfsdp\n.\nfully_sharded_data_parallel\nimport\n(\nFullyShardedDataParallel\n,\nShardingStrategy\n,\n)\nFullyShardedDataParallel\n(\nmodule\n,\nsharding_strategy\n=\nShardingStrategy\n.\nFULL_SHARD\n)\nSignature of FSDP\nauto_wrap_policy\nrelated APIs were changed in (\n#88450\n).\n1.13\n2.0\nlambda_auto_wrap_policy\n(\nm\n,\nunwrapped_params\n=\n...)\ntransformer_auto_wrap_policy\n(\nm\n,\nunwrapped_params\n=\n...)\nsize_based_auto_wrap_policy\n(\nm\n,\nunwrapped_params\n=\n...)\nlambda_auto_wrap_policy\n(\nm\n,\nnonwrapped_numel\n=\n...)\ntransformer_auto_wrap_policy\n(\nm\n,\nnonwrapped_numel\n=\n...)\nsize_based_auto_wrap_policy\n(\nm\n,\nnonwrapped_numel\n=\n...)\nUpdated\nalltoall\nsignature to be consistent with other c10d APIs (\n#90569\n)\nThe keyword argument names have been changed.\n1.13\n2.0\nalltoall\n(\noutput\n=\n...,\ninput\n=\n...)\nalltoall\n(\noutput_tensors\n=\n...,\ninput_tensors\n=\n...)\nRemove unused functions in torch.ao.quantization.fx.utils (\n#90025\n)\nThis commit removes the following unused functions from both the torch.quantization and the\ntorch.ao.quantization namespaces:\ngraph_pretty_str\nget_per_tensor_qparams\nquantize_node\nget_qconv_op\ncreate_qparam_nodes\nnode_return_type_is_int\nis_get_tensor_info_node\nMake\ntorch.ao.quantization.backend_config.BackendConfig\naccept inputs in the right order (\n#90698\n)\nThe existing\nBackendConfig\nfusion pattern uses a \"reversed nested tuple\" format that is unintuitive.\nThis pattern format also complicates the signatures of the user specified \"fuser methods\", which needed to accept arguments in reverse nested order to match\nthe patterns:\n1.13\n2.0\nimport\ntorch\nas\nnn\nimport\ntorch\n.\nao\n.\nnn\n.\nintrinsic\nas\nnni\nfrom\ntorch\n.\nao\n.\nquantization\n.\nbackend_config\nimport\n(\nBackendPatternConfig\n)\ndef\nfuse_linear_relu\n(\nis_qat\n,\nrelu\n,\nbn_conv\n):\n    (\nbn\n,\nconv\n)\n=\nbn_conv\nreturn\nnni\n.\nConvBnReLU2d\n(\nconv\n,\nbn\n,\nrelu\n)\nconfig\n=\n(\nBackendPatternConfig\n((\nnn\n.\nReLU\n, (\nnn\n.\nBatchNorm2d\n,\nnn\n.\nConv2d\n)))\n    .\nset_dtype_configs\n(...)\n    .\nset_fuser_method\n(\nfuse_conv_bn_relu\n)\n    .\nset_fused_module\n(\nnni\n.\nConvBnReLU2d\n)\n)\nbackend_config\n.\nconfigs\n# returns Dict[Pattern, BackendPatternConfig]\ndef\nfuse_linear_relu\n(\nis_qat\n,\nconv\n,\nbn\n,\nrelu\n):\nreturn\nnni\n.\nConvBnReLU2d\n(\nconv\n,\nbn\n,\nrelu\n)\nconfig\n=\n(\nBackendPatternConfig\n((\nnn\n.\nConv2d\n,\nnn\n.\nBatchNorm2d\n,\nnn\n.\nReLU\n))\n    .\nset_dtype_configs\n(...)\n    .\nset_fuser_method\n(\nfuse_conv_bn_relu\n)\n    .\nset_fused_module\n(\nnni\n.\nConvBnReLU2d\n)\n)\n# Or for backward-compatibility\ndef\nfuse_linear_relu\n(\nis_qat\n,\nrelu\n,\nbn_conv\n):\n    (\nbn\n,\nconv\n)\n=\nbn_conv\nreturn\nnni\n.\nConvBnReLU2d\n(\nconv\n,\nbn\n,\nrelu\n)\nconfig\n=\n(\nBackendPatternConfig\n()\n    .\n_set_pattern_complex_format\n((\nnn\n.\nReLU\n, (\nnn\n.\nBatchNorm2d\n,\nnn\n.\nConv2d\n)))\n    .\nset_dtype_configs\n(...)\n    .\nset_fuser_method\n(\nfuse_conv_bn_relu\n)\n    .\nset_fused_module\n(\nnni\n.\nConvBnReLU2d\n)\n)\nbackend_config\n.\nconfigs\n# returns List[BackendPatternConfig]\nMake the AO codebase compliant with the public vs private API guidelines of pytorch\nPublic-API-definition-and-documentation\nIf users were using any of the AO private APIs then these would have to be accessed with a preceding\n_\nto conform with the guidelines.\n1.13\n2.0\nget_observer_dict\n()\n_get_observer_dict\n()\nPull Requests: (\n#86029\n,\n#87515\n,\n#87516\n,\n#87517\n,\n#87518\n,\n#87519\n,\n#88392\n,\n#88394\n,\n#88396\n,\n#88397\n,\n#87521\n,\n#88395\n,\n#87883\n,\n#88399\n,\n#88398\n,\n#86022\n,\n#86023\n,\n#86024\n,\n#86025\n,\n#86026\n,\n#86027\n,\n#86028\n,\n#86030\n,\n#86031\n,\n#86032\n,\n#86033\n,\n#86034\n,\n#86037\n,\n#90315\n,\n#88391\n,\n#90554\n,\n#87520\n)\nRemove overwrite_output_observer and represent the observer constraints for fixed qparams ops through the existing DTypeWithConstraints mechanism (\n#88620\n)\nThis commit removes\noverwrite_output_observer\nand\noverwrite_output_fake_quantize\noverwrite observer settings in the BackendConfig. Instead, we represent the observer constraints for\nfixed qparams ops through the existing DTypeWithConstraints mechanism. Note that, however, to be consistent with other DTypeWithConstraints checks, we no longer throw an error if an incorrect observer is specified, but simply ignore the offending QConfig and log a warning instead. This is the BC-breaking part of the change.\n1.13\nfrom\ntorch\n.\nao\n.\nquantization\n.\nqconfig\nimport\ndefault_qconfig\nfrom\ntorch\n.\nao\n.\nquantization\n.\nquantize_fx\nimport\nprepare_fx\nmodel\n=\nModelWithFixedQParamsOps\n()\nqconfig_mapping\n=\nQConfigMapping\n().\nset_global\n(\ndefault_qconfig\n)\nexample_inputs\n=\n...\nprepare_fx\n(\nmodel\n,\nqconfig_mapping\n,\nexample_inputs\n)\nBefore this commit, running the above leads to an exception because the wrong observers are used for fixed qparams ops. After this commit, the above will only encounter a warning,and the fixed qparams ops will not be quantized. In both cases, switching to\nget_default_qconfig_mapping\nwill cause the fixed qparams ops to be quantized.\nRemove\ntorch.ao.quantization.quantization_patterns\nand\ntorch.ao.quantization.fusion_patterns\n(\n#89872\n)\nThe following classes under the\ntorch.ao.quantization.fx.quantization_patterns\nnamespace are migrated to the\ntorch.ao.quantization.fx.quantize_handler\nnamespace:\nQuantizeHandler\nBinaryOpQuantizeHandler\nCatQuantizeHandler\nConvReluQuantizeHandler\nLinearReLUQuantizeHandler\nBatchNormQuantizeHandler\nEmbeddingQuantizeHandler\nRNNDynamicQuantizeHandler\nDefaultNodeQuantizeHandler\nFixedQParamsOpQuantizeHandler\nCopyNodeQuantizeHandler\nGeneralTensorShapeOpQuantizeHandler\nCustomModuleQuantizeHandler\nStandaloneModuleQuantizeHandler\nThe following classes under the torch.ao.quantization.fx.fusion_patterns namespace are migrated to the torch.ao.quantization.fx.fuse_handler\nnamespace:\nDefaultFuseHandler\nFuseHandler\nRemove public APIs under the\ntorch.ao.quantization.fx.backend_config_utils\nnamespace(\n#89810\n)\nThe following APIs that were mistakenly public under the\ntorch.ao.quantization.fx.backend_config_utils\nnamespace are removed in this commit.\nget_quantize_handler_cls\nget_fusion_pattern_to_fuse_handler_cls\nget_native_quant_patterns\nget_pattern_to_quantize_handlers\n1.13\n2.0\nfrom\ntorch\n.\nao\n.\nquantization\n.\nfx\n.\nbackend_config_utils\nimport\n(\nget_quantize_handler_cls\n,\nget_fusion_pattern_to_fuse_handler_cls\n,\nget_native_quant_patterns\n,\nget_pattern_to_quantize_handlers\n,\n)\nall_quant_patterns\n=\nget_native_quant_patterns\n()\nfrom\ntorch\n.\nao\n.\nquantization\n.\nfx\n.\nquantization_patterns\nimport\n(\n_get_quantize_handler_cls\n,\n_get_pattern_to_quantize_handlers\n,\n)\nfrom\ntorch\n.\nao\n.\nquantization\n.\nfx\n.\nfusion_patterns\nimport\n(\n_get_fusion_pattern_to_fuse_handler_cls\n,\n)\nfrom\ntorch\n.\nao\n.\nquantization\n.\nbackend_config\nimport\n(\nget_native_backend_config\n,\n)\nall_quant_patterns\n=\n_get_pattern_to_quantize_handlers\n(\nget_native_backend_config\n()\n)\nUpdate torch.{slice|select|diagonal|as_strided}_scatter ops to preserve input stride/storage_offset (\n#91029\n)\nThese operators are primarily used by the\nfunctionalization pass\n, used in AOTAutograd. Previously, they would always return contiguous tensors. Now, they return a tensor with the same striding as their first argument.\n1.13\n2.0\n>\n>>\nx\n=\ntorch\n.\nones\n(\n2\n,\n2\n,\n2\n)\n>\n>>\nbase\n=\nx\n[:, :,\n1\n]\n>\n>>\nbase\n.\nstride\n()\n(\n4\n,\n2\n)\n>\n>>\nx\n=\ntorch\n.\nzeros\n(\n2\n,\n2\n,\n2\n)\n>\n>>\nbase\n=\nx\n[:, :,\n1\n]\n>\n>>\nbase\n.\nstride\n()\n(\n4\n,\n2\n)\n>\n>>\ntorch\n.\ndiagonal_scatter\n(\nbase\n,\ntorch\n.\nones\n(\n2\n)).\nstride\n()\n# returns a tensor with same strides as base.\n(\n4\n,\n2\n)\n>\n>>\nx\n=\ntorch\n.\nones\n(\n2\n,\n2\n,\n2\n)\n>\n>>\nbase\n=\nx\n[:, :,\n1\n]\n>\n>>\nbase\n.\nstride\n()\n(\n4\n,\n2\n)\n>\n>>\nx\n=\ntorch\n.\nzeros\n(\n2\n,\n2\n,\n2\n)\n>\n>>\nbase\n=\nx\n[:, :,\n1\n]\n>\n>>\nbase\n.\nstride\n()\n(\n4\n,\n2\n)\n>\n>>\ntorch\n.\ndiagonal_scatter\n(\nbase\n,\ntorch\n.\nones\n(\n2\n)).\nstride\n()\n# returns a contiguous tensor\n(\n2\n,\n1\n)\nRemove ONNX deprecated monkey patches to torch.Graph (\n#94747\n)\nThe Deprecated monkey patches to\ntorch.Graph\n,\ntorch.Block\nand\ntorch.Node\nare removed\nMonkey patches to the classes\ntorch.Graph\n,\ntorch.Block\nand\ntorch.Node\nfrom\ntorch.onnx\nhave been removed. This means the methods\ntorch.Graph.op()\n,\ntorch..Graph.at()\n,\ntorch.Block.op()\n,\ntorch.Graph.constant()\n, and\ntorch.Node.__getitem__\nare no longer available.\nUsers creating custom symbolic functions for the\ntorch.onnx\nexporter can continue to assume the\ng.op()\ninterface for creating an operator in the graph, which is now exposed via the\nGraphContext\nclass. Users should not assume any other methods from the\nGraphContext\nclass other than those defined natively by\ntorch.Graph\nand\n.op()\n.\nCode change to existing symbolic functions is not expected with this change.\nAdd full checker mode in torch.onnx.export (\n#83186\n)\nThis removes boolean value of\nfull_check\nparameter in TORCH API\ncheck_onnx_proto\n, and forces\nfull_check\nwith warning messages if it fails.\nAlso, the API didnt check on types in the graph even with\nfull_check=True\npreviously. With the change, a warning message will show if the graph contains type error.\nC++ API specific BC-Breaking Changes:\nDeleted torch::deploy from PyTorch Core (\n#85953\n)\ntorch::deploy\nhas been migrated to over to\nMultiPy\n. Ongoing development will continue in this repository.\nRemove the use of\nlazy::View\n(\n#87822\n)\nThe view and aliasing infrastructure in lazy tensor core has been deprecated in favor of functionalization.\nRenamed\nc10::fromIntArrayRef\nto\nc10::fromIntArrayRefSlow\nand changed call sites (\n#86235\n)\nThe function has been renamed to more accurately reflect its performance characteristics.\nDeprecations\ntorch.func aka functorch\nWeve deprecated the functorch module in favor of the new torch.func module\nWere excited to announce that, as the final step of upstreaming and integrating functorch into PyTorch, the functorch APIs are now available in the torch.func module. Our function transform APIs are identical to before, but we have changed how the interaction with NN modules work.\nWeve deprecated\nfunctorch._\nfunction transforms (e.g.\nvmap\n,\ngrad\n,\njvp\n) in favor of their identical\ntorch.func._\ncounterparts (\n#92279\n).\nPyTorch has consolidated on\ntorch.func.functional_call\nas the NN module functional API. Please migrate from\nfunctorch.{make_functional, make_functional_with_buffers}\nto it. For more details see this\nGuide\nPlease migrate from\nfunctorch.combine_state_for_ensemble\nto\ntorch.func.stack_module_state\n. For more details see this\nGuide\nWe are no longer supporting functorch.compile (also known as AOTAutograd) as a frontend for compilation in PyTorch; we have integrated AOTAutograd into PyTorchs compilation story. If you are a user, please use\ntorch.compile()\ninstead.\nPython API\nDeprecate TypedStorage, its derived classes, and all of their public methods (\n#85303\n)\nTyped storages have been removed from the C++ side and torch.UntypedStorage is used in place. The use of torch.TypedStorage and all of its subclasses is now deprecated.\n1.13\n2.0\ntensor\n.\nstorage\n()\ntorch\n.\nTypedStorage\n(...)\ntensor\n.\nuntyped_storage\n()\ntorch\n.\nUntypedStorage\n(...)\nIf you need to access individual elements in a storage as a particular dtype, you can simply create a tensor to view it:\ntorch\n.\ntensor\n(\nstorage\n,\ndtype\n=\n...)\nDeprecate\ntensor.mT\n,\ntensor.T\n,\ntensor.mH\n,\ntensor.H\non 0D-tensors (\n#92143\n)\n1.13\n2.0\n>\n>>\na\n=\ntorch\n.\ntensor\n(\n10\n)\n>\n>>\na\n.\nT\n>\n>>\na\n.\nH\n>\n>>\na\n=\ntorch\n.\ntensor\n(\n10\n)\n>\n>>\na\n.\nT\nUserWarning\n:\nTensor\n.\nT\nis\ndeprecated\non\n0\n-\nD\ntensors\n.\nThis\nfunction\nis\nthe\nidentity\nin\nthese\ncases\n.\n>\n>>\na\n.\nH\nUserWarning\n:\nTensor\n.\nH\nis\ndeprecated\non\n0\n-\nD\ntensors\n.\nConsider\nusing\nx\n.\nconj\n().\nAutograd API\nDeprecate decorating classes with torch.no_grad (\n#89522\n)\nDecorating classes with\ntorch.no_grad\nis now deprecated. You should be decorating its functions or methods instead. To preserve the current behavior of class decoration, you can directly decorate the\n__init__\nmethod and nothing else.\n1.13\n2.0\n@\ntorch\n.\nno_grad\n()\nclass\nBlah\n():\npass\nclass\nBlah\n():\n@\ntorch\n.\nno_grad\n()\ndef\n__init__\n(\nself\n):\npass\nLinalg\nRemove the use of overload at::frobenius_norm(const Tensor&) (\n#81762\n)\nIn continuation with the deprecation process from release 1.12 the tensor overload for this function has been removed. This function was not used in the bindings of Pytorch and should not impact users of\ntorch.norm\n.\ntorch.nn API\nCanceling deprecation of\nfunctional.{tanh, sigmoid}\nfunctions (\n#86905\n)\nBoth these ops are heavily used and so will not be removed. Deprecation warnings have been removed.\nDeprecated torch.nn.utils.stateless.functional_call in favor of torch.func.functional_call (\n#92280\n)\nWeve moved torch.nn.stateless.functional_call under the torch.func module to reflect how it is useful for working with nn.Modules in a functional style. As of PyTorch\n2.0\n,\ntorch.func.functional_call\nis a drop-in replacement for\ntorch.nn.stateless.functional_call\nand we will remove\ntorch.nn.utils.stateless.functional_call\nin a future version of PyTorch. However, please note that we did change the default behavior of\ntorch.nn.stateless.functional_call\nin PyTorch 2.0 (see torch.nn.utils.stateless.functional_call now respects tied weights under BC-breaking notes).\nReleng\nDeprecated private API torch._six (\n#94709\n)\nRemoved the Python 2 and 3 compatibility library six and future and torch._six.\n2.0\n# from torch._six import string_classes\nstr\n# from torch._six import int_classes\nint\n# from torch._six import inf, nan\nfrom\ntorch\nimport\ninf\n,\nnan\n# torch._six.string_classes\nstr\nOnnx\nDeprecated Caffe2 ONNX exporter support\n#95071\nUsers must use PyTorch 1.x versions to use Caffe2 ONNX exporter. This capability will be completely removed from PyTorch 2.x series.\nNew Features\ntorch.nn API\nAdd\ntorch.nn.functional.scaled_dot_product_attention()\nto allow writing fast Transformer-like functions and use it to speed up\nnn.Transformer()\n(\n#91362\n,\n#91066\n,\n#90413\n,\n#87312\n,\n#94008\n,\n#89470\n,\n#90776\n,\n#92189\n)\nAdd hooks for\nModule.register_{buffer,module,parameter}\nfunctions (\n#86148\n,\n#87369\n)\nAdd\nModule.full_backward_pre_hook\n(\n#86700\n)\nAdd\nModule.state_dict_pre_hook\n(\n#90435\n)\nAdd\nModule.call_super_init: bool\nflag that can be used to ensure\nModule\ninitialization is properly calling parents\n__init__\n(\n#91819\n)\ntorch.func\nAdd\nfunctorch\nsupport\nfor torch.autograd.Function\n: one is now able to apply function transformations (e.g. vmap, grad, jvp) over torch.autograd.Function. (\n#92023\n,\n#91452\n,\n#91222\n,\n#90037\n,\n#90077\n,\n#90966\n,\n#89860\n,\n#91211\n,\n#92030\n)\nAdd support for linearize a-la\njax.linearize\n(\n#94173\n)\nAdd torch.func.functional_call, a new utility function to work with NN modules. (\n#89213\n)\nAdd torch.func.stack_module_state, a new utility function to help with model ensembling (\n#88850\n)\nCuda\nIntroduce CUDA Device Assertions Infrastructure (\n#84609\n)\nLogcumsumexp\nfor complex dtypes for CUDA (build-time optimized) (\n#94310\n)\nCaching allocator tracing (\n#86241\n)\nAdd Pluggable CUDA allocator backend (\n#86786\n)\nAdd cudaMallocAsync as an alternative backend for the CUDA allocator (\n#82682\n)\nCpp API\nAdd\nset_to_none\nflag for C++ optim endpoint (\n#92989\n)\nNestedTensor API\nAdd support for\ntensor.to()\nfor NestedTensor backend (\n#87146\n)\nAdd backwards support for\ngelu\nand\nrelu\noperators (\n#94776\n)\nAdd support for\ntorch.neg\noperator (\n#88131\n)\nDistributed\nDistributed Tensor (Prototype Release)\nPyTorch\nDistributedTensor\n(DTensor) is a prototyping effort with distributed tensor primitives to allow easier distributed computation authoring in the SPMD (Single Program Multiple Devices) paradigm. The primitives are simple but powerful when used to express tensor distributions with both sharded and replicated parallelism strategies. PyTorch DTensor empowered PyTorch\nTensor Parallelism\nalong with other advanced parallelism explorations. In addition, it also offers a uniform way to save/load state_dict for distributed checkpointing purposes, even when therere complex tensor distribution strategies such as combining tensor parallelism with parameter sharding in FSDP. (\n#88176\n,\n#88177\n,\n#88178\n,\n#88179\n,\n#88551\n,\n#88549\n,\n#88550\n,\n#89800\n,\n#89967\n,\n#89968\n,\n#89991\n,\n#90106\n,\n#90241\n,\n#90449\n,\n#90731\n,\n#90732\n,\n#90733\n,\n#90734\n,\n#90735\n,\n#91756\n,\n#91783\n,\n#91785\n,\n#91801\n,\n#91802\n,\n#92069\n,\n#92197\n,\n#92198\n,\n#92290\n,\n#92611\n,\n#92651\n,\n#92652\n,\n#92677\n,\n#93040\n,\n#93160\n,\n#93306\n,\n#93832\n,\n#93957\n,\n#94517\n,\n#94524\n)\nWe also design and implement Tensor Parallel & 2D Parallel (Tensor Parallel + FSDP) on top of DistributedTensor. (\n#88180\n,\n#89242\n,\n#89467\n,\n#89535\n,\n#89779\n,\n#89878\n,\n#93029\n,\n#93412\n,\n#94421\n,\n#94748\n)\nDistributed Checkpoint\nPyTorch Distributed Checkpointing (DCP) API was first introduced in PyTorch 1.13 and this will be an official prototype release in PyTorch 2.0. The distributed checkpoint API in PT2.0 decouples the storage layer from the checkpoint planning layer. Planner types are introduced to perform the coordination of storage both locally and globally to plan the save/load process. Checkpointing support for FSDP\nsharded_state_dict\nis added as well. (\n#87987\n,\n#88698\n,\n#89256\n,\n#89398\n,\n#89399\n,\n#89501\n,\n#89503\n,\n#89537\n,\n#89542\n,\n#89873\n,\n#89964\n,\n#90212\n,\n#91036\n,\n#91092\n,\n#91209\n,\n#91269\n,\n#92553\n,\n#92705\n,\n#92829\n,\n#92869\n,\n#92933\n,\n#94379\n,\n#94501\n)\nDistributedDataParallel\nEnable DDP for PyTorch 2.0 (\n#87549\n,\n#88523\n,\n#89096\n,\n#88460\n,\n#88480\n,\n#88521\n,\n#94749\n,\n#93162\n,\n#89802\n,\n#92986\n)\nFullyShardedDataParallel\nAdd the option to use the original parameters via\nuse_orig_params=True\nin the FSDP constructor (\n#84911\n)\nEnable the use of TorchDispatch with FSDP (\n#88014\n)\nHybrid Sharded Data Parallel (\n#89915\n)\nEnable FSDP for PyTorch 2.0 (\n#88781\n,\n#89330\n,\n#89523\n)\nDistributed (c10d)\nDispatchable collectives: An improvement to the existing\ninit_process_group\nAPI which changes backend to an optional argument. For users, this feature will allow for code that runs on both GPU and CPU machines without having to change the backend specification. The dispatchability feature will also allow users to perform both GPU and CPU collectives using the same ProcessGroup, as PyTorch will automatically find an appropriate backend for the tensor type (as of PyTorch 2.0, the default is NCCL for CUDA and Gloo for CPU). Existing backend specifications by users will be honored and will not require change (\n#83679\n,\n#83735\n,\n#83810\n,\n#83859\n,\n#83876\n,\n#83916\n,\n#84423\n,\n#86166\n,\n#86368\n,\n#86407\n,\n#86408\n,\n#86409\n,\n#88351\n,\n#88846\n,\n#88889\n,\n#88903\n,\n#89317\n,\n#89318\n,\n#89505\n,\n#89813\n,\n#88330\n,\n#91257\n,\n#91172\n)\nMps\nAdd native support for:\ntorch.nn.functional.group_norm\n(\n#91190\n),\ntorch.var_mean\n(\n#91190\n),\ntorch.nansym\n(\n#93845\n),\ntorch.frac\n(\n#86625\n),\ntorch.signbit\n(\n#87214\n),\ntorch.exp1m\n(\n#87147\n),\ntorch.cumsum\n(\n#88319\n),\ntorch.trace\n(\n#87910\n),\ntorch.nn.Hardswish\n(\n#87952\n),\ntorch.inverse\n(\n#90428\n),\ntorch.floor_divide\n(\n#91126\n),\nunfold\n(\n#91266\n),\nbincount\n(\n#91267\n),\nnonzero\n(\n#91616\n),\nnorm_dtype\nand\ncdist\n(\n#91643\n),\nunique\nand\nunique_consecutive\n(\n#88532\n),\nnan_to_num\n(\n#91110\n),\ntorch.linalg.cross\n(\n#91642\n),\nrandperm\n(\n#91708\n),\ntriangular_solve\n(\n#94345\n),\ngrid_sampler2d\n(\n#94273\n),\nremainder\n(\n#92139\n),\naddr\n(\n#94538\n),\nfmod\n(\n#94722\n),\nrepeat_interleave\n(\n#88649\n),\nsort\nand\nargSort\n(\n#94697\n),\nrange\n(\n#91075\n)\nAdd functions to handle rng and force device synchronization\ntorch.mps.{get_rng_state, set_rng_state, synchronize, manual_seed, seed}\n(\n#94417\n)\nAdd support for the\nmps\ndevice for\ntorch.Generator\n(\n#91348\n)\nAdd\ntorch.int64\nsupport for unary ops (\n#86615\n)\nProfiler\nImprove Memory Profiler(alpha): enhancement to the existing memory profiler that can attribute memory consumptions to activations, gradients, parameters, and optimizer states (\n#86802\n,\n#86853\n,\n#86854\n,\n#86880\n,\n#87006\n,\n#87566\n,\n#87567\n,\n#87568\n,\n#88924\n,\n#88925\n,\n#88926\n,\n#89355\n,\n#89356\n,\n#86355\n,\n#88917\n,\n#87133\n,\n#86753\n,\n#86754\n,\n#87096\n,\n#86909\n,\n#87825\n)\nAdd Linux perf event support in profiler (\n#87866\n,\n#87874\n)\nForeach API\nImplement:\ntorch._foreach_lerp\n(\n#87562\n),\nfused adamw\n(\n#88015\n)\n_foreach_addc\n(div/mul)(_).Tensor (\n#88157\n)\nclamp_min\nclamp_max\n(\n#91384\n)\nadamw\n(\n#88015\n)\nMobile\nAdd XNNPACK Delegate Framework.\nEnable a XNNPACK graph to be built from the torchscript IR and performing checks (\n#86980\n,\n#87128\n,\n#87824\n)\nAdd flatbuffer serialization support (\n#87826\n,\n#87906\n,\n#87907\n,\n#87908\n)\nCreate\nExecutor\nand\nCompiler\nclasses which compiles the XNNPACK graph and preps for execution (\n#88779\n,\n#88778\n,\n#88780\n,\n#89090\n)\nOptimize library includes (\n#88863\n,\n#89231\n)\nAdd Constant Data which will be used in Convolution (\n#89445\n)\nAdd support for better benchmarking\nAdd support in lite_predictor benchmark binary to select event lists and perform benchmarking using Linux perf through Kineto profiler (\n#87876\n)\nList all missing ops at once (\n#94205\n)\nSparse API\nAdd\ntorch.sparse.check_sparse_tensor_invariants\ncontext manager that allows users to opt into more checks at runtime for better debugging. (\n#92094\n)\nAdd\ncheck_invariants\nflag to\ntorch.sparse_coo/csr/csc/bsr/bsc/compressed_tensor\nto allow users to verify components at construction time. (\n#92094\n)\nAdd\nreduce\nflag for CPU to torch.sparse.mm with support for\nsum, mean, amax, amin\n(\n#83727\n)\nOptimizer API\nMake\n{Adadelta, Adagrad, Adamax, AdamW, ASGD, NAdam, RAdam, RProp}\ndifferentiable (\n#86096\n,\n#86258\n,\n#86183\n)\nPublicly expose _LRScheduler to LRScheduler (\n#88503\n)\nDistributions\nAdd a transform for positive-definite matrices. (\n#76777\n)\nSignals\nSet up new module torch.signal.windows (\n#85599\n)\nAdd the Nuttall window to signals/ (\n#90103\n)\nImplement old singal/windows in Python (\n#87082\n,\n#87330\n)\nQuantization\nAdd support for oneDNN backend for server CPU quantized inference (\n#91056\n,\n#88478\n,\n#88665\n,\n#88668\n,\n#88879\n,\n#88923\n,\n#89188\n,\n#91297\n,\n#90262\n,\n#90364\n,\n#91152\n,\n#91153\n,\n#91154\n,\n#91155\n,\n#91934\n,\n#88661\n)\nAdd new x86 backend to be used for quantized CPU inference (\n#91235\n,\n#88799\n)\nVulkan\nAdd Vulkan support for several torch operators:\ntorch.abs\n(\n#87414\n)\ntorch.select\nfor height and width dimensions (\n#94612\n)\nVulkan optimization passes now automatically apply data transfers between the CPU and GPU for input and output tensors (\n#87432\n)\nIf the\nrequires_backend_transfers\nflag of a model is set to\nfalse\n, then input tensors do not to be transferred to the GPU (via\ntensor.gpu()\n) and output tensors do not to be transferred back to the CPU (via\ntensor.cpu()\n) since these transfers are inserted into the model\nTo avoid inserting data transfers into a model, add\nMobileOptimizer.VULKAN_AUTOMATIC_GPU_TRANSFER\nunder\ntorch.utils.mobile_optimizer\nto the\noptimization_blocklist\nargument of\noptimize_for_mobile\n(\n#92081\n)\nROCm\nhipGraph\nsupport for pytorch mainline (\n#88202\n)\nFx\nIntroduce symbolic shape guards (\n#87570\n,\n#90528\n,\n#90665\n,\n#90679\n,\n#90876\n,\n#91058\n,\n#93894\n,\n#94782\n)\nIntroduce a match filter for SubgraphRewriter (\n#86430\n,\n#87998\n,\n#87257\n)\nSupport list-typed args in PatternMatcher (\n#88656\n)\nAdd\nany_chain()\nin operator support (\n#90949\n)\nHave replace_pattern return replaced nodes (\n#90244\n)\nJit\nAllow freezing JIT modules that contain mutable interfaces (\n#86039\n,\n#91020\n)\nApplyLinear-BatchNormNd folding during torch.jit.freeze (\n#86706\n)\nAdd an option to skip loading of debug traces, in order to reduce memory usage (\n#91430\n)\nIntroduce torch.jit._drop function modifier to avoid compiling a method on a non-nn.Module class (\n#93012\n)\nAllow providing a kwargs-like dict of example inputs to torch.jit.trace with the new\nexample_kwarg_inputs\nargument (\n#81623\n,\n#94032\n)\nInclude example input shapes when serializing jit.traced modules to assist with debugging (\n#90744\n)\nBuild\nAdd Ada Lovelace (cuda arch sm8.9) support (\n#87436\n)\nAdd an option to disable TORCH_WARN and TORCH_WARN_ONCE log (\n#87188\n)\nEnable memory map file support for Android, Apple, and CXX (\n#88545\n)\nSupport DNNL_GRAPH_CPU_RUNTIME=TBB build option (\n#87512\n)\nONNX\nVerification tool to find mismatch in model export (\n#89946\n,\n#89807\n,\n#89808\n,\n#89947\n,\n#94648\n)\nCudnn\nAdd an environment variable to skip cudnn version compatibility check (\n#89184\n)\nEnable cuDNN Frontend v8 API by Default (\n#91117\n)\nImprovements\nPython API\nSet std/var correction overloads default value to None (\n#56398\n)\nImplement correction argument in torch.masked.{std,var} (\n#87118\n)\nUpdate\ntorch.squeeze\nto allow squeezing multiple dimensions at once (\n#89017\n)\nAdd support for int32 indices in index/index_put ops (\n#86309\n)\nEnable\nwhere\nto have cpu scalar args (\n#87022\n)\nAdd support for NumPy scalars to\ntorch.tensor.asarray\n(\n#90914\n)\nUpdate opt_einsum to have more reasonable defaults (\n#86985\n)\nImprove error message for\nTensor.set_\nwhen dtypes mismatch(\n#88804\n)\nEnable out variant of\ntorch.max\n(\n#85926\n)\nImplement faster gradient clipping using foreach function (\n#91846\n)\nAutograd API\nAdd backward support for\ntorch.ormqr\n(\n#86800\n)\nPre-hooks registered on tensor are guaranteed to run before pre-hooks registered on grad_fn (\n#85849\n)\nAdd a new overridable method\nsetup_context\n(\n#89859\n,\n#92312\n)\nYou must use override this method if you plan to use your autograd Function with functorch\nIf you choose to override this method,\nforward\nshould no longer take ctx as an input.\nAdd context manager\ntorch.autograd.set_multithreading_enabled\nfor disabling multithreading in the autograd engine (\n#86245\n)\nAdd backward AD support for unary foreach functions (\n#89591\n)\ntorch.nn API\nAdd\nremove_duplicate\nflag to\nModule.named_buffers()\nmethod (\n#84984\n) and\nModule.named_parameters()\n(\n#88090\n)\nAdd kwarg support for\nModule\nforward-pre and forward hooks (\n#89389\n)\nImprove error message for\nTransformer()\nfast path (\n#90783\n) and kernel selection (\n#90783\n)\nAdd support for\ntorch.bf16\nfor\nEmbedding\n(\n#94163\n)\nAdd\nfreeze\nargument to\nEmbedding()\n(\n#86769\n)\nAdd\ntorch.channels_last_3d\nsupport for\nSyncBatchNorm()\n(\n#88401\n)\nAdd\ntorch.bfloat16\nsupport on CPU for\nfunctional.{mish,hardtanh,silu}\n(\n#82460\n)\nAdd support for inputs with different data types for\nLayerNorm()\n(\n#81851\n,\n#88064\n),\nBatchNorm{1,2,3}d()\n(\n#84410\n),\nGroupNorm()\n(\n#89485\n,\n#81852\n,\n#88663\n,\n#92671\n,\n#92668\n)\nImprove printing of\nModuleList()\n(\n#90452\n)\nAdd\ntorch.uint8\nsupport for\nfunctional.interpolate()\non CPU (\n#90771\n)\nMake\nfunctional.max_pool1d\nerror checking consistent between CPU and CUDA (\n#90211\n)\nAdd\nSyncBatchNorm()\nfallback to\nBatchNorm()\nwhen it is used in a non-distributed setting (\n#89706\n)\nAdd channels-last support for\nGroupNorm()\non XPU (\n#87680\n)\nAdd\nis_causal\nkwarg to\nTransformerEncoder()\nlayer (\n#90508\n)\nAdd\nprepend\nargument to\nModule\nhooks to register a hook that will be called before the existing ones (\n#87370\n)\nDistributed\nActivation checkpointing\nReturn\nNone\nfrom\napply_activation_checkpointing\n(\n#87871\n)\nEnable non-reentrant support for\ncheckpoint_sequential\n(\n#86331\n)\nSeparate CPU offload activation to its own wrapper (\n#85459\n)\nDistributedDataParallel\nAdd\nPackedSequence\nsupport when\ndevice_ids\nis specified (\n#86614\n)\nEnable DDP to handle custom dataclass forward outputs (\n#92334\n)\nDistributed (c10d)\nAdd sequence number support for UCC PG (\n#85047\n)\nFullyShardedDataParallel\nDefault to\nBACKWARD_PRE\nfor the backward_prefetch of FSDP (\n#88428\n)\nSkip collective communications for\nNO_SHARD\nin\nclip_grad_norm_\n(\n#89137\n)\nAllow handle training state to be both\nBACKWARD_PRE\nand\nBACKWARD_POST\nin the post-backward assert (\n#89791\n)\nLimit all gather after pre-unshard (\n#89057\n)\nInclude module classes in\nModuleWrapPolicy.__repr__\n(\n#89058\n)\nApply the \"largest\" dtype across all parameters/gradients as defined by PyTorch's type promotion semantics for the total norm returned in\nclip_grad_norm_\nfor low prec grads (\n#90028\n)\nIntroduce\nModuleWrapPolicy\nfor simplicity in FSDP autowrap (\n#88450\n)\nEnable mixed hybrid/non-hybrid sharding strategies (\n#90846\n)\nRe-support model dtype change after FSDP init (\n#91192\n)\nEnable\nuse_orig_params=True\n,\nno_sync\nand mixed precision to work together (\n#91193\n)\nEnable\nsummon_full_params(with_grads=True)\n(\n#85738\n,\n#87314\n)\nAdd\nkeep_low_precision_grads\nsupport when CPU offloading (\n#86495\n)\nConsolidate FSDP\nstate_dict\noffload_to_cpu\nsettings (\n#86211\n)\nAdd\nset_state_dict_type\nAPI to setup\nstate_dict_type\nwithout using context manager (\n#86243\n)\nEnable the support of\nuse_orig_param\nfor FSDPs\noptim_state_dict\n(\n#89898\n,\n#89899\n,\n#89900\n)\nEnable nested FSDP wrapper to use different mixed precision (\n#90523\n)\nEnable input cast skip in MixedPrecision (\n#90620\n)\nPublish\noptim_state_dict\nand\noptim_state_dict_to_load\nfor FSDP (\n#90798\n,\n#91343\n,\n#92744\n,\n#92118\n,\n#92991\n,\n#92992\n,\n#93285\n,\n#93318\n,\n#94109\n,\n#94129\n)\nMake default input casting in root module only and enable the ability to set different mixed precisions for different submodules (\n#91365\n)\nTorch Elastic\nUpdate\ntorchrun\nand\nTorchElastic\nto take optional\nlocal_addr\nparam to allow skip local IP lookup if specified (\n#88922\n)\ntorch.func\nUpdate vmap to accept None(s) in out_dim (\n#91644\n)\ntorch.func.jacrev: Support chunked computation (\n#89376\n,\n#91326\n)\nvmap: chunk_size support (\n#91157\n)\ntorch.vmap: Implement checks (rather than internal asserts) for vmap escaped errors (\n#89585\n)\nAvoid calling allclose in the backward if there are tensor subclasses (\n#91444\n)\nRefactor NN stateless APIs by swapping module tensors (\n#92536\n)\nCuda\nUse binary units for CUDA memory summary (\n#91854\n)\nImprove perf by avoiding implicit string creation in c10_cuda_check_implementation (\n#88350\n)\nAdd option to record C++ backtraces in _record_memory_history (\n#86145\n)\nSet CUDA_MODULE_LOADING to LAZY when not set by the user (\n#85692\n)\nAdd warning if captured graph is empty (\n#88754\n)\nAdd option to dump a captured graph for debugging (\n#85519\n)\nAdd support to foreach torch zero for bfloat16s (\n#90437\n)\nEnable bfloat16 for hardtanh_backward_cuda (\n#91511\n)\nUse pytree to allow any input format for cuda graph (\n#90941\n)\nAdd requested_bytes to CUDA Caching Allocator Stats (\n#88575\n)\nAdd an option to disable reduced precision reductions for BF16 GEMM (\n#89172\n)\nAdd an env variable to disable addmm_cuda_lt kernel (\n#91436\n)\nSerialization\nAdd XPU backend to support torch.save and torch.load (\n#89679\n)\nCpp API\nReduce ambiguity in Tensor namespace collisions (\n#92266\n)\nDataloader API\nAdd support for pin memory on xpu device (\n#86545\n)\nAdd type annotation to\nget_worker_info\n(\n#87017\n)\nAllow prefetch factor to be optional (\n#88972\n)\nNestedTensor API\nAdd add/mul for nested dense [B, *, D], [B, 1, D] case (CUDA-only) (\n#88289\n)\nAdd support for torch.select over irregular dimensions (\n#88585\n)\nAdd torch.nested.nested_tensor() constructor (\n#88213\n)\nComplex API\nImprove complex support for:\ntorch.nn.functional.conv_transpose3d\n(\n#87967\n),\ntorch.log1p\n(\n#89214\n,\n#90422\n),\ntorch.lerp\n(\n#75584\n),\ntorch.logcumsumexp\nfor CPU (\n#93153\n)\nSolve under/overflow for complex division (\n#92539\n)\nComposability\nImprove coverage of primtorch and torch._ref decompositions:\nprims.clone\n(\n#86705\n),\nndtr, ndtri, log_ndtr, erfcx\n(\n#86077\n),\nNLL loss\n(\n#81128\n),\nconv backward\n(\n#87047\n),\nxlogy and xlog1py\n(\n#77712\n),\nalpha_dropout\n(\n#87989\n)\nMore operations now work with meta tensors:\n_adaptive_avg_pool2d_backward\n(\n#86359\n), (\n#87074\n),\navg_pool2d and avg_pool2d_backward\n(\n#87043\n),\nscalar_tensor and argmax\n(\n#88590\n),\ntopk\n(\n#88694\n),\nmax_pool2d_with_indices_backward\n(\n#88743\n),\ngrid_sampler_2d_backward\n(\n#88745\n),\nlinalg_cholesky\nand\nlinalg_cholesky_ex\n(\n#89430\n),\naten._cdist_forward\n(\n#90042\n),\naten.pixel_shuffle\n(\n#91605\n)\nLinalg API\nFix typos in messages under aten (#88964)\nMobile\nImprove CoreML logging and dependent libraries.\nUpdated Cocoapods (#88075)\nPreserved CoreML errors by using special throw macro when encountering CoreML API errors (#86938)\nClean Up MobileOptimizerType Rewrite Flags Public API and Documentation (#91600)\nClean up flatbuffer lib dependency and fixed its test to match pkl models (#86041, #93022)\nType corrections to avoid unnecessary static_casts (#93898)\nAdd flake8-logging-format linter (#90805, #94840)\nSparse API\nAdd autograd support for\nlinear\n(#86137, #86302),\nmm\n,\nlog1p\n(#86301, #88155),\nto_sparse_*\n(#90281)\nImprove support for\nsparse_dim\n,\ndense_dim\n(#86203, #86203),\ntorch.sum\n(#86300, #92979), torch.sparse.sampled_addmm\n(#86401),\nfrac\n,\ndeg2rad\n,\nrad2deg\n,\nrelu\n(#88153, #88156, #88442, #86749),\nconj()\n(#91695),\nto_sparse\n(#90718),\nsparse_mask` (#92248, #94829)\nAdd support for per batch index contiguity in CSR/CSC/BSR/BSC (#91243), non-contiguous values in CSR/CSC/BSR/BSC (#91243), non-zero dense_dim to COO/CSC/BSR/BSC/Strided conversions. (#90177), uncoalesced operands to\nsparse_mask\n(#91964)\nImprove error messages for\nindices, values, (c)row_indices, (c)col_indices\n(#93149) and\naddmm\n(#94843)\nExtend gradcheck to BSR and BSC inputs. (#90719)\nSort BSR indices as part of CSR to BSR conversion (#90918)\nCpu\nImplement aten::native_batch_norm.out for CPU (#88604)\nLog1p for complex in CPU (#89691)\nEnable oneDNN implementation for LSTM (#91158)\nPackage\nAdd better debugging for torch.package (#92939)\nQuantization\nRemove weight arg from DTypeConfig for non-weighted ops (#86335)\nAdd get_symmetric_qnnpack_qconfig_mapping for XNNPACK quantized ops (#87002)\nAdd assert for backend correctness in get_default_qconfig related apis (#86259)\nReplacing List[QConfigMapping] in parallel numeric profiler (#86922)\nCheck the fixedqparam op qconfig based on backend_config (#87425)\nExplicitly set default quantized engine instead of relying on the order of supported_qengines (#89804)\nSupport setting qconfig by module_type in QConfigMapping in PT 2.0 export flow (#92355)\nMigration of quantization code from torch._ to torch.ao._ (#86171, #86172)\nImprovements to qnnpack fully connected sparse ops (#85243, #85244, #85245, #85246, #85247)\nSupport lowering of channel shuffle in FX (#83731)\nRemove explicitly default QConfigMapping settings (#90066)\nquant: make various configs printable (#91419)\nEnable FX quant for patterns like x.view(x.size(...), ...) (#90001)\nX86 qengine always uses fbgemm kernels on OS other than Linux (#93218)\nChange prepare_fx and convert_fx to preserve the GraphModule type of input (#94412)\nupdate xnnpack to newer version and update API usage in pytorch (#94330)\nRemove _input_output_observed from backend_config (#92589)\nAdd support for LSTM Structured Pruning prune_functions + pattern (#90801)\nEnable FX static quantization for LSTM (#85068)\nAllow setting fixed quantization params for inner LSTM ops (#88456)\nAdd support for GRU in fx graph mode quantization (#91976)\nONNX\nOperator support\ncol2im\nopset 18 (#84594),\nmse_loss\n(#90717),\naten::contains\n(#91660), src/index dynamic axes support for\naten::scatter_add\n(#90090),\naten::zero\n(#91731), Raise Unsupported for\nGridSample\nwith volumetric 5D input (#92212)\nPretty print diagnostic logging (#88261)\nBump onnx to 1.13.1, onnxruntime to 1.14.0 (#90332,\n#94767\n)\nAdd full graph checker option for\ntorch.onnx.export\nAPI (\n#83186\n)\nIntegrate all ONNX operators with a new\nJitScalarType\nAPI (#87245)\nAdd\nshare_from_this\nto\ntorch::jit::Graph\n(#87343)\nUse optional op to keep None in results for ONNX internal tests (#84789)\nAdd support for autograd function inlining in\nONNX_ATEN_FALLBACK\nmode (#85736)\nDefault runtime type checking to raising errors (#86555)\nRemove the\nINT64_MAX\nmagic numbers (#88341)\nFx\nRefactor graph partition to check for cyclic dependency (#86511)\nEnable nvprims.transpose fusions for nvFuser (#86967)\nSimplify magic method definition code. (#88017)\nAdd sym_floor, sym_sqrt, sym_int (#88760)\nPropagate .meta info when replacing subgraphs in fx (#87255)\nMake\ntorch.fx\ncompatible with Python-3.11 (#92895)\nAdd type(module) to be stored in the module stack (#87149)\nEnsure that symbolic variables incorporate fresh constraints before they're used (#87254)\nAdd type annotation to\ngetitem\nnode before\nsplit_module\n(#88510)\nImplement pass for annotating getitem nodes (#90237)\nGuard Symbol and ShapeGuardPrinter behind HAS_SYMPY (#90704)\nCopy meta field in fx.GraphModule on deepcopy (#92062, #92623)\nMatch get_attr when comparing nodes (#91657)\nMake\ndeepcopy\nof fx.GraphModule handle circular reference. (#93038)\nPopulate memo in deepcopy BEFORE copying children. (#93295)\nMps\nAdd fp16 support for\ntorch.nn.Linear\n(#89774),\ntorch.nn.GELU\n(#86218)\nAdd support for empty Tensors in\ntorch.bitwise_not\n(#87286),\ntorch.nn.LayerNorm\n(#94212), many backward functions (#94343),\ntorch.nn.functional.hardswish\n(#94342),\ntorch.topk\n(#91884),\ntorch.arange\n(#94485),\ntorch.linal.inv\n(#94551),\nImprove error message for\nnn.Conv2d\nwhen inputs are on different devices (#86303)\nAdd support via fallback for\ntorch.nn.{Fold, UnFold}\n(#94491)\nAdd support for reduction ops on multiple axis at a time (#91734)\nAdd support for\nk\ngreater than 16 for\ntorch.topk\n(#94639)\nBuild\nAdd\n@pytorch\nin tools/bazel.bzl (#91424)\nChange visibility for //c10:headers (#91422)\nSimplify OpenMP detection in CMake (#91576)\nUse\n@pytorch//\nin bazel build files which improves embedding usecases (#89660)\nEnable\nUSE_CUDA\nfor bazel build (#92640)\nAdd missing default initializers to class members (#94049)\nJit\nSkip builtins while enumerating class methods (#91805)\nSupport lovelace for NVRTC (#87611)\nExpanded symbolic shape support (movedim) (#91696)\nReleng\nUpdate CI test environment; Add symbolic functions (#94564)\nImport\nLiteral\n,\nProtocol\n, and\nFinal\nfrom standard library\ntyping\nas of Python 3.8+ (#94490)\nAdd cpuinfo to collect_env.py for new issues reporting which helps triaging on CPU (#93899)\nRefactor nvfuser build (#89621)\nAdd error checking to flaky test bot platform parser (#86632)\nMake LazyGraphExecutor extensible (#87218)\nDelete BUILD_SPLIT_CUDA option (#87502)\nUse faster cache flush in triton benchmarking (#88557)\nGuard global observer init against Edge profiler (#86347)\nBug fixes\nPython API\nFix as_strided_scatter derivative formula(#87646)\nAdd bfloat16 support to torch.prod (#87205)\nDisable dimension wrapping for scalar tensors (#89234)\nFix SIGSEGV on a big-endian machine when reading pickle data (#92810)\nFix BC-breaking change to reduction arguments\namin\n/\namax\n(#93091)\nFix incorrect tensor storage check (#86845)\nEnsure einsum contracts left to right (#87199)\nAdd nondeterministic error for\ntorch.tensor.scatter\n(#88244)\nFix multi-index for\ntorch.tensor.index_select\nover scalar tensor (#94347)\nAdd scalar support for\ntorch.tensor.where\n(#92849)\nImprove error message for unsupported argument types (#87601)\nChange as_strided_scatters storage offset default to None from 0 (#87481)\nMake\ntorch.histc\nconsistent between CPU and CUDA (#87832)\nAdd float to list of allowed ops for serialization (#94910)\nFix numpy1.24 deprecations in unittests ([#93997] (\nhttps://github.com/pytorch/pytorch/pull/93997\n))\nProperly moving segment_reduce to be private as expected (#93166)\nAutograd API\nFix behavior of hooks registered to Tensors that had previously been modified in-place (#92734)\nPreviously hooks registered to a tensor after it is modified in-place would erroneously receive the gradients of the output w.r.t. to that tensor before it is modified in-place if that tensor had previously had a hook registered to it before it was modified in-place.\nSee\ndocumentation\nfor more details about backward hooks execution when tensors are modified in-place.\nUpdate saved variable hooks to no longer trigger on wrapped numbers (#87316)\nModifying a view created in no-grad mode in-place no longer triggers an internal assert (#88243)\nImprove error message when saved tensor is detached inplace (#88860)\nPrevent module full_backward_hook from erroring in double backward (#88357)\nFix forward AD custom Function non-differentiable outputs (#90787)\nDon't materialize forward grad for non-differentiable types (#91183)\nReturn input as-is if marked dirty even when requires_grad=False (#91214)\nFix saved tensor hooks to propogate errors back to python as-is (#94456)\nFix NumPy broadcasting for backward of\nlinalg.solve\n(#91456),\nlinalg.lstsq\n(#91460)\nFix torch.var backward when input numel == correction (#94546)\nFix CopySlices logic to ensure wrapped node runs properly. (#89812)\ntorch.nn API\nFix for RNN-like\nModule\ns to work with\nstateless.functional_call()\n(#91111), better error messages (#87442),\nAdd missing dim checks\nEmbeddingBag\n(#85433)\nFix\nUpsample\nand\nEmbeddingBag\nmodule printing (#93850)\nFix segfaul in\nConv3D\nCPU implementation (#94325)\nFix overflow issue in\nUpsample\n(#94290)\nFix\nfunctiona.pixel_{shuffle,unshuffle}\nto consistently return views or not (#86608)\nFix 64bit indexing\nConv3d()\n(#87527),\nUpsample()\n(#87901)\nFix preserving requires_grad-ness in fusion utils (#89100)\nFix support for empty inputs/outputs for\nConv{1,2,3}d()\n(#86521),\nfunctional.adaptive_{avg, max}_pool()\n(#88906)\nFix buffer overflow in\nUpsample()\n(#89252),\nMaxUnpool3d()\n(#94372)\nFix\nfunctional.grid_sample()\nloss of precision for\ntorch.float16\ninputs (#90427)\nFix\nfunctional.interpolate()\nbicubic interpolation to properly preserve memory format (#90470)\ntorch.func\nFix cross to match unbatched behavior (#86926)\nProperly error on complex inputs or outputs in jacrev, jacfwd (#94805)\nFix batching rule for dropout (#92975)\nFix vmap and anomaly mode interaction (#92672)\nFix and update type hints for\nmake_functional.py\n(#91579)\ntorch.tril & torch.tril : add out of bound checks (#89384)\nFix torch.cat batching rule (#86932)\nFix reduction boxed batching rules (#91109)\nCuda\nCheck SM version before calling flash attention with BFloat16 (#86600)\nAdd range check to multi margin loss target (#89008)\nFix NVML visible device parsing (#92315)\nTake\nCUDA_VISIBLE_DEVICES\ninto account for nvml calls (#94568)\nFix topk IMA (#93095)\nFix: half reduction with multiple sub-iterators (#85596)\nFix segfault when swapping custom allocator (#89613)\nConditionally set device in autograd engine (#91191)\nStore\nautocast_gpu_dtype\nin\ncustom_fwd\nand\ncustom_bwd\nfor BFloat16 autocast (#88029)\nDo not use at::cuda::getDefaultCUDAStream() (#91180)\nEnsure that our error handling runs with the GIL enabled (#92848)\nFix C10_CUDA_CHECK for failing to capture last cuda error occasionally (#93192)\nFixes a memory leak by making autocast cache global instead of thread-local (#86492)\nTake\nCUDA_VISIBLE_DEVICES\ninto account for nvml calls (#94568)\nExplicitly set the workspace for cuBLAS handles (#86645)\nCpp API\nFix CUDNN_PATH handling on Windows (#88898)\nFix typos in warning/error messages(#88961)\nRemove uneeded checks from embedding bag impl (#92982)\nFix c++ : segfault in modulelist and moduledict (#93074)\nVisualization\nFix overflow issue in tensorboard image summary (#90423)\nRemove deprecated call to tf.io.gfile.get_filesystem (#89832)\nNestedTensor API\nEnable non-contiguous Nested Tensors for BMM inputs for NT on CUDA (#88108), linear backward (#94317)\nFix bug in unsqueeze_nested stride calculation (#88688)\nDistributed\nDistributed(c10d)\nFix a static initialization order fiasco in c10d (#90149)\nFix\nsend\n,\nrecv\nreturn type (#92152)\nFix MPI backend PG initialization (#92847)\nFix header-filter for clang-tidy c10 and apply some fixes to c10 and c10d (#91178)\nFix\nbackend_type\nfor backend/PG plugin (#93129)\nFix UCC PG barrier (#86961)\nProperly finalize unsuccessful UCC collective posts (#89306)\nAdd pre & post processing for UCC CPU collectives (#89030)\nRe-enabl\nisinstance\nwith\ntorch.distributed.ReduceOp\n(#87303, #88275)\nAmeliorate custom\n__eq__\nfor\nReduceOp\n(#90088)\nFix warning if backend registers timer (#91702)\nDistributedDataParallel\nFix DDP when the number of output features is zero (#87793)\nFullyShardedDataParallel\nFix\nuse_orig_params=True\nfor reentrant activation checkpointing by disabling the post-backward hooks (#87413)\nRe-establish the wrapped module in\n_lazy_init\nin case module changing after FSDP constructor (#87837)\nFix the incorrect norm calculation for\nNO_SHARD\nby handling sharded and non-sharded parameters differently in\nFSDP.clip_grad_norm_\n(#88955)\nPass through\nActivationWrapper\ndirectly to the inner wrapped module to fix\nstate_dict\nissues (#87950)\nRemove the clean of FQNs even for\nuse_orig_params=True\nin FSDP (#91767, #92662)\nRestrict meta model check to non ignored modules in FSDP (#86766)\nFix\nkeep_low_precision_grads=True\nfor\nuse_orig_params=True\n(#90027)\nFix for\nuse_orig_params=True\n+\nno_sync\n(#90546)\nFix\nno_sync\n,\nuse_orig_params=True\n, mixed precision, sharded (#92874)\nFix input grad propagation when using param mixed precision (#90921)\nFix\n_mp_shard\nin\nrecord_stream\n(#91096)\nFix \"use-after-free\" in reshard logic (#94859)\nFix\nclip_grad_norm_\nissues (#94835), (#86337)\nFix\nload_sharded_state_dict\nFQN mismatches for shared parameters (#86524)\nFix grad zero vs.\nNone\nedge case (#87308)\nFix FSDP\nstate_dict\ntransformations of modules with persistent buffers failure with mixed precision enabled (#93396)\n[FSDP] Fix\nnn.Parameter\nusage for 2D and\nuse_orig_params=True\n(#89782, #89845, #90562)\nRPC\nFFixixed use after free in tensorpipe agent (#87627)\nTorch Elastic\nMake TorchElastic timer importable on Windows (#88522)\nTensor parallel & 2D parallel\nFix the logic to trigger load hooks for 2D parallel integration with FSDP. (#86272)\nProfiler\nMinor bug fixes for ROCM tracing (#89785, #88207)\nForeach API\nFix\n_foreach_norm\non some tensor sizes (#91844)\nExempt\n_foreach_norm\nfrom autograd_not_implemented_fallback check (#93995)\nComplex API\nFix serialization of\nconj\nand\nneg_view\n(#88182)\nLinalg API\nAdd empty tensor check to _compute_linear_combination (#94245)\nOptimizer API\nFix discrepancy between mt vs st impl (#92699)\nDo NOT inplace modify gradients (#92706)\nFix memory leak in _LRScheduler.step() (#85602)\nLook up\ngroup[\"capturable\"]\n, not\ndefaults[\"capturable\"]\nin Adam(W) (#94149)\nFusedAdam(W)\nshould take\nOptState\ninto account before unscaling grads (#94060)\nFix LinearLR scheduler start_factor (#86695)\nKeep AveragedModel buffers in sync when use_buffers=False (#84054)\nFix OneCycleLR error log (#92040)\nFix SparseAdam consuming iterator (#86210)\nFix empty grad support for SparseAdam (#86459)\nSerialization\nFix set pickle_module if not specified (#88570)\nExplicitly check filelike arg of\ntorch.save\n(#88867)\nFix dtype mismatch for unallocated storage deserialization (#91285)\nAdd float to list of allowed ops (#94910)\nComposability\nFix segfault in has_torch_function (#88559)\nFix for usages of\ntorch_dispatch\nwith operators that take in an OptionalTensorList argument (#88887)\nAllow direct Tensor constructor to return preexisting PyObject (#92754)\nAdd fallthrough kernel for AutogradMeta key (#94603)\nSeveral fixes to existing primtorch and reference decompositions:\ncat\n: fix striding (#89332)\nprelu\n: Fix prelu ref when a.ndim < 2 (#89809)\nhuber_loss_backward\nfix (#86955)\nuniform\nfix (#90094)\nunfold_copy\nfix (#86371)\nFix aliasing for primtorch view meta kernels (#86285)\nProperly compute device for elementwise operations with CPU scalar tensor (#93073)\nSeveral fixes to existing operators meta tensor kernels:\naten._embedding_bag (#92549)\naten.fill_ (#87493)\naten.group_norm\ntype promotion fix (#86607)\naten._cudnn_rnn (#91333)\naten.bernoulli (#88676)\nunsqueeze_ (#88675)\nSeveral bug fixes as part of hardening functionalization, which is used in AOTAutograd:\nfix detach() in functionalization (#87750)\nfix\ntorch.as_strided_scatter_backward\nmemory initialization (#88342)\nfix functionalization resize stride compute (#94018)\nfix x.is_contiguous(channels_last) in functionalization (#94195)\nfix set_() with functionalization (#90722)\ncheck for undefined tensors in advanced indexing during functionalization (#90791)\nfix some composite compliance ops for functionalization (#86470)\nMake\naten.copy\npreserve strides (#89464)\nSparse API\nFixes to\ntorch.mm\n: (#90763), (#90917), (#91094)\nFix CSR to CSC conversion when given indices of int32 dtype (#91061)\nFix\nmul\nwhen given CUDA CSR Tensor and scalar (#91239)\nFix conversion from CSC, BSC to COO to only result in coalesced Tensors when appropriate (#91440)\nFix numel after resizing a CSR/BSR/CSC/BSC tensor. (#91831)\nFix\ntorch.triangular_solve\nfor CSR on CPU when\nunitriangular=True\n. (#93352)\nDistributions\nFix philox randn to follow standard normal distribution (#91945)\nCpu\nFix access to uninitialized memory in VSX vector functions (#89833)\nFix buffer overflow from AddressSanitizer checks due to inaccurate bfloat16 representation of large integer (#89210)\nMake torch.histc ignore NaNs on CPU (consistent with CUDA) (#85870)\nFix vectorized trigonometric functions for VSX (#86453)\nCall\nsymint::sizes()\ninstead of\nsizes()\non convolution error messages. (#89549)\nMake\ntorch.linspace\nresult on CPU consistent with numpy (#89048)\nRemove variable_excluded_from_dispatch() assertion from mkldnncommon (#92168)\nexponential_\nfew fixes (1) lambda > 0 (2) mkl kernel to continuous (3) better error log on dtype (#92891)\nVectorize more stable complex division (#93277)\ncauchy_\nfew fixes (1) check gamma > 0 (2) better dtype error log (#93314)\nIntel\nFix CPU autocast for torch.cat due to the new type ITensorListRef (#87756)\nAdd parameters check for torch._mkldnn_transpose (#85318)\nFix build with Intel compiler due to c10/util/TypeIndex.h (#89610)\nPackage\nTreat builtins as default extern module (#88385)\nSupport pickle version 4 by adding missing ops (#90223)\nCheck spec for module source before falling back to file in package exporter (#90258)\nQuantization\nFix the call to get_executorch_backend_config (#86338)\nFix weight_dtype and bias_dtype backend_config checks (#86719)\nRespect non_leaf_module_list for activation modules (#88498)\nFix incorrect integer cast on histogram observer bounds (#90355)\nImprove numerical stability of HistogramObserver (#86522)\nQuant_min typo bugfix in utils.py (#88024)\nFix fuse_func method overwrite (#87791)\nFix get_default_qat_qconfig for PT 1.13 (#88876)\nCheck the value of numel to avoid segfault (#81547)\nFix mkldnn quantization issue for weight reorder error (#86876)\nFix Memory Leak in QNNPACK QSoftmax Op (#89544)\nCopy MHA's batch_first attribute in prepare() (#91680)\nFix for swap_custom_module_to_observer doing duplicate swaps on the same node.target (#91905)\nFx\nCorrectly restore pybind11 error_already_set (#93238)\nRemove proxy tensor's check for data dependent output (#93265)\nMake ShapeEnv deepcopy-able (#93403)\nFix SubgraphMatcher for case of no anchor found (#86421)\nFix for partitioner with symbolic shapes (#86425)\nFix getitem in partitioner and make metadata storage more consistent (#87012)\nFix magic method try reverse protocol (#88030)\nFix FakeTensorProp on Module with Parameters or Buffers (#88700)\nFix PassManager to not use a class variable mutable list (#89108)\nPrevent tracing when we track_tensor_tree (#89139)\nMake all\nmake_fx\ninvocations isolated (opaque to higher\nmake_fx\ninvocations) by default (#93290)\nFix matching args in PatternMatcher (#94375)\nAllow FakeTensorProp to run on graphs traced with some None inputs (#94569)\nCopy codegen in legalize_graph (#90023)\nFix proxy unwrapping for cond() (#91907)\nONNX\nFix\ntriu\n/\ntril\noperator export with diagonal input (#86843)\nSkip tensor printing during model tracing (#86223)\nFix\naten::index_put(self, mask, v)\nexport when\nrank(mask) &lt; rank(self)\n(#92862)\nFix 0d-tensor broadcast export (#87211)\nFix device type detection based on strings (#86168)\nFix\nscatter_add\nwith different static shape of src and index (#89787)\nFix\n_pad_circular\nexport (#86984)\nFix concat with empty tensors (#87620)\nDisable ONNX\nceil_mode\nand\ncount_include_pad\nto align torch\nceil_mode\nresults in corner case (#87892)\nFix ignored small eps in layer normalization in fp16 (#89869)\nFix\nunconvertible_ops\nas per #89261 (#89299)\nFix\nGather\nreplacement in\nRNN peephole\n(#93120)\nFix\ncat\noperator for tensors with unknown rank (#94870)\nFix scalar type analysis for copied constant (#86716)\nFix scalar type detection for optional tensors (#94427)\nFix 'prim::PackPadded' shape inference (#91829)\nAdd\nonnx::Max\ninto standard Op for scalar type alignment (#88750)\nAdd\nsetType\nfrom user into\nInferredType\nand\nReliable\nin\nConstantValueMap\n(#88622)\nIntegrate ONNX ATen Fallback export with the new operator registry (#87735)\nFix ONNX ATen Fallback integration for\nBUILD_CAFFE2=0\nbuilds (#88504)\nFix\ntorch.autograd.Function.symbolic\nmethod support (#94746)\nFix\nFindCommonAncestor\nin\nfunction_extraction\n(#86650)\nUpdate training state logic to support\nScriptedModule\n(#86745)\nROCm\nFix hipify mapping for cuDeviceGet (#90726)\nMps\nFix issues with non-contiguous Tensor handling (#86956, #86958)\nFix issues with ops implementation\ntorch.median\n(#90326, #88807),\ntorch.{std,var}\ncorrection\nargument (#91203),\ntorch.index_select\n(#94117, #91064),\ntorch.cumsum\n(#94119),\ntorch.where\n(#86240),\ntorch.nn.Embedding\n(#82809),\ntorch.nn.Softplus\n(#88555),\ntorch.nn.functional.pad\n(#89864),\ntorch.max\n(#91520), padding functions (#91522),\ntorch.nn.functional.upsample\n(#91669), pooling functions (#91519, #94348),\ntorch.nn.{NLLLoss,SmoothL1Loss}\n(#94226),\ntorch.nn.SoftPlus\n(#94256),\ntorch.masked_fill\n(#94263),\ntorch.fill_\n(#94479),\ntorch.median\n(#94489),\ntorch.nonzero\n(#94442),\ntorch.nn.BatchNorm\n(#94351),\ntorch.{min,max}\n(#94386),\ntorch.nn.GELU\n(#94529),\ntorch.nn.LSTM\n(#94889), #95137),\ntorch.nn.Conv2d\n(#95078),\ntorch.nn.functional.bilinear\n(#94892),\ntorch.copy\\_\n(#95272),\ntorch.max_pool2d\n(#94963),\ntorch.div\n(#95769)\nFix issues with\ntorch.bool\nfor Unary ops (#91120), scatter ops (#94464),\nFix issues with\ntorch.float16\nfor\ntorch.nan_to_num\n(#94220),\ntorch.nn.HuberLoss\n(#94567)\nProperly raise error for\ntorch.int64\ninputs for\ntorch.dot\n(#94270),\ntorch.floor_divide\n(#94488),\ntorch.square\n(#94766),\nProperly cast\ntorch.int64\nto\ntorch.int32\nfor reduction ops and raise warning. (#94484)\nProperly raise unimplemented error for\ntorch.nn.Conv3d\n(#94492),\nFix data type issues with index_add for non-\ntorch.float\ninputs by casting them to\ntorch.float\n(#88542)\nFix the high watermark value for unified memory allocation on x86 (#91268)\nFix handling of ops taking multiple dtypes as input (#91197, #91514)\nFix handling of channels last for\ntorch.cat\n(#91786, #94662),\ntorch.Conv2d\n(#91822, #94384),\ntorch.nn.{ELU,ReLU,Hardswish}\n(#94664),\ntorch.nn.BatchNorm\n(#94760),\ntorch.nn.MaxPool2d\n(#94877)\nFix view operations handling (#94259, #94278,#95145, #95762, #95905)\nFix numerical stability issues with various ops (#94889)\nFix TORCH_WARN_ONCE (#95559) (#95559)\nBuild\nMove incorrectly placed closing curly brace of\nextern \"C\"\nblock (#87853)\nSet INTERFACE_LINK_DIRECTORIES on caffe2::mkl (#89359)\nAlso include MKL_THREAD_LIB in link libraries for caffe2::mkl (#89378)\nFix MSVC compiler error in basic_ops.h (#93322)\nFix a bug that redefines __STDC_FORMAT_MACROS (#89310)\nFix ReplaceWithMaybeCopy test in OSS (#88099)\nJit\nFix out-of-bounds error in torch.jit.script for functions with many decorators (#87804)\nAssorted fixes for NNC cpu fuser (#85056, #86788, #88798, #89978)\nSet the correct size of aten tensor in presence of MKL-DNN padding (#86767)\nFix Scalar(bool) handling in toIValue (#87179)\nVulkan\nFix an issue with Vulkan not being able to be compiled on Windows (#92207)\nFix a possible empty vector dereference in the Vulkan optimization pass (#92918)\nCudnn\nFix cudnn RNN reproducibility issue (#90522)\nFix\nbenchmark_limit\nignoring failed kernels in FIND (#91032)\nReleng\nSet nvfuser default to disabled, keep CI (#86369)\nAdd manual cuda deps search logic (#90411)\nWorkaround for NumPy builds that ship with a broken Dlpack deleter (#89759)\nWorkaround MSVC ICE due to constexpr char* template argument (#86288)\nAdd define to fix issue with compatibility with latest Windows SDK (#85408)\nRemove invalid git option when updating submodules (#91132)\nPerformance\nPython API\nImprove torch.lerp performance on cpu (#84845)\nImprove torch.istft performance (#88060)\nCall view within einsum to remediate MPS regression (#87135)\nRemove unnecessary calls to python builtins(#94323)\nImprove type hints for Module forward hooks (#92061)\nAutograd API\nUse in-place input accumulation fast path for dense Tensors. (#90217)\ntorch.nn API\nImprove\nfunctional.interpolate()\nspeed for\ntorch.channels_last\n(#86361, #86361, #90302)\nImprove performance for\nfunctional.multi_head_attention_forward()\n(#93234, #89847)\nImprove performance for\nTransformerEncoderLayer()\nand\nMultiheadAttention()\n(#87377, #88488, #88831, #88854, #88970, #91171)\nImprove\nSyncBatchNorm()\nperformance by using the right gathering ops (#89521)\nImprove\nConvTransposed2D()\nCPU performance for\ntorch.{float32, bfloat16}\n(#92530)\nImprove\nfunctional.local_response_norm()\nperformance for 3d inputs (#91052)\ntorch.func\nAdd vmap batching rule for:\nbitwise operators\n(#91971),\nnansum\n&\nnanmean\n(#91372),\nall\n&\nany\n(#91966),\ntorch.linalg.vander\n(#91749),\nslogdet\n(#86815),\ntorch.index_fill\n(#91364),\nnarrow_copy\n(#88130),\nview_copy\n(#88150),\ngreater_equal.Scaler\n(#91324)\nCuda\nLayer norm backward speed gain with warp shuffles (#87445, #87814)\nAvoid unnecessary type casts (#86086)\nUse\natomicAdd\nfor\nbfloat16\nin Ampere and above (#84981)\nCpp API\nVectorize torch.exp2 on CPU and add complex support (#92115)\nAdd various performance fixes to c++ STL usage (#94034)\nNestedTensor API\nImprove performance for NestedTensor\ntorch.bmm\n(#86856), (#85894)\nRemove unnecessary check in\nselect_nested\n(#89150)\nDistributed\nDo not call\npad\nin no-padding case(#88769)\nComplex API\nImprove complex\nlerp\nperformance (#84844)\nMobile\nPassing serialized XNNPACK model by reference (#89089)\nFix to add multiple outputs for the CoreML delegate (#88345)\nSparse API\nImprove performance of\nmul\nwhen given COO (#86269)\nImprove\nto(dtype)\nsupport for all sparse compressed formats (#89055)\nImprove conversion of BSR/BSC to COO using\nto_sparse\n(#91389)\nImprove\nsparse_mask\n(#91964)\nImprove\nto_dense\nbackward by removing redundant call to\ncoalesce\n(#92001)\nImprove validation of CSR/CSC/BSR/BSC tensors for low dimensional inputs (#94048)\nImprove torch.sparse.sampled_addmm performance on CPU for CSR inputs (#90978)\nOptimizer API\nImprove foreach implementations by pre-grouping tensors to maximize fast path for\n{Adadelta, Adagrad, Adam, Adamax, AdamW, ASGD, NAdam, RAdam, RMSProp, RProp, SGD}\n(#92048, #92362, #92363, #92349, #92364, #92365, #92369, #92372, #92338)\nCpu\nOptimizations for flip (#89414, #91806,#88989, #90013)\nAdd fmsub to vectorization primitives (#86568)\nOptimize GELU BFloat16 Impl in CPU path (#79378)\nFix\nbiasadd\nOMP perf issue for the packed MKL SGEMM (#92300)\nOptimize LogSoftmax by improving thread-allocation in\n_vec_log_softmax_lastdim\n(#85398)\nBF16 autocast conv transpose 1d/2d/3d for CPU (#92527)\nAdd mkl implementation for exponential on CPU (#69967)\nFx\nUse deque instead of list for BFS (#91139)\nRefactor the dfs cyclic search from recursive to iterative approach (#91042)\nMps\nIncrease performance of\ntorch.add{cmul,cdiv,mm}\n(#94214, #94534)\ntorch.multinomial\n(#86342), faster op launch time (#86437),\ntorch.linear\n(#91114), view handling (#91743, #94218),\nconvolutions\n(#94661),\nscatter/gather\n(#94663)\nJit\nAdd BFloat16 dtype support for oneDNN Graph JIT fuser (#85591)\nCudnn\nImprove hot path heuristics performance in V8 (#90811)\nDocumentation\nPython API\nFix various spelling and grammatical errors (#87357, #87583, #88033, #91641, #91871, #86642, #86721, #90110, #87724, #88483, #92049, #92762, #88962)\nFix the documentation of various functions (#88059, #94545, #86593, #93145, #90071, #87870, #91627, #89910, #79086)\nFix dev-discuss link in the maintainer docs (#89493)\nAdd General Project Policies (#87385)\nAutograd API\nImprove autograd documentation (#89401, #93065)\ntorch.nn API\nImprove documentation for:\nMaxPool2d\n(#86559),\nutils.clip_grad_norm_()\n(#91312),\nModule()\n(#87142),\n{Unfold,Fold}()\n(#88819),\ntorch.nn.functional.gelu\n(#89061),\nfunctional.conv2d\npadding\n(#85004),\nfunctional.leaky_relu()\n(#94090),\nMaxUnpool{1,2,3}D\n(#94629)\nNestedTensor API\nUpdate Persons of Interest (#90069)\nFix path to nested_tensor in example (#86891)\nMps\nAdd 'mps' to the tensor attributes doc page (#86585)\nDistributed\nActivation checkpointing\nClean up comments in activation checkpoint (#86622)\nDistributed (c10d)\nImprove documentation for various functions (#87018, #94543, #91116,#89905, #86438 )\nDistributedDataParallel\nImprove Documentation (#86221, #91832)\nRPC\nFix non-existing parameters in docstrings in benchmarks (#91115)\nTensor parallelism and DTensor:\nAdd more clarifications and fix errors in tensor parallelism docs (#94786)\nUpdate 2D parallelism API naming and docs (#94771)\nFullyShardedDataParallel\nAdd docs to explain the running the forward pass of of submodules in FSDP (#86343)\nClarify warnings to mention collectives (#87478)\nRemove HSDP Zero-2 from doc (#90503)\nImprove the comments for FSDP (#92359)\nDistributed Checkpoint\nEnable documentation for Distributed Checkpoint. (#92813)\nTorch Elastic\nFix a minor typo in documentation (#90667)\nFix\ntorch.distributed.run\ninit connect timeout by comparing\nhost\nwith the current IP list (#90221)\ntorch.func\nDowngrade the warning about forward-mode AD coverage (#87383)\nAdd version selector back to functorch docs (#86602)\nAdd documentation for torch.func (#91319)\nFix AOTAutograd tutorial (#87415)\nAdd migration guide from functorch (#91811)\nImprove inplace/view note on copy slices (#89856)\nAdd more details to the functorch install page (#86823)\nLinalg API\nAdd a note on the stability of linalg functions. (#88313)\nImprove documentation for various linalg functions (#89013,#89383, #91129)\nComposability\nFix ScalarTensor\nrepr\nin Extending PyTorch example (#86330)\nFix incorrect wrapping of function decorator (#94446)\nAdd\nall\nto torch.{autograd, fx, cuda} submodules (#85343)\nDataloader API\nUpdate dataloader docstring mentioning prefetch factor behavior (#89874)\nSparse API\nExtend documentation for\nto_sparse\n(#89912)\nSmall correction to\ntorch.sparse\noverview documentation(#93258)\nOptimizer API\nImprove documentation for various optimizers (#91195, #91196, #91881, #89575, #86629, #92111)\nAdd general documentation on our algorithm defaults (#95391)\nSerialization\nFix various spelling and grammatical errors (#90662, #91253)\nDistributions\nImprove documentation for various distributions (#91091, #87577)\nAdd original sources/references to Wishart.py in distributions (#86543)\nQuantization\nImprovements to various READMEs (#89319, #86914,#86523, #89795, #90403)\nAdd docstrings for operators defined in torch.ops.quantized_decomposed namespace (#89547)\nAdd x86 backend as default backend of server inference (#86794)\nFix non-existing parameters in docstrings in torch/ao (#90875)\nMove parts of BackendConfig tutorial (#91999)\nONNX\nFix non-existing parameters in docstrings in torch/onnx (#90593)\nUpdate diagnostics system (#94565)\nReleng\nEnabled xdoctest runner in CI (#83816)",
    "crawl_status": "success"
  },
  {
    "library_name": "Django",
    "url": "https://docs.djangoproject.com/en/6.0/releases/6.0/",
    "version": "6.0",
    "title": "Django 6.0 release notes | Django documentation | Django",
    "release_date": "Unknown release date",
    "content": "The web framework for perfectionists with deadlines.\nOverview\nDownload\nDocumentation\nNews\nCode\nIssues\nCommunity\nFoundation\n Donate\nSearch\n\n\n\n\nSubmit\nToggle theme (current theme: auto)\nToggle theme (current theme: light)\nToggle theme (current theme: dark)\nToggle Light / Dark / Auto color theme\nDocumentation\nGetting Help\nel\nes\nfr\nid\nit\nja\nko\npl\npt-br\nsv\nzh-hans\nLanguage: en\ndev\nDocumentation version:\n          6.0\nDjango 6.0 release notes露\nDecember 3, 2025\nWelcome to Django 6.0!\nThese release notes cover the new features, as well as\nsome backwards incompatible changes you\nshould be aware of when upgrading from Django 5.2 or earlier. Weve\nbegun the deprecation process for some features.\nSee the How to upgrade Django to a newer version guide if youre updating an existing\nproject.\nPython compatibility露\nDjango 6.0 supports Python 3.12, 3.13, and 3.14. We highly recommend, and\nonly officially support, the latest release of each series.\nThe Django 5.2.x series is the last to support Python 3.10 and 3.11.\nThird-party library support for older versions of Django露\nFollowing the release of Django 6.0, we suggest that third-party app authors\ndrop support for all versions of Django prior to 5.2. At that time, you should\nbe able to run your packages tests using python -Wd so that deprecation\nwarnings appear. After making the deprecation warning fixes, your app should be\ncompatible with Django 6.0.\npython -Wd\nWhats new in Django 6.0露\nContent Security Policy support露\nBuilt-in support for the Content Security Policy (CSP)\nstandard is now available, making it easier to protect web applications against\ncontent injection attacks such as cross-site scripting (XSS). CSP allows\ndeclaring trusted sources of content by giving browsers strict rules about\nwhich scripts, styles, images, or other resources can be loaded.\nCSP policies can now be enforced or monitored directly using built-in tools:\nheaders are added via the\nContentSecurityPolicyMiddleware, nonces are\nsupported through the csp() context\nprocessor, and policies are configured using the SECURE_CSP and\nSECURE_CSP_REPORT_ONLY settings.\nContentSecurityPolicyMiddleware\ncsp()\nSECURE_CSP\nSECURE_CSP_REPORT_ONLY\nThese settings accept Python dictionaries and support Django-provided constants\nfor clarity and safety. For example:\nfrom django.utils.csp import CSP\n\nSECURE_CSP = {\n    \"default-src\": [CSP.SELF],\n    \"script-src\": [CSP.SELF, CSP.NONCE],\n    \"img-src\": [CSP.SELF, \"https:\"],\n}\nThe resulting Content-Security-Policy header would be set to:\nContent-Security-Policy\ndefault-src 'self'; script-src 'self' 'nonce-SECRET'; img-src 'self' https:\nTo get started, follow the CSP how-to guide. For in-depth\nguidance, see the CSP security overview and the\nreference docs, which include details about decorators to\noverride or disable policies on a per-view basis.\nTemplate Partials露\nThe Django Template Language now supports\ntemplate partials, making it easier to encapsulate\nand reuse small named fragments within a template file. The new tags\n{% partialdef %} and {% partial %}\ndefine a partial and render it, respectively.\n{% partialdef %}\n{% partial %}\nPartials can also be referenced using the template_name#partial_name syntax\nwith get_template(),\nrender(), {% include %}, and other\ntemplate-loading tools, enabling more modular and maintainable templates\nwithout needing to split components into separate files.\ntemplate_name#partial_name\nget_template()\nrender()\n{% include %}\nA migration guide is available if youre updating from the\ndjango-template-partials third-party package.\nBackground Tasks露\nDjango now includes a built-in Tasks framework for running code outside the\nHTTP requestresponse cycle. This enables offloading work, such as sending\nemails or processing data, to background workers.\nThe framework provides task definition, validation, queuing, and result\nhandling. Django guarantees consistent behavior for creating and managing\ntasks, while the responsibility for running them continues to belong to\nexternal worker processes.\nTasks are defined using the task() decorator:\ntask()\nfrom django.core.mail import send_mail\nfrom django.tasks import task\n\n\n@task\ndef email_users(emails, subject, message):\n    return send_mail(subject, message, None, emails)\nOnce defined, tasks can be enqueued through a configured backend:\nemail_users.enqueue(\n    emails=[\"user@example.com\"],\n    subject=\"You have a message\",\n    message=\"Hello there!\",\n)\nBackends are configured via the TASKS setting. The two\nbuilt-in backends included in this release are\nprimarily intended for development and testing.\nTASKS\nDjango handles task creation and queuing, but does not provide a worker\nmechanism to run tasks. Execution must be managed by external infrastructure,\nsuch as a separate process or service.\nSee Djangos Tasks framework for an overview and the Tasks reference for API details.\nAdoption of Pythons modern email API露\nEmail handling in Django now uses Pythons modern email API, introduced in\nPython 3.6. This API, centered around the\nemail.message.EmailMessage class, offers a cleaner and\nUnicode-friendly interface for composing and sending emails. It replaces use of\nPythons older legacy (Compat32) API, which relied on lower-level MIME\nclasses (from email.mime) and required more manual handling of\nmessage structure and encoding.\nemail.message.EmailMessage\nCompat32\nemail.mime\nNotably, the return type of the EmailMessage.message() method is now an instance of Pythons\nemail.message.EmailMessage. This supports the same API as the\nprevious SafeMIMEText and SafeMIMEMultipart return types, but is not an\ninstance of those now-deprecated classes.\nEmailMessage.message()\nemail.message.EmailMessage\nSafeMIMEText\nSafeMIMEMultipart\nMinor features露\ndjango.contrib.admin露\ndjango.contrib.admin\nThe Font Awesome Free icon set (version 6.7.2) is now used for the admin\ninterface icons.\nThe Font Awesome Free icon set (version 6.7.2) is now used for the admin\ninterface icons.\nThe new AdminSite.password_change_form attribute allows customizing\nthe form used in the admin site password change view.\nThe new AdminSite.password_change_form attribute allows customizing\nthe form used in the admin site password change view.\nAdminSite.password_change_form\nMessage levels messages.DEBUG and messages.INFO now have distinct\nicons and CSS styling. Previously, both levels shared the same appearance as\nmessages.SUCCESS. Given that ModelAdmin.message_user() uses\nmessages.INFO by default, set the level to messages.SUCCESS to keep\nthe previous icon and styling.\nMessage levels messages.DEBUG and messages.INFO now have distinct\nicons and CSS styling. Previously, both levels shared the same appearance as\nmessages.SUCCESS. Given that ModelAdmin.message_user() uses\nmessages.INFO by default, set the level to messages.SUCCESS to keep\nthe previous icon and styling.\nmessages.DEBUG\nmessages.INFO\nmessages.SUCCESS\nModelAdmin.message_user()\nmessages.INFO\nmessages.SUCCESS\ndjango.contrib.auth露\ndjango.contrib.auth\nThe default iteration count for the PBKDF2 password hasher is increased from\n1,000,000 to 1,200,000.\nThe default iteration count for the PBKDF2 password hasher is increased from\n1,000,000 to 1,200,000.\ndjango.contrib.gis露\ndjango.contrib.gis\nThe new GEOSGeometry.hasm property checks whether the geometry has\nthe M dimension.\nThe new GEOSGeometry.hasm property checks whether the geometry has\nthe M dimension.\nGEOSGeometry.hasm\nThe new Rotate database\nfunction rotates a geometry by a specified angle around the origin or a\nspecified point.\nThe new Rotate database\nfunction rotates a geometry by a specified angle around the origin or a\nspecified point.\nRotate\nThe new BaseGeometryWidget.base_layer attribute allows specifying a\nJavaScript map base layer, enabling customization of map tile providers.\nThe new BaseGeometryWidget.base_layer attribute allows specifying a\nJavaScript map base layer, enabling customization of map tile providers.\nBaseGeometryWidget.base_layer\ncoveredby and isvalid lookups,\nCollect aggregation, and\nGeoHash and\nIsValid database functions\nare now supported on MariaDB 12.0.1+.\ncoveredby and isvalid lookups,\nCollect aggregation, and\nGeoHash and\nIsValid database functions\nare now supported on MariaDB 12.0.1+.\ncoveredby\nisvalid\nCollect\nGeoHash\nIsValid\nThe new geom_type lookup and\nGeometryType()\ndatabase function allow filtering geometries by their types.\nThe new geom_type lookup and\nGeometryType()\ndatabase function allow filtering geometries by their types.\ngeom_type\nGeometryType()\nWidgets from django.contrib.gis.forms.widgets now render without\ninline JavaScript in templates. If you have customized any geometry widgets\nor their templates, you may need to update them to match the new layout.\nWidgets from django.contrib.gis.forms.widgets now render without\ninline JavaScript in templates. If you have customized any geometry widgets\nor their templates, you may need to update them to match the new layout.\ndjango.contrib.gis.forms.widgets\ndjango.contrib.postgres露\ndjango.contrib.postgres\nThe new Lexeme expression\nfor full text search provides fine-grained control over search terms.\nLexeme objects automatically escape their input and support logical\ncombination operators (&, |, ~), prefix matching, and term\nweighting.\nThe new Lexeme expression\nfor full text search provides fine-grained control over search terms.\nLexeme objects automatically escape their input and support logical\ncombination operators (&, |, ~), prefix matching, and term\nweighting.\nLexeme\nLexeme\n&\n|\n~\nModel fields, indexes, and constraints from django.contrib.postgres\nnow include system checks to verify that django.contrib.postgres is an\ninstalled app.\nModel fields, indexes, and constraints from django.contrib.postgres\nnow include system checks to verify that django.contrib.postgres is an\ninstalled app.\ndjango.contrib.postgres\ndjango.contrib.postgres\nThe CreateExtension, BloomExtension,\nBtreeGinExtension, BtreeGistExtension,\nCITextExtension, CryptoExtension,\nHStoreExtension, TrigramExtension, and\nUnaccentExtension operations now support the optional hints\nparameter. This allows providing database hints to database routers to assist\nthem in making routing decisions.\nThe CreateExtension, BloomExtension,\nBtreeGinExtension, BtreeGistExtension,\nCITextExtension, CryptoExtension,\nHStoreExtension, TrigramExtension, and\nUnaccentExtension operations now support the optional hints\nparameter. This allows providing database hints to database routers to assist\nthem in making routing decisions.\nCreateExtension\nBloomExtension\nBtreeGinExtension\nBtreeGistExtension\nCITextExtension\nCryptoExtension\nHStoreExtension\nTrigramExtension\nUnaccentExtension\nhints\ndjango.contrib.staticfiles露\ndjango.contrib.staticfiles\nManifestStaticFilesStorage now\nensures consistent path ordering in manifest files, making them more\nreproducible and reducing unnecessary diffs.\nManifestStaticFilesStorage now\nensures consistent path ordering in manifest files, making them more\nreproducible and reducing unnecessary diffs.\nManifestStaticFilesStorage\nThe collectstatic command now reports only a summary for skipped\nfiles (and for deleted files when using --clear) at --verbosity 1. To\nsee per-file details for either case, set --verbosity to 2 or higher.\nThe collectstatic command now reports only a summary for skipped\nfiles (and for deleted files when using --clear) at --verbosity 1. To\nsee per-file details for either case, set --verbosity to 2 or higher.\ncollectstatic\n--clear\n--verbosity\n--verbosity\nEmail露\nThe new policy argument for EmailMessage.message() allows specifying the email policy,\nthe set of rules for updating and serializing the representation of the\nmessage. Defaults to email.policy.default.\nThe new policy argument for EmailMessage.message() allows specifying the email policy,\nthe set of rules for updating and serializing the representation of the\nmessage. Defaults to email.policy.default.\npolicy\nEmailMessage.message()\nemail.policy.default\nEmailMessage.attach() now\naccepts a MIMEPart object from Pythons modern email\nAPI.\nEmailMessage.attach() now\naccepts a MIMEPart object from Pythons modern email\nAPI.\nEmailMessage.attach()\nMIMEPart\nInternationalization露\nAdded support and translations for the Haitian Creole language.\nAdded support and translations for the Haitian Creole language.\nManagement Commands露\nThe startproject and startapp commands now create the\ncustom target directory if it doesnt exist.\nThe startproject and startapp commands now create the\ncustom target directory if it doesnt exist.\nstartproject\nstartapp\nCommon utilities, such as django.conf.settings, are now automatically\nimported to the shell by default.\nCommon utilities, such as django.conf.settings, are now automatically\nimported to the shell by default.\ndjango.conf.settings\nshell\nMigrations露\nSquashed migrations can now themselves be squashed before being transitioned\nto normal migrations.\nSquashed migrations can now themselves be squashed before being transitioned\nto normal migrations.\nMigrations now support serialization of zoneinfo.ZoneInfo instances.\nMigrations now support serialization of zoneinfo.ZoneInfo instances.\nzoneinfo.ZoneInfo\nSerialization of deconstructible objects now supports keyword arguments with\nnames that are not valid Python identifiers.\nSerialization of deconstructible objects now supports keyword arguments with\nnames that are not valid Python identifiers.\nModels露\nConstraints now implement a check()\nmethod that is already registered with the check framework.\nConstraints now implement a check()\nmethod that is already registered with the check framework.\ncheck()\nThe new order_by argument for Aggregate allows\nspecifying the ordering of the elements in the result.\nThe new order_by argument for Aggregate allows\nspecifying the ordering of the elements in the result.\norder_by\nAggregate\nThe new Aggregate.allow_order_by class attribute determines whether\nthe aggregate function allows passing an order_by keyword argument.\nThe new Aggregate.allow_order_by class attribute determines whether\nthe aggregate function allows passing an order_by keyword argument.\nAggregate.allow_order_by\norder_by\nThe new StringAgg aggregate returns the input\nvalues concatenated into a string, separated by the delimiter string.\nThis aggregate was previously supported only for PostgreSQL.\nThe new StringAgg aggregate returns the input\nvalues concatenated into a string, separated by the delimiter string.\nThis aggregate was previously supported only for PostgreSQL.\nStringAgg\ndelimiter\nThe save() method now raises a specialized\nModel.NotUpdated exception, when\na forced update results in no affected rows,\ninstead of a generic django.db.DatabaseError.\nThe save() method now raises a specialized\nModel.NotUpdated exception, when\na forced update results in no affected rows,\ninstead of a generic django.db.DatabaseError.\nsave()\nModel.NotUpdated\ndjango.db.DatabaseError\nQuerySet.raw() now supports models with a\nCompositePrimaryKey.\nQuerySet.raw() now supports models with a\nCompositePrimaryKey.\nQuerySet.raw()\nCompositePrimaryKey\nSubqueries returning a CompositePrimaryKey can now\nbe used as the target of lookups other than __in, such as __exact.\nSubqueries returning a CompositePrimaryKey can now\nbe used as the target of lookups other than __in, such as __exact.\nCompositePrimaryKey\n__in\n__exact\nJSONField now supports\nnegative array indexing on SQLite.\nJSONField now supports\nnegative array indexing on SQLite.\nJSONField\nThe new AnyValue aggregate returns an arbitrary\nvalue from the non-null input values. This is supported on SQLite, MySQL,\nOracle, and PostgreSQL 16+.\nThe new AnyValue aggregate returns an arbitrary\nvalue from the non-null input values. This is supported on SQLite, MySQL,\nOracle, and PostgreSQL 16+.\nAnyValue\nGeneratedFields and fields assigned\nexpressions are now refreshed from the\ndatabase after save() on backends that support\nthe RETURNING clause (SQLite, PostgreSQL, and Oracle). On backends that\ndont support it (MySQL and MariaDB), the fields are marked as deferred to\ntrigger a refresh on subsequent accesses.\nGeneratedFields and fields assigned\nexpressions are now refreshed from the\ndatabase after save() on backends that support\nthe RETURNING clause (SQLite, PostgreSQL, and Oracle). On backends that\ndont support it (MySQL and MariaDB), the fields are marked as deferred to\ntrigger a refresh on subsequent accesses.\nGeneratedField\nsave()\nRETURNING\nUsing a ForeignObject with multiple\nfrom_fields in Model indexes, constraints, or unique_together now emits a system check error.\nUsing a ForeignObject with multiple\nfrom_fields in Model indexes, constraints, or unique_together now emits a system check error.\nfrom_fields\nunique_together\nPagination露\nThe new AsyncPaginator and\nAsyncPage provide async implementations of\nPaginator and\nPage respectively.\nThe new AsyncPaginator and\nAsyncPage provide async implementations of\nPaginator and\nPage respectively.\nAsyncPaginator\nAsyncPage\nPaginator\nPage\nRequests and Responses露\nMultiple Cookie headers are now supported for HTTP/2 requests when\nrunning with ASGI.\nMultiple Cookie headers are now supported for HTTP/2 requests when\nrunning with ASGI.\nCookie\nTemplates露\nThe new variable forloop.length is now available within a for\nloop.\nThe new variable forloop.length is now available within a for\nloop.\nforloop.length\nfor\nThe querystring template tag now consistently prefixes the returned\nquery string with a ?, ensuring reliable link generation behavior.\nThe querystring template tag now consistently prefixes the returned\nquery string with a ?, ensuring reliable link generation behavior.\nquerystring\n?\nThe querystring template tag now accepts multiple positional\narguments, which must be mappings, such as QueryDict\nor dict.\nThe querystring template tag now accepts multiple positional\narguments, which must be mappings, such as QueryDict\nor dict.\nquerystring\nQueryDict\ndict\nTests露\nThe DiscoverRunner now supports parallel test execution on systems\nusing the forkserver multiprocessing start method.\nThe DiscoverRunner now supports parallel test execution on systems\nusing the forkserver multiprocessing start method.\nDiscoverRunner\nforkserver\nmultiprocessing\nBackwards incompatible changes in 6.0露\nDatabase backend API露\nThis section describes changes that may be needed in third-party database\nbackends.\nBaseDatabaseSchemaEditor and\nPostgreSQL backends no longer use CASCADE when dropping a column.\nBaseDatabaseSchemaEditor and\nPostgreSQL backends no longer use CASCADE when dropping a column.\nBaseDatabaseSchemaEditor\nCASCADE\nDatabaseOperations.return_insert_columns() and\nDatabaseOperations.fetch_returned_insert_rows() methods are renamed to\nreturning_columns() and fetch_returned_rows(), respectively, to\ndenote they can be used in the context of UPDATE  RETURNING statements\nas well as INSERT  RETURNING.\nDatabaseOperations.return_insert_columns() and\nDatabaseOperations.fetch_returned_insert_rows() methods are renamed to\nreturning_columns() and fetch_returned_rows(), respectively, to\ndenote they can be used in the context of UPDATE  RETURNING statements\nas well as INSERT  RETURNING.\nDatabaseOperations.return_insert_columns()\nDatabaseOperations.fetch_returned_insert_rows()\nreturning_columns()\nfetch_returned_rows()\nUPDATE  RETURNING\nINSERT  RETURNING\nThe DatabaseOperations.fetch_returned_insert_columns() method is removed\nand the fetch_returned_rows() method replacing\nfetch_returned_insert_rows() expects both a cursor and\nreturning_params to be provided, just like\nfetch_returned_insert_columns() did.\nThe DatabaseOperations.fetch_returned_insert_columns() method is removed\nand the fetch_returned_rows() method replacing\nfetch_returned_insert_rows() expects both a cursor and\nreturning_params to be provided, just like\nfetch_returned_insert_columns() did.\nDatabaseOperations.fetch_returned_insert_columns()\nfetch_returned_rows()\nfetch_returned_insert_rows()\ncursor\nreturning_params\nfetch_returned_insert_columns()\nIf the database supports UPDATE  RETURNING statements, backends can set\nDatabaseFeatures.can_return_rows_from_update=True.\nIf the database supports UPDATE  RETURNING statements, backends can set\nDatabaseFeatures.can_return_rows_from_update=True.\nUPDATE  RETURNING\nDatabaseFeatures.can_return_rows_from_update=True\nDropped support for MariaDB 10.5露\nUpstream support for MariaDB 10.5 ends in June 2025. Django 6.0 supports\nMariaDB 10.6 and higher.\nDropped support for Python < 3.12露\nBecause Python 3.12 is now the minimum supported version for Django, any\noptional dependencies must also meet that requirement. The following versions\nof each library are the first to add or confirm compatibility with Python 3.12:\naiosmtpd 1.4.5\naiosmtpd 1.4.5\naiosmtpd\nargon2-cffi 23.1.0\nargon2-cffi 23.1.0\nargon2-cffi\nbcrypt 4.1.1\nbcrypt 4.1.1\nbcrypt\ndocutils 0.22\ndocutils 0.22\ndocutils\ngeoip2 4.8.0\ngeoip2 4.8.0\ngeoip2\nPillow 10.1.0\nPillow 10.1.0\nPillow\nmysqlclient 2.2.1\nmysqlclient 2.2.1\nmysqlclient\nnumpy 1.26.0\nnumpy 1.26.0\nnumpy\nPyYAML 6.0.2\nPyYAML 6.0.2\nPyYAML\npsycopg 3.1.12\npsycopg 3.1.12\npsycopg\npsycopg2 2.9.9\npsycopg2 2.9.9\npsycopg2\nredis-py 5.1.0\nredis-py 5.1.0\nredis-py\nselenium 4.23.0\nselenium 4.23.0\nselenium\nsqlparse 0.5.0\nsqlparse 0.5.0\nsqlparse\ntblib 3.0.0\ntblib 3.0.0\ntblib\nEmail露\nThe undocumented mixed_subtype and alternative_subtype properties\nof EmailMessage and\nEmailMultiAlternatives are no longer supported.\nThe undocumented mixed_subtype and alternative_subtype properties\nof EmailMessage and\nEmailMultiAlternatives are no longer supported.\nmixed_subtype\nalternative_subtype\nEmailMessage\nEmailMultiAlternatives\nThe undocumented encoding property of\nEmailMessage no longer supports Python legacy\nemail.charset.Charset objects.\nThe undocumented encoding property of\nEmailMessage no longer supports Python legacy\nemail.charset.Charset objects.\nencoding\nEmailMessage\nemail.charset.Charset\nAs the internal implementations of EmailMessage\nand EmailMultiAlternatives have changed\nsignificantly, closely examine any custom subclasses that rely on overriding\nundocumented, internal underscore methods.\nAs the internal implementations of EmailMessage\nand EmailMultiAlternatives have changed\nsignificantly, closely examine any custom subclasses that rely on overriding\nundocumented, internal underscore methods.\nEmailMessage\nEmailMultiAlternatives\nDEFAULT_AUTO_FIELD setting now defaults to BigAutoField露\nDEFAULT_AUTO_FIELD\nBigAutoField\nSince Django 3.2, when the DEFAULT_AUTO_FIELD setting was added,\nthe default startproject templates settings.py contained:\nDEFAULT_AUTO_FIELD\nstartproject\nsettings.py\nDEFAULT_AUTO_FIELD = \"django.db.models.BigAutoField\"\nand the default startapp templates AppConfig contained:\nstartapp\nAppConfig\ndefault_auto_field = \"django.db.models.BigAutoField\"\nAt that time, the default value of DEFAULT_AUTO_FIELD remained\ndjango.db.models.AutoField for backwards compatibility.\nDEFAULT_AUTO_FIELD\ndjango.db.models.AutoField\nIn Django 6.0, DEFAULT_AUTO_FIELD now defaults to\ndjango.db.models.BigAutoField and the aforementioned lines in the\nproject and app templates are removed.\nDEFAULT_AUTO_FIELD\ndjango.db.models.BigAutoField\nMost projects shouldnt be affected, since Django 3.2 has raised the system\ncheck warning models.W042 for projects that dont set\nDEFAULT_AUTO_FIELD.\nDEFAULT_AUTO_FIELD\nIf you havent dealt with this warning by now, add\nDEFAULT_AUTO_FIELD = 'django.db.models.AutoField' to your projects\nsettings, or default_auto_field = 'django.db.models.AutoField' to an apps\nAppConfig, as needed.\nDEFAULT_AUTO_FIELD = 'django.db.models.AutoField'\ndefault_auto_field = 'django.db.models.AutoField'\nAppConfig\nCustom ORM expressions should return params as a tuple露\nPrior to Django 6.0, custom lookups and\ncustom expressions implementing the\nas_sql() method (and its supporting methods process_lhs() and\nprocess_rhs()) were allowed to return a sequence of params in either a list\nor a tuple. To address the interoperability problems that resulted, the second\nreturn element of the as_sql() method should now be a tuple:\nas_sql()\nprocess_lhs()\nprocess_rhs()\nas_sql()\ndef as_sql(self, compiler, connection) -> tuple[str, tuple]: ...\nIf your custom expressions support multiple versions of Django, you should\nadjust any pre-processing of parameters to be resilient against either tuples\nor lists. For instance, prefer unpacking like this:\nparams = (*lhs_params, *rhs_params)\nMiscellaneous露\nThe JSON serializer now writes a newline\nat the end of the output, even without the indent option set.\nThe JSON serializer now writes a newline\nat the end of the output, even without the indent option set.\nindent\nThe minimum supported version of asgiref is increased from 3.8.1 to\n3.9.1.\nThe minimum supported version of asgiref is increased from 3.8.1 to\n3.9.1.\nasgiref\nFeatures deprecated in 6.0露\nPositional arguments in django.core.mail APIs露\ndjango.core.mail\ndjango.core.mail APIs now require keyword arguments for less commonly\nused parameters. Using positional arguments for these now emits a deprecation\nwarning and will raise a TypeError when the deprecation period ends:\ndjango.core.mail\nTypeError\nAll optional parameters (fail_silently and later) must be passed as\nkeyword arguments to get_connection(), mail_admins(),\nmail_managers(), send_mail(), and send_mass_mail().\nAll optional parameters (fail_silently and later) must be passed as\nkeyword arguments to get_connection(), mail_admins(),\nmail_managers(), send_mail(), and send_mass_mail().\nfail_silently\nget_connection()\nmail_admins()\nmail_managers()\nsend_mail()\nsend_mass_mail()\nAll parameters must be passed as keyword arguments when creating an\nEmailMessage or EmailMultiAlternatives instance, except\nfor the first four (subject, body, from_email, and to), which\nmay still be passed either as positional or keyword arguments.\nAll parameters must be passed as keyword arguments when creating an\nEmailMessage or EmailMultiAlternatives instance, except\nfor the first four (subject, body, from_email, and to), which\nmay still be passed either as positional or keyword arguments.\nEmailMessage\nEmailMultiAlternatives\nsubject\nbody\nfrom_email\nto\nMiscellaneous露\nBaseDatabaseCreation.create_test_db(serialize) is deprecated. Use\nserialize_db_to_string() instead.\nBaseDatabaseCreation.create_test_db(serialize) is deprecated. Use\nserialize_db_to_string() instead.\nBaseDatabaseCreation.create_test_db(serialize)\nserialize_db_to_string()\nThe PostgreSQL StringAgg class is deprecated in favor of the generally\navailable StringAgg class.\nThe PostgreSQL StringAgg class is deprecated in favor of the generally\navailable StringAgg class.\nStringAgg\nStringAgg\nThe PostgreSQL OrderableAggMixin is deprecated in favor of the\norder_by attribute now available on the\nAggregate class.\nThe PostgreSQL OrderableAggMixin is deprecated in favor of the\norder_by attribute now available on the\nAggregate class.\nOrderableAggMixin\norder_by\nAggregate\nThe default protocol in urlize and urlizetrunc will\nchange from HTTP to HTTPS in Django 7.0. Set the transitional setting\nURLIZE_ASSUME_HTTPS to True to opt into assuming HTTPS during\nthe Django 6.x release cycle.\nThe default protocol in urlize and urlizetrunc will\nchange from HTTP to HTTPS in Django 7.0. Set the transitional setting\nURLIZE_ASSUME_HTTPS to True to opt into assuming HTTPS during\nthe Django 6.x release cycle.\nurlize\nurlizetrunc\nURLIZE_ASSUME_HTTPS\nTrue\nThe URLIZE_ASSUME_HTTPS transitional setting is deprecated.\nThe URLIZE_ASSUME_HTTPS transitional setting is deprecated.\nURLIZE_ASSUME_HTTPS\nSetting ADMINS or MANAGERS to a list of (name, address)\ntuples is deprecated. Set to a list of email address strings instead. Django\nnever used the name portion. To include a name, format the address string as\n'\"Name\" <address>' or use Pythons email.utils.formataddr().\nSetting ADMINS or MANAGERS to a list of (name, address)\ntuples is deprecated. Set to a list of email address strings instead. Django\nnever used the name portion. To include a name, format the address string as\n'\"Name\" <address>' or use Pythons email.utils.formataddr().\nADMINS\nMANAGERS\n'\"Name\" <address>'\nemail.utils.formataddr()\nSupport for the orphans argument being larger than or equal to the\nper_page argument of django.core.paginator.Paginator and\ndjango.core.paginator.AsyncPaginator is deprecated.\nSupport for the orphans argument being larger than or equal to the\nper_page argument of django.core.paginator.Paginator and\ndjango.core.paginator.AsyncPaginator is deprecated.\norphans\nper_page\ndjango.core.paginator.Paginator\ndjango.core.paginator.AsyncPaginator\nUsing a percent sign in a column alias or annotation is deprecated.\nUsing a percent sign in a column alias or annotation is deprecated.\nSupport for passing Pythons legacy email MIMEBase\nobject to\nEmailMessage.attach() (or\nincluding one in the messages attachments list) is deprecated. For\ncomplex attachments requiring additional headers or parameters, switch to the\nmodern email APIs MIMEPart.\nSupport for passing Pythons legacy email MIMEBase\nobject to\nEmailMessage.attach() (or\nincluding one in the messages attachments list) is deprecated. For\ncomplex attachments requiring additional headers or parameters, switch to the\nmodern email APIs MIMEPart.\nMIMEBase\nEmailMessage.attach()\nattachments\nMIMEPart\nThe django.core.mail.BadHeaderError exception is deprecated. Pythons\nmodern email raises a ValueError for email headers containing\nprohibited characters.\nThe django.core.mail.BadHeaderError exception is deprecated. Pythons\nmodern email raises a ValueError for email headers containing\nprohibited characters.\ndjango.core.mail.BadHeaderError\nValueError\nThe django.core.mail.SafeMIMEText and SafeMIMEMultipart classes are\ndeprecated.\nThe django.core.mail.SafeMIMEText and SafeMIMEMultipart classes are\ndeprecated.\ndjango.core.mail.SafeMIMEText\nSafeMIMEMultipart\nThe undocumented django.core.mail.forbid_multi_line_headers() and\ndjango.core.mail.message.sanitize_address() functions are deprecated.\nThe undocumented django.core.mail.forbid_multi_line_headers() and\ndjango.core.mail.message.sanitize_address() functions are deprecated.\ndjango.core.mail.forbid_multi_line_headers()\ndjango.core.mail.message.sanitize_address()\nFeatures removed in 6.0露\nThese features have reached the end of their deprecation cycle and are removed\nin Django 6.0.\nSee Features deprecated in 5.0 for details on these changes, including how\nto remove usage of these features.\nSupport for passing positional arguments to BaseConstraint is removed.\nSupport for passing positional arguments to BaseConstraint is removed.\nBaseConstraint\nThe DjangoDivFormRenderer and Jinja2DivFormRenderer transitional form\nrenderers are removed.\nThe DjangoDivFormRenderer and Jinja2DivFormRenderer transitional form\nrenderers are removed.\nDjangoDivFormRenderer\nJinja2DivFormRenderer\nBaseDatabaseOperations.field_cast_sql() is removed.\nBaseDatabaseOperations.field_cast_sql() is removed.\nBaseDatabaseOperations.field_cast_sql()\nrequest is required in the signature of ModelAdmin.lookup_allowed()\nsubclasses.\nrequest is required in the signature of ModelAdmin.lookup_allowed()\nsubclasses.\nrequest\nModelAdmin.lookup_allowed()\nSupport for calling format_html() without passing args or kwargs is\nremoved.\nSupport for calling format_html() without passing args or kwargs is\nremoved.\nformat_html()\nThe default scheme for forms.URLField has changed from \"http\" to\n\"https\".\nThe default scheme for forms.URLField has changed from \"http\" to\n\"https\".\nforms.URLField\n\"http\"\n\"https\"\nThe FORMS_URLFIELD_ASSUME_HTTPS transitional setting is removed.\nThe FORMS_URLFIELD_ASSUME_HTTPS transitional setting is removed.\nFORMS_URLFIELD_ASSUME_HTTPS\nThe django.db.models.sql.datastructures.Join no longer falls back to\nget_joining_columns().\nThe django.db.models.sql.datastructures.Join no longer falls back to\nget_joining_columns().\ndjango.db.models.sql.datastructures.Join\nget_joining_columns()\nThe get_joining_columns() method of ForeignObject and\nForeignObjectRel is removed.\nThe get_joining_columns() method of ForeignObject and\nForeignObjectRel is removed.\nget_joining_columns()\nForeignObject\nForeignObjectRel\nThe ForeignObject.get_reverse_joining_columns() method is removed.\nThe ForeignObject.get_reverse_joining_columns() method is removed.\nForeignObject.get_reverse_joining_columns()\nSupport for cx_Oracle is removed.\nSupport for cx_Oracle is removed.\ncx_Oracle\nThe ChoicesMeta alias to django.db.models.enums.ChoicesType is\nremoved.\nThe ChoicesMeta alias to django.db.models.enums.ChoicesType is\nremoved.\nChoicesMeta\ndjango.db.models.enums.ChoicesType\nThe Prefetch.get_current_queryset() method is removed.\nThe Prefetch.get_current_queryset() method is removed.\nPrefetch.get_current_queryset()\nThe get_prefetch_queryset() method of related managers and descriptors is\nremoved.\nThe get_prefetch_queryset() method of related managers and descriptors is\nremoved.\nget_prefetch_queryset()\nget_prefetcher() and prefetch_related_objects() no longer fall back\nto get_prefetch_queryset().\nget_prefetcher() and prefetch_related_objects() no longer fall back\nto get_prefetch_queryset().\nget_prefetcher()\nprefetch_related_objects()\nget_prefetch_queryset()\nSee Features deprecated in 5.1 for details on these changes, including how\nto remove usage of these features.\ndjango.urls.register_converter() no longer allows overriding existing\nconverters.\ndjango.urls.register_converter() no longer allows overriding existing\nconverters.\ndjango.urls.register_converter()\nThe ModelAdmin.log_deletion() and LogEntryManager.log_action()\nmethods are removed.\nThe ModelAdmin.log_deletion() and LogEntryManager.log_action()\nmethods are removed.\nModelAdmin.log_deletion()\nLogEntryManager.log_action()\nThe undocumented django.utils.itercompat.is_iterable() function and the\ndjango.utils.itercompat module are removed.\nThe undocumented django.utils.itercompat.is_iterable() function and the\ndjango.utils.itercompat module are removed.\ndjango.utils.itercompat.is_iterable()\ndjango.utils.itercompat\nThe django.contrib.gis.geoip2.GeoIP2.coords() method is removed.\nThe django.contrib.gis.geoip2.GeoIP2.coords() method is removed.\ndjango.contrib.gis.geoip2.GeoIP2.coords()\nThe django.contrib.gis.geoip2.GeoIP2.open() method is removed.\nThe django.contrib.gis.geoip2.GeoIP2.open() method is removed.\ndjango.contrib.gis.geoip2.GeoIP2.open()\nSupport for passing positional arguments to Model.save() and\nModel.asave() is removed.\nSupport for passing positional arguments to Model.save() and\nModel.asave() is removed.\nModel.save()\nModel.asave()\nThe setter for django.contrib.gis.gdal.OGRGeometry.coord_dim is removed.\nThe setter for django.contrib.gis.gdal.OGRGeometry.coord_dim is removed.\ndjango.contrib.gis.gdal.OGRGeometry.coord_dim\nThe check keyword argument of CheckConstraint is removed.\nThe check keyword argument of CheckConstraint is removed.\ncheck\nCheckConstraint\nThe get_cache_name() method of FieldCacheMixin is removed.\nThe get_cache_name() method of FieldCacheMixin is removed.\nget_cache_name()\nFieldCacheMixin\nThe OS_OPEN_FLAGS attribute of\nFileSystemStorage is removed.\nThe OS_OPEN_FLAGS attribute of\nFileSystemStorage is removed.\nOS_OPEN_FLAGS\nFileSystemStorage\nAdditional Information\nSupport Django!\nOmen Apps donated to the Django Software Foundation to support Django development. Donate today!\nContents\nDjango 6.0 release notes\nPython compatibility\nThird-party library support for older versions of Django\nWhats new in Django 6.0\nContent Security Policy support\nTemplate Partials\nBackground Tasks\nAdoption of Pythons modern email API\nMinor features\ndjango.contrib.admin\ndjango.contrib.auth\ndjango.contrib.gis\ndjango.contrib.postgres\ndjango.contrib.staticfiles\nEmail\nInternationalization\nManagement Commands\nMigrations\nModels\nPagination\nRequests and Responses\nTemplates\nTests\n\n\n\n\nBackwards incompatible changes in 6.0\nDatabase backend API\nDropped support for MariaDB 10.5\nDropped support for Python < 3.12\nEmail\nDEFAULT_AUTO_FIELD setting now defaults to BigAutoField\nCustom ORM expressions should return params as a tuple\nMiscellaneous\n\n\nFeatures deprecated in 6.0\nPositional arguments in django.core.mail APIs\nMiscellaneous\n\n\nFeatures removed in 6.0\nPython compatibility\nThird-party library support for older versions of Django\nWhats new in Django 6.0\nContent Security Policy support\nTemplate Partials\nBackground Tasks\nAdoption of Pythons modern email API\nMinor features\ndjango.contrib.admin\ndjango.contrib.auth\ndjango.contrib.gis\ndjango.contrib.postgres\ndjango.contrib.staticfiles\nEmail\nInternationalization\nManagement Commands\nMigrations\nModels\nPagination\nRequests and Responses\nTemplates\nTests\nContent Security Policy support\nTemplate Partials\nBackground Tasks\nAdoption of Pythons modern email API\nMinor features\ndjango.contrib.admin\ndjango.contrib.auth\ndjango.contrib.gis\ndjango.contrib.postgres\ndjango.contrib.staticfiles\nEmail\nInternationalization\nManagement Commands\nMigrations\nModels\nPagination\nRequests and Responses\nTemplates\nTests\ndjango.contrib.admin\ndjango.contrib.admin\ndjango.contrib.auth\ndjango.contrib.auth\ndjango.contrib.gis\ndjango.contrib.gis\ndjango.contrib.postgres\ndjango.contrib.postgres\ndjango.contrib.staticfiles\ndjango.contrib.staticfiles\nEmail\nInternationalization\nManagement Commands\nMigrations\nModels\nPagination\nRequests and Responses\nTemplates\nTests\nBackwards incompatible changes in 6.0\nDatabase backend API\nDropped support for MariaDB 10.5\nDropped support for Python < 3.12\nEmail\nDEFAULT_AUTO_FIELD setting now defaults to BigAutoField\nCustom ORM expressions should return params as a tuple\nMiscellaneous\nDatabase backend API\nDropped support for MariaDB 10.5\nDropped support for Python < 3.12\nEmail\nDEFAULT_AUTO_FIELD setting now defaults to BigAutoField\nDEFAULT_AUTO_FIELD\nBigAutoField\nCustom ORM expressions should return params as a tuple\nMiscellaneous\nFeatures deprecated in 6.0\nPositional arguments in django.core.mail APIs\nMiscellaneous\nPositional arguments in django.core.mail APIs\ndjango.core.mail\nMiscellaneous\nFeatures removed in 6.0\nBrowse\nPrev: Django 6.0.1 release notes\nNext: Django 5.2.10 release notes\nTable of contents\nGeneral Index\nPython Module Index\nYou are here:\nDjango 6.0 documentation\nRelease notes\nDjango 6.0 release notes\nRelease notes\nDjango 6.0 release notes\nDjango 6.0 release notes\nGetting help\nDownload:\nOffline (Django 6.0):\n          HTML |\n          PDF |\n          ePub\n\n\n            Provided by Read the Docs.\nDiamond and Platinum Members\nSentry\nMonitor your Django Code\r\nResolve performance bottlenecks and errors using monitoring, replays, logs and Seer an AI agent for debugging.\nJetBrains\nJetBrains delivers intelligent software solutions that make developers more productive by simplifying their challenging tasks, automating the routine, and helping them adopt the best development practices. PyCharm is the Python IDE for Professional Developers by JetBrains providing a complete set of tools for productive Python, Web and scientific development.\nDjango Links\nLearn More\nAbout Django\nGetting Started with Django\nTeam Organization\nDjango Software Foundation\nCode of Conduct\nDiversity Statement\nGet Involved\nJoin a Group\nContribute\n              to Django\nSubmit\n              a Bug\nReport\n              a Security Issue\nIndividual membership\nGet Help\nGetting Help FAQ\nDjango Discord\nOfficial Django Forum\nFollow Us\nGitHub\nX\nFediverse (Mastodon)\nBluesky\nLinkedIn\nNews RSS\nSupport Us\nSponsor Django\nCorporate membership\nOfficial merchandise store\nBenevity Workplace Giving Program\nHosting by In-kind\n            donors\nDesign by Threespot\n& andrevv\n漏 2005-2025\n         Django Software\n          Foundation and individual contributors. Django is a\n        registered\n          trademark of the Django Software Foundation.",
    "crawl_status": "success"
  },
  {
    "library_name": "Django",
    "url": "https://docs.djangoproject.com/en/5.0/releases/5.0/",
    "version": "5.0",
    "title": "Django 5.0 release notes | Django documentation | Django",
    "release_date": "Unknown release date",
    "content": "The web framework for perfectionists with deadlines.\nOverview\nDownload\nDocumentation\nNews\nCode\nIssues\nCommunity\nFoundation\n Donate\nSearch\n\n\n\n\nSubmit\nToggle theme (current theme: auto)\nToggle theme (current theme: light)\nToggle theme (current theme: dark)\nToggle Light / Dark / Auto color theme\nDocumentation\nGetting Help\nel\nes\nfr\nid\nit\nja\nko\npl\npt-br\nzh-hans\nLanguage: en\n5.1\n5.2\n6.0\ndev\nDocumentation version:\n          5.0\nDjango 5.0 release notes露\nDecember 4, 2023\nWelcome to Django 5.0!\nThese release notes cover the new features, as well as\nsome backwards incompatible changes youll\nwant to be aware of when upgrading from Django 4.2 or earlier. Weve\nbegun the deprecation process for some features.\nSee the How to upgrade Django to a newer version guide if youre updating an existing\nproject.\nPython compatibility露\nDjango 5.0 supports Python 3.10, 3.11, and 3.12. We highly recommend and\nonly officially support the latest release of each series.\nThe Django 4.2.x series is the last to support Python 3.8 and 3.9.\nThird-party library support for older version of Django露\nFollowing the release of Django 5.0, we suggest that third-party app authors\ndrop support for all versions of Django prior to 4.2. At that time, you should\nbe able to run your packages tests using python -Wd so that deprecation\nwarnings appear. After making the deprecation warning fixes, your app should be\ncompatible with Django 5.0.\npython -Wd\nWhats new in Django 5.0露\nFacet filters in the admin露\nFacet counts are now shown for applied filters in the admin changelist when\ntoggled on via the UI. This behavior can be changed via the new\nModelAdmin.show_facets attribute. For more information see\nFacets.\nModelAdmin.show_facets\nSimplified templates for form field rendering露\nDjango 5.0 introduces the concept of a field group, and field group templates.\nThis simplifies rendering of the related elements of a Django form field such\nas its label, widget, help text, and errors.\nFor example, the template below:\n<form>\n...\n<div>\n  {{ form.name.label_tag }}\n  {% if form.name.help_text %}\n    <div class=\"helptext\" id=\"{{ form.name.auto_id }}_helptext\">\n      {{ form.name.help_text|safe }}\n    </div>\n  {% endif %}\n  {{ form.name.errors }}\n  {{ form.name }}\n  <div class=\"row\">\n    <div class=\"col\">\n      {{ form.email.label_tag }}\n      {% if form.email.help_text %}\n        <div class=\"helptext\" id=\"{{ form.email.auto_id }}_helptext\">\n          {{ form.email.help_text|safe }}\n        </div>\n      {% endif %}\n      {{ form.email.errors }}\n      {{ form.email }}\n    </div>\n    <div class=\"col\">\n      {{ form.password.label_tag }}\n      {% if form.password.help_text %}\n        <div class=\"helptext\" id=\"{{ form.password.auto_id }}_helptext\">\n          {{ form.password.help_text|safe }}\n        </div>\n      {% endif %}\n      {{ form.password.errors }}\n      {{ form.password }}\n    </div>\n  </div>\n</div>\n...\n</form>\nCan now be simplified to:\n<form>\n...\n<div>\n  {{ form.name.as_field_group }}\n  <div class=\"row\">\n    <div class=\"col\">{{ form.email.as_field_group }}</div>\n    <div class=\"col\">{{ form.password.as_field_group }}</div>\n  </div>\n</div>\n...\n</form>\nas_field_group() renders fields with the\n\"django/forms/field.html\" template by default and can be customized on a\nper-project, per-field, or per-request basis. See\nReusable field group templates.\nas_field_group()\n\"django/forms/field.html\"\nDatabase-computed default values露\nThe new Field.db_default parameter\nsets a database-computed default value. For example:\nField.db_default\nfrom django.db import models\nfrom django.db.models.functions import Now, Pi\n\n\nclass MyModel(models.Model):\n    age = models.IntegerField(db_default=18)\n    created = models.DateTimeField(db_default=Now())\n    circumference = models.FloatField(db_default=2 * Pi())\nDatabase generated model field露\nThe new GeneratedField allows creation of database\ngenerated columns. This field can be used on all supported database backends\nto create a field that is always computed from other fields. For example:\nGeneratedField\nfrom django.db import models\nfrom django.db.models import F\n\n\nclass Square(models.Model):\n    side = models.IntegerField()\n    area = models.GeneratedField(\n        expression=F(\"side\") * F(\"side\"),\n        output_field=models.BigIntegerField(),\n        db_persist=True,\n    )\nMore options for declaring field choices露\nField.choices (for model fields) and ChoiceField.choices\n(for form fields) allow for more flexibility when declaring their values. In\nprevious versions of Django, choices should either be a list of 2-tuples,\nor an Enumeration types subclass, but the latter required\naccessing the .choices attribute to provide the values in the expected\nform:\nField.choices\nChoiceField.choices\nchoices\n.choices\nfrom django.db import models\n\nMedal = models.TextChoices(\"Medal\", \"GOLD SILVER BRONZE\")\n\nSPORT_CHOICES = [\n    (\"Martial Arts\", [(\"judo\", \"Judo\"), (\"karate\", \"Karate\")]),\n    (\"Racket\", [(\"badminton\", \"Badminton\"), (\"tennis\", \"Tennis\")]),\n    (\"unknown\", \"Unknown\"),\n]\n\n\nclass Winner(models.Model):\n    name = models.CharField(...)\n    medal = models.CharField(..., choices=Medal.choices)\n    sport = models.CharField(..., choices=SPORT_CHOICES)\nDjango 5.0 adds support for accepting a mapping or a callable instead of an\niterable, and also no longer requires .choices to be used directly to\nexpand enumeration types:\n.choices\nfrom django.db import models\n\nMedal = models.TextChoices(\"Medal\", \"GOLD SILVER BRONZE\")\n\nSPORT_CHOICES = {  # Using a mapping instead of a list of 2-tuples.\n    \"Martial Arts\": {\"judo\": \"Judo\", \"karate\": \"Karate\"},\n    \"Racket\": {\"badminton\": \"Badminton\", \"tennis\": \"Tennis\"},\n    \"unknown\": \"Unknown\",\n}\n\n\ndef get_scores():\n    return [(i, str(i)) for i in range(10)]\n\n\nclass Winner(models.Model):\n    name = models.CharField(...)\n    medal = models.CharField(..., choices=Medal)  # Using `.choices` not required.\n    sport = models.CharField(..., choices=SPORT_CHOICES)\n    score = models.IntegerField(choices=get_scores)  # A callable is allowed.\nUnder the hood the provided choices are normalized into a list of 2-tuples\nas the canonical form whenever the choices value is updated. For more\ninformation, please check the model field reference on choices.\nchoices\nchoices\nMinor features露\ndjango.contrib.admin露\ndjango.contrib.admin\nThe new AdminSite.get_log_entries() method allows customizing the\nqueryset for the sites listed log entries.\nThe new AdminSite.get_log_entries() method allows customizing the\nqueryset for the sites listed log entries.\nAdminSite.get_log_entries()\nThe django.contrib.admin.AllValuesFieldListFilter,\nChoicesFieldListFilter, RelatedFieldListFilter, and\nRelatedOnlyFieldListFilter admin filters now handle multi-valued query\nparameters.\nThe django.contrib.admin.AllValuesFieldListFilter,\nChoicesFieldListFilter, RelatedFieldListFilter, and\nRelatedOnlyFieldListFilter admin filters now handle multi-valued query\nparameters.\ndjango.contrib.admin.AllValuesFieldListFilter\nChoicesFieldListFilter\nRelatedFieldListFilter\nRelatedOnlyFieldListFilter\nXRegExp is upgraded from version 3.2.0 to 5.1.1.\nXRegExp is upgraded from version 3.2.0 to 5.1.1.\nXRegExp\nThe new AdminSite.get_model_admin() method returns an admin class for\nthe given model class.\nThe new AdminSite.get_model_admin() method returns an admin class for\nthe given model class.\nAdminSite.get_model_admin()\nProperties in ModelAdmin.list_display now support boolean\nattribute.\nProperties in ModelAdmin.list_display now support boolean\nattribute.\nModelAdmin.list_display\nboolean\njQuery is upgraded from version 3.6.4 to 3.7.1.\njQuery is upgraded from version 3.6.4 to 3.7.1.\ndjango.contrib.auth露\ndjango.contrib.auth\nThe default iteration count for the PBKDF2 password hasher is increased from\n600,000 to 720,000.\nThe default iteration count for the PBKDF2 password hasher is increased from\n600,000 to 720,000.\nThe new asynchronous functions are now provided, using an\na prefix: django.contrib.auth.aauthenticate(),\naget_user(),\nalogin(), alogout(),\nand aupdate_session_auth_hash().\nThe new asynchronous functions are now provided, using an\na prefix: django.contrib.auth.aauthenticate(),\naget_user(),\nalogin(), alogout(),\nand aupdate_session_auth_hash().\na\ndjango.contrib.auth.aauthenticate()\naget_user()\nalogin()\nalogout()\naupdate_session_auth_hash()\nAuthenticationMiddleware now adds an HttpRequest.auser()\nasynchronous method that returns the currently logged-in user.\nAuthenticationMiddleware now adds an HttpRequest.auser()\nasynchronous method that returns the currently logged-in user.\nAuthenticationMiddleware\nHttpRequest.auser()\nThe new django.contrib.auth.hashers.acheck_password() asynchronous\nfunction and AbstractBaseUser.acheck_password() method allow\nasynchronous checking of user passwords.\nThe new django.contrib.auth.hashers.acheck_password() asynchronous\nfunction and AbstractBaseUser.acheck_password() method allow\nasynchronous checking of user passwords.\ndjango.contrib.auth.hashers.acheck_password()\nAbstractBaseUser.acheck_password()\ndjango.contrib.contenttypes露\ndjango.contrib.contenttypes\nQuerySet.prefetch_related() now supports prefetching\nGenericForeignKey with\nnon-homogeneous set of results.\nQuerySet.prefetch_related() now supports prefetching\nGenericForeignKey with\nnon-homogeneous set of results.\nQuerySet.prefetch_related()\nGenericForeignKey\ndjango.contrib.gis露\ndjango.contrib.gis\nThe new\nClosestPoint()\nfunction returns a 2-dimensional point on the geometry that is closest to\nanother geometry.\nThe new\nClosestPoint()\nfunction returns a 2-dimensional point on the geometry that is closest to\nanother geometry.\nClosestPoint()\nGIS aggregates now support the filter\nargument.\nGIS aggregates now support the filter\nargument.\nfilter\nSupport for GDAL 3.7 and GEOS 3.12 is added.\nSupport for GDAL 3.7 and GEOS 3.12 is added.\nThe new GEOSGeometry.equals_identical() method allows point-wise\nequivalence checking of geometries.\nThe new GEOSGeometry.equals_identical() method allows point-wise\nequivalence checking of geometries.\nGEOSGeometry.equals_identical()\ndjango.contrib.messages露\ndjango.contrib.messages\nThe new MessagesTestMixin.assertMessages() assertion method allows\ntesting messages added to a\nresponse.\nThe new MessagesTestMixin.assertMessages() assertion method allows\ntesting messages added to a\nresponse.\nMessagesTestMixin.assertMessages()\nmessages\nresponse\ndjango.contrib.postgres露\ndjango.contrib.postgres\nThe new violation_error_code attribute of\nExclusionConstraint allows\ncustomizing the code of ValidationError raised during\nmodel validation.\nThe new violation_error_code attribute of\nExclusionConstraint allows\ncustomizing the code of ValidationError raised during\nmodel validation.\nviolation_error_code\nExclusionConstraint\ncode\nValidationError\nAsynchronous views露\nUnder ASGI, http.disconnect events are now handled. This allows views to\nperform any necessary cleanup if a client disconnects before the response is\ngenerated. See Handling disconnects for more details.\nUnder ASGI, http.disconnect events are now handled. This allows views to\nperform any necessary cleanup if a client disconnects before the response is\ngenerated. See Handling disconnects for more details.\nhttp.disconnect\nDecorators露\nThe following decorators now support wrapping asynchronous view functions:\n\ncache_control()\nnever_cache()\nno_append_slash()\ncsrf_exempt()\ncsrf_protect()\nensure_csrf_cookie()\nrequires_csrf_token()\nsensitive_variables()\nsensitive_post_parameters()\ngzip_page()\ncondition()\nconditional_page()\netag()\nlast_modified()\nrequire_http_methods()\nrequire_GET()\nrequire_POST()\nrequire_safe()\nvary_on_cookie()\nvary_on_headers()\nxframe_options_deny()\nxframe_options_sameorigin()\nxframe_options_exempt()\nThe following decorators now support wrapping asynchronous view functions:\ncache_control()\ncache_control()\ncache_control()\nnever_cache()\nnever_cache()\nnever_cache()\nno_append_slash()\nno_append_slash()\nno_append_slash()\ncsrf_exempt()\ncsrf_exempt()\ncsrf_exempt()\ncsrf_protect()\ncsrf_protect()\ncsrf_protect()\nensure_csrf_cookie()\nensure_csrf_cookie()\nensure_csrf_cookie()\nrequires_csrf_token()\nrequires_csrf_token()\nrequires_csrf_token()\nsensitive_variables()\nsensitive_variables()\nsensitive_variables()\nsensitive_post_parameters()\nsensitive_post_parameters()\nsensitive_post_parameters()\ngzip_page()\ngzip_page()\ngzip_page()\ncondition()\ncondition()\ncondition()\nconditional_page()\nconditional_page()\nconditional_page()\netag()\netag()\netag()\nlast_modified()\nlast_modified()\nlast_modified()\nrequire_http_methods()\nrequire_http_methods()\nrequire_http_methods()\nrequire_GET()\nrequire_GET()\nrequire_GET()\nrequire_POST()\nrequire_POST()\nrequire_POST()\nrequire_safe()\nrequire_safe()\nrequire_safe()\nvary_on_cookie()\nvary_on_cookie()\nvary_on_cookie()\nvary_on_headers()\nvary_on_headers()\nvary_on_headers()\nxframe_options_deny()\nxframe_options_deny()\nxframe_options_deny()\nxframe_options_sameorigin()\nxframe_options_sameorigin()\nxframe_options_sameorigin()\nxframe_options_exempt()\nxframe_options_exempt()\nxframe_options_exempt()\nError Reporting露\nsensitive_variables() and\nsensitive_post_parameters() can now be\nused with asynchronous functions.\nsensitive_variables() and\nsensitive_post_parameters() can now be\nused with asynchronous functions.\nsensitive_variables()\nsensitive_post_parameters()\nFile Storage露\nFile.open() now passes all positional (*args) and keyword\narguments (**kwargs) to Pythons built-in open().\nFile.open() now passes all positional (*args) and keyword\narguments (**kwargs) to Pythons built-in open().\nFile.open()\n*args\n**kwargs\nopen()\nForms露\nThe new assume_scheme argument for\nURLField allows specifying a default URL scheme.\nThe new assume_scheme argument for\nURLField allows specifying a default URL scheme.\nassume_scheme\nURLField\nIn order to improve accessibility, the following changes are made:\n\nForm fields now include the aria-describedby HTML attribute to enable\nscreen readers to associate form fields with their help text.\nInvalid form fields now include the aria-invalid=\"true\" HTML attribute.\nIn order to improve accessibility, the following changes are made:\nForm fields now include the aria-describedby HTML attribute to enable\nscreen readers to associate form fields with their help text.\nForm fields now include the aria-describedby HTML attribute to enable\nscreen readers to associate form fields with their help text.\naria-describedby\nInvalid form fields now include the aria-invalid=\"true\" HTML attribute.\nInvalid form fields now include the aria-invalid=\"true\" HTML attribute.\naria-invalid=\"true\"\nInternationalization露\nSupport and translations for the Uyghur language are now available.\nSupport and translations for the Uyghur language are now available.\nMigrations露\nSerialization of functions decorated with functools.cache() or\nfunctools.lru_cache() is now supported without the need to write a\ncustom serializer.\nSerialization of functions decorated with functools.cache() or\nfunctools.lru_cache() is now supported without the need to write a\ncustom serializer.\nfunctools.cache()\nfunctools.lru_cache()\nModels露\nThe new create_defaults argument of QuerySet.update_or_create()\nand QuerySet.aupdate_or_create() methods allows specifying a different\nfield values for the create operation.\nThe new create_defaults argument of QuerySet.update_or_create()\nand QuerySet.aupdate_or_create() methods allows specifying a different\nfield values for the create operation.\ncreate_defaults\nQuerySet.update_or_create()\nQuerySet.aupdate_or_create()\nThe new violation_error_code attribute of\nBaseConstraint,\nCheckConstraint, and\nUniqueConstraint allows customizing the code\nof ValidationError raised during\nmodel validation.\nThe new violation_error_code attribute of\nBaseConstraint,\nCheckConstraint, and\nUniqueConstraint allows customizing the code\nof ValidationError raised during\nmodel validation.\nviolation_error_code\nBaseConstraint\nCheckConstraint\nUniqueConstraint\ncode\nValidationError\nThe force_insert argument of\nModel.save() now allows specifying a tuple of parent classes that must\nbe forced to be inserted.\nThe force_insert argument of\nModel.save() now allows specifying a tuple of parent classes that must\nbe forced to be inserted.\nModel.save()\nQuerySet.bulk_create() and QuerySet.abulk_create() methods now\nset the primary key on each model instance when the update_conflicts\nparameter is enabled (if the database supports it).\nQuerySet.bulk_create() and QuerySet.abulk_create() methods now\nset the primary key on each model instance when the update_conflicts\nparameter is enabled (if the database supports it).\nQuerySet.bulk_create()\nQuerySet.abulk_create()\nupdate_conflicts\nThe new UniqueConstraint.nulls_distinct attribute allows customizing\nthe treatment of NULL values on PostgreSQL 15+.\nThe new UniqueConstraint.nulls_distinct attribute allows customizing\nthe treatment of NULL values on PostgreSQL 15+.\nUniqueConstraint.nulls_distinct\nNULL\nThe new aget_object_or_404() and\naget_list_or_404() asynchronous shortcuts allow\nasynchronous getting objects.\nThe new aget_object_or_404() and\naget_list_or_404() asynchronous shortcuts allow\nasynchronous getting objects.\naget_object_or_404()\naget_list_or_404()\nThe new aprefetch_related_objects() function allows\nasynchronous prefetching of model instances.\nThe new aprefetch_related_objects() function allows\nasynchronous prefetching of model instances.\naprefetch_related_objects()\nQuerySet.aiterator() now supports previous calls to\nprefetch_related().\nQuerySet.aiterator() now supports previous calls to\nprefetch_related().\nQuerySet.aiterator()\nprefetch_related()\nOn MariaDB 10.7+, UUIDField is now created as UUID column rather than\nCHAR(32) column. See the migration guide above for more details on\nMigrating existing UUIDField on MariaDB 10.7+.\nOn MariaDB 10.7+, UUIDField is now created as UUID column rather than\nCHAR(32) column. See the migration guide above for more details on\nMigrating existing UUIDField on MariaDB 10.7+.\nUUIDField\nUUID\nCHAR(32)\nDjango now supports oracledb version 1.3.2 or higher. Support for\ncx_Oracle is deprecated as of this release and will be removed in Django\n6.0.\nDjango now supports oracledb version 1.3.2 or higher. Support for\ncx_Oracle is deprecated as of this release and will be removed in Django\n6.0.\ncx_Oracle\nPagination露\nThe new django.core.paginator.Paginator.error_messages argument\nallows customizing the error messages raised by Paginator.page().\nThe new django.core.paginator.Paginator.error_messages argument\nallows customizing the error messages raised by Paginator.page().\ndjango.core.paginator.Paginator.error_messages\nPaginator.page()\nSignals露\nThe new Signal.asend() and Signal.asend_robust() methods allow\nasynchronous signal dispatch. Signal receivers may be synchronous or\nasynchronous, and will be automatically adapted to the correct calling style.\nThe new Signal.asend() and Signal.asend_robust() methods allow\nasynchronous signal dispatch. Signal receivers may be synchronous or\nasynchronous, and will be automatically adapted to the correct calling style.\nSignal.asend()\nSignal.asend_robust()\nTemplates露\nThe new escapeseq template filter applies escape to\neach element of a sequence.\nThe new escapeseq template filter applies escape to\neach element of a sequence.\nescapeseq\nescape\nTests露\nClient and AsyncClient now\nprovide asynchronous methods, using an a prefix:\nasession(), alogin(),\naforce_login(), and\nalogout().\nClient and AsyncClient now\nprovide asynchronous methods, using an a prefix:\nasession(), alogin(),\naforce_login(), and\nalogout().\nClient\nAsyncClient\na\nasession()\nalogin()\naforce_login()\nalogout()\nAsyncClient now supports the follow parameter.\nAsyncClient now supports the follow parameter.\nAsyncClient\nfollow\nThe new test --durations option allows showing the duration of the\nslowest tests on Python 3.12+.\nThe new test --durations option allows showing the duration of the\nslowest tests on Python 3.12+.\ntest --durations\nValidators露\nThe new offset argument of\nStepValueValidator allows specifying an\noffset for valid values.\nThe new offset argument of\nStepValueValidator allows specifying an\noffset for valid values.\noffset\nStepValueValidator\nBackwards incompatible changes in 5.0露\nDatabase backend API露\nThis section describes changes that may be needed in third-party database\nbackends.\nDatabaseFeatures.supports_expression_defaults should be set to False\nif the database doesnt support using database functions as defaults.\nDatabaseFeatures.supports_expression_defaults should be set to False\nif the database doesnt support using database functions as defaults.\nDatabaseFeatures.supports_expression_defaults\nFalse\nDatabaseFeatures.supports_default_keyword_in_insert should be set to\nFalse if the database doesnt support the DEFAULT keyword in\nINSERT queries.\nDatabaseFeatures.supports_default_keyword_in_insert should be set to\nFalse if the database doesnt support the DEFAULT keyword in\nINSERT queries.\nDatabaseFeatures.supports_default_keyword_in_insert\nFalse\nDEFAULT\nINSERT\nDatabaseFeatures.supports_default_keyword_in_bulk_insert should be set to\nFalse if the database doesnt support the DEFAULT keyword in bulk\nINSERT queries.\nDatabaseFeatures.supports_default_keyword_in_bulk_insert should be set to\nFalse if the database doesnt support the DEFAULT keyword in bulk\nINSERT queries.\nDatabaseFeatures.supports_default_keyword_in_bulk_insert\nFalse\nDEFAULT\nINSERT\ndjango.contrib.gis露\ndjango.contrib.gis\nSupport for GDAL 2.2 and 2.3 is removed.\nSupport for GDAL 2.2 and 2.3 is removed.\nSupport for GEOS 3.6 and 3.7 is removed.\nSupport for GEOS 3.6 and 3.7 is removed.\ndjango.contrib.sitemaps露\ndjango.contrib.sitemaps\nThe django.contrib.sitemaps.ping_google() function and the\nping_google management command are removed as the Google\nSitemaps ping endpoint is deprecated and will be removed in January 2024.\nThe django.contrib.sitemaps.ping_google() function and the\nping_google management command are removed as the Google\nSitemaps ping endpoint is deprecated and will be removed in January 2024.\ndjango.contrib.sitemaps.ping_google()\nping_google\nThe django.contrib.sitemaps.SitemapNotFound exception class is removed.\nThe django.contrib.sitemaps.SitemapNotFound exception class is removed.\ndjango.contrib.sitemaps.SitemapNotFound\nDropped support for MySQL < 8.0.11露\nSupport for pre-releases of MySQL 8.0.x series is removed. Django 5.0 supports\nMySQL 8.0.11 and higher.\nUsing create_defaults__exact may now be required with QuerySet.update_or_create()露\ncreate_defaults__exact\nQuerySet.update_or_create()\nQuerySet.update_or_create() now supports the parameter\ncreate_defaults. As a consequence, any models that have a field named\ncreate_defaults that are used with an update_or_create() should specify\nthe field in the lookup with create_defaults__exact.\nQuerySet.update_or_create()\ncreate_defaults\ncreate_defaults\nupdate_or_create()\ncreate_defaults__exact\nMigrating existing UUIDField on MariaDB 10.7+露\nUUIDField\nOn MariaDB 10.7+, UUIDField is now created as UUID column rather than\nCHAR(32) column. As a consequence, any UUIDField created in\nDjango < 5.0 should be replaced with a UUIDField subclass backed by\nCHAR(32):\nUUIDField\nUUID\nCHAR(32)\nUUIDField\nUUIDField\nCHAR(32)\nclass Char32UUIDField(models.UUIDField):\n    def db_type(self, connection):\n        return \"char(32)\"\n\n    def get_db_prep_value(self, value, connection, prepared=False):\n        value = super().get_db_prep_value(value, connection, prepared)\n        if value is not None:\n            value = value.hex\n        return value\nFor example:\nclass MyModel(models.Model):\n    uuid = models.UUIDField(primary_key=True, default=uuid.uuid4)\nShould become:\nclass Char32UUIDField(models.UUIDField): ...\n\n\nclass MyModel(models.Model):\n    uuid = Char32UUIDField(primary_key=True, default=uuid.uuid4)\nRunning the makemigrations command will generate a migration\ncontaining a no-op AlterField operation.\nmakemigrations\nAlterField\nMiscellaneous露\nThe instance argument of the undocumented\nBaseModelFormSet.save_existing() method is renamed to obj.\nThe instance argument of the undocumented\nBaseModelFormSet.save_existing() method is renamed to obj.\ninstance\nBaseModelFormSet.save_existing()\nobj\nThe undocumented django.contrib.admin.helpers.checkbox is removed.\nThe undocumented django.contrib.admin.helpers.checkbox is removed.\ndjango.contrib.admin.helpers.checkbox\nInteger fields are now validated as 64-bit integers on SQLite to match the\nbehavior of sqlite3.\nInteger fields are now validated as 64-bit integers on SQLite to match the\nbehavior of sqlite3.\nsqlite3\nThe undocumented Query.annotation_select_mask attribute is changed from a\nset of strings to an ordered list of strings.\nThe undocumented Query.annotation_select_mask attribute is changed from a\nset of strings to an ordered list of strings.\nQuery.annotation_select_mask\nImageField.update_dimension_fields() is no longer called on the\npost_init signal if width_field and height_field are not set.\nImageField.update_dimension_fields() is no longer called on the\npost_init signal if width_field and height_field are not set.\nImageField.update_dimension_fields()\npost_init\nwidth_field\nheight_field\nNow database function now uses\nLOCALTIMESTAMP instead of CURRENT_TIMESTAMP on Oracle.\nNow database function now uses\nLOCALTIMESTAMP instead of CURRENT_TIMESTAMP on Oracle.\nNow\nLOCALTIMESTAMP\nCURRENT_TIMESTAMP\nAdminSite.site_header is now rendered in a <div> tag instead of\n<h1>. Screen reader users rely on heading elements for navigation within\na page. Having two <h1> elements was confusing and the site header wasnt\nhelpful as it is repeated on all pages.\nAdminSite.site_header is now rendered in a <div> tag instead of\n<h1>. Screen reader users rely on heading elements for navigation within\na page. Having two <h1> elements was confusing and the site header wasnt\nhelpful as it is repeated on all pages.\nAdminSite.site_header\n<div>\n<h1>\n<h1>\nIn order to improve accessibility, the admins main content area and header\ncontent area are now rendered in a <main> and <header> tag instead of\n<div>.\nIn order to improve accessibility, the admins main content area and header\ncontent area are now rendered in a <main> and <header> tag instead of\n<div>.\n<main>\n<header>\n<div>\nOn databases without native support for the SQL XOR operator, ^ as\nthe exclusive or (XOR) operator now returns rows that are matched by an\nodd number of operands rather than exactly one operand. This is consistent\nwith the behavior of MySQL, MariaDB, and Python.\nOn databases without native support for the SQL XOR operator, ^ as\nthe exclusive or (XOR) operator now returns rows that are matched by an\nodd number of operands rather than exactly one operand. This is consistent\nwith the behavior of MySQL, MariaDB, and Python.\nXOR\n^\nXOR\nThe minimum supported version of asgiref is increased from 3.6.0 to\n3.7.0.\nThe minimum supported version of asgiref is increased from 3.6.0 to\n3.7.0.\nasgiref\nThe minimum supported version of selenium is increased from 3.8.0 to\n4.8.0.\nThe minimum supported version of selenium is increased from 3.8.0 to\n4.8.0.\nselenium\nThe AlreadyRegistered and NotRegistered exceptions are moved from\ndjango.contrib.admin.sites to django.contrib.admin.exceptions.\nThe AlreadyRegistered and NotRegistered exceptions are moved from\ndjango.contrib.admin.sites to django.contrib.admin.exceptions.\nAlreadyRegistered\nNotRegistered\ndjango.contrib.admin.sites\ndjango.contrib.admin.exceptions\nThe minimum supported version of SQLite is increased from 3.21.0 to 3.27.0.\nThe minimum supported version of SQLite is increased from 3.21.0 to 3.27.0.\nSupport for cx_Oracle < 8.3 is removed.\nSupport for cx_Oracle < 8.3 is removed.\ncx_Oracle\nExecuting SQL queries before the app registry has been fully populated now\nraises RuntimeWarning.\nExecuting SQL queries before the app registry has been fully populated now\nraises RuntimeWarning.\nRuntimeWarning\nBadRequest is raised for non-UTF-8 encoded\nrequests with the application/x-www-form-urlencoded content type.\nSee RFC 1866 for more details.\nBadRequest is raised for non-UTF-8 encoded\nrequests with the application/x-www-form-urlencoded content type.\nSee RFC 1866 for more details.\nBadRequest\nThe minimum supported version of colorama is increased to 0.4.6.\nThe minimum supported version of colorama is increased to 0.4.6.\ncolorama\nThe minimum supported version of docutils is increased to 0.19.\nThe minimum supported version of docutils is increased to 0.19.\ndocutils\nFiltering querysets against overflowing integer values now always returns an\nempty queryset. As a consequence, you may need to use ExpressionWrapper()\nto explicitly wrap arithmetic against\ninteger fields in such cases.\nFiltering querysets against overflowing integer values now always returns an\nempty queryset. As a consequence, you may need to use ExpressionWrapper()\nto explicitly wrap arithmetic against\ninteger fields in such cases.\nExpressionWrapper()\nFeatures deprecated in 5.0露\nMiscellaneous露\nThe DjangoDivFormRenderer and Jinja2DivFormRenderer transitional form\nrenderers are deprecated.\nThe DjangoDivFormRenderer and Jinja2DivFormRenderer transitional form\nrenderers are deprecated.\nDjangoDivFormRenderer\nJinja2DivFormRenderer\nPassing positional arguments name and violation_error_message to\nBaseConstraint is deprecated in favor of\nkeyword-only arguments.\nPassing positional arguments name and violation_error_message to\nBaseConstraint is deprecated in favor of\nkeyword-only arguments.\nname\nviolation_error_message\nBaseConstraint\nrequest is added to the signature of ModelAdmin.lookup_allowed().\nSupport for ModelAdmin subclasses that do not accept this argument is\ndeprecated.\nrequest is added to the signature of ModelAdmin.lookup_allowed().\nSupport for ModelAdmin subclasses that do not accept this argument is\ndeprecated.\nrequest\nModelAdmin.lookup_allowed()\nModelAdmin\nThe get_joining_columns() method of ForeignObject and\nForeignObjectRel is deprecated. Starting with Django 6.0,\ndjango.db.models.sql.datastructures.Join will no longer fallback to\nget_joining_columns(). Subclasses should implement\nget_joining_fields() instead.\nThe get_joining_columns() method of ForeignObject and\nForeignObjectRel is deprecated. Starting with Django 6.0,\ndjango.db.models.sql.datastructures.Join will no longer fallback to\nget_joining_columns(). Subclasses should implement\nget_joining_fields() instead.\nget_joining_columns()\nForeignObject\nForeignObjectRel\ndjango.db.models.sql.datastructures.Join\nget_joining_columns()\nget_joining_fields()\nThe ForeignObject.get_reverse_joining_columns() method is deprecated.\nThe ForeignObject.get_reverse_joining_columns() method is deprecated.\nForeignObject.get_reverse_joining_columns()\nThe default scheme for forms.URLField will change from \"http\" to\n\"https\" in Django 6.0. Set FORMS_URLFIELD_ASSUME_HTTPS\ntransitional setting to True to opt into assuming \"https\" during the\nDjango 5.x release cycle.\nThe default scheme for forms.URLField will change from \"http\" to\n\"https\" in Django 6.0. Set FORMS_URLFIELD_ASSUME_HTTPS\ntransitional setting to True to opt into assuming \"https\" during the\nDjango 5.x release cycle.\nforms.URLField\n\"http\"\n\"https\"\nFORMS_URLFIELD_ASSUME_HTTPS\nTrue\n\"https\"\nFORMS_URLFIELD_ASSUME_HTTPS transitional setting is deprecated.\nFORMS_URLFIELD_ASSUME_HTTPS transitional setting is deprecated.\nFORMS_URLFIELD_ASSUME_HTTPS\nSupport for calling format_html() without passing args or kwargs will be\nremoved.\nSupport for calling format_html() without passing args or kwargs will be\nremoved.\nformat_html()\nSupport for cx_Oracle is deprecated in favor of oracledb 1.3.2+ Python\ndriver.\nSupport for cx_Oracle is deprecated in favor of oracledb 1.3.2+ Python\ndriver.\ncx_Oracle\nDatabaseOperations.field_cast_sql() is deprecated in favor of\nDatabaseOperations.lookup_cast(). Starting with Django 6.0,\nBuiltinLookup.process_lhs() will no longer call field_cast_sql().\nThird-party database backends should implement lookup_cast() instead.\nDatabaseOperations.field_cast_sql() is deprecated in favor of\nDatabaseOperations.lookup_cast(). Starting with Django 6.0,\nBuiltinLookup.process_lhs() will no longer call field_cast_sql().\nThird-party database backends should implement lookup_cast() instead.\nDatabaseOperations.field_cast_sql()\nDatabaseOperations.lookup_cast()\nBuiltinLookup.process_lhs()\nfield_cast_sql()\nlookup_cast()\nThe django.db.models.enums.ChoicesMeta metaclass is renamed to\nChoicesType.\nThe django.db.models.enums.ChoicesMeta metaclass is renamed to\nChoicesType.\ndjango.db.models.enums.ChoicesMeta\nChoicesType\nThe Prefetch.get_current_queryset() method is deprecated.\nThe Prefetch.get_current_queryset() method is deprecated.\nPrefetch.get_current_queryset()\nThe get_prefetch_queryset() method of related managers and descriptors\nis deprecated. Starting with Django 6.0, get_prefetcher() and\nprefetch_related_objects() will no longer fallback to\nget_prefetch_queryset(). Subclasses should implement\nget_prefetch_querysets() instead.\nThe get_prefetch_queryset() method of related managers and descriptors\nis deprecated. Starting with Django 6.0, get_prefetcher() and\nprefetch_related_objects() will no longer fallback to\nget_prefetch_queryset(). Subclasses should implement\nget_prefetch_querysets() instead.\nget_prefetch_queryset()\nget_prefetcher()\nprefetch_related_objects()\nget_prefetch_queryset()\nget_prefetch_querysets()\nFeatures removed in 5.0露\nThese features have reached the end of their deprecation cycle and are removed\nin Django 5.0.\nSee Features deprecated in 4.0 for details on these changes, including how\nto remove usage of these features.\nThe SERIALIZE test setting is removed.\nThe SERIALIZE test setting is removed.\nSERIALIZE\nThe undocumented django.utils.baseconv module is removed.\nThe undocumented django.utils.baseconv module is removed.\ndjango.utils.baseconv\nThe undocumented django.utils.datetime_safe module is removed.\nThe undocumented django.utils.datetime_safe module is removed.\ndjango.utils.datetime_safe\nThe default value of the USE_TZ setting is changed from False to\nTrue.\nThe default value of the USE_TZ setting is changed from False to\nTrue.\nUSE_TZ\nFalse\nTrue\nThe default sitemap protocol for sitemaps built outside the context of a\nrequest is changed from 'http' to 'https'.\nThe default sitemap protocol for sitemaps built outside the context of a\nrequest is changed from 'http' to 'https'.\n'http'\n'https'\nThe extra_tests argument for DiscoverRunner.build_suite() and\nDiscoverRunner.run_tests() is removed.\nThe extra_tests argument for DiscoverRunner.build_suite() and\nDiscoverRunner.run_tests() is removed.\nextra_tests\nDiscoverRunner.build_suite()\nDiscoverRunner.run_tests()\nThe django.contrib.postgres.aggregates.ArrayAgg, JSONBAgg, and\nStringAgg aggregates no longer return [], [], and '',\nrespectively, when there are no rows.\nThe django.contrib.postgres.aggregates.ArrayAgg, JSONBAgg, and\nStringAgg aggregates no longer return [], [], and '',\nrespectively, when there are no rows.\ndjango.contrib.postgres.aggregates.ArrayAgg\nJSONBAgg\nStringAgg\n[]\n[]\n''\nThe USE_L10N setting is removed.\nThe USE_L10N setting is removed.\nUSE_L10N\nThe USE_DEPRECATED_PYTZ transitional setting is removed.\nThe USE_DEPRECATED_PYTZ transitional setting is removed.\nUSE_DEPRECATED_PYTZ\nSupport for pytz timezones is removed.\nSupport for pytz timezones is removed.\npytz\nThe is_dst argument is removed from:\n\nQuerySet.datetimes()\ndjango.utils.timezone.make_aware()\ndjango.db.models.functions.Trunc()\ndjango.db.models.functions.TruncSecond()\ndjango.db.models.functions.TruncMinute()\ndjango.db.models.functions.TruncHour()\ndjango.db.models.functions.TruncDay()\ndjango.db.models.functions.TruncWeek()\ndjango.db.models.functions.TruncMonth()\ndjango.db.models.functions.TruncQuarter()\ndjango.db.models.functions.TruncYear()\nThe is_dst argument is removed from:\nis_dst\nQuerySet.datetimes()\nQuerySet.datetimes()\nQuerySet.datetimes()\ndjango.utils.timezone.make_aware()\ndjango.utils.timezone.make_aware()\ndjango.utils.timezone.make_aware()\ndjango.db.models.functions.Trunc()\ndjango.db.models.functions.Trunc()\ndjango.db.models.functions.Trunc()\ndjango.db.models.functions.TruncSecond()\ndjango.db.models.functions.TruncSecond()\ndjango.db.models.functions.TruncSecond()\ndjango.db.models.functions.TruncMinute()\ndjango.db.models.functions.TruncMinute()\ndjango.db.models.functions.TruncMinute()\ndjango.db.models.functions.TruncHour()\ndjango.db.models.functions.TruncHour()\ndjango.db.models.functions.TruncHour()\ndjango.db.models.functions.TruncDay()\ndjango.db.models.functions.TruncDay()\ndjango.db.models.functions.TruncDay()\ndjango.db.models.functions.TruncWeek()\ndjango.db.models.functions.TruncWeek()\ndjango.db.models.functions.TruncWeek()\ndjango.db.models.functions.TruncMonth()\ndjango.db.models.functions.TruncMonth()\ndjango.db.models.functions.TruncMonth()\ndjango.db.models.functions.TruncQuarter()\ndjango.db.models.functions.TruncQuarter()\ndjango.db.models.functions.TruncQuarter()\ndjango.db.models.functions.TruncYear()\ndjango.db.models.functions.TruncYear()\ndjango.db.models.functions.TruncYear()\nThe django.contrib.gis.admin.GeoModelAdmin and OSMGeoAdmin classes\nare removed.\nThe django.contrib.gis.admin.GeoModelAdmin and OSMGeoAdmin classes\nare removed.\ndjango.contrib.gis.admin.GeoModelAdmin\nOSMGeoAdmin\nThe undocumented BaseForm._html_output() method is removed.\nThe undocumented BaseForm._html_output() method is removed.\nBaseForm._html_output()\nThe ability to return a str, rather than a SafeString, when rendering\nan ErrorDict and ErrorList is removed.\nThe ability to return a str, rather than a SafeString, when rendering\nan ErrorDict and ErrorList is removed.\nstr\nSafeString\nErrorDict\nErrorList\nSee Features deprecated in 4.1 for details on these changes, including how\nto remove usage of these features.\nThe SitemapIndexItem.__str__() method is removed.\nThe SitemapIndexItem.__str__() method is removed.\nSitemapIndexItem.__str__()\nThe CSRF_COOKIE_MASKED transitional setting is removed.\nThe CSRF_COOKIE_MASKED transitional setting is removed.\nCSRF_COOKIE_MASKED\nThe name argument of django.utils.functional.cached_property() is\nremoved.\nThe name argument of django.utils.functional.cached_property() is\nremoved.\nname\ndjango.utils.functional.cached_property()\nThe opclasses argument of\ndjango.contrib.postgres.constraints.ExclusionConstraint is removed.\nThe opclasses argument of\ndjango.contrib.postgres.constraints.ExclusionConstraint is removed.\nopclasses\ndjango.contrib.postgres.constraints.ExclusionConstraint\nThe undocumented ability to pass errors=None to\nSimpleTestCase.assertFormError() and assertFormsetError() is removed.\nThe undocumented ability to pass errors=None to\nSimpleTestCase.assertFormError() and assertFormsetError() is removed.\nerrors=None\nSimpleTestCase.assertFormError()\nassertFormsetError()\ndjango.contrib.sessions.serializers.PickleSerializer is removed.\ndjango.contrib.sessions.serializers.PickleSerializer is removed.\ndjango.contrib.sessions.serializers.PickleSerializer\nThe usage of QuerySet.iterator() on a queryset that prefetches related\nobjects without providing the chunk_size argument is no longer allowed.\nThe usage of QuerySet.iterator() on a queryset that prefetches related\nobjects without providing the chunk_size argument is no longer allowed.\nQuerySet.iterator()\nchunk_size\nPassing unsaved model instances to related filters is no longer allowed.\nPassing unsaved model instances to related filters is no longer allowed.\ncreated=True is required in the signature of\nRemoteUserBackend.configure_user() subclasses.\ncreated=True is required in the signature of\nRemoteUserBackend.configure_user() subclasses.\ncreated=True\nRemoteUserBackend.configure_user()\nSupport for logging out via GET requests in the\ndjango.contrib.auth.views.LogoutView and\ndjango.contrib.auth.views.logout_then_login() is removed.\nSupport for logging out via GET requests in the\ndjango.contrib.auth.views.LogoutView and\ndjango.contrib.auth.views.logout_then_login() is removed.\nGET\ndjango.contrib.auth.views.LogoutView\ndjango.contrib.auth.views.logout_then_login()\nThe django.utils.timezone.utc alias to datetime.timezone.utc is\nremoved.\nThe django.utils.timezone.utc alias to datetime.timezone.utc is\nremoved.\ndjango.utils.timezone.utc\ndatetime.timezone.utc\nPassing a response object and a form/formset name to\nSimpleTestCase.assertFormError() and assertFormSetError() is no\nlonger allowed.\nPassing a response object and a form/formset name to\nSimpleTestCase.assertFormError() and assertFormSetError() is no\nlonger allowed.\nSimpleTestCase.assertFormError()\nassertFormSetError()\nThe django.contrib.gis.admin.OpenLayersWidget is removed.\nThe django.contrib.gis.admin.OpenLayersWidget is removed.\ndjango.contrib.gis.admin.OpenLayersWidget\nThe django.contrib.auth.hashers.CryptPasswordHasher is removed.\nThe django.contrib.auth.hashers.CryptPasswordHasher is removed.\ndjango.contrib.auth.hashers.CryptPasswordHasher\nThe \"django/forms/default.html\" and\n\"django/forms/formsets/default.html\" templates are removed.\nThe \"django/forms/default.html\" and\n\"django/forms/formsets/default.html\" templates are removed.\n\"django/forms/default.html\"\n\"django/forms/formsets/default.html\"\nThe default form and formset rendering style is changed to the div-based.\nThe default form and formset rendering style is changed to the div-based.\nPassing nulls_first=False or nulls_last=False to Expression.asc()\nand Expression.desc() methods, and the OrderBy expression is no\nlonger allowed.\nPassing nulls_first=False or nulls_last=False to Expression.asc()\nand Expression.desc() methods, and the OrderBy expression is no\nlonger allowed.\nnulls_first=False\nnulls_last=False\nExpression.asc()\nExpression.desc()\nOrderBy\nAdditional Information\nSupport Django!\nDeby Lepage donated to the Django Software Foundation to support Django development. Donate today!\nContents\nDjango 5.0 release notes\nPython compatibility\nThird-party library support for older version of Django\nWhats new in Django 5.0\nFacet filters in the admin\nSimplified templates for form field rendering\nDatabase-computed default values\nDatabase generated model field\nMore options for declaring field choices\nMinor features\ndjango.contrib.admin\ndjango.contrib.auth\ndjango.contrib.contenttypes\ndjango.contrib.gis\ndjango.contrib.messages\ndjango.contrib.postgres\nAsynchronous views\nDecorators\nError Reporting\nFile Storage\nForms\nInternationalization\nMigrations\nModels\nPagination\nSignals\nTemplates\nTests\nValidators\n\n\n\n\nBackwards incompatible changes in 5.0\nDatabase backend API\ndjango.contrib.gis\ndjango.contrib.sitemaps\nDropped support for MySQL < 8.0.11\nUsing create_defaults__exact may now be required with QuerySet.update_or_create()\nMigrating existing UUIDField on MariaDB 10.7+\nMiscellaneous\n\n\nFeatures deprecated in 5.0\nMiscellaneous\n\n\nFeatures removed in 5.0\nPython compatibility\nThird-party library support for older version of Django\nWhats new in Django 5.0\nFacet filters in the admin\nSimplified templates for form field rendering\nDatabase-computed default values\nDatabase generated model field\nMore options for declaring field choices\nMinor features\ndjango.contrib.admin\ndjango.contrib.auth\ndjango.contrib.contenttypes\ndjango.contrib.gis\ndjango.contrib.messages\ndjango.contrib.postgres\nAsynchronous views\nDecorators\nError Reporting\nFile Storage\nForms\nInternationalization\nMigrations\nModels\nPagination\nSignals\nTemplates\nTests\nValidators\nFacet filters in the admin\nSimplified templates for form field rendering\nDatabase-computed default values\nDatabase generated model field\nMore options for declaring field choices\nMinor features\ndjango.contrib.admin\ndjango.contrib.auth\ndjango.contrib.contenttypes\ndjango.contrib.gis\ndjango.contrib.messages\ndjango.contrib.postgres\nAsynchronous views\nDecorators\nError Reporting\nFile Storage\nForms\nInternationalization\nMigrations\nModels\nPagination\nSignals\nTemplates\nTests\nValidators\ndjango.contrib.admin\ndjango.contrib.admin\ndjango.contrib.auth\ndjango.contrib.auth\ndjango.contrib.contenttypes\ndjango.contrib.contenttypes\ndjango.contrib.gis\ndjango.contrib.gis\ndjango.contrib.messages\ndjango.contrib.messages\ndjango.contrib.postgres\ndjango.contrib.postgres\nAsynchronous views\nDecorators\nError Reporting\nFile Storage\nForms\nInternationalization\nMigrations\nModels\nPagination\nSignals\nTemplates\nTests\nValidators\nBackwards incompatible changes in 5.0\nDatabase backend API\ndjango.contrib.gis\ndjango.contrib.sitemaps\nDropped support for MySQL < 8.0.11\nUsing create_defaults__exact may now be required with QuerySet.update_or_create()\nMigrating existing UUIDField on MariaDB 10.7+\nMiscellaneous\nDatabase backend API\ndjango.contrib.gis\ndjango.contrib.gis\ndjango.contrib.sitemaps\ndjango.contrib.sitemaps\nDropped support for MySQL < 8.0.11\nUsing create_defaults__exact may now be required with QuerySet.update_or_create()\ncreate_defaults__exact\nQuerySet.update_or_create()\nMigrating existing UUIDField on MariaDB 10.7+\nUUIDField\nMiscellaneous\nFeatures deprecated in 5.0\nMiscellaneous\nMiscellaneous\nFeatures removed in 5.0\nBrowse\nPrev: Django 5.0.1 release notes\nNext: Django 4.2.20 release notes\nTable of contents\nGeneral Index\nPython Module Index\nYou are here:\nDjango 5.0 documentation\nRelease notes\nDjango 5.0 release notes\nRelease notes\nDjango 5.0 release notes\nDjango 5.0 release notes\nGetting help\nDownload:\nOffline (Django 5.0):\n          HTML |\n          PDF |\n          ePub\n\n\n            Provided by Read the Docs.\nDiamond and Platinum Members\nSentry\nMonitor your Django Code\r\nResolve performance bottlenecks and errors using monitoring, replays, logs and Seer an AI agent for debugging.\nJetBrains\nJetBrains delivers intelligent software solutions that make developers more productive by simplifying their challenging tasks, automating the routine, and helping them adopt the best development practices. PyCharm is the Python IDE for Professional Developers by JetBrains providing a complete set of tools for productive Python, Web and scientific development.\nDjango Links\nLearn More\nAbout Django\nGetting Started with Django\nTeam Organization\nDjango Software Foundation\nCode of Conduct\nDiversity Statement\nGet Involved\nJoin a Group\nContribute\n              to Django\nSubmit\n              a Bug\nReport\n              a Security Issue\nIndividual membership\nGet Help\nGetting Help FAQ\nDjango Discord\nOfficial Django Forum\nFollow Us\nGitHub\nX\nFediverse (Mastodon)\nBluesky\nLinkedIn\nNews RSS\nSupport Us\nSponsor Django\nCorporate membership\nOfficial merchandise store\nBenevity Workplace Giving Program\nHosting by In-kind\n            donors\nDesign by Threespot\n& andrevv\n漏 2005-2025\n         Django Software\n          Foundation and individual contributors. Django is a\n        registered\n          trademark of the Django Software Foundation.",
    "crawl_status": "success"
  },
  {
    "library_name": "Django",
    "url": "https://docs.djangoproject.com/en/5.1/releases/5.1/",
    "version": "5.1",
    "title": "Django 5.1 release notes | Django documentation | Django",
    "release_date": "Unknown release date",
    "content": "The web framework for perfectionists with deadlines.\nOverview\nDownload\nDocumentation\nNews\nCode\nIssues\nCommunity\nFoundation\n Donate\nSearch\n\n\n\n\nSubmit\nToggle theme (current theme: auto)\nToggle theme (current theme: light)\nToggle theme (current theme: dark)\nToggle Light / Dark / Auto color theme\nDocumentation\nGetting Help\nel\nes\nfr\nid\nit\nja\nko\npl\npt-br\nzh-hans\nLanguage: en\n5.2\n6.0\ndev\nDocumentation version:\n          5.1\nDjango 5.1 release notes露\nAugust 7, 2024\nWelcome to Django 5.1!\nThese release notes cover the new features, as well as\nsome backwards incompatible changes you\nshould be aware of when upgrading from Django 5.0 or earlier. Weve\nbegun the deprecation process for some features.\nSee the How to upgrade Django to a newer version guide if youre updating an existing\nproject.\nPython compatibility露\nDjango 5.1 supports Python 3.10, 3.11, 3.12, and 3.13 (as of 5.1.3). We\nhighly recommend and only officially support the latest release of each\nseries.\nWhats new in Django 5.1露\n{% querystring %} template tag露\n{% querystring %}\nDjango 5.1 introduces the {% querystring %} template\ntag, simplifying the modification of query parameters in URLs, making it easier\nto generate links that maintain existing query parameters while adding or\nchanging specific ones.\n{% querystring %}\nFor instance, navigating pagination and query strings in templates can be\ncumbersome. Consider this template fragment that dynamically generates a URL\nfor navigating to the next page within a paginated view:\n{# Linebreaks added for readability, this should be one, long line. #}\n<a href=\"?{% for key, values in request.GET.iterlists %}\n  {% if key != \"page\" %}\n    {% for value in values %}\n      {{ key }}={{ value }}&amp;\n    {% endfor %}\n  {% endif %}\n{% endfor %}page={{ page.next_page_number }}\">Next page</a>\nWhen switching to using this new template tag, the above magically becomes:\n<a href=\"{% querystring page=page.next_page_number %}\">Next page</a>\nPostgreSQL Connection Pools露\nDjango 5.1 also introduces connection pool support for\nPostgreSQL. As the time to establish a new connection can be relatively long,\nkeeping connections open can reduce latency.\nTo use a connection pool with psycopg, you can set the \"pool\" option\ninside OPTIONS to be a dict to be passed to\nConnectionPool, or to True to use the\nConnectionPool defaults:\n\"pool\"\nOPTIONS\nConnectionPool\nTrue\nConnectionPool\nDATABASES = {\n    \"default\": {\n        \"ENGINE\": \"django.db.backends.postgresql\",\n        # ...\n        \"OPTIONS\": {\n            \"pool\": {\n                \"min_size\": 2,\n                \"max_size\": 4,\n                \"timeout\": 10,\n            }\n        },\n    },\n}\nMiddleware to require authentication by default露\nThe new LoginRequiredMiddleware\nredirects all unauthenticated requests to a login page. Views can allow\nunauthenticated requests by using the new\nlogin_not_required() decorator.\nLoginRequiredMiddleware\nlogin_not_required()\nLoginRequiredMiddleware respects the login_url and\nredirect_field_name values set via the\nlogin_required() decorator, but does not\nsupport setting login_url or redirect_field_name via the\nLoginRequiredMixin.\nLoginRequiredMiddleware\nlogin_url\nredirect_field_name\nlogin_required()\nlogin_url\nredirect_field_name\nLoginRequiredMixin\nTo enable this, add \"django.contrib.auth.middleware.LoginRequiredMiddleware\"\nto your MIDDLEWARE setting.\n\"django.contrib.auth.middleware.LoginRequiredMiddleware\"\nMIDDLEWARE\nMinor features露\ndjango.contrib.admin露\ndjango.contrib.admin\nModelAdmin.list_display now supports using __ lookups to list\nfields from related models.\nModelAdmin.list_display now supports using __ lookups to list\nfields from related models.\nModelAdmin.list_display\n__\ndjango.contrib.auth露\ndjango.contrib.auth\nThe default iteration count for the PBKDF2 password hasher is increased from\n720,000 to 870,000.\nThe default iteration count for the PBKDF2 password hasher is increased from\n720,000 to 870,000.\nThe default parallelism of the ScryptPasswordHasher is\nincreased from 1 to 5, to follow OWASP recommendations.\nThe default parallelism of the ScryptPasswordHasher is\nincreased from 1 to 5, to follow OWASP recommendations.\nparallelism\nScryptPasswordHasher\nThe new AdminUserCreationForm and\nthe existing AdminPasswordChangeForm now\nsupport disabling password-based authentication by setting an unusable\npassword on form save. This is now available in the admin when visiting the\nuser creation and password change pages.\nThe new AdminUserCreationForm and\nthe existing AdminPasswordChangeForm now\nsupport disabling password-based authentication by setting an unusable\npassword on form save. This is now available in the admin when visiting the\nuser creation and password change pages.\nAdminUserCreationForm\nAdminPasswordChangeForm\nlogin_required(),\npermission_required(), and\nuser_passes_test() decorators now\nsupport wrapping asynchronous view functions.\nlogin_required(),\npermission_required(), and\nuser_passes_test() decorators now\nsupport wrapping asynchronous view functions.\nlogin_required()\npermission_required()\nuser_passes_test()\nReadOnlyPasswordHashWidget now includes a button to reset the users\npassword, which replaces the link previously embedded in the\nReadOnlyPasswordHashFields help text, improving the overall\naccessibility of the\nUserChangeForm.\nReadOnlyPasswordHashWidget now includes a button to reset the users\npassword, which replaces the link previously embedded in the\nReadOnlyPasswordHashFields help text, improving the overall\naccessibility of the\nUserChangeForm.\nReadOnlyPasswordHashWidget\nReadOnlyPasswordHashField\nUserChangeForm\ndjango.contrib.gis露\ndjango.contrib.gis\nBoundingCircle is now\nsupported on SpatiaLite 5.1+.\nBoundingCircle is now\nsupported on SpatiaLite 5.1+.\nBoundingCircle\nCollect is now supported on MySQL\n8.0.24+.\nCollect is now supported on MySQL\n8.0.24+.\nCollect\nGeoIP2 now allows querying using\nipaddress.IPv4Address or ipaddress.IPv6Address objects.\nGeoIP2 now allows querying using\nipaddress.IPv4Address or ipaddress.IPv6Address objects.\nGeoIP2\nipaddress.IPv4Address\nipaddress.IPv6Address\nGeoIP2.country() now exposes the continent_code,\ncontinent_name, and is_in_european_union values.\nGeoIP2.country() now exposes the continent_code,\ncontinent_name, and is_in_european_union values.\nGeoIP2.country()\ncontinent_code\ncontinent_name\nis_in_european_union\nGeoIP2.city() now exposes the accuracy_radius and region_name\nvalues. In addition, the dma_code and region values are now exposed\nas metro_code and region_code, but the previous keys are also\nretained for backward compatibility.\nGeoIP2.city() now exposes the accuracy_radius and region_name\nvalues. In addition, the dma_code and region values are now exposed\nas metro_code and region_code, but the previous keys are also\nretained for backward compatibility.\nGeoIP2.city()\naccuracy_radius\nregion_name\ndma_code\nregion\nmetro_code\nregion_code\nArea now supports the ha unit.\nArea now supports the ha unit.\nArea\nha\nThe new OGRGeometry.is_3d attribute allows checking if a geometry\nhas a Z coordinate dimension.\nThe new OGRGeometry.is_3d attribute allows checking if a geometry\nhas a Z coordinate dimension.\nOGRGeometry.is_3d\nZ\nThe new OGRGeometry.set_3d() method allows addition and removal of the\nZ coordinate dimension.\nThe new OGRGeometry.set_3d() method allows addition and removal of the\nZ coordinate dimension.\nOGRGeometry.set_3d()\nZ\nOGRGeometry,\nPoint,\nLineString,\nPolygon, and\nGeometryCollection and its subclasses now\nsupport measured geometries via the new OGRGeometry.is_measured and\nm properties, and the OGRGeometry.set_measured() method.\nOGRGeometry,\nPoint,\nLineString,\nPolygon, and\nGeometryCollection and its subclasses now\nsupport measured geometries via the new OGRGeometry.is_measured and\nm properties, and the OGRGeometry.set_measured() method.\nOGRGeometry\nPoint\nLineString\nPolygon\nGeometryCollection\nOGRGeometry.is_measured\nm\nOGRGeometry.set_measured()\nOGRGeometry.centroid is now available on all supported geometry\ntypes.\nOGRGeometry.centroid is now available on all supported geometry\ntypes.\nOGRGeometry.centroid\nFromWKB() and\nFromWKT() functions\nnow support the optional srid argument (except for Oracle where it is\nignored).\nFromWKB() and\nFromWKT() functions\nnow support the optional srid argument (except for Oracle where it is\nignored).\nFromWKB()\nFromWKT()\nsrid\ndjango.contrib.postgres露\ndjango.contrib.postgres\nBTreeIndex now supports the\ndeduplicate_items parameter.\nBTreeIndex now supports the\ndeduplicate_items parameter.\nBTreeIndex\ndeduplicate_items\ndjango.contrib.sessions露\ndjango.contrib.sessions\ndjango.contrib.sessions.backends.cached_db.SessionStore now handles\nexceptions when storing session information in the cache, logging proper\nerror messages with their traceback via the newly added\nsessions logger.\ndjango.contrib.sessions.backends.cached_db.SessionStore now handles\nexceptions when storing session information in the cache, logging proper\nerror messages with their traceback via the newly added\nsessions logger.\ndjango.contrib.sessions.backends.cached_db.SessionStore\ndjango.contrib.sessions.backends.base.SessionBase and all built-in\nsession engines now provide async API. The new asynchronous methods all have\na prefixed names, e.g. aget(), akeys(), or acycle_key().\ndjango.contrib.sessions.backends.base.SessionBase and all built-in\nsession engines now provide async API. The new asynchronous methods all have\na prefixed names, e.g. aget(), akeys(), or acycle_key().\ndjango.contrib.sessions.backends.base.SessionBase\na\naget()\nakeys()\nacycle_key()\nDatabase backends露\n\"init_command\" option is now supported in OPTIONS on SQLite\nto allow specifying pragma options to set upon\nconnection.\n\"init_command\" option is now supported in OPTIONS on SQLite\nto allow specifying pragma options to set upon\nconnection.\n\"init_command\"\nOPTIONS\n\"transaction_mode\" option is now supported in OPTIONS on\nSQLite to allow specifying the Transactions behavior.\n\"transaction_mode\" option is now supported in OPTIONS on\nSQLite to allow specifying the Transactions behavior.\n\"transaction_mode\"\nOPTIONS\n\"pool\" option is now supported in OPTIONS on PostgreSQL to\nallow using connection pools.\n\"pool\" option is now supported in OPTIONS on PostgreSQL to\nallow using connection pools.\n\"pool\"\nOPTIONS\nError Reporting露\nIn order to improve accessibility, the technical 404 and 500 error pages now\nuse HTML landmark elements for the header, footer, and main content areas.\nIn order to improve accessibility, the technical 404 and 500 error pages now\nuse HTML landmark elements for the header, footer, and main content areas.\nFile Storage露\nThe allow_overwrite\nparameter of FileSystemStorage now allows\nsaving new files over existing ones.\nThe allow_overwrite\nparameter of FileSystemStorage now allows\nsaving new files over existing ones.\nallow_overwrite\nFileSystemStorage\nForms露\nIn order to improve accessibility and enable screen readers to associate\nfieldsets with their help text, the form fieldset now includes the\naria-describedby HTML attribute.\nIn order to improve accessibility and enable screen readers to associate\nfieldsets with their help text, the form fieldset now includes the\naria-describedby HTML attribute.\naria-describedby\nManagement Commands露\nThe makemigrations command now displays meaningful symbols for\neach operation to highlight operation categories.\nThe makemigrations command now displays meaningful symbols for\neach operation to highlight operation categories.\nmakemigrations\noperation categories\nMigrations露\nThe new Operation.category attribute allows specifying an\noperation category used by the\nmakemigrations to display a meaningful symbol for the operation.\nThe new Operation.category attribute allows specifying an\noperation category used by the\nmakemigrations to display a meaningful symbol for the operation.\nOperation.category\noperation category\nmakemigrations\nModels露\nQuerySet.explain() now supports the generic_plan option on\nPostgreSQL 16+.\nQuerySet.explain() now supports the generic_plan option on\nPostgreSQL 16+.\nQuerySet.explain()\ngeneric_plan\nRowRange now accepts positive integers\nfor the start argument and negative integers for the end argument.\nRowRange now accepts positive integers\nfor the start argument and negative integers for the end argument.\nRowRange\nstart\nend\nThe new exclusion argument of\nRowRange and\nValueRange allows excluding rows,\ngroups, and ties from the window frames.\nThe new exclusion argument of\nRowRange and\nValueRange allows excluding rows,\ngroups, and ties from the window frames.\nexclusion\nRowRange\nValueRange\nQuerySet.order_by() now supports ordering by annotation transforms\nsuch as JSONObject keys and ArrayAgg indices.\nQuerySet.order_by() now supports ordering by annotation transforms\nsuch as JSONObject keys and ArrayAgg indices.\nQuerySet.order_by()\nJSONObject\nArrayAgg\nF() and OuterRef() expressions that output\nCharField, EmailField,\nSlugField, URLField,\nTextField, or\nArrayField can now be sliced.\nF() and OuterRef() expressions that output\nCharField, EmailField,\nSlugField, URLField,\nTextField, or\nArrayField can now be sliced.\nF()\nOuterRef()\nCharField\nEmailField\nSlugField\nURLField\nTextField\nArrayField\nThe new from_queryset argument of Model.refresh_from_db() and\nModel.arefresh_from_db()  allows customizing the queryset used to\nreload a models value. This can be used to lock the row before reloading or\nto select related objects.\nThe new from_queryset argument of Model.refresh_from_db() and\nModel.arefresh_from_db()  allows customizing the queryset used to\nreload a models value. This can be used to lock the row before reloading or\nto select related objects.\nfrom_queryset\nModel.refresh_from_db()\nModel.arefresh_from_db()\nThe new Expression.constraint_validation_compatible attribute allows\nspecifying that the expression should be ignored during a constraint\nvalidation.\nThe new Expression.constraint_validation_compatible attribute allows\nspecifying that the expression should be ignored during a constraint\nvalidation.\nExpression.constraint_validation_compatible\nTemplates露\nCustom tags may now set extra data on the Parser object that will later\nbe made available on the Template instance. Such data may be used, for\nexample, by the template loader, or other template clients.\nCustom tags may now set extra data on the Parser object that will later\nbe made available on the Template instance. Such data may be used, for\nexample, by the template loader, or other template clients.\nParser\nTemplate\nTemplate engines now implement a check() method\nthat is already registered with the check framework.\nTemplate engines now implement a check() method\nthat is already registered with the check framework.\ncheck()\nTests露\nassertContains(),\nassertNotContains(), and\nassertInHTML() assertions now add haystacks\nto assertion error messages.\nassertContains(),\nassertNotContains(), and\nassertInHTML() assertions now add haystacks\nto assertion error messages.\nassertContains()\nassertNotContains()\nassertInHTML()\nThe RequestFactory,\nAsyncRequestFactory, Client, and\nAsyncClient classes now support the query_params\nparameter, which accepts a dictionary of query string keys and values. This\nallows setting query strings on any HTTP methods more easily.\nself.client.post(\"/items/1\", query_params={\"action\": \"delete\"})\nawait self.async_client.post(\"/items/1\", query_params={\"action\": \"delete\"})\nThe RequestFactory,\nAsyncRequestFactory, Client, and\nAsyncClient classes now support the query_params\nparameter, which accepts a dictionary of query string keys and values. This\nallows setting query strings on any HTTP methods more easily.\nRequestFactory\nAsyncRequestFactory\nClient\nAsyncClient\nquery_params\nself.client.post(\"/items/1\", query_params={\"action\": \"delete\"})\nawait self.async_client.post(\"/items/1\", query_params={\"action\": \"delete\"})\nThe new SimpleTestCase.assertNotInHTML() assertion allows testing that\nan HTML fragment is not contained in the given HTML haystack.\nThe new SimpleTestCase.assertNotInHTML() assertion allows testing that\nan HTML fragment is not contained in the given HTML haystack.\nSimpleTestCase.assertNotInHTML()\nIn order to enforce test isolation, database connections inside threads are\nno longer allowed in SimpleTestCase.\nIn order to enforce test isolation, database connections inside threads are\nno longer allowed in SimpleTestCase.\nSimpleTestCase\nValidators露\nThe new DomainNameValidator validates domain\nnames, including internationalized domain names. The new\nvalidate_domain_name() function returns an\ninstance of DomainNameValidator.\nThe new DomainNameValidator validates domain\nnames, including internationalized domain names. The new\nvalidate_domain_name() function returns an\ninstance of DomainNameValidator.\nDomainNameValidator\nvalidate_domain_name()\nDomainNameValidator\nBackwards incompatible changes in 5.1露\ndjango.contrib.gis露\ndjango.contrib.gis\nSupport for PostGIS 2.5 is removed.\nSupport for PostGIS 2.5 is removed.\nSupport for PROJ < 6 is removed.\nSupport for PROJ < 6 is removed.\nSupport for GDAL 2.4 is removed.\nSupport for GDAL 2.4 is removed.\nGeoIP2 no longer opens both city and\ncountry databases when a directory path is provided, preferring the city\ndatabase, if it is available. The country database is a subset of the city\ndatabase and both are not typically needed. If you require use of the country\ndatabase when in the same directory as the city database, explicitly pass the\ncountry database path to the constructor.\nGeoIP2 no longer opens both city and\ncountry databases when a directory path is provided, preferring the city\ndatabase, if it is available. The country database is a subset of the city\ndatabase and both are not typically needed. If you require use of the country\ndatabase when in the same directory as the city database, explicitly pass the\ncountry database path to the constructor.\nGeoIP2\nDropped support for MariaDB 10.4露\nUpstream support for MariaDB 10.4 ends in June 2024. Django 5.1 supports\nMariaDB 10.5 and higher.\nDropped support for PostgreSQL 12露\nUpstream support for PostgreSQL 12 ends in November 2024. Django 5.1 supports\nPostgreSQL 13 and higher.\nMiscellaneous露\nIn order to improve accessibility, the admins changelist filter is now\nrendered in a <nav> tag instead of a <div>.\nIn order to improve accessibility, the admins changelist filter is now\nrendered in a <nav> tag instead of a <div>.\n<nav>\n<div>\nIn order to improve accessibility, the admins footer is now rendered in\na <footer> tag instead of a <div>, and also moved below the\n<div id=\"main\"> element.\nIn order to improve accessibility, the admins footer is now rendered in\na <footer> tag instead of a <div>, and also moved below the\n<div id=\"main\"> element.\n<footer>\n<div>\n<div id=\"main\">\nIn order to improve accessibility, the expandable widget used for\nModelAdmin.fieldsets and\nInlineModelAdmin.fieldsets,\nwhen the fieldset has a name and use the collapse class, now includes\n<details> and <summary> elements.\nIn order to improve accessibility, the expandable widget used for\nModelAdmin.fieldsets and\nInlineModelAdmin.fieldsets,\nwhen the fieldset has a name and use the collapse class, now includes\n<details> and <summary> elements.\nModelAdmin.fieldsets\nInlineModelAdmin.fieldsets\ncollapse\n<details>\n<summary>\nThe JavaScript file collapse.js is removed since it is no longer needed\nin the Django admin site.\nThe JavaScript file collapse.js is removed since it is no longer needed\nin the Django admin site.\ncollapse.js\nSimpleTestCase.assertURLEqual() and\nassertInHTML() now add \": \" to the\nmsg_prefix. This is consistent with the behavior of other assertions.\nSimpleTestCase.assertURLEqual() and\nassertInHTML() now add \": \" to the\nmsg_prefix. This is consistent with the behavior of other assertions.\nSimpleTestCase.assertURLEqual()\nassertInHTML()\n\": \"\nmsg_prefix\ndjango.utils.text.Truncator used by truncatechars_html and\ntruncatewords_html template filters now uses\nhtml.parser.HTMLParser subclasses. This results in a more robust\nand faster operation, but there may be small differences in the output.\ndjango.utils.text.Truncator used by truncatechars_html and\ntruncatewords_html template filters now uses\nhtml.parser.HTMLParser subclasses. This results in a more robust\nand faster operation, but there may be small differences in the output.\ndjango.utils.text.Truncator\ntruncatechars_html\ntruncatewords_html\nhtml.parser.HTMLParser\nThe undocumented django.urls.converters.get_converter() function is\nremoved.\nThe undocumented django.urls.converters.get_converter() function is\nremoved.\ndjango.urls.converters.get_converter()\nThe minimum supported version of SQLite is increased from 3.27.0 to 3.31.0.\nThe minimum supported version of SQLite is increased from 3.27.0 to 3.31.0.\nFileField now raises a\nFieldError when saving a file without a\nname.\nFileField now raises a\nFieldError when saving a file without a\nname.\nFileField\nFieldError\nname\nImageField.update_dimension_fields(force=True) is no longer called after\nsaving the image to storage. If your storage backend resizes images, the\nwidth_field and height_field will not match the width and height of\nthe image.\nImageField.update_dimension_fields(force=True) is no longer called after\nsaving the image to storage. If your storage backend resizes images, the\nwidth_field and height_field will not match the width and height of\nthe image.\nImageField.update_dimension_fields(force=True)\nwidth_field\nheight_field\nThe minimum supported version of asgiref is increased from 3.7.0 to\n3.8.1.\nThe minimum supported version of asgiref is increased from 3.7.0 to\n3.8.1.\nasgiref\nTo improve performance, the delete_selected admin action now uses\nQuerySet.bulk_create() when creating multiple LogEntry objects. As a\nresult, pre_save and post_save signals for LogEntry are not sent\nwhen multiple objects are deleted via this admin action.\nTo improve performance, the delete_selected admin action now uses\nQuerySet.bulk_create() when creating multiple LogEntry objects. As a\nresult, pre_save and post_save signals for LogEntry are not sent\nwhen multiple objects are deleted via this admin action.\ndelete_selected\nQuerySet.bulk_create()\nLogEntry\npre_save\npost_save\nLogEntry\nFeatures deprecated in 5.1露\nMiscellaneous露\nThe ModelAdmin.log_deletion() and LogEntryManager.log_action()\nmethods are deprecated. Subclasses should implement\nModelAdmin.log_deletions() and  LogEntryManager.log_actions()\ninstead.\nThe ModelAdmin.log_deletion() and LogEntryManager.log_action()\nmethods are deprecated. Subclasses should implement\nModelAdmin.log_deletions() and  LogEntryManager.log_actions()\ninstead.\nModelAdmin.log_deletion()\nLogEntryManager.log_action()\nModelAdmin.log_deletions()\nLogEntryManager.log_actions()\nThe undocumented django.utils.itercompat.is_iterable() function and the\ndjango.utils.itercompat module are deprecated. Use\nisinstance(..., collections.abc.Iterable) instead.\nThe undocumented django.utils.itercompat.is_iterable() function and the\ndjango.utils.itercompat module are deprecated. Use\nisinstance(..., collections.abc.Iterable) instead.\ndjango.utils.itercompat.is_iterable()\ndjango.utils.itercompat\nisinstance(..., collections.abc.Iterable)\nThe django.contrib.gis.geoip2.GeoIP2.coords() method is deprecated. Use\ndjango.contrib.gis.geoip2.GeoIP2.lon_lat() instead.\nThe django.contrib.gis.geoip2.GeoIP2.coords() method is deprecated. Use\ndjango.contrib.gis.geoip2.GeoIP2.lon_lat() instead.\ndjango.contrib.gis.geoip2.GeoIP2.coords()\ndjango.contrib.gis.geoip2.GeoIP2.lon_lat()\nThe django.contrib.gis.geoip2.GeoIP2.open() method is deprecated. Use the\nGeoIP2 constructor instead.\nThe django.contrib.gis.geoip2.GeoIP2.open() method is deprecated. Use the\nGeoIP2 constructor instead.\ndjango.contrib.gis.geoip2.GeoIP2.open()\nGeoIP2\nPassing positional arguments to Model.save() and Model.asave()\nis deprecated in favor of keyword-only arguments.\nPassing positional arguments to Model.save() and Model.asave()\nis deprecated in favor of keyword-only arguments.\nModel.save()\nModel.asave()\nSetting django.contrib.gis.gdal.OGRGeometry.coord_dim is deprecated. Use\nset_3d() instead.\nSetting django.contrib.gis.gdal.OGRGeometry.coord_dim is deprecated. Use\nset_3d() instead.\ndjango.contrib.gis.gdal.OGRGeometry.coord_dim\nset_3d()\nOverriding existing converters with django.urls.register_converter() is\ndeprecated.\nOverriding existing converters with django.urls.register_converter() is\ndeprecated.\ndjango.urls.register_converter()\nThe check keyword argument of CheckConstraint is deprecated in favor\nof condition.\nThe check keyword argument of CheckConstraint is deprecated in favor\nof condition.\ncheck\nCheckConstraint\ncondition\nThe undocumented OS_OPEN_FLAGS property of\nFileSystemStorage is deprecated. To allow\noverwriting files in storage, set the new\nallow_overwrite option\nto True instead.\nThe undocumented OS_OPEN_FLAGS property of\nFileSystemStorage is deprecated. To allow\noverwriting files in storage, set the new\nallow_overwrite option\nto True instead.\nOS_OPEN_FLAGS\nFileSystemStorage\nallow_overwrite\nTrue\nThe get_cache_name() method of FieldCacheMixin is deprecated in favor\nof the cache_name cached property.\nThe get_cache_name() method of FieldCacheMixin is deprecated in favor\nof the cache_name cached property.\nget_cache_name()\nFieldCacheMixin\ncache_name\nFeatures removed in 5.1露\nThese features have reached the end of their deprecation cycle and are removed\nin Django 5.1.\nSee Features deprecated in 4.2 for details on these changes, including how\nto remove usage of these features.\nThe BaseUserManager.make_random_password() method is removed.\nThe BaseUserManager.make_random_password() method is removed.\nBaseUserManager.make_random_password()\nThe models Meta.index_together option is removed.\nThe models Meta.index_together option is removed.\nMeta.index_together\nThe length_is template filter is removed.\nThe length_is template filter is removed.\nlength_is\nThe django.contrib.auth.hashers.SHA1PasswordHasher,\ndjango.contrib.auth.hashers.UnsaltedSHA1PasswordHasher, and\ndjango.contrib.auth.hashers.UnsaltedMD5PasswordHasher are removed.\nThe django.contrib.auth.hashers.SHA1PasswordHasher,\ndjango.contrib.auth.hashers.UnsaltedSHA1PasswordHasher, and\ndjango.contrib.auth.hashers.UnsaltedMD5PasswordHasher are removed.\ndjango.contrib.auth.hashers.SHA1PasswordHasher\ndjango.contrib.auth.hashers.UnsaltedSHA1PasswordHasher\ndjango.contrib.auth.hashers.UnsaltedMD5PasswordHasher\nThe model django.contrib.postgres.fields.CICharField,\ndjango.contrib.postgres.fields.CIEmailField, and\ndjango.contrib.postgres.fields.CITextField are removed, except for\nsupport in historical migrations.\nThe model django.contrib.postgres.fields.CICharField,\ndjango.contrib.postgres.fields.CIEmailField, and\ndjango.contrib.postgres.fields.CITextField are removed, except for\nsupport in historical migrations.\ndjango.contrib.postgres.fields.CICharField\ndjango.contrib.postgres.fields.CIEmailField\ndjango.contrib.postgres.fields.CITextField\nThe django.contrib.postgres.fields.CIText mixin is removed.\nThe django.contrib.postgres.fields.CIText mixin is removed.\ndjango.contrib.postgres.fields.CIText\nThe map_width and map_height attributes of BaseGeometryWidget are\nremoved.\nThe map_width and map_height attributes of BaseGeometryWidget are\nremoved.\nmap_width\nmap_height\nBaseGeometryWidget\nThe SimpleTestCase.assertFormsetError() method is removed.\nThe SimpleTestCase.assertFormsetError() method is removed.\nSimpleTestCase.assertFormsetError()\nThe TransactionTestCase.assertQuerysetEqual() method is removed.\nThe TransactionTestCase.assertQuerysetEqual() method is removed.\nTransactionTestCase.assertQuerysetEqual()\nSupport for passing encoded JSON string literals to JSONField and\nassociated lookups and expressions is removed.\nSupport for passing encoded JSON string literals to JSONField and\nassociated lookups and expressions is removed.\nJSONField\nSupport for passing positional arguments to Signer and\nTimestampSigner is removed.\nSupport for passing positional arguments to Signer and\nTimestampSigner is removed.\nSigner\nTimestampSigner\nThe DEFAULT_FILE_STORAGE and STATICFILES_STORAGE settings is removed.\nThe DEFAULT_FILE_STORAGE and STATICFILES_STORAGE settings is removed.\nDEFAULT_FILE_STORAGE\nSTATICFILES_STORAGE\nThe django.core.files.storage.get_storage_class() function is removed.\nThe django.core.files.storage.get_storage_class() function is removed.\ndjango.core.files.storage.get_storage_class()\nAdditional Information\nSupport Django!\nJames Turk donated to the Django Software Foundation to support Django development. Donate today!\nContents\nDjango 5.1 release notes\nPython compatibility\nWhats new in Django 5.1\n{% querystring %} template tag\nPostgreSQL Connection Pools\nMiddleware to require authentication by default\nMinor features\ndjango.contrib.admin\ndjango.contrib.auth\ndjango.contrib.gis\ndjango.contrib.postgres\ndjango.contrib.sessions\nDatabase backends\nError Reporting\nFile Storage\nForms\nManagement Commands\nMigrations\nModels\nTemplates\nTests\nValidators\n\n\n\n\nBackwards incompatible changes in 5.1\ndjango.contrib.gis\nDropped support for MariaDB 10.4\nDropped support for PostgreSQL 12\nMiscellaneous\n\n\nFeatures deprecated in 5.1\nMiscellaneous\n\n\nFeatures removed in 5.1\nPython compatibility\nWhats new in Django 5.1\n{% querystring %} template tag\nPostgreSQL Connection Pools\nMiddleware to require authentication by default\nMinor features\ndjango.contrib.admin\ndjango.contrib.auth\ndjango.contrib.gis\ndjango.contrib.postgres\ndjango.contrib.sessions\nDatabase backends\nError Reporting\nFile Storage\nForms\nManagement Commands\nMigrations\nModels\nTemplates\nTests\nValidators\n{% querystring %} template tag\n{% querystring %}\nPostgreSQL Connection Pools\nMiddleware to require authentication by default\nMinor features\ndjango.contrib.admin\ndjango.contrib.auth\ndjango.contrib.gis\ndjango.contrib.postgres\ndjango.contrib.sessions\nDatabase backends\nError Reporting\nFile Storage\nForms\nManagement Commands\nMigrations\nModels\nTemplates\nTests\nValidators\ndjango.contrib.admin\ndjango.contrib.admin\ndjango.contrib.auth\ndjango.contrib.auth\ndjango.contrib.gis\ndjango.contrib.gis\ndjango.contrib.postgres\ndjango.contrib.postgres\ndjango.contrib.sessions\ndjango.contrib.sessions\nDatabase backends\nError Reporting\nFile Storage\nForms\nManagement Commands\nMigrations\nModels\nTemplates\nTests\nValidators\nBackwards incompatible changes in 5.1\ndjango.contrib.gis\nDropped support for MariaDB 10.4\nDropped support for PostgreSQL 12\nMiscellaneous\ndjango.contrib.gis\ndjango.contrib.gis\nDropped support for MariaDB 10.4\nDropped support for PostgreSQL 12\nMiscellaneous\nFeatures deprecated in 5.1\nMiscellaneous\nMiscellaneous\nFeatures removed in 5.1\nBrowse\nPrev: Django 5.1.1 release notes\nNext: Django 5.0.14 release notes\nTable of contents\nGeneral Index\nPython Module Index\nYou are here:\nDjango 5.1 documentation\nRelease notes\nDjango 5.1 release notes\nRelease notes\nDjango 5.1 release notes\nDjango 5.1 release notes\nGetting help\nDownload:\nOffline (Django 5.1):\n          HTML |\n          PDF |\n          ePub\n\n\n            Provided by Read the Docs.\nDiamond and Platinum Members\nSentry\nMonitor your Django Code\r\nResolve performance bottlenecks and errors using monitoring, replays, logs and Seer an AI agent for debugging.\nJetBrains\nJetBrains delivers intelligent software solutions that make developers more productive by simplifying their challenging tasks, automating the routine, and helping them adopt the best development practices. PyCharm is the Python IDE for Professional Developers by JetBrains providing a complete set of tools for productive Python, Web and scientific development.\nDjango Links\nLearn More\nAbout Django\nGetting Started with Django\nTeam Organization\nDjango Software Foundation\nCode of Conduct\nDiversity Statement\nGet Involved\nJoin a Group\nContribute\n              to Django\nSubmit\n              a Bug\nReport\n              a Security Issue\nIndividual membership\nGet Help\nGetting Help FAQ\nDjango Discord\nOfficial Django Forum\nFollow Us\nGitHub\nX\nFediverse (Mastodon)\nBluesky\nLinkedIn\nNews RSS\nSupport Us\nSponsor Django\nCorporate membership\nOfficial merchandise store\nBenevity Workplace Giving Program\nHosting by In-kind\n            donors\nDesign by Threespot\n& andrevv\n漏 2005-2025\n         Django Software\n          Foundation and individual contributors. Django is a\n        registered\n          trademark of the Django Software Foundation.",
    "crawl_status": "success"
  },
  {
    "library_name": "FastAPI",
    "url": "https://github.com/fastapi/fastapi/releases/tag/0.120.0",
    "version": "0.120.0",
    "title": "Release 0.120.0 路 fastapi/fastapi 路 GitHub",
    "release_date": "2025-10-23T20:55:59Z",
    "content": "There are no major nor breaking changes in this release. 锔\nThe internal reference documentation now uses\nannotated_doc.Doc\ninstead of\ntyping_extensions.Doc\n, this adds a new (very small) dependency on\nannotated-doc\n, a package made just to provide that\nDoc\ndocumentation utility class.\nI would expect\ntyping_extensions.Doc\nto be deprecated and then removed at some point from\ntyping_extensions\n, for that reason there's the new\nannotated-doc\nmicro-package. If you are curious about this, you can read more in the repo for\nannotated-doc\n.\nThis new version\n0.120.0\nonly contains that transition to the new home package for that utility class\nDoc\n.\nTranslations\n Sync German docs. PR\n#14188\nby\n@nilslindemann\n.\nInternal\n Migrate internal reference documentation from\ntyping_extensions.Doc\nto\nannotated_doc.Doc\n. PR\n#14222\nby\n@tiangolo\n.\n锔 Update German LLM prompt and test file. PR\n#14189\nby\n@nilslindemann\n.\n猬 [pre-commit.ci] pre-commit autoupdate. PR\n#14181\nby\n@pre-commit-ci[bot]\n.",
    "crawl_status": "success"
  },
  {
    "library_name": "FastAPI",
    "url": "https://github.com/fastapi/fastapi/releases/tag/0.110.0",
    "version": "0.110.0",
    "title": "Release 0.110.0 路 fastapi/fastapi 路 GitHub",
    "release_date": "2024-02-24T23:20:47Z",
    "content": "Breaking Changes\n Fix unhandled growing memory for internal server errors, refactor dependencies with\nyield\nand\nexcept\nto require raising again as in regular Python. PR\n#11191\nby\n@tiangolo\n.\nThis is a breaking change (and only slightly) if you used dependencies with\nyield\n, used\nexcept\nin those dependencies, and didn't raise again.\nThis was reported internally by\n@rushilsrivastava\nas a memory leak when the server had unhandled exceptions that would produce internal server errors, the memory allocated before that point would not be released.\nRead the new docs:\nDependencies with\nyield\nand\nexcept\n.\nIn short, if you had dependencies that looked like:\ndef\nmy_dep\n():\ntry\n:\nyield\nexcept\nSomeException\n:\npass\nNow you need to make sure you raise again after\nexcept\n, just as you would in regular Python:\ndef\nmy_dep\n():\ntry\n:\nyield\nexcept\nSomeException\n:\nraise\nDocs\n锔 Fix minor typos in\ndocs/ko/docs/\n. PR\n#11126\nby\n@KaniKim\n.\n锔 Fix minor typo in\nfastapi/applications.py\n. PR\n#11099\nby\n@JacobHayes\n.\nTranslations\n Add German translation for\ndocs/de/docs/reference/background.md\n. PR\n#10820\nby\n@nilslindemann\n.\n Add German translation for\ndocs/de/docs/reference/templating.md\n. PR\n#10842\nby\n@nilslindemann\n.\n Add German translation for\ndocs/de/docs/external-links.md\n. PR\n#10852\nby\n@nilslindemann\n.\n Update Turkish translation for\ndocs/tr/docs/tutorial/query-params.md\n. PR\n#11162\nby\n@hasansezertasan\n.\n Add German translation for\ndocs/de/docs/reference/encoders.md\n. PR\n#10840\nby\n@nilslindemann\n.\n Add German translation for\ndocs/de/docs/reference/responses.md\n. PR\n#10825\nby\n@nilslindemann\n.\n Add German translation for\ndocs/de/docs/reference/request.md\n. PR\n#10821\nby\n@nilslindemann\n.\n Add Turkish translation for\ndocs/tr/docs/tutorial/query-params.md\n. PR\n#11078\nby\n@emrhnsyts\n.\n Add German translation for\ndocs/de/docs/reference/fastapi.md\n. PR\n#10813\nby\n@nilslindemann\n.\n Add German translation for\ndocs/de/docs/newsletter.md\n. PR\n#10853\nby\n@nilslindemann\n.\n Add Traditional Chinese translation for\ndocs/zh-hant/docs/learn/index.md\n. PR\n#11142\nby\n@hsuanchi\n.\n Add Korean translation for\n/docs/ko/docs/tutorial/dependencies/global-dependencies.md\n. PR\n#11123\nby\n@riroan\n.\n Add Korean translation for\n/docs/ko/docs/tutorial/dependencies/dependencies-in-path-operation-decorators.md\n. PR\n#11124\nby\n@riroan\n.\n Add Korean translation for\n/docs/ko/docs/tutorial/schema-extra-example.md\n. PR\n#11121\nby\n@KaniKim\n.\n Add Korean translation for\n/docs/ko/docs/tutorial/body-fields.md\n. PR\n#11112\nby\n@KaniKim\n.\n Add Korean translation for\n/docs/ko/docs/tutorial/cookie-params.md\n. PR\n#11118\nby\n@riroan\n.\n Update Korean translation for\n/docs/ko/docs/dependencies/index.md\n. PR\n#11114\nby\n@KaniKim\n.\n Update Korean translation for\n/docs/ko/docs/deployment/docker.md\n. PR\n#11113\nby\n@KaniKim\n.\n Update Turkish translation for\ndocs/tr/docs/tutorial/first-steps.md\n. PR\n#11094\nby\n@hasansezertasan\n.\n Add Spanish translation for\ndocs/es/docs/advanced/security/index.md\n. PR\n#2278\nby\n@Xaraxx\n.\n Add Spanish translation for\ndocs/es/docs/advanced/response-headers.md\n. PR\n#2276\nby\n@Xaraxx\n.\n Add Spanish translation for\ndocs/es/docs/deployment/index.md\nand\n~/deployment/versions.md\n. PR\n#9669\nby\n@pabloperezmoya\n.\n Add Spanish translation for\ndocs/es/docs/benchmarks.md\n. PR\n#10928\nby\n@pablocm83\n.\n Add Spanish translation for\ndocs/es/docs/advanced/response-change-status-code.md\n. PR\n#11100\nby\n@alejsdev\n.",
    "crawl_status": "success"
  },
  {
    "library_name": "FastAPI",
    "url": "https://github.com/fastapi/fastapi/releases/tag/0.100.0",
    "version": "0.100.0",
    "title": "Release 0.100.0 路 fastapi/fastapi 路 GitHub",
    "release_date": "2023-07-07T17:32:15Z",
    "content": " Support for\nPydantic v2\n\nPydantic version 2 has the\ncore\nre-written in\nRust\nand includes a lot of improvements and features, for example:\nImproved\ncorrectness\nin corner cases.\nSafer\ntypes.\nBetter\nperformance\nand\nless energy\nconsumption.\nBetter\nextensibility\n.\netc.\n...all this while keeping the\nsame Python API\n. In most of the cases, for simple models, you can simply upgrade the Pydantic version and get all the benefits. \nIn some cases, for pure data validation and processing, you can get performance improvements of\n20x\nor more. This means 2,000% or more. く\nWhen you use\nFastAPI\n, there's a lot more going on, processing the request and response, handling dependencies, executing\nyour own code\n, and particularly,\nwaiting for the network\n. But you will probably still get some nice performance improvements just from the upgrade.\nThe focus of this release is\ncompatibility\nwith Pydantic v1 and v2, to make sure your current apps keep working. Later there will be more focus on refactors, correctness, code improvements, and then\nperformance\nimprovements. Some third-party early beta testers that ran benchmarks on the beta releases of FastAPI reported improvements of\n2x - 3x\n. Which is not bad for just doing\npip install --upgrade fastapi pydantic\n. This was not an official benchmark and I didn't check it myself, but it's a good sign.\nMigration\nCheck out the\nPydantic migration guide\n.\nFor the things that need changes in your Pydantic models, the Pydantic team built\nbump-pydantic\n.\nA command line tool that will\nprocess your code\nand update most of the things\nautomatically\nfor you. Make sure you have your code in git first, and review each of the changes to make sure everything is correct before committing the changes.\nPydantic v1\nThis version of FastAPI still supports Pydantic v1\n. And although Pydantic v1 will be deprecated at some point, ti will still be supported for a while.\nThis means that you can install the new Pydantic v2, and if something fails, you can install Pydantic v1 while you fix any problems you might have, but having the latest FastAPI.\nThere are\ntests for both Pydantic v1 and v2\n, and test\ncoverage\nis kept at\n100%\n.\nChanges\nThere are\nnew parameter\nfields supported by Pydantic\nField()\nfor:\nPath()\nQuery()\nHeader()\nCookie()\nBody()\nForm()\nFile()\nThe new parameter fields are:\ndefault_factory\nalias_priority\nvalidation_alias\nserialization_alias\ndiscriminator\nstrict\nmultiple_of\nallow_inf_nan\nmax_digits\ndecimal_places\njson_schema_extra\n...you can read about them in the Pydantic docs.\nThe parameter\nregex\nhas been deprecated and replaced by\npattern\n.\nYou can read more about it in the docs for\nQuery Parameters and String Validations: Add regular expressions\n.\nNew Pydantic models use an improved and simplified attribute\nmodel_config\nthat takes a simple dict instead of an internal class\nConfig\nfor their configuration.\nYou can read more about it in the docs for\nDeclare Request Example Data\n.\nThe attribute\nschema_extra\nfor the internal class\nConfig\nhas been replaced by the key\njson_schema_extra\nin the new\nmodel_config\ndict.\nYou can read more about it in the docs for\nDeclare Request Example Data\n.\nWhen you install\n\"fastapi[all]\"\nit now also includes:\npydantic-settings\n- for settings management.\npydantic-extra-types\n- for extra types to be used with Pydantic.\nNow Pydantic Settings is an additional optional package (included in\n\"fastapi[all]\"\n). To use settings you should now import\nfrom pydantic_settings import BaseSettings\ninstead of importing from\npydantic\ndirectly.\nYou can read more about it in the docs for\nSettings and Environment Variables\n.\nPR\n#9816\nby\n@tiangolo\n, included all the work done (in multiple PRs) on the beta branch (\nmain-pv2\n).",
    "crawl_status": "success"
  },
  {
    "library_name": "Scikit-learn",
    "url": "https://scikit-learn.org/stable/whats_new/v1.7.html",
    "version": "v1.7.html",
    "title": "Version 1.7  scikit-learn 1.7.2 documentation",
    "release_date": "Unknown release date",
    "content": "Release History\nVersion 1.7\nVersion 1.7\n#\nFor a short description of the main highlights of the release, please refer to\nRelease Highlights for scikit-learn 1.7\n.\nLegend for changelogs\nMajor Feature\nsomething big that you couldnt do before.\nFeature\nsomething that you couldnt do before.\nEfficiency\nan existing feature now may not require as much computation or\nmemory.\nEnhancement\na miscellaneous minor improvement.\nFix\nsomething that previously didnt work as documented  or according\nto reasonable expectations  should now work.\nAPI Change\nyou will need to change your code to have the same effect in the\nfuture; or a feature will be removed in the future.\nVersion 1.7.2\n#\nSeptember 2025\nsklearn.compose\n#\nFix\ncompose.TransformedTargetRegressor\nnow passes the transformed target to\nthe regressor with the same number of dimensions as the original target.\nBy\nkryggird\n.\n#31563\nsklearn.feature_extraction\n#\nFix\nSet the tag\nrequires_fit=False\nfor the classes\nfeature_extraction.FeatureHasher\nand\nfeature_extraction.text.HashingVectorizer\n.\nBy\nhakan 莽anakc谋\n.\n#31851\nsklearn.impute\n#\nFix\nFixed a bug in\nimpute.SimpleImputer\nwith\nstrategy=\"most_frequent\"\nwhen there is a tie in the most frequent value and the input data has mixed types.\nBy\nAlexandre Abraham\n.\n#31820\nsklearn.linear_model\n#\nFix\nFixed a bug with\nsolver=\"newton-cholesky\"\non multi-class problems in\nlinear_model.LogisticRegressionCV\nand in\nlinear_model.LogisticRegression\nwhen used with\nwarm_start=True\n. The bug\nappeared either with\nfit_intercept=True\nor with\npenalty=None\n(both resulting in\nunpenalized parameters for the solver). The coefficients and intercepts of the last\nclass as provided by warm start were partially wrongly overwritten by zero.\nBy\nChristian Lorentzen\n.\n#31866\nsklearn.pipeline\n#\nFix\npipeline.FeatureUnion\nnow validates that all transformers return 2D\noutputs and raises an informative error when transformers return 1D outputs,\npreventing silent failures that previously produced meaningless concatenated results.\nBy\ngguiomar\n.\n#31559\nVersion 1.7.1\n#\nJuly 2025\nsklearn.base\n#\nFix\nFix regression in HTML representation when detecting the non-default parameters\nthat where of array-like types.\nBy\nDea Mar铆a L茅on\n#31528\nsklearn.compose\n#\nFix\ncompose.ColumnTransformer\nnow correctly preserves non-default index\nwhen mixing pandas Series and Dataframes.\nBy\nNicolas Bolle\n.\n#31079\nsklearn.datasets\n#\nFix\nFixed a regression preventing to extract the downloaded dataset in\ndatasets.fetch_20newsgroups\n,\ndatasets.fetch_20newsgroups_vectorized\n,\ndatasets.fetch_lfw_people\nand\ndatasets.fetch_lfw_pairs\n. This\nonly affects Python versions\n>=3.10.0,<=3.10.11\nand\n>=3.11.0,<=3.11.3\n.\nBy\nJ茅r茅mie du Boisberranger\n.\n#31685\nsklearn.inspection\n#\nFix\nFix multiple issues in the multiclass setting of\ninspection.DecisionBoundaryDisplay\n:\ncontour\nplotting now correctly shows the decision boundary.\ncmap\nand\ncolors\nare now properly ignored in favor of\nmulticlass_colors\n.\nLinear segmented colormaps are now fully supported.\nBy\nYunjie Lin\n#31553\nsklearn.naive_bayes\n#\nFix\nnaive_bayes.CategoricalNB\nnow correctly declares that it accepts\ncategorical features in the tags returned by its\n__sklearn_tags__\nmethod.\nBy\nOlivier Grisel\n#31556\nsklearn.utils\n#\nFix\nFixed a spurious warning (about the number of unique classes being\ngreater than 50% of the number of samples) that could occur when\npassing\nclasses\nutils.multiclass.type_of_target\n.\nBy\nSascha D. Krauss\n.\n#31584\nVersion 1.7.0\n#\nJune 2025\nChanged models\n#\nFix\nChange the\nConvergenceWarning\nmessage of estimators that rely on the\n\"lbfgs\"\noptimizer internally to be more informative and to avoid\nsuggesting to increase the maximum number of iterations when it is not\nuser-settable or when the convergence problem happens before reaching it.\nBy\nOlivier Grisel\n.\n#31316\nChanges impacting many modules\n#\nSparse update: As part of the SciPy change from spmatrix to sparray, all\ninternal use of sparse now supports both sparray and spmatrix.\nAll manipulations of sparse objects should work for either spmatrix or sparray.\nThis is pass 1 of a migration toward sparray (see\nSciPy migration to sparray\nBy\nDan Schult\n#30858\nSupport for Array API\n#\nAdditional estimators and functions have been updated to include support for all\nArray API\ncompliant inputs.\nSee\nArray API support (experimental)\nfor more details.\nFeature\nsklearn.utils.check_consistent_length\nnow supports Array API compatible\ninputs.\nBy\nStefanie Senger\n#29519\nFeature\nsklearn.metrics.explained_variance_score\nand\nsklearn.metrics.mean_pinball_loss\nnow support Array API compatible inputs.\nBy\nVirgil Chan\n#29978\nFeature\nsklearn.metrics.fbeta_score\n,\nsklearn.metrics.precision_score\nand\nsklearn.metrics.recall_score\nnow support Array API compatible inputs.\nBy\nOmar Salman\n#30395\nFeature\nsklearn.utils.extmath.randomized_svd\nnow support Array API compatible inputs.\nBy\nConnor Lane\nand\nJ茅r茅mie du Boisberranger\n.\n#30819\nFeature\nsklearn.metrics.hamming_loss\nnow support Array API compatible inputs.\nBy\nThomas Li\n#30838\nFeature\npreprocessing.Binarizer\nnow supports Array API compatible inputs.\nBy\nYaroslav Korobko\n,\nOlivier Grisel\n, and\nThomas Li\n.\n#31190\nFeature\nsklearn.metrics.jaccard_score\nnow supports Array API compatible inputs.\nBy\nOmar Salman\n#31204\narray-api-compat and array-api-extra are now vendored within the\nscikit-learn source. Users of the experimental array API standard\nsupport no longer need to install array-api-compat in their environment.\nby\nLucas Colley\n#30340\nMetadata routing\n#\nRefer to the\nMetadata Routing User Guide\nfor\nmore details.\nFeature\nensemble.BaggingClassifier\nand\nensemble.BaggingRegressor\nnow support\nmetadata routing through their\npredict\n,\npredict_proba\n,\npredict_log_proba\nand\ndecision_function\nmethods and pass\n**params\nto the underlying estimators.\nBy\nStefanie Senger\n.\n#30833\nsklearn.base\n#\nEnhancement\nbase.BaseEstimator\nnow has a parameter table added to the\nestimators HTML representation that can be visualized with jupyter.\nBy\nGuillaume Lemaitre\nand\nDea Mar铆a L茅on\n#30763\nsklearn.calibration\n#\nFix\nCalibratedClassifierCV\nnow raises\nFutureWarning\ninstead of\nUserWarning\nwhen passing\ncv=\"prefit\n. By\nOlivier Grisel\nCalibratedClassifierCV\nwith\nmethod=\"sigmoid\"\nno\nlonger crashes when passing\nfloat64\n-dtyped\nsample_weight\nalong with a\nbase estimator that outputs\nfloat32\n-dtyped predictions. By\nOlivier\nGrisel\n#30873\nsklearn.compose\n#\nAPI Change\nThe\nforce_int_remainder_cols\nparameter of\ncompose.ColumnTransformer\nand\ncompose.make_column_transformer\nis deprecated and will be removed in 1.9.\nIt has no effect.\nBy\nJ茅r茅mie du Boisberranger\n#31167\nsklearn.covariance\n#\nFix\nSupport for\nn_samples\n==\nn_features\nin\nsklearn.covariance.MinCovDet\nhas\nbeen restored.  By\nAntony Lee\n.\n#30483\nsklearn.datasets\n#\nEnhancement\nNew parameter\nreturn_X_y\nadded to\ndatasets.make_classification\n. The\ndefault value of the parameter does not change how the function behaves.\nBy\nSuccess Moses\nand\nAdam Cooper\n#30196\nsklearn.decomposition\n#\nFeature\nDictionaryLearning\n,\nSparseCoder\nand\nMiniBatchDictionaryLearning\nnow have a\ninverse_transform\nmethod. By\nR茅mi Flamary\n#30443\nsklearn.ensemble\n#\nFeature\nensemble.HistGradientBoostingClassifier\nand\nensemble.HistGradientBoostingRegressor\nallow for more control over the\nvalidation set used for early stopping. You can now pass data to be used for\nvalidation directly to\nfit\nvia the arguments\nX_val\n,\ny_val\nand\nsample_weight_val\n.\nBy\nChristian Lorentzen\n.\n#27124\nFix\nensemble.VotingClassifier\nand\nensemble.VotingRegressor\nvalidate\nestimators\nto make sure it is a list of tuples. By\nThomas Fan\n.\n#30649\nsklearn.feature_selection\n#\nEnhancement\nfeature_selection.RFECV\nnow gives access to the ranking and support in each\niteration and cv step of feature selection.\nBy\nMarie S.\n#30179\nFix\nfeature_selection.SelectFromModel\nnow correctly works when the estimator\nis an instance of\nlinear_model.ElasticNetCV\nwith its\nl1_ratio\nparameter\nbeing an array-like.\nBy\nVasco Pereira\n.\n#31107\nsklearn.gaussian_process\n#\nEnhancement\ngaussian_process.GaussianProcessClassifier\nnow includes a\nlatent_mean_and_variance\nmethod that exposes the mean and the variance of the latent function,\n\\(f\\)\n, used in the Laplace approximation. By\nMiguel Gonz谩lez Duque\n#22227\nsklearn.inspection\n#\nEnhancement\nAdd\ncustom_values\nparameter in\ninspection.partial_dependence\n. It enables\nusers to pass their own grid of values at which the partial dependence should be\ncalculated.\nBy\nFreddy A. Boulton\nand\nStephen Pardy\n#26202\nEnhancement\ninspection.DecisionBoundaryDisplay\nnow supports\nplotting all classes for multi-class problems when\nresponse_method\nis\ndecision_function, predict_proba or auto.\nBy\nLucy Liu\n#29797\nFix\ninspection.partial_dependence\nnow raises an informative error when passing\nan empty list as the\ncategorical_features\nparameter.\nNone\nshould be used instead\nto indicate that no categorical features are present.\nBy\nPedro Lopes\n.\n#31146\nAPI Change\ninspection.partial_dependence\ndoes no longer accept integer dtype for\nnumerical feature columns. Explicit conversion to floating point values is\nnow required before calling this tool (and preferably even before fitting the\nmodel to inspect).\nBy\nOlivier Grisel\n#30409\nsklearn.linear_model\n#\nEnhancement\nlinear_model.SGDClassifier\nand\nlinear_model.SGDRegressor\nnow accept\nl1_ratio=None\nwhen\npenalty\nis not\n\"elasticnet\"\n.\nBy\nMarc Bresson\n.\n#30730\nEnhancement\nFitting\nlinear_model.Lasso\nand\nlinear_model.ElasticNet\nwith\nfit_intercept=True\nis faster for sparse input\nX\nbecause an unnecessary\nre-computation of the sum of residuals is avoided.\nBy\nChristian Lorentzen\n#31387\nFix\nlinear_model.LogisticRegression\nand\nlinear_model.LogisticRegressionCV\nnow properly pass sample weights to\nutils.class_weight.compute_class_weight\nwhen fit with\nclass_weight=\"balanced\"\n.\nBy\nShruti Nath\nand\nOlivier Grisel\n#30057\nFix\nAdded a new parameter\ntol\nto\nlinear_model.LinearRegression\nthat determines the precision of the\nsolution\ncoef_\nwhen fitting on sparse data.\nBy\nSuccess Moses\n#30521\nFix\nThe update and initialization of the hyperparameters now properly handle\nsample weights in\nlinear_model.BayesianRidge\n.\nBy\nAntoine Baker\n.\n#30644\nFix\nlinear_model.BayesianRidge\nnow uses the full SVD to correctly estimate\nthe posterior covariance matrix\nsigma_\nwhen\nn_samples\n<\nn_features\n.\nBy\nAntoine Baker\n#31094\nAPI Change\nThe parameter\nn_alphas\nhas been deprecated in the following classes:\nlinear_model.ElasticNetCV\nand\nlinear_model.LassoCV\nand\nlinear_model.MultiTaskElasticNetCV\nand\nlinear_model.MultiTaskLassoCV\n, and will be removed in 1.9. The parameter\nalphas\nnow supports both integers and array-likes, removing the need for\nn_alphas\n.\nFrom now on, only\nalphas\nshould be set to either indicate the number of alphas to\nautomatically generate (int) or to provide a list of alphas (array-like) to test along\nthe regularization path.\nBy\nSiddharth Bansal\n.\n#30616\nAPI Change\nUsing the\n\"liblinear\"\nsolver for multiclass classification with a one-versus-rest\nscheme in\nlinear_model.LogisticRegression\nand\nlinear_model.LogisticRegressionCV\nis deprecated and will raise an error in\nversion 1.8. Either use a solver which supports the multinomial loss or wrap the\nestimator in a\nsklearn.multiclass.OneVsRestClassifier\nto keep applying a\none-versus-rest scheme.\nBy\nJ茅r茅mie du Boisberranger\n.\n#31241\nsklearn.manifold\n#\nEnhancement\nmanifold.MDS\nwill switch to use\nn_init=1\nby default,\nstarting from version 1.9.\nBy\nDmitry Kobak\n#31117\nFix\nmanifold.MDS\nnow correctly handles non-metric MDS. Furthermore,\nthe returned stress value now corresponds to the returned embedding and\nnormalized stress is now allowed for metric MDS.\nBy\nDmitry Kobak\n#30514\nFix\nmanifold.MDS\nnow uses\neps=1e-6\nby default and the convergence\ncriterion was adjusted to make sense for both metric and non-metric MDS\nand to follow the reference R implementation. The formula for normalized\nstress was adjusted to follow the original definition by Kruskal.\nBy\nDmitry Kobak\n#31117\nsklearn.metrics\n#\nFeature\nmetrics.brier_score_loss\nimplements the Brier score for multiclass\nclassification problems and adds a\nscale_by_half\nargument. This metric is\nnotably useful to assess both sharpness and calibration of probabilistic\nclassifiers. See the docstrings for more details. By\nVarun Aggarwal\n,\nOlivier Grisel\nand\nAntoine Baker\n.\n#22046\nFeature\nAdd class method\nfrom_cv_results\nto\nmetrics.RocCurveDisplay\n, which allows\neasy plotting of multiple ROC curves from\nmodel_selection.cross_validate\nresults.\nBy\nLucy Liu\n#30399\nEnhancement\nmetrics.det_curve\n,\nmetrics.DetCurveDisplay.from_estimator\n,\nand\nmetrics.DetCurveDisplay.from_estimator\nnow accept a\ndrop_intermediate\noption to drop thresholds where true positives (tp) do not\nchange from the previous or subsequent thresholds. All points with the same tp\nvalue have the same\nfnr\nand thus same y coordinate in a DET curve.\nBy\nArturo Amor\n#29151\nEnhancement\nclass_likelihood_ratios\nnow has a\nreplace_undefined_by\nparam.\nWhen there is a division by zero, the metric is undefined and the set values are\nreturned for\nLR+\nand\nLR-\n.\nBy\nStefanie Senger\n#29288\nFix\nmetrics.log_loss\nnow raises a\nValueError\nif values of\ny_true\nare missing in\nlabels\n. By\nVarun Aggarwal\n,\nOlivier Grisel\nand\nAntoine Baker\n.\n#22046\nFix\nmetrics.det_curve\nand\nmetrics.DetCurveDisplay\nnow return an\nextra threshold at infinity where the classifier always predicts the negative\nclass i.e. tps = fps = 0.\nBy\nArturo Amor\n#29151\nFix\nclass_likelihood_ratios\nnow raises\nUndefinedMetricWarning\ninstead\nof\nUserWarning\nwhen a division by zero occurs.\nBy\nStefanie Senger\n#29288\nFix\nmetrics.RocCurveDisplay\nwill no longer set a legend when\nlabel\nis\nNone\nin both the\nline_kwargs\nand the\nchance_level_kw\n.\nBy\nArturo Amor\n#29727\nFix\nAdditional\nsample_weight\nchecking has been added to\nmetrics.mean_absolute_error\n,\nmetrics.mean_pinball_loss\n,\nmetrics.mean_absolute_percentage_error\n,\nmetrics.mean_squared_error\n,\nmetrics.root_mean_squared_error\n,\nmetrics.mean_squared_log_error\n,\nmetrics.root_mean_squared_log_error\n,\nmetrics.explained_variance_score\n,\nmetrics.r2_score\n,\nmetrics.mean_tweedie_deviance\n,\nmetrics.mean_poisson_deviance\n,\nmetrics.mean_gamma_deviance\nand\nmetrics.d2_tweedie_score\n.\nsample_weight\ncan only be 1D, consistent to\ny_true\nand\ny_pred\nin length\nor a scalar.\nBy\nLucy Liu\n.\n#30886\nFix\nd2_log_loss_score\nnow properly handles the case when\nlabels\nis\npassed and not all of the labels are present in\ny_true\n.\nBy\nVassilis Margonis\n#30903\nFix\nFix\nmetrics.adjusted_mutual_info_score\nnumerical issue when number of\nclasses and samples is low.\nBy\nHleb Levitski\n#31065\nAPI Change\nThe\nsparse\nparameter of\nmetrics.fowlkes_mallows_score\nis deprecated and\nwill be removed in 1.9. It has no effect.\nBy\nLuc Rocher\n.\n#28981\nAPI Change\nThe\nraise_warning\nparameter of\nmetrics.class_likelihood_ratios\nis deprecated\nand will be removed in 1.9. An\nUndefinedMetricWarning\nwill always be raised in case\nof a division by zero.\nBy\nStefanie Senger\n.\n#29288\nAPI Change\nIn\nsklearn.metrics.RocCurveDisplay.from_predictions\n,\nthe argument\ny_pred\nhas been renamed to\ny_score\nto better reflect its purpose.\ny_pred\nwill be removed in 1.9.\nBy\nBagus Tris Atmaja\nin\n#29865\nsklearn.mixture\n#\nFeature\nAdded an attribute\nlower_bounds_\nin the\nmixture.BaseMixture\nclass to save the list of lower bounds for each iteration thereby providing\ninsights into the convergence behavior of mixture models like\nmixture.GaussianMixture\n.\nBy\nManideep Yenugula\n#28559\nEfficiency\nSimplified redundant computation when estimating covariances in\nGaussianMixture\nwith a\ncovariance_type=\"spherical\"\nor\ncovariance_type=\"diag\"\n.\nBy\nLeonce Mekinda\nand\nOlivier Grisel\n#30414\nEfficiency\nGaussianMixture\nnow consistently operates at\nfloat32\nprecision when fitted with\nfloat32\ndata to improve training speed and\nmemory efficiency. Previously, part of the computation would be implicitly\ncast to\nfloat64\n. By\nOlivier Grisel\nand\nOmar Salman\n.\n#30415\nsklearn.model_selection\n#\nFix\nHyper-parameter optimizers such as\nmodel_selection.GridSearchCV\nnow forward\nsample_weight\nto the scorer even when metadata routing is not enabled.\nBy\nAntoine Baker\n#30743\nsklearn.multiclass\n#\nFix\nThe\npredict_proba\nmethod of\nsklearn.multiclass.OneVsRestClassifier\nnow\nreturns zero for all classes when all inner estimators never predict their positive\nclass.\nBy\nLuis M. B. Varona\n,\nMarc Bresson\n, and\nJ茅r茅mie du Boisberranger\n.\n#31228\nsklearn.multioutput\n#\nEnhancement\nThe parameter\nbase_estimator\nhas been deprecated in favour of\nestimator\nfor\nmultioutput.RegressorChain\nand\nmultioutput.ClassifierChain\n.\nBy\nSuccess Moses\nand\ndikraMasrour\n#30152\nsklearn.neural_network\n#\nFeature\nAdded support for\nsample_weight\nin\nneural_network.MLPClassifier\nand\nneural_network.MLPRegressor\n.\nBy\nZach Shu\nand\nChristian Lorentzen\n#30155\nFeature\nAdded parameter for\nloss\nin\nneural_network.MLPRegressor\nwith options\n\"squared_error\"\n(default) and\n\"poisson\"\n(new).\nBy\nChristian Lorentzen\n#30712\nFix\nneural_network.MLPRegressor\nnow raises an informative error when\nearly_stopping\nis set and the computed validation set is too small.\nBy\nDavid Shumway\n.\n#24788\nsklearn.pipeline\n#\nEnhancement\nExpose the\nverbose_feature_names_out\nargument in the\npipeline.make_union\nfunction, allowing users to control\nfeature name uniqueness in the\npipeline.FeatureUnion\n.\nBy\nAbhijeetsingh Meena\n#30406\nsklearn.preprocessing\n#\nEnhancement\npreprocessing.KBinsDiscretizer\nwith\nstrategy=\"uniform\"\nnow\naccepts\nsample_weight\n. Additionally with\nstrategy=\"quantile\"\nthe\nquantile_method\ncan now be specified (in the future\nquantile_method=\"averaged_inverted_cdf\"\nwill become the default).\nBy\nShruti Nath\nand\nOlivier Grisel\n#29907\nFix\npreprocessing.KBinsDiscretizer\nnow uses weighted resampling when\nsample weights are given and subsampling is used. This may change results\neven when not using sample weights, although in absolute and not in terms\nof statistical properties.\nBy\nShruti Nath\nand\nJ茅r茅mie du Boisberranger\n#29907\nFix\nNow using\nscipy.stats.yeojohnson\ninstead of our own implementation of the Yeo-Johnson transform.\nFixed numerical stability (mostly overflows) of the Yeo-Johnson transform with\nPowerTransformer(method=\"yeo-johnson\")\nwhen scipy version is\n>=\n1.12\n.\nInitial PR by\nXuefeng Xu\ncompleted by\nMohamed Yaich\n,\nOussama Er-rabie\n,\nMohammed Yaslam Dlimi\n,\nHamza Zaroual\n,\nAmine Hannoun\nand\nSylvain Mari茅\n.\n#31227\nsklearn.svm\n#\nFix\nsvm.LinearSVC\nnow properly passes sample weights to\nutils.class_weight.compute_class_weight\nwhen fit with\nclass_weight=\"balanced\"\n.\nBy\nShruti Nath\n#30057\nsklearn.utils\n#\nEnhancement\nutils.multiclass.type_of_target\nraises a warning when the number\nof unique classes is greater than 50% of the number of samples. This warning is raised\nonly if\ny\nhas more than 20 samples.\nBy\nRahil Parikh\n.\n#26335\nEnhancement\n:func:\nresample\nnow handles sample weights which allows\nweighted resampling.\nBy\nShruti Nath\nand\nOlivier Grisel\n#29907\nEnhancement\nutils.class_weight.compute_class_weight\nnow properly accounts for\nsample weights when using strategy balanced to calculate class weights.\nBy\nShruti Nath\n#30057\nEnhancement\nWarning filters from the main process are propagated to joblib workers.\nBy\nThomas Fan\n#30380\nEnhancement\nThe private helper function\nutils._safe_indexing\nnow officially supports\npyarrow data. For instance, passing a pyarrow\nTable\nas\nX\nin a\ncompose.ColumnTransformer\nis now possible.\nBy\nChristian Lorentzen\n#31040\nFix\nIn\nutils.estimator_checks\nwe now enforce for binary classifiers a\nbinary\ny\nby taking the minimum as the negative class instead of the first\nelement, which makes it robust to\ny\nshuffling. It prevents two checks from\nwrongly failing on binary classifiers.\nBy\nAntoine Baker\n.\n#30775\nFix\nutils.extmath.randomized_svd\nand\nutils.extmath.randomized_range_finder\nnow validate their input array to fail early with an informative error message on\ninvalid input.\nBy\nConnor Lane\n.\n#30819\nCode and documentation contributors\nThanks to everyone who has contributed to the maintenance and improvement of\nthe project since version 1.6, including:\n4hm3d, Aaron Schumacher, Abhijeetsingh Meena, Acciaro Gennaro Daniele,\nAchraf Tasfaout, Adriano Le茫o, Adrien Linares, Adrin Jalali, Agriya Khetarpal,\nAiden Frank, Aitsaid Azzedine Idir, ajay-sentry, Akanksha Mhadolkar, Alexandre\nAbraham, Alfredo Saucedo, Anderson Chaves, Andres Guzman-Ballen, Aniruddha\nSaha, antoinebaker, Antony Lee, Arjun S, ArthurDbrn, Arturo, Arturo Amor, ash,\nAshton Powell, ayoub.agouzoul, Ayrat, Bagus Tris Atmaja, Benjamin Danek, Boney\nPatel, Camille Troillard, Chems Ben, Christian Lorentzen, Christian Veenhuis,\nChristine P. Chai, claudio, Code_Blooded, Colas, Colin Coe, Connor Lane, Corey\nFarwell, Daniel Agyapong, Dan Schult, Dea Mar铆a L茅on, Deepak Saldanha,\ndependabot[bot], Dhyey Findoriya, Dimitri Papadopoulos Orfanos, Dmitry Kobak,\nDomenico, elenafillo, Elham Babaei, emelia-hdz, EmilyXinyi, Emma Carballal,\nEric Larson, Eugen-Bleck, Evgeni Burovski, fabianhenning, Gael Varoquaux,\nGaetandeCast, Gil Ramot, Gon莽alo Guiomar, Gordon Grey, Goutam, G Sreeja,\nGuillaume Lemaitre, Haesun Park, hakan 莽anak莽谋, Hanjun Kim, Helder Geovane\nGomes de Lima, Henri Bonamy, Hleb Levitski, Hugo Boulenger, IlyaSolomatin,\nIrene, J茅r茅mie du Boisberranger, J茅r么me Dock猫s, JoaoRodriguesIST, Joel\nNothman, Joris Van den Bossche, Josh, jshn9515, KALLA GANASEKHAR, Kevin Klein,\nKrishnan Vignesh, kryggird, Loic Esteve, Lucas Colley, Luc Rocher, Lucy Liu,\nLuis M. B. Varona, lunovian, Mamduh Zabidi, Marc Bresson, Marco Edward Gorelli,\nMarco Maggi, Marek Pokropiski, Maren Westermann, Marie Sacksick, Marija\nVlajic, Martin Jura, Mayank Raj, Michael Burkhart, Miguel Gonz谩lez Duque,\nMihir Waknis, Miro Hronok, Mohamed Ali SRIR, Mohamed DHIFALLAH, mohammed\nbenyamna, Mohit Singh Thakur, Mounir Lbath, myenugula, Natalia Mokeeva, Nicolas\nBolle, Olivier Grisel, omahs, Omar Salman, Pedro Lopes, Pedro Olivares, Peter\nHolzer, Prashant Bansal, Preyas Shah, Radovenchyk, Rahil Parikh, R茅mi Flamary,\nReshama Shaikh, Richard Harris, Rishab Saini, rolandrmgservices, SanchitD,\nSantiago Castro, Santiago V铆quez, saskra, scikit-learn-bot, Scott Huberty,\nShashank S, Shaurya Bisht, Shivam, Shruti Nath, Siddharth Bansal, SIKAI ZHANG,\nSimarjot Sidhu, sisird864, SiyuJin-1, Somdutta Banerjee, Sortofamudkip, sotagg,\nSourabh Kumar, Stefan, Stefanie Senger, Stefano Gaspari, Steffen Rehberg,\nStephen Pardy, Success Moses, Sylvain Combettes, Tahar Allouche, Thomas J. Fan,\nThomas Li, ThorbenMaa, Tim Head, Tingwei Zhu, TJ Norred, Umberto Fasci, UV,\nVasco Pereira, Vassilis Margonis, Velislav Babatchev, Victoria Shevchenko,\nviktor765, Vipsa Kamani, VirenPassi, Virgil Chan, vpz, Xiao Yuan, Yaich\nMohamed, Yair Shimony, Yao Xiao, Yaroslav Halchenko, Yulia Vilensky, Yuvi Panda\nprevious\nRelease History\nnext\nVersion 1.6\nOn this page\nVersion 1.7.2\nsklearn.compose\nsklearn.feature_extraction\nsklearn.impute\nsklearn.linear_model\nsklearn.pipeline\nVersion 1.7.1\nsklearn.base\nsklearn.compose\nsklearn.datasets\nsklearn.inspection\nsklearn.naive_bayes\nsklearn.utils\nVersion 1.7.0\nChanged models\nChanges impacting many modules\nSupport for Array API\nMetadata routing\nsklearn.base\nsklearn.calibration\nsklearn.compose\nsklearn.covariance\nsklearn.datasets\nsklearn.decomposition\nsklearn.ensemble\nsklearn.feature_selection\nsklearn.gaussian_process\nsklearn.inspection\nsklearn.linear_model\nsklearn.manifold\nsklearn.metrics\nsklearn.mixture\nsklearn.model_selection\nsklearn.multiclass\nsklearn.multioutput\nsklearn.neural_network\nsklearn.pipeline\nsklearn.preprocessing\nsklearn.svm\nsklearn.utils\nThis Page\nShow Source",
    "crawl_status": "success"
  },
  {
    "library_name": "Scikit-learn",
    "url": "https://scikit-learn.org/stable/whats_new/v1.3.html",
    "version": "v1.3.html",
    "title": "Version 1.3  scikit-learn 1.7.2 documentation",
    "release_date": "Unknown release date",
    "content": "Release History\nVersion 1.3\nVersion 1.3\n#\nFor a short description of the main highlights of the release, please refer to\nRelease Highlights for scikit-learn 1.3\n.\nLegend for changelogs\nMajor Feature\nsomething big that you couldnt do before.\nFeature\nsomething that you couldnt do before.\nEfficiency\nan existing feature now may not require as much computation or\nmemory.\nEnhancement\na miscellaneous minor improvement.\nFix\nsomething that previously didnt work as documented  or according\nto reasonable expectations  should now work.\nAPI Change\nyou will need to change your code to have the same effect in the\nfuture; or a feature will be removed in the future.\nVersion 1.3.2\n#\nOctober 2023\nChangelog\n#\nsklearn.datasets\n#\nFix\nAll dataset fetchers now accept\ndata_home\nas any object that implements\nthe\nos.PathLike\ninterface, for instance,\npathlib.Path\n.\n#27468\nby\nYao Xiao\n.\nsklearn.decomposition\n#\nFix\nFixes a bug in\ndecomposition.KernelPCA\nby forcing the output of\nthe internal\npreprocessing.KernelCenterer\nto be a default array. When the\narpack solver is used, it expects an array with a\ndtype\nattribute.\n#27583\nby\nGuillaume Lemaitre\n.\nsklearn.metrics\n#\nFix\nFixes a bug for metrics using\nzero_division=np.nan\n(e.g.\nprecision_score\n) within a parallel loop\n(e.g.\ncross_val_score\n) where the singleton for\nnp.nan\nwill be different in the sub-processes.\n#27573\nby\nGuillaume Lemaitre\n.\nsklearn.tree\n#\nFix\nDo not leak data via non-initialized memory in decision tree pickle files and make\nthe generation of those files deterministic.\n#27580\nby\nLo茂c Est猫ve\n.\nVersion 1.3.1\n#\nSeptember 2023\nChanged models\n#\nThe following estimators and functions, when fit with the same data and\nparameters, may produce different models from the previous version. This often\noccurs due to changes in the modelling logic (bug fixes or enhancements), or in\nrandom sampling procedures.\nFix\nRidge models with\nsolver='sparse_cg'\nmay have slightly different\nresults with scipy>=1.12, because of an underlying change in the scipy solver\n(see\nscipy#18488\nfor more\ndetails)\n#26814\nby\nLo茂c Est猫ve\nChanges impacting all modules\n#\nFix\nThe\nset_output\nAPI correctly works with list input.\n#27044\nby\nThomas Fan\n.\nChangelog\n#\nsklearn.calibration\n#\nFix\ncalibration.CalibratedClassifierCV\ncan now handle models that\nproduce large prediction scores. Before it was numerically unstable.\n#26913\nby\nOmar Salman\n.\nsklearn.cluster\n#\nFix\ncluster.BisectingKMeans\ncould crash when predicting on data\nwith a different scale than the data used to fit the model.\n#27167\nby\nOlivier Grisel\n.\nFix\ncluster.BisectingKMeans\nnow works with data that has a single feature.\n#27243\nby\nJ茅r茅mie du Boisberranger\n.\nsklearn.cross_decomposition\n#\nFix\ncross_decomposition.PLSRegression\nnow automatically ravels the output\nof\npredict\nif fitted with one dimensional\ny\n.\n#26602\nby\nYao Xiao\n.\nsklearn.ensemble\n#\nFix\nFix a bug in\nensemble.AdaBoostClassifier\nwith\nalgorithm=\"SAMME\"\nwhere the decision function of each weak learner should be symmetric (i.e.\nthe sum of the scores should sum to zero for a sample).\n#26521\nby\nGuillaume Lemaitre\n.\nsklearn.feature_selection\n#\nFix\nfeature_selection.mutual_info_regression\nnow correctly computes the\nresult when\nX\nis of integer dtype.\n#26748\nby\nYao Xiao\n.\nsklearn.impute\n#\nFix\nimpute.KNNImputer\nnow correctly adds a missing indicator column in\ntransform\nwhen\nadd_indicator\nis set to\nTrue\nand missing values are observed\nduring\nfit\n.\n#26600\nby\nShreesha Kumar Bhat\n.\nsklearn.metrics\n#\nFix\nScorers used with\nmetrics.get_scorer\nhandle properly\nmultilabel-indicator matrix.\n#27002\nby\nGuillaume Lemaitre\n.\nsklearn.mixture\n#\nFix\nThe initialization of\nmixture.GaussianMixture\nfrom user-provided\nprecisions_init\nfor\ncovariance_type\nof\nfull\nor\ntied\nwas not correct,\nand has been fixed.\n#26416\nby\nYang Tao\n.\nsklearn.neighbors\n#\nFix\nneighbors.KNeighborsClassifier.predict\nno longer raises an\nexception for\npandas.DataFrames\ninput.\n#26772\nby\nJ茅r茅mie du Boisberranger\n.\nFix\nReintroduce\nsklearn.neighbors.BallTree.valid_metrics\nand\nsklearn.neighbors.KDTree.valid_metrics\nas public class attributes.\n#26754\nby\nJulien Jerphanion\n.\nFix\nsklearn.model_selection.HalvingRandomSearchCV\nno longer raises\nwhen the input to the\nparam_distributions\nparameter is a list of dicts.\n#26893\nby\nStefanie Senger\n.\nFix\nNeighbors based estimators now correctly work when\nmetric=\"minkowski\"\nand the\nmetric parameter\np\nis in the range\n0\n<\np\n<\n1\n, regardless of the\ndtype\nof\nX\n.\n#26760\nby\nShreesha Kumar Bhat\n.\nsklearn.preprocessing\n#\nFix\npreprocessing.LabelEncoder\ncorrectly accepts\ny\nas a keyword\nargument.\n#26940\nby\nThomas Fan\n.\nFix\npreprocessing.OneHotEncoder\nshows a more informative error message\nwhen\nsparse_output=True\nand the output is configured to be pandas.\n#26931\nby\nThomas Fan\n.\nsklearn.tree\n#\nFix\ntree.plot_tree\nnow accepts\nclass_names=True\nas documented.\n#26903\nby\nThomas Roehr\nFix\nThe\nfeature_names\nparameter of\ntree.plot_tree\nnow accepts any kind of\narray-like instead of just a list.\n#27292\nby\nRahil Parikh\n.\nVersion 1.3.0\n#\nJune 2023\nChanged models\n#\nThe following estimators and functions, when fit with the same data and\nparameters, may produce different models from the previous version. This often\noccurs due to changes in the modelling logic (bug fixes or enhancements), or in\nrandom sampling procedures.\nEnhancement\nmulticlass.OutputCodeClassifier.predict\nnow uses a more\nefficient pairwise distance reduction. As a consequence, the tie-breaking\nstrategy is different and thus the predicted labels may be different.\n#25196\nby\nGuillaume Lemaitre\n.\nEnhancement\nThe\nfit_transform\nmethod of\ndecomposition.DictionaryLearning\nis more efficient but may produce different results as in previous versions when\ntransform_algorithm\nis not the same as\nfit_algorithm\nand the number of iterations\nis small.\n#24871\nby\nOmar Salman\n.\nEnhancement\nThe\nsample_weight\nparameter now will be used in centroids\ninitialization for\ncluster.KMeans\n,\ncluster.BisectingKMeans\nand\ncluster.MiniBatchKMeans\n.\nThis change will break backward compatibility, since numbers generated\nfrom same random seeds will be different.\n#25752\nby\nHleb Levitski\n,\nJ茅r茅mie du Boisberranger\n,\nGuillaume Lemaitre\n.\nFix\nTreat more consistently small values in the\nW\nand\nH\nmatrices during the\nfit\nand\ntransform\nsteps of\ndecomposition.NMF\nand\ndecomposition.MiniBatchNMF\nwhich can produce different results than previous\nversions.\n#25438\nby\nYotam Avidar-Constantini\n.\nFix\ndecomposition.KernelPCA\nmay produce different results through\ninverse_transform\nif\ngamma\nis\nNone\n. Now it will be chosen correctly as\n1/n_features\nof the data that it is fitted on, while previously it might be\nincorrectly chosen as\n1/n_features\nof the data passed to\ninverse_transform\n.\nA new attribute\ngamma_\nis provided for revealing the actual value of\ngamma\nused each time the kernel is called.\n#26337\nby\nYao Xiao\n.\nChanged displays\n#\nEnhancement\nmodel_selection.LearningCurveDisplay\ndisplays both the\ntrain and test curves by default. You can set\nscore_type=\"test\"\nto keep the\npast behaviour.\n#25120\nby\nGuillaume Lemaitre\n.\nFix\nmodel_selection.ValidationCurveDisplay\nnow accepts passing a\nlist to the\nparam_range\nparameter.\n#27311\nby\nArturo Amor\n.\nChanges impacting all modules\n#\nEnhancement\nThe\nget_feature_names_out\nmethod of the following classes now\nraises a\nNotFittedError\nif the instance is not fitted. This ensures the error is\nconsistent in all estimators with the\nget_feature_names_out\nmethod.\nimpute.MissingIndicator\nfeature_extraction.DictVectorizer\nfeature_extraction.text.TfidfTransformer\nfeature_selection.GenericUnivariateSelect\nfeature_selection.RFE\nfeature_selection.RFECV\nfeature_selection.SelectFdr\nfeature_selection.SelectFpr\nfeature_selection.SelectFromModel\nfeature_selection.SelectFwe\nfeature_selection.SelectKBest\nfeature_selection.SelectPercentile\nfeature_selection.SequentialFeatureSelector\nfeature_selection.VarianceThreshold\nkernel_approximation.AdditiveChi2Sampler\nimpute.IterativeImputer\nimpute.KNNImputer\nimpute.SimpleImputer\nisotonic.IsotonicRegression\npreprocessing.Binarizer\npreprocessing.KBinsDiscretizer\npreprocessing.MaxAbsScaler\npreprocessing.MinMaxScaler\npreprocessing.Normalizer\npreprocessing.OrdinalEncoder\npreprocessing.PowerTransformer\npreprocessing.QuantileTransformer\npreprocessing.RobustScaler\npreprocessing.SplineTransformer\npreprocessing.StandardScaler\nrandom_projection.GaussianRandomProjection\nrandom_projection.SparseRandomProjection\nThe\nNotFittedError\ndisplays an informative message asking to fit the instance\nwith the appropriate arguments.\n#25294\n,\n#25308\n,\n#25291\n,\n#25367\n,\n#25402\n,\nby\nJohn Pangas\n,\nRahil Parikh\n,\nand\nAlex Buzenet\n.\nEnhancement\nAdded a multi-threaded Cython routine to the compute squared\nEuclidean distances (sometimes followed by a fused reduction operation) for a\npair of datasets consisting of a sparse CSR matrix and a dense NumPy.\nThis can improve the performance of following functions and estimators:\nsklearn.metrics.pairwise_distances_argmin\nsklearn.metrics.pairwise_distances_argmin_min\nsklearn.cluster.AffinityPropagation\nsklearn.cluster.Birch\nsklearn.cluster.MeanShift\nsklearn.cluster.OPTICS\nsklearn.cluster.SpectralClustering\nsklearn.feature_selection.mutual_info_regression\nsklearn.neighbors.KNeighborsClassifier\nsklearn.neighbors.KNeighborsRegressor\nsklearn.neighbors.RadiusNeighborsClassifier\nsklearn.neighbors.RadiusNeighborsRegressor\nsklearn.neighbors.LocalOutlierFactor\nsklearn.neighbors.NearestNeighbors\nsklearn.manifold.Isomap\nsklearn.manifold.LocallyLinearEmbedding\nsklearn.manifold.TSNE\nsklearn.manifold.trustworthiness\nsklearn.semi_supervised.LabelPropagation\nsklearn.semi_supervised.LabelSpreading\nA typical example of this performance improvement happens when passing a sparse\nCSR matrix to the\npredict\nor\ntransform\nmethod of estimators that rely on\na dense NumPy representation to store their fitted parameters (or the reverse).\nFor instance,\nsklearn.neighbors.NearestNeighbors.kneighbors\nis now up\nto 2 times faster for this case on commonly available laptops.\n#25044\nby\nJulien Jerphanion\n.\nEnhancement\nAll estimators that internally rely on OpenMP multi-threading\n(via Cython) now use a number of threads equal to the number of physical\n(instead of logical) cores by default. In the past, we observed that using as\nmany threads as logical cores on SMT hosts could sometimes cause severe\nperformance problems depending on the algorithms and the shape of the data.\nNote that it is still possible to manually adjust the number of threads used\nby OpenMP as documented in\nParallelism\n.\n#26082\nby\nJ茅r茅mie du Boisberranger\nand\nOlivier Grisel\n.\nExperimental / Under Development\n#\nMajor Feature\nMetadata routing\ns related base\nmethods are included in this release. This feature is only available via the\nenable_metadata_routing\nfeature flag which can be enabled using\nsklearn.set_config\nand\nsklearn.config_context\n. For now this\nfeature is mostly useful for third party developers to prepare their code\nbase for metadata routing, and we strongly recommend that they also hide it\nbehind the same feature flag, rather than having it enabled by default.\n#24027\nby\nAdrin Jalali\n,\nBenjamin Bossan\n, and\nOmar Salman\n.\nChangelog\n#\nsklearn\n#\nFeature\nAdded a new option\nskip_parameter_validation\n, to the function\nsklearn.set_config\nand context manager\nsklearn.config_context\n, that\nallows to skip the validation of the parameters passed to the estimators and public\nfunctions. This can be useful to speed up the code but should be used with care\nbecause it can lead to unexpected behaviors or raise obscure error messages when\nsetting invalid parameters.\n#25815\nby\nJ茅r茅mie du Boisberranger\n.\nsklearn.base\n#\nFeature\nA\n__sklearn_clone__\nprotocol is now available to override the\ndefault behavior of\nbase.clone\n.\n#24568\nby\nThomas Fan\n.\nFix\nbase.TransformerMixin\nnow currently keeps a namedtuples class\nif\ntransform\nreturns a namedtuple.\n#26121\nby\nThomas Fan\n.\nsklearn.calibration\n#\nFix\ncalibration.CalibratedClassifierCV\nnow does not enforce sample\nalignment on\nfit_params\n.\n#25805\nby\nAdrin Jalali\n.\nsklearn.cluster\n#\nMajor Feature\nAdded\ncluster.HDBSCAN\n, a modern hierarchical density-based\nclustering algorithm. Similarly to\ncluster.OPTICS\n, it can be seen as a\ngeneralization of\ncluster.DBSCAN\nby allowing for hierarchical instead of flat\nclustering, however it varies in its approach from\ncluster.OPTICS\n. This\nalgorithm is very robust with respect to its hyperparameters values and can\nbe used on a wide variety of data without much, if any, tuning.\nThis implementation is an adaptation from the original implementation of HDBSCAN in\nscikit-learn-contrib/hdbscan\n,\nby\nLeland McInnes\net al.\n#26385\nby\nMeekail Zain\nEnhancement\nThe\nsample_weight\nparameter now will be used in centroids\ninitialization for\ncluster.KMeans\n,\ncluster.BisectingKMeans\nand\ncluster.MiniBatchKMeans\n.\nThis change will break backward compatibility, since numbers generated\nfrom same random seeds will be different.\n#25752\nby\nHleb Levitski\n,\nJ茅r茅mie du Boisberranger\n,\nGuillaume Lemaitre\n.\nFix\ncluster.KMeans\n,\ncluster.MiniBatchKMeans\nand\ncluster.k_means\nnow correctly handle the combination of\nn_init=\"auto\"\nand\ninit\nbeing an array-like, running one initialization in that case.\n#26657\nby\nBinesh Bannerjee\n.\nAPI Change\nThe\nsample_weight\nparameter in\npredict\nfor\ncluster.KMeans.predict\nand\ncluster.MiniBatchKMeans.predict\nis now deprecated and will be removed in v1.5.\n#25251\nby\nHleb Levitski\n.\nAPI Change\nThe\nXred\nargument in\ncluster.FeatureAgglomeration.inverse_transform\nis renamed to\nXt\nand will be removed in v1.5.\n#26503\nby\nAdrin Jalali\n.\nsklearn.compose\n#\nFix\ncompose.ColumnTransformer\nraises an informative error when the individual\ntransformers of\nColumnTransformer\noutput pandas dataframes with indexes that are\nnot consistent with each other and the output is configured to be pandas.\n#26286\nby\nThomas Fan\n.\nFix\ncompose.ColumnTransformer\ncorrectly sets the output of the\nremainder when\nset_output\nis called.\n#26323\nby\nThomas Fan\n.\nsklearn.covariance\n#\nFix\nAllows\nalpha=0\nin\ncovariance.GraphicalLasso\nto be\nconsistent with\ncovariance.graphical_lasso\n.\n#26033\nby\nGenesis Valencia\n.\nFix\ncovariance.empirical_covariance\nnow gives an informative\nerror message when input is not appropriate.\n#26108\nby\nQuentin Barth茅lemy\n.\nAPI Change\nDeprecates\ncov_init\nin\ncovariance.graphical_lasso\nin 1.3 since\nthe parameter has no effect. It will be removed in 1.5.\n#26033\nby\nGenesis Valencia\n.\nAPI Change\nAdds\ncosts_\nfitted attribute in\ncovariance.GraphicalLasso\nand\ncovariance.GraphicalLassoCV\n.\n#26033\nby\nGenesis Valencia\n.\nAPI Change\nAdds\ncovariance\nparameter in\ncovariance.GraphicalLasso\n.\n#26033\nby\nGenesis Valencia\n.\nAPI Change\nAdds\neps\nparameter in\ncovariance.GraphicalLasso\n,\ncovariance.graphical_lasso\n, and\ncovariance.GraphicalLassoCV\n.\n#26033\nby\nGenesis Valencia\n.\nsklearn.datasets\n#\nEnhancement\nAllows to overwrite the parameters used to open the ARFF file using\nthe parameter\nread_csv_kwargs\nin\ndatasets.fetch_openml\nwhen using the\npandas parser.\n#26433\nby\nGuillaume Lemaitre\n.\nFix\ndatasets.fetch_openml\nreturns improved data types when\nas_frame=True\nand\nparser=\"liac-arff\"\n.\n#26386\nby\nThomas Fan\n.\nFix\nFollowing the ARFF specs, only the marker\n\"?\"\nis now considered as a missing\nvalues when opening ARFF files fetched using\ndatasets.fetch_openml\nwhen using\nthe pandas parser. The parameter\nread_csv_kwargs\nallows to overwrite this behaviour.\n#26551\nby\nGuillaume Lemaitre\n.\nFix\ndatasets.fetch_openml\nwill consistently use\nnp.nan\nas missing marker\nwith both parsers\n\"pandas\"\nand\n\"liac-arff\"\n.\n#26579\nby\nGuillaume Lemaitre\n.\nAPI Change\nThe\ndata_transposed\nargument of\ndatasets.make_sparse_coded_signal\nis deprecated and will be removed in v1.5.\n#25784\nby\n@J茅r茅mie du Boisberranger\n.\nsklearn.decomposition\n#\nEfficiency\ndecomposition.MiniBatchDictionaryLearning\nand\ndecomposition.MiniBatchSparsePCA\nare now faster for small batch sizes by\navoiding duplicate validations.\n#25490\nby\nJ茅r茅mie du Boisberranger\n.\nEnhancement\ndecomposition.DictionaryLearning\nnow accepts the parameter\ncallback\nfor consistency with the function\ndecomposition.dict_learning\n.\n#24871\nby\nOmar Salman\n.\nFix\nTreat more consistently small values in the\nW\nand\nH\nmatrices during the\nfit\nand\ntransform\nsteps of\ndecomposition.NMF\nand\ndecomposition.MiniBatchNMF\nwhich can produce different results than previous\nversions.\n#25438\nby\nYotam Avidar-Constantini\n.\nAPI Change\nThe\nW\nargument in\ndecomposition.NMF.inverse_transform\nand\ndecomposition.MiniBatchNMF.inverse_transform\nis renamed to\nXt\nand\nwill be removed in v1.5.\n#26503\nby\nAdrin Jalali\n.\nsklearn.discriminant_analysis\n#\nEnhancement\ndiscriminant_analysis.LinearDiscriminantAnalysis\nnow\nsupports the\nPyTorch\n. See\nArray API support (experimental)\nfor more details.\n#25956\nby\nThomas Fan\n.\nsklearn.ensemble\n#\nFeature\nensemble.HistGradientBoostingRegressor\nnow supports\nthe Gamma deviance loss via\nloss=\"gamma\"\n.\nUsing the Gamma deviance as loss function comes in handy for modelling skewed\ndistributed, strictly positive valued targets.\n#22409\nby\nChristian Lorentzen\n.\nFeature\nCompute a custom out-of-bag score by passing a callable to\nensemble.RandomForestClassifier\n,\nensemble.RandomForestRegressor\n,\nensemble.ExtraTreesClassifier\nand\nensemble.ExtraTreesRegressor\n.\n#25177\nby\nTim Head\n.\nFeature\nensemble.GradientBoostingClassifier\nnow exposes\nout-of-bag scores via the\noob_scores_\nor\noob_score_\nattributes.\n#24882\nby\nAshwin Mathur\n.\nEfficiency\nensemble.IsolationForest\npredict time is now faster\n(typically by a factor of 8 or more). Internally, the estimator now precomputes\ndecision path lengths per tree at\nfit\ntime. It is therefore not possible\nto load an estimator trained with scikit-learn 1.2 to make it predict with\nscikit-learn 1.3: retraining with scikit-learn 1.3 is required.\n#25186\nby\nFelipe Breve Siola\n.\nEfficiency\nensemble.RandomForestClassifier\nand\nensemble.RandomForestRegressor\nwith\nwarm_start=True\nnow only\nrecomputes out-of-bag scores when there are actually more\nn_estimators\nin subsequent\nfit\ncalls.\n#26318\nby\nJoshua Choo Yun Keat\n.\nEnhancement\nensemble.BaggingClassifier\nand\nensemble.BaggingRegressor\nexpose the\nallow_nan\ntag from the\nunderlying estimator.\n#25506\nby\nThomas Fan\n.\nFix\nensemble.RandomForestClassifier.fit\nsets\nmax_samples\n=\n1\nwhen\nmax_samples\nis a float and\nround(n_samples\n*\nmax_samples)\n<\n1\n.\n#25601\nby\nJan Fidor\n.\nFix\nensemble.IsolationForest.fit\nno longer warns about missing\nfeature names when called with\ncontamination\nnot\n\"auto\"\non a pandas\ndataframe.\n#25931\nby\nYao Xiao\n.\nFix\nensemble.HistGradientBoostingRegressor\nand\nensemble.HistGradientBoostingClassifier\ntreats negative values for\ncategorical features consistently as missing values, following LightGBMs and\npandas conventions.\n#25629\nby\nThomas Fan\n.\nFix\nFix deprecation of\nbase_estimator\nin\nensemble.AdaBoostClassifier\nand\nensemble.AdaBoostRegressor\nthat was introduced in\n#23819\n.\n#26242\nby\nMarko Toplak\n.\nsklearn.exceptions\n#\nFeature\nAdded\nexceptions.InconsistentVersionWarning\nwhich is raised\nwhen a scikit-learn estimator is unpickled with a scikit-learn version that is\ninconsistent with the scikit-learn version the estimator was pickled with.\n#25297\nby\nThomas Fan\n.\nsklearn.feature_extraction\n#\nAPI Change\nfeature_extraction.image.PatchExtractor\nnow follows the\ntransformer API of scikit-learn. This class is defined as a stateless transformer\nmeaning that it is not required to call\nfit\nbefore calling\ntransform\n.\nParameter validation only happens at\nfit\ntime.\n#24230\nby\nGuillaume Lemaitre\n.\nsklearn.feature_selection\n#\nEnhancement\nAll selectors in\nsklearn.feature_selection\nwill preserve\na DataFrames dtype when transformed.\n#25102\nby\nThomas Fan\n.\nFix\nfeature_selection.SequentialFeatureSelector\ns\ncv\nparameter\nnow supports generators.\n#25973\nby\nYao\nXiao\n<Charlie-XIAO>\n.\nsklearn.impute\n#\nEnhancement\nAdded the parameter\nfill_value\nto\nimpute.IterativeImputer\n.\n#25232\nby\nThijs van Weezel\n.\nFix\nimpute.IterativeImputer\nnow correctly preserves the Pandas\nIndex when the\nset_config(transform_output=\"pandas\")\n.\n#26454\nby\nThomas Fan\n.\nsklearn.inspection\n#\nEnhancement\nAdded support for\nsample_weight\nin\ninspection.partial_dependence\nand\ninspection.PartialDependenceDisplay.from_estimator\n. This allows for\nweighted averaging when aggregating for each value of the grid we are making the\ninspection on. The option is only available when\nmethod\nis set to\nbrute\n.\n#25209\nand\n#26644\nby\nCarlo Lemos\n.\nAPI Change\ninspection.partial_dependence\nreturns a\nutils.Bunch\nwith\nnew key:\ngrid_values\n. The\nvalues\nkey is deprecated in favor of\ngrid_values\nand the\nvalues\nkey will be removed in 1.5.\n#21809\nand\n#25732\nby\nThomas Fan\n.\nsklearn.kernel_approximation\n#\nFix\nkernel_approximation.AdditiveChi2Sampler\nis now stateless.\nThe\nsample_interval_\nattribute is deprecated and will be removed in 1.5.\n#25190\nby\nVincent Maladi猫re\n.\nsklearn.linear_model\n#\nEfficiency\nAvoid data scaling when\nsample_weight=None\nand other\nunnecessary data copies and unexpected dense to sparse data conversion in\nlinear_model.LinearRegression\n.\n#26207\nby\nOlivier Grisel\n.\nEnhancement\nlinear_model.SGDClassifier\n,\nlinear_model.SGDRegressor\nand\nlinear_model.SGDOneClassSVM\nnow preserve dtype for\nnumpy.float32\n.\n#25587\nby\nOmar Salman\n.\nEnhancement\nThe\nn_iter_\nattribute has been included in\nlinear_model.ARDRegression\nto expose the actual number of iterations\nrequired to reach the stopping criterion.\n#25697\nby\nJohn Pangas\n.\nFix\nUse a more robust criterion to detect convergence of\nlinear_model.LogisticRegression\nwith\npenalty=\"l1\"\nand\nsolver=\"liblinear\"\non linearly separable problems.\n#25214\nby\nTom Dupre la Tour\n.\nFix\nFix a crash when calling\nfit\non\nlinear_model.LogisticRegression\nwith\nsolver=\"newton-cholesky\"\nand\nmax_iter=0\nwhich failed to inspect the state of the model prior to the\nfirst parameter update.\n#26653\nby\nOlivier Grisel\n.\nAPI Change\nDeprecates\nn_iter\nin favor of\nmax_iter\nin\nlinear_model.BayesianRidge\nand\nlinear_model.ARDRegression\n.\nn_iter\nwill be removed in scikit-learn 1.5. This change makes those\nestimators consistent with the rest of estimators.\n#25697\nby\nJohn Pangas\n.\nsklearn.manifold\n#\nFix\nmanifold.Isomap\nnow correctly preserves the Pandas\nIndex when the\nset_config(transform_output=\"pandas\")\n.\n#26454\nby\nThomas Fan\n.\nsklearn.metrics\n#\nFeature\nAdds\nzero_division=np.nan\nto multiple classification metrics:\nmetrics.precision_score\n,\nmetrics.recall_score\n,\nmetrics.f1_score\n,\nmetrics.fbeta_score\n,\nmetrics.precision_recall_fscore_support\n,\nmetrics.classification_report\n. When\nzero_division=np.nan\nand there is a\nzero division, the metric is undefined and is excluded from averaging. When not used\nfor averages, the value returned is\nnp.nan\n.\n#25531\nby\nMarc Torrellas Socastro\n.\nFeature\nmetrics.average_precision_score\nnow supports the\nmulticlass case.\n#17388\nby\nGeoffrey Bolmier\nand\n#24769\nby\nAshwin Mathur\n.\nEfficiency\nThe computation of the expected mutual information in\nmetrics.adjusted_mutual_info_score\nis now faster when the number of\nunique labels is large and its memory usage is reduced in general.\n#25713\nby\nKshitij Mathur\n,\nGuillaume Lemaitre\n,\nOmar Salman\nand\nJ茅r茅mie du Boisberranger\n.\nEnhancement\nmetrics.silhouette_samples\nnow accepts a sparse\nmatrix of pairwise distances between samples, or a feature array.\n#18723\nby\nSahil Gupta\nand\n#24677\nby\nAshwin Mathur\n.\nEnhancement\nA new parameter\ndrop_intermediate\nwas added to\nmetrics.precision_recall_curve\n,\nmetrics.PrecisionRecallDisplay.from_estimator\n,\nmetrics.PrecisionRecallDisplay.from_predictions\n,\nwhich drops some suboptimal thresholds to create lighter precision-recall\ncurves.\n#24668\nby\n@dberenbaum\n.\nEnhancement\nmetrics.RocCurveDisplay.from_estimator\nand\nmetrics.RocCurveDisplay.from_predictions\nnow accept two new keywords,\nplot_chance_level\nand\nchance_level_kw\nto plot the baseline chance\nlevel. This line is exposed in the\nchance_level_\nattribute.\n#25987\nby\nYao Xiao\n.\nEnhancement\nmetrics.PrecisionRecallDisplay.from_estimator\nand\nmetrics.PrecisionRecallDisplay.from_predictions\nnow accept two new\nkeywords,\nplot_chance_level\nand\nchance_level_kw\nto plot the baseline\nchance level. This line is exposed in the\nchance_level_\nattribute.\n#26019\nby\nYao Xiao\n.\nFix\nmetrics.pairwise.manhattan_distances\nnow supports readonly sparse datasets.\n#25432\nby\nJulien Jerphanion\n.\nFix\nFixed\nmetrics.classification_report\nso that empty input will return\nnp.nan\n. Previously, macro avg and\nweighted\navg\nwould return\ne.g.\nf1-score=np.nan\nand\nf1-score=0.0\n, being inconsistent. Now, they\nboth return\nnp.nan\n.\n#25531\nby\nMarc Torrellas Socastro\n.\nFix\nmetrics.ndcg_score\nnow gives a meaningful error message for input of\nlength 1.\n#25672\nby\nLene Preuss\nand\nWei-Chun Chu\n.\nFix\nmetrics.log_loss\nraises a warning if the values of the parameter\ny_pred\nare not normalized, instead of actually normalizing them in the metric.\nStarting from 1.5 this will raise an error.\n#25299\nby\n@Omar Salman <OmarManzoor\n.\nFix\nIn\nmetrics.roc_curve\n, use the threshold value\nnp.inf\ninstead of\narbitrary\nmax(y_score)\n+\n1\n. This threshold is associated with the ROC curve point\ntpr=0\nand\nfpr=0\n.\n#26194\nby\nGuillaume Lemaitre\n.\nFix\nThe\n'matching'\nmetric has been removed when using SciPy>=1.9\nto be consistent with\nscipy.spatial.distance\nwhich does not support\n'matching'\nanymore.\n#26264\nby\nBarata T. Onggo\nAPI Change\nThe\neps\nparameter of the\nmetrics.log_loss\nhas been deprecated and\nwill be removed in 1.5.\n#25299\nby\nOmar Salman\n.\nsklearn.gaussian_process\n#\nFix\ngaussian_process.GaussianProcessRegressor\nhas a new argument\nn_targets\n, which is used to decide the number of outputs when sampling\nfrom the prior distributions.\n#23099\nby\nZhehao Liu\n.\nsklearn.mixture\n#\nEfficiency\nmixture.GaussianMixture\nis more efficient now and will bypass\nunnecessary initialization if the weights, means, and precisions are\ngiven by users.\n#26021\nby\nJiawei Zhang\n.\nsklearn.model_selection\n#\nMajor Feature\nAdded the class\nmodel_selection.ValidationCurveDisplay\nthat allows easy plotting of validation curves obtained by the function\nmodel_selection.validation_curve\n.\n#25120\nby\nGuillaume Lemaitre\n.\nAPI Change\nThe parameter\nlog_scale\nin the method\nplot\nof the class\nmodel_selection.LearningCurveDisplay\nhas been deprecated in 1.3 and\nwill be removed in 1.5. The default scale can be overridden by setting it\ndirectly on the\nax\nobject and will be set automatically from the spacing\nof the data points otherwise.\n#25120\nby\nGuillaume Lemaitre\n.\nEnhancement\nmodel_selection.cross_validate\naccepts a new parameter\nreturn_indices\nto return the train-test indices of each cv split.\n#25659\nby\nGuillaume Lemaitre\n.\nsklearn.multioutput\n#\nFix\ngetattr\non\nmultioutput.MultiOutputRegressor.partial_fit\nand\nmultioutput.MultiOutputClassifier.partial_fit\nnow correctly raise\nan\nAttributeError\nif done before calling\nfit\n.\n#26333\nby\nAdrin\nJalali\n.\nsklearn.naive_bayes\n#\nFix\nnaive_bayes.GaussianNB\ndoes not raise anymore a\nZeroDivisionError\nwhen the provided\nsample_weight\nreduces the problem to a single class in\nfit\n.\n#24140\nby\nJonathan Ohayon\nand\nChiara Marmo\n.\nsklearn.neighbors\n#\nEnhancement\nThe performance of\nneighbors.KNeighborsClassifier.predict\nand of\nneighbors.KNeighborsClassifier.predict_proba\nhas been improved\nwhen\nn_neighbors\nis large and\nalgorithm=\"brute\"\nwith non Euclidean metrics.\n#24076\nby\nMeekail Zain\n,\nJulien Jerphanion\n.\nFix\nRemove support for\nKulsinskiDistance\nin\nneighbors.BallTree\n. This\ndissimilarity is not a metric and cannot be supported by the BallTree.\n#25417\nby\nGuillaume Lemaitre\n.\nAPI Change\nThe support for metrics other than\neuclidean\nand\nmanhattan\nand for\ncallables in\nneighbors.NearestNeighbors\nis deprecated and will be removed in\nversion 1.5.\n#24083\nby\nValentin Laurent\n.\nsklearn.neural_network\n#\nFix\nneural_network.MLPRegressor\nand\nneural_network.MLPClassifier\nreports the right\nn_iter_\nwhen\nwarm_start=True\n. It corresponds to the number\nof iterations performed on the current call to\nfit\ninstead of the total number\nof iterations performed since the initialization of the estimator.\n#25443\nby\nMarvin Krawutschke\n.\nsklearn.pipeline\n#\nFeature\npipeline.FeatureUnion\ncan now use indexing notation (e.g.\nfeature_union[\"scalar\"]\n) to access transformers by name.\n#25093\nby\nThomas Fan\n.\nFeature\npipeline.FeatureUnion\ncan now access the\nfeature_names_in_\nattribute if the\nX\nvalue seen during\n.fit\nhas a\ncolumns\nattribute and all columns are strings. e.g. when\nX\nis a\npandas.DataFrame\n#25220\nby\nIan Thompson\n.\nFix\npipeline.Pipeline.fit_transform\nnow raises an\nAttributeError\nif the last step of the pipeline does not support\nfit_transform\n.\n#26325\nby\nAdrin Jalali\n.\nsklearn.preprocessing\n#\nMajor Feature\nIntroduces\npreprocessing.TargetEncoder\nwhich is a\ncategorical encoding based on target mean conditioned on the value of the\ncategory.\n#25334\nby\nThomas Fan\n.\nFeature\npreprocessing.OrdinalEncoder\nnow supports grouping\ninfrequent categories into a single feature. Grouping infrequent categories\nis enabled by specifying how to select infrequent categories with\nmin_frequency\nor\nmax_categories\n.\n#25677\nby\nThomas Fan\n.\nEnhancement\npreprocessing.PolynomialFeatures\nnow calculates the\nnumber of expanded terms a-priori when dealing with sparse\ncsr\nmatrices\nin order to optimize the choice of\ndtype\nfor\nindices\nand\nindptr\n. It\ncan now output\ncsr\nmatrices with\nnp.int32\nindices/indptr\ncomponents\nwhen there are few enough elements, and will automatically use\nnp.int64\nfor sufficiently large matrices.\n#20524\nby\nniuk-a\nand\n#23731\nby\nMeekail Zain\nEnhancement\nA new parameter\nsparse_output\nwas added to\npreprocessing.SplineTransformer\n, available as of SciPy 1.8. If\nsparse_output=True\n,\npreprocessing.SplineTransformer\nreturns a sparse\nCSR matrix.\n#24145\nby\nChristian Lorentzen\n.\nEnhancement\nAdds a\nfeature_name_combiner\nparameter to\npreprocessing.OneHotEncoder\n. This specifies a custom callable to\ncreate feature names to be returned by\npreprocessing.OneHotEncoder.get_feature_names_out\n. The callable\ncombines input arguments\n(input_feature,\ncategory)\nto a string.\n#22506\nby\nMario Kostelac\n.\nEnhancement\nAdded support for\nsample_weight\nin\npreprocessing.KBinsDiscretizer\n. This allows specifying the parameter\nsample_weight\nfor each sample to be used while fitting. The option is only\navailable when\nstrategy\nis set to\nquantile\nand\nkmeans\n.\n#24935\nby\nSeladus\n,\nGuillaume Lemaitre\n, and\nDea Mar铆a L茅on\n,\n#25257\nby\nHleb Levitski\n.\nEnhancement\nSubsampling through the\nsubsample\nparameter can now be used in\npreprocessing.KBinsDiscretizer\nregardless of the strategy used.\n#26424\nby\nJ茅r茅mie du Boisberranger\n.\nFix\npreprocessing.PowerTransformer\nnow correctly preserves the Pandas\nIndex when the\nset_config(transform_output=\"pandas\")\n.\n#26454\nby\nThomas Fan\n.\nFix\npreprocessing.PowerTransformer\nnow correctly raises error when\nusing\nmethod=\"box-cox\"\non data with a constant\nnp.nan\ncolumn.\n#26400\nby\nYao Xiao\n.\nFix\npreprocessing.PowerTransformer\nwith\nmethod=\"yeo-johnson\"\nnow leaves\nconstant features unchanged instead of transforming with an arbitrary value for\nthe\nlambdas_\nfitted parameter.\n#26566\nby\nJ茅r茅mie du Boisberranger\n.\nAPI Change\nThe default value of the\nsubsample\nparameter of\npreprocessing.KBinsDiscretizer\nwill change from\nNone\nto\n200_000\nin\nversion 1.5 when\nstrategy=\"kmeans\"\nor\nstrategy=\"uniform\"\n.\n#26424\nby\nJ茅r茅mie du Boisberranger\n.\nsklearn.svm\n#\nAPI Change\ndual\nparameter now accepts\nauto\noption for\nsvm.LinearSVC\nand\nsvm.LinearSVR\n.\n#26093\nby\nHleb Levitski\n.\nsklearn.tree\n#\nMajor Feature\ntree.DecisionTreeRegressor\nand\ntree.DecisionTreeClassifier\nsupport missing values when\nsplitter='best'\nand criterion is\ngini\n,\nentropy\n, or\nlog_loss\n,\nfor classification or\nsquared_error\n,\nfriedman_mse\n, or\npoisson\nfor regression.\n#23595\n,\n#26376\nby\nThomas Fan\n.\nEnhancement\nAdds a\nclass_names\nparameter to\ntree.export_text\n. This allows specifying the parameter\nclass_names\nfor each target class in ascending numerical order.\n#25387\nby\nWilliam M\nand\ncrispinlogan\n.\nFix\ntree.export_graphviz\nand\ntree.export_text\nnow accepts\nfeature_names\nand\nclass_names\nas array-like rather than lists.\n#26289\nby\nYao Xiao\nsklearn.utils\n#\nFix\nFixes\nutils.check_array\nto properly convert pandas\nextension arrays.\n#25813\nand\n#26106\nby\nThomas Fan\n.\nFix\nutils.check_array\nnow supports pandas DataFrames with\nextension arrays and object dtypes by returning an ndarray with object dtype.\n#25814\nby\nThomas Fan\n.\nAPI Change\nutils.estimator_checks.check_transformers_unfitted_stateless\nhas been\nintroduced to ensure stateless transformers dont raise\nNotFittedError\nduring\ntransform\nwith no prior call to\nfit\nor\nfit_transform\n.\n#25190\nby\nVincent Maladi猫re\n.\nAPI Change\nA\nFutureWarning\nis now raised when instantiating a class which inherits from\na deprecated base class (i.e. decorated by\nutils.deprecated\n) and which\noverrides the\n__init__\nmethod.\n#25733\nby\nBrigitta Sipcz\nand\nJ茅r茅mie du Boisberranger\n.\nsklearn.semi_supervised\n#\nEnhancement\nsemi_supervised.LabelSpreading.fit\nand\nsemi_supervised.LabelPropagation.fit\nnow accepts sparse metrics.\n#19664\nby\nKaushik Amar Das\n.\nMiscellaneous\n#\nEnhancement\nReplace obsolete exceptions\nEnvironmentError\n,\nIOError\nand\nWindowsError\n.\n#26466\nby\nDimitri Papadopoulos ORfanos\n.\nCode and documentation contributors\nThanks to everyone who has contributed to the maintenance and improvement of\nthe project since version 1.2, including:\n2357juan, Abhishek Singh Kushwah, Adam Handke, Adam Kania, Adam Li, adienes,\nAdmir Demiraj, adoublet, Adrin Jalali, A.H.Mansouri, Ahmedbgh, Ala-Na, Alex\nBuzenet, AlexL, Ali H. El-Kassas, amay, Andr谩s Simon, Andr茅 Pedersen, Andrew\nWang, Ankur Singh, annegnx, Ansam Zedan, Anthony22-dev, Artur Hermano, Arturo\nAmor, as-90, ashah002, Ashish Dutt, Ashwin Mathur, AymericBasset, Azaria\nGebremichael, Barata Tripramudya Onggo, Benedek Harsanyi, Benjamin Bossan,\nBharat Raghunathan, Binesh Bannerjee, Boris Feld, Brendan Lu, Brevin Kunde,\ncache-missing, Camille Troillard, Carla J, carlo, Carlo Lemos, c-git, Changyao\nChen, Chiara Marmo, Christian Lorentzen, Christian Veenhuis, Christine P. Chai,\ncrispinlogan, Da-Lan, DanGonite57, Dave Berenbaum, davidblnc, david-cortes,\nDayne, Dea Mar铆a L茅on, Denis, Dimitri Papadopoulos Orfanos, Dimitris\nLitsidis, Dmitry Nesterov, Dominic Fox, Dominik Prodinger, Edern, Ekaterina\nButyugina, Elabonga Atuo, Emir, farhan khan, Felipe Siola, futurewarning, Gael\nVaroquaux, genvalen, Hleb Levitski, Guillaume Lemaitre, gunesbayir, Haesun\nPark, hujiahong726, i-aki-y, Ian Thompson, Ido M, Ily, Irene, Jack McIvor,\njakirkham, James Dean, JanFidor, Jarrod Millman, JB Mountford, J茅r茅mie du\nBoisberranger, Jessicakk0711, Jiawei Zhang, Joey Ortiz, JohnathanPi, John\nPangas, Joshua Choo Yun Keat, Joshua Hedlund, JuliaSchoepp, Julien Jerphanion,\njygerardy, ka00ri, Kaushik Amar Das, Kento Nozawa, Kian Eliasi, Kilian Kluge,\nLene Preuss, Linus, Logan Thomas, Loic Esteve, Louis Fouquet, Lucy Liu, Madhura\nJayaratne, Marc Torrellas Socastro, Maren Westermann, Mario Kostelac, Mark\nHarfouche, Marko Toplak, Marvin Krawutschke, Masanori Kanazu, mathurinm, Matt\nHaberland, Max Halford, maximeSaur, Maxwell Liu, m. bou, mdarii, Meekail Zain,\nMikhail Iljin, murezzda, Nawazish Alam, Nicola Fanelli, Nightwalkx, Nikolay\nPetrov, Nishu Choudhary, NNLNR, npache, Olivier Grisel, Omar Salman, ouss1508,\nPAB, Pandata, partev, Peter Piontek, Phil, pnucci, Pooja M, Pooja Subramaniam,\nprecondition, Quentin Barth茅lemy, Rafal Wojdyla, Raghuveer Bhat, Rahil Parikh,\nRalf Gommers, ram vikram singh, Rushil Desai, Sadra Barikbin, SANJAI_3, Sashka\nWarner, Scott Gigante, Scott Gustafson, searchforpassion, Seoeun\nHong, Shady el Gewily, Shiva chauhan, Shogo Hida, Shreesha Kumar Bhat, sonnivs,\nSortofamudkip, Stanislav (Stanley) Modrak, Stefanie Senger, Steven Van\nVaerenbergh, Tabea Kossen, Th茅ophile Baranger, Thijs van Weezel, Thomas A\nCaswell, Thomas Germer, Thomas J. Fan, Tim Head, Tim P, Tom Dupr茅 la Tour,\ntomiock, tspeng, Valentin Laurent, Veghit, VIGNESH D, Vijeth Moudgalya, Vinayak\nMehta, Vincent M, Vincent-violet, Vyom Pathak, William M, windiana42, Xiao\nYuan, Yao Xiao, Yaroslav Halchenko, Yotam Avidar-Constantini, Yuchen Zhou,\nYusuf Raji, zeeshan lone\nprevious\nVersion 1.4\nnext\nVersion 1.2\nOn this page\nVersion 1.3.2\nChangelog\nsklearn.datasets\nsklearn.decomposition\nsklearn.metrics\nsklearn.tree\nVersion 1.3.1\nChanged models\nChanges impacting all modules\nChangelog\nsklearn.calibration\nsklearn.cluster\nsklearn.cross_decomposition\nsklearn.ensemble\nsklearn.feature_selection\nsklearn.impute\nsklearn.metrics\nsklearn.mixture\nsklearn.neighbors\nsklearn.preprocessing\nsklearn.tree\nVersion 1.3.0\nChanged models\nChanged displays\nChanges impacting all modules\nExperimental / Under Development\nChangelog\nsklearn\nsklearn.base\nsklearn.calibration\nsklearn.cluster\nsklearn.compose\nsklearn.covariance\nsklearn.datasets\nsklearn.decomposition\nsklearn.discriminant_analysis\nsklearn.ensemble\nsklearn.exceptions\nsklearn.feature_extraction\nsklearn.feature_selection\nsklearn.impute\nsklearn.inspection\nsklearn.kernel_approximation\nsklearn.linear_model\nsklearn.manifold\nsklearn.metrics\nsklearn.gaussian_process\nsklearn.mixture\nsklearn.model_selection\nsklearn.multioutput\nsklearn.naive_bayes\nsklearn.neighbors\nsklearn.neural_network\nsklearn.pipeline\nsklearn.preprocessing\nsklearn.svm\nsklearn.tree\nsklearn.utils\nsklearn.semi_supervised\nMiscellaneous\nThis Page\nShow Source",
    "crawl_status": "success"
  },
  {
    "library_name": "Scikit-learn",
    "url": "https://scikit-learn.org/stable/whats_new/v1.5.html",
    "version": "v1.5.html",
    "title": "Version 1.5  scikit-learn 1.7.2 documentation",
    "release_date": "Unknown release date",
    "content": "Release History\nVersion 1.5\nVersion 1.5\n#\nFor a short description of the main highlights of the release, please refer to\nRelease Highlights for scikit-learn 1.5\n.\nLegend for changelogs\nMajor Feature\nsomething big that you couldnt do before.\nFeature\nsomething that you couldnt do before.\nEfficiency\nan existing feature now may not require as much computation or\nmemory.\nEnhancement\na miscellaneous minor improvement.\nFix\nsomething that previously didnt work as documented  or according\nto reasonable expectations  should now work.\nAPI Change\nyou will need to change your code to have the same effect in the\nfuture; or a feature will be removed in the future.\nVersion 1.5.2\n#\nSeptember 2024\nChanges impacting many modules\n#\nFix\nFixed performance regression in a few Cython modules in\nsklearn._loss\n,\nsklearn.manifold\n,\nsklearn.metrics\nand\nsklearn.utils\n,\nwhich were built without OpenMP support.\n#29694\nby\nLo茂c Est猫vce\n.\nChangelog\n#\nsklearn.calibration\n#\nFix\nRaise error when\nLeaveOneOut\nused in\ncv\n, matching what would happen if\nKFold(n_splits=n_samples)\nwas used.\n#29545\nby\nLucy Liu\nsklearn.compose\n#\nFix\nFixed\ncompose.TransformedTargetRegressor\nnot to raise\nUserWarning\nif\ntransform output is set to\npandas\nor\npolars\n, since it isnt a transformer.\n#29401\nby\nStefanie Senger\n.\nsklearn.decomposition\n#\nFix\nIncrease rank deficiency threshold in the whitening step of\ndecomposition.FastICA\nwith\nwhiten_solver=\"eigh\"\nto improve the\nplatform-agnosticity of the estimator.\n#29612\nby\nOlivier Grisel\n.\nsklearn.metrics\n#\nFix\nFix a regression in\nmetrics.accuracy_score\nand in\nmetrics.zero_one_loss\ncausing an error for Array API dispatch with multilabel\ninputs.\n#29336\nby\nEdoardo Abati\n.\nsklearn.svm\n#\nFix\nFixed a regression in\nsvm.SVC\nand\nsvm.SVR\nsuch that we accept\nC=float(\"inf\")\n.\n#29780\nby\nGuillaume Lemaitre\n.\nVersion 1.5.1\n#\nJuly 2024\nChanges impacting many modules\n#\nFix\nFixed a regression in the validation of the input data of all estimators where\nan unexpected error was raised when passing a DataFrame backed by a read-only buffer.\n#29018\nby\nJ茅r茅mie du Boisberranger\n.\nFix\nFixed a regression causing a dead-lock at import time in some settings.\n#29235\nby\nJ茅r茅mie du Boisberranger\n.\nChangelog\n#\nsklearn.compose\n#\nEfficiency\nFix a performance regression in\ncompose.ColumnTransformer\nwhere the full input data was copied for each transformer when\nn_jobs\n>\n1\n.\n#29330\nby\nJ茅r茅mie du Boisberranger\n.\nsklearn.metrics\n#\nFix\nFix a regression in\nmetrics.r2_score\n. Passing torch CPU tensors\nwith array API dispatched disabled would complain about non-CPU devices\ninstead of implicitly converting those inputs as regular NumPy arrays.\n#29119\nby\n@Olivier Grisel\n.\nFix\nFix a regression in\nmetrics.zero_one_loss\ncausing an error for Array API dispatch with multilabel\ninputs.\n#29269\nby\nYaroslav Korobko\n.\nsklearn.model_selection\n#\nFix\nFix a regression in\nmodel_selection.GridSearchCV\nfor parameter\ngrids that have heterogeneous parameter values.\n#29078\nby\nLo茂c Est猫ve\n.\nFix\nFix a regression in\nmodel_selection.GridSearchCV\nfor parameter\ngrids that have estimators as parameter values.\n#29179\nby\nMarco Gorelli\n.\nFix\nFix a regression in\nmodel_selection.GridSearchCV\nfor parameter\ngrids that have arrays of different sizes as parameter values.\n#29314\nby\nMarco Gorelli\n.\nsklearn.tree\n#\nFix\nFix an issue in\ntree.export_graphviz\nand\ntree.plot_tree\nthat could potentially result in exception or wrong results on 32bit OSes.\n#29327\nby\nLo茂c Est猫ve\n.\nsklearn.utils\n#\nAPI Change\nutils.validation.check_array\nhas a new parameter,\nforce_writeable\n, to\ncontrol the writeability of the output array. If set to\nTrue\n, the output array will\nbe guaranteed to be writeable and a copy will be made if the input array is read-only.\nIf set to\nFalse\n, no guarantee is made about the writeability of the output array.\n#29018\nby\nJ茅r茅mie du Boisberranger\n.\nVersion 1.5.0\n#\nMay 2024\nSecurity\n#\nFix\nfeature_extraction.text.CountVectorizer\nand\nfeature_extraction.text.TfidfVectorizer\nno longer store discarded\ntokens from the training set in their\nstop_words_\nattribute. This attribute\nwould hold too frequent (above\nmax_df\n) but also too rare tokens (below\nmin_df\n). This fixes a potential security issue (data leak) if the discarded\nrare tokens hold sensitive information from the training set without the\nmodel developers knowledge.\nNote: users of those classes are encouraged to either retrain their pipelines\nwith the new scikit-learn version or to manually clear the\nstop_words_\nattribute from previously trained instances of those transformers. This\nattribute was designed only for model inspection purposes and has no impact\non the behavior of the transformers.\n#28823\nby\nOlivier Grisel\n.\nChanged models\n#\nEfficiency\nThe subsampling in\npreprocessing.QuantileTransformer\nis now\nmore efficient for dense arrays but the fitted quantiles and the results of\ntransform\nmay be slightly different than before (keeping the same statistical\nproperties).\n#27344\nby\nXuefeng Xu\n.\nEnhancement\ndecomposition.PCA\n,\ndecomposition.SparsePCA\nand\ndecomposition.TruncatedSVD\nnow set the sign of the\ncomponents_\nattribute based on the component values instead of using the transformed data\nas reference. This change is needed to be able to offer consistent component\nsigns across all\nPCA\nsolvers, including the new\nsvd_solver=\"covariance_eigh\"\noption introduced in this release.\nChanges impacting many modules\n#\nFix\nRaise\nValueError\nwith an informative error message when passing 1D\nsparse arrays to methods that expect 2D sparse inputs.\n#28988\nby\nOlivier Grisel\n.\nAPI Change\nThe name of the input of the\ninverse_transform\nmethod of estimators has been\nstandardized to\nX\n. As a consequence,\nXt\nis deprecated and will be removed in\nversion 1.7 in the following estimators:\ncluster.FeatureAgglomeration\n,\ndecomposition.MiniBatchNMF\n,\ndecomposition.NMF\n,\nmodel_selection.GridSearchCV\n,\nmodel_selection.RandomizedSearchCV\n,\npipeline.Pipeline\nand\npreprocessing.KBinsDiscretizer\n.\n#28756\nby\nWill Dean\n.\nSupport for Array API\n#\nAdditional estimators and functions have been updated to include support for all\nArray API\ncompliant inputs.\nSee\nArray API support (experimental)\nfor more details.\nFunctions:\nsklearn.metrics.r2_score\nnow supports Array API compliant inputs.\n#27904\nby\nEric Lindgren\n,\nFranck Charras\n,\nOlivier Grisel\nand\nTim Head\n.\nClasses:\nlinear_model.Ridge\nnow supports the Array API for the\nsvd\nsolver.\nSee\nArray API support (experimental)\nfor more details.\n#27800\nby\nFranck Charras\n,\nOlivier Grisel\nand\nTim Head\n.\nSupport for building with Meson\n#\nFrom scikit-learn 1.5 onwards, Meson is the main supported way to build\nscikit-learn, see\nBuilding from source\nfor more\ndetails.\nUnless we discover a major blocker, setuptools support will be dropped in\nscikit-learn 1.6. The 1.5.x releases will support building scikit-learn with\nsetuptools.\nMeson support for building scikit-learn was added in\n#28040\nby\nLo茂c Est猫ve\nMetadata Routing\n#\nThe following models now support metadata routing in one or more of their\nmethods. Refer to the\nMetadata Routing User Guide\nfor\nmore details.\nFeature\nimpute.IterativeImputer\nnow supports metadata routing in\nits\nfit\nmethod.\n#28187\nby\nStefanie Senger\n.\nFeature\nensemble.BaggingClassifier\nand\nensemble.BaggingRegressor\nnow support metadata routing. The fit methods now\naccept\n**fit_params\nwhich are passed to the underlying estimators\nvia their\nfit\nmethods.\n#28432\nby\nAdam Li\nand\nBenjamin Bossan\n.\nFeature\nlinear_model.RidgeCV\nand\nlinear_model.RidgeClassifierCV\nnow support metadata routing in\ntheir\nfit\nmethod and route metadata to the underlying\nmodel_selection.GridSearchCV\nobject or the underlying scorer.\n#27560\nby\nOmar Salman\n.\nFeature\nGraphicalLassoCV\nnow supports metadata routing in its\nfit\nmethod and routes metadata to the CV splitter.\n#27566\nby\nOmar Salman\n.\nFeature\nlinear_model.RANSACRegressor\nnow supports metadata routing\nin its\nfit\n,\nscore\nand\npredict\nmethods and route metadata to its\nunderlying estimators\nfit\n,\nscore\nand\npredict\nmethods.\n#28261\nby\nStefanie Senger\n.\nFeature\nensemble.VotingClassifier\nand\nensemble.VotingRegressor\nnow support metadata routing and pass\n**fit_params\nto the underlying estimators via their\nfit\nmethods.\n#27584\nby\nStefanie Senger\n.\nFeature\npipeline.FeatureUnion\nnow supports metadata routing in its\nfit\nand\nfit_transform\nmethods and route metadata to the underlying\ntransformers\nfit\nand\nfit_transform\n.\n#28205\nby\nStefanie Senger\n.\nFix\nFix an issue when resolving default routing requests set via class\nattributes.\n#28435\nby\nAdrin Jalali\n.\nFix\nFix an issue when\nset_{method}_request\nmethods are used as unbound\nmethods, which can happen if one tries to decorate them.\n#28651\nby\nAdrin Jalali\n.\nFix\nPrevent a\nRecursionError\nwhen estimators with the default\nscoring\nparam (\nNone\n) route metadata.\n#28712\nby\nStefanie Senger\n.\nChangelog\n#\nsklearn.calibration\n#\nFix\nFixed a regression in\ncalibration.CalibratedClassifierCV\nwhere\nan error was wrongly raised with string targets.\n#28843\nby\nJ茅r茅mie du Boisberranger\n.\nsklearn.cluster\n#\nFix\nThe\ncluster.MeanShift\nclass now properly converges for constant data.\n#28951\nby\nAkihiro Kuno\n.\nFix\nCreate copy of precomputed sparse matrix within the\nfit\nmethod of\nOPTICS\nto avoid in-place modification of the sparse matrix.\n#28491\nby\nThanh Lam Dang\n.\nFix\ncluster.HDBSCAN\nnow supports all metrics supported by\nsklearn.metrics.pairwise_distances\nwhen\nalgorithm=\"brute\"\nor\n\"auto\"\n.\n#28664\nby\nManideep Yenugula\n.\nsklearn.compose\n#\nFeature\nA fitted\ncompose.ColumnTransformer\nnow implements\n__getitem__\nwhich returns the fitted transformers by name.\n#27990\nby\nThomas Fan\n.\nEnhancement\ncompose.TransformedTargetRegressor\nnow raises an error in\nfit\nif only\ninverse_func\nis provided without\nfunc\n(that would default to identity)\nbeing explicitly set as well.\n#28483\nby\nStefanie Senger\n.\nEnhancement\ncompose.ColumnTransformer\ncan now expose the remainder\ncolumns in the fitted\ntransformers_\nattribute as column names or boolean\nmasks, rather than column indices.\n#27657\nby\nJ茅r么me Dock猫s\n.\nFix\nFixed a bug in\ncompose.ColumnTransformer\nwith\nn_jobs\n>\n1\n, where the\nintermediate selected columns were passed to the transformers as read-only arrays.\n#28822\nby\nJ茅r茅mie du Boisberranger\n.\nsklearn.cross_decomposition\n#\nFix\nThe\ncoef_\nfitted attribute of\ncross_decomposition.PLSRegression\nnow takes into account both the scale of\nX\nand\nY\nwhen\nscale=True\n. Note that\nthe previous predicted values were not affected by this bug.\n#28612\nby\nGuillaume Lemaitre\n.\nAPI Change\nDeprecates\nY\nin favor of\ny\nin the methods\nfit\n,\ntransform\nand\ninverse_transform\nof:\ncross_decomposition.PLSRegression\n,\ncross_decomposition.PLSCanonical\n,\nand\ncross_decomposition.CCA\n,\nand methods\nfit\nand\ntransform\nof:\ncross_decomposition.PLSSVD\n.\nY\nwill be removed in version 1.7.\n#28604\nby\nDavid Leon\n.\nsklearn.datasets\n#\nEnhancement\nAdds optional arguments\nn_retries\nand\ndelay\nto functions\ndatasets.fetch_20newsgroups\n,\ndatasets.fetch_20newsgroups_vectorized\n,\ndatasets.fetch_california_housing\n,\ndatasets.fetch_covtype\n,\ndatasets.fetch_kddcup99\n,\ndatasets.fetch_lfw_pairs\n,\ndatasets.fetch_lfw_people\n,\ndatasets.fetch_olivetti_faces\n,\ndatasets.fetch_rcv1\n,\nand\ndatasets.fetch_species_distributions\n.\nBy default, the functions will retry up to 3 times in case of network failures.\n#28160\nby\nZhehao Liu\nand\nFilip Karlo Do拧ilovi\n.\nsklearn.decomposition\n#\nEfficiency\ndecomposition.PCA\nwith\nsvd_solver=\"full\"\nnow assigns\na contiguous\ncomponents_\nattribute instead of a non-contiguous slice of\nthe singular vectors. When\nn_components\n<<\nn_features\n, this can save some\nmemory and, more importantly, help speed-up subsequent calls to the\ntransform\nmethod by more than an order of magnitude by leveraging cache locality of\nBLAS GEMM on contiguous arrays.\n#27491\nby\nOlivier Grisel\n.\nEnhancement\nPCA\nnow automatically selects the ARPACK solver\nfor sparse inputs when\nsvd_solver=\"auto\"\ninstead of raising an error.\n#28498\nby\nThanh Lam Dang\n.\nEnhancement\ndecomposition.PCA\nnow supports a new solver option\nnamed\nsvd_solver=\"covariance_eigh\"\nwhich offers an order of magnitude\nspeed-up and reduced memory usage for datasets with a large number of data\npoints and a small number of features (say,\nn_samples\n>>\n1000\n>\nn_features\n). The\nsvd_solver=\"auto\"\noption has been updated to use the new\nsolver automatically for such datasets. This solver also accepts sparse input\ndata.\n#27491\nby\nOlivier Grisel\n.\nFix\ndecomposition.PCA\nfit with\nsvd_solver=\"arpack\"\n,\nwhiten=True\nand a value for\nn_components\nthat is larger than the rank of\nthe training set, no longer returns infinite values when transforming\nhold-out data.\n#27491\nby\nOlivier Grisel\n.\nsklearn.dummy\n#\nEnhancement\ndummy.DummyClassifier\nand\ndummy.DummyRegressor\nnow\nhave the\nn_features_in_\nand\nfeature_names_in_\nattributes after\nfit\n.\n#27937\nby\nMarco vd Boom\n.\nsklearn.ensemble\n#\nEfficiency\nImproves runtime of\npredict\nof\nensemble.HistGradientBoostingClassifier\nby avoiding to call\npredict_proba\n.\n#27844\nby\nChristian Lorentzen\n.\nEfficiency\nensemble.HistGradientBoostingClassifier\nand\nensemble.HistGradientBoostingRegressor\nare now a tiny bit faster by\npre-sorting the data before finding the thresholds for binning.\n#28102\nby\nChristian Lorentzen\n.\nFix\nFixes a bug in\nensemble.HistGradientBoostingClassifier\nand\nensemble.HistGradientBoostingRegressor\nwhen\nmonotonic_cst\nis specified\nfor non-categorical features.\n#28925\nby\nXiao Yuan\n.\nsklearn.feature_extraction\n#\nEfficiency\nfeature_extraction.text.TfidfTransformer\nis now faster\nand more memory-efficient by using a NumPy vector instead of a sparse matrix\nfor storing the inverse document frequency.\n#18843\nby\nPaolo Montesel\n.\nEnhancement\nfeature_extraction.text.TfidfTransformer\nnow preserves\nthe data type of the input matrix if it is\nnp.float64\nor\nnp.float32\n.\n#28136\nby\nGuillaume Lemaitre\n.\nsklearn.feature_selection\n#\nEnhancement\nfeature_selection.mutual_info_regression\nand\nfeature_selection.mutual_info_classif\nnow support\nn_jobs\nparameter.\n#28085\nby\nNeto Menoci\nand\nFlorin Andrei\n.\nEnhancement\nThe\ncv_results_\nattribute of\nfeature_selection.RFECV\nhas\na new key,\nn_features\n, containing an array with the number of features selected\nat each step.\n#28670\nby\nMiguel Silva\n.\nsklearn.impute\n#\nEnhancement\nimpute.SimpleImputer\nnow supports custom strategies\nby passing a function in place of a strategy name.\n#28053\nby\nMark Elliot\n.\nsklearn.inspection\n#\nFix\ninspection.DecisionBoundaryDisplay.from_estimator\nno longer\nwarns about missing feature names when provided a\npolars.DataFrame\n.\n#28718\nby\nPatrick Wang\n.\nsklearn.linear_model\n#\nEnhancement\nSolver\n\"newton-cg\"\nin\nlinear_model.LogisticRegression\nand\nlinear_model.LogisticRegressionCV\nnow emits information when\nverbose\nis\nset to positive values.\n#27526\nby\nChristian Lorentzen\n.\nFix\nlinear_model.ElasticNet\n,\nlinear_model.ElasticNetCV\n,\nlinear_model.Lasso\nand\nlinear_model.LassoCV\nnow explicitly dont\naccept large sparse data formats.\n#27576\nby\nStefanie Senger\n.\nFix\nlinear_model.RidgeCV\nand\nRidgeClassifierCV\ncorrectly pass\nsample_weight\nto the underlying scorer when\ncv\nis None.\n#27560\nby\nOmar Salman\n.\nFix\nn_nonzero_coefs_\nattribute in\nlinear_model.OrthogonalMatchingPursuit\nwill now always be\nNone\nwhen\ntol\nis set, as\nn_nonzero_coefs\nis ignored in\nthis case.\n#28557\nby\nLucy Liu\n.\nAPI Change\nlinear_model.RidgeCV\nand\nlinear_model.RidgeClassifierCV\nwill now allow\nalpha=0\nwhen\ncv\n!=\nNone\n, which is consistent with\nlinear_model.Ridge\nand\nlinear_model.RidgeClassifier\n.\n#28425\nby\nLucy Liu\n.\nAPI Change\nPassing\naverage=0\nto disable averaging is deprecated in\nlinear_model.PassiveAggressiveClassifier\n,\nlinear_model.PassiveAggressiveRegressor\n,\nlinear_model.SGDClassifier\n,\nlinear_model.SGDRegressor\nand\nlinear_model.SGDOneClassSVM\n. Pass\naverage=False\ninstead.\n#28582\nby\nJ茅r茅mie du Boisberranger\n.\nAPI Change\nParameter\nmulti_class\nwas deprecated in\nlinear_model.LogisticRegression\nand\nlinear_model.LogisticRegressionCV\n.\nmulti_class\nwill be removed in 1.8,\nand internally, for 3 and more classes, it will always use multinomial.\nIf you still want to use the one-vs-rest scheme, you can use\nOneVsRestClassifier(LogisticRegression(..))\n.\n#28703\nby\nChristian Lorentzen\n.\nAPI Change\nParameters\nstore_cv_values\nand\ncv_values_\nare deprecated in favor of\nstore_cv_results\nand\ncv_results_\nin\n~linear_model.RidgeCV\nand\n~linear_model.RidgeClassifierCV\n.\n#28915\nby\nLucy Liu\n.\nsklearn.manifold\n#\nAPI Change\nDeprecates\nn_iter\nin favor of\nmax_iter\nin\nmanifold.TSNE\n.\nn_iter\nwill be removed in version 1.7. This makes\nmanifold.TSNE\nconsistent with the rest of the estimators.\n#28471\nby\nLucy Liu\nsklearn.metrics\n#\nFeature\nmetrics.pairwise_distances\naccepts calculating pairwise distances\nfor non-numeric arrays as well. This is supported through custom metrics only.\n#27456\nby\nVenkatachalam N\n,\nKshitij Mathur\nand\nJulian Libiseller-Egger\n.\nFeature\nsklearn.metrics.check_scoring\nnow returns a multi-metric scorer\nwhen\nscoring\nas a\ndict\n,\nset\n,\ntuple\n, or\nlist\n.\n#28360\nby\nThomas Fan\n.\nFeature\nmetrics.d2_log_loss_score\nhas been added which\ncalculates the D^2 score for the log loss.\n#28351\nby\nOmar Salman\n.\nEfficiency\nImprove efficiency of functions\nbrier_score_loss\n,\ncalibration_curve\n,\ndet_curve\n,\nprecision_recall_curve\n,\nroc_curve\nwhen\npos_label\nargument is specified.\nAlso improve efficiency of methods\nfrom_estimator\nand\nfrom_predictions\nin\nRocCurveDisplay\n,\nPrecisionRecallDisplay\n,\nDetCurveDisplay\n,\nCalibrationDisplay\n.\n#28051\nby\nPierre de Fr茅minville\n.\nFix\nmetrics.classification_report\nnow shows only accuracy and not\nmicro-average when input is a subset of labels.\n#28399\nby\nVineet Joshi\n.\nFix\nFix OpenBLAS 0.3.26 dead-lock on Windows in pairwise distances\ncomputation. This is likely to affect neighbor-based algorithms.\n#28692\nby\nLo茂c Est猫ve\n.\nAPI Change\nmetrics.precision_recall_curve\ndeprecated the keyword argument\nprobas_pred\nin favor of\ny_score\n.\nprobas_pred\nwill be removed in version 1.7.\n#28092\nby\nAdam Li\n.\nAPI Change\nmetrics.brier_score_loss\ndeprecated the keyword argument\ny_prob\nin favor of\ny_proba\n.\ny_prob\nwill be removed in version 1.7.\n#28092\nby\nAdam Li\n.\nAPI Change\nFor classifiers and classification metrics, labels encoded as bytes\nis deprecated and will raise an error in v1.7.\n#18555\nby\nKaushik Amar Das\n.\nsklearn.mixture\n#\nFix\nThe\nconverged_\nattribute of\nmixture.GaussianMixture\nand\nmixture.BayesianGaussianMixture\nnow reflects the convergence status of\nthe best fit whereas it was previously\nTrue\nif any of the fits converged.\n#26837\nby\nKrsto Prorokovi\n.\nsklearn.model_selection\n#\nMajor Feature\nmodel_selection.TunedThresholdClassifierCV\nfinds\nthe decision threshold of a binary classifier that maximizes a\nclassification metric through cross-validation.\nmodel_selection.FixedThresholdClassifier\nis an alternative when one wants\nto use a fixed decision threshold without any tuning scheme.\n#26120\nby\nGuillaume Lemaitre\n.\nEnhancement\nCV splitters\nthat ignores the group parameter now\nraises a warning when groups are passed in to\nsplit\n.\n#28210\nby\nThomas Fan\n.\nEnhancement\nThe HTML diagram representation of\nGridSearchCV\n,\nRandomizedSearchCV\n,\nHalvingGridSearchCV\n, and\nHalvingRandomSearchCV\nwill show the best estimator when\nrefit=True\n.\n#28722\nby\nYao Xiao\nand\nThomas Fan\n.\nFix\nthe\ncv_results_\nattribute (of\nmodel_selection.GridSearchCV\n) now\nreturns masked arrays of the appropriate NumPy dtype, as opposed to always returning\ndtype\nobject\n.\n#28352\nby\nMarco Gorelli\n.\nFix\nmodel_selection.train_test_split\nworks with Array API inputs.\nPreviously indexing was not handled correctly leading to exceptions when using strict\nimplementations of the Array API like CuPY.\n#28407\nby\nTim Head\n.\nsklearn.multioutput\n#\nEnhancement\nchain_method\nparameter added to\nmultioutput.ClassifierChain\n.\n#27700\nby\nLucy Liu\n.\nsklearn.neighbors\n#\nFix\nFixes\nneighbors.NeighborhoodComponentsAnalysis\nsuch that\nget_feature_names_out\nreturns the correct number of feature names.\n#28306\nby\nBrendan Lu\n.\nsklearn.pipeline\n#\nFeature\npipeline.FeatureUnion\ncan now use the\nverbose_feature_names_out\nattribute. If\nTrue\n,\nget_feature_names_out\nwill prefix all feature names with the name of the transformer\nthat generated that feature. If\nFalse\n,\nget_feature_names_out\nwill not\nprefix any feature names and will error if feature names are not unique.\n#25991\nby\nJiawei Zhang\n.\nsklearn.preprocessing\n#\nEnhancement\npreprocessing.QuantileTransformer\nand\npreprocessing.quantile_transform\nnow supports disabling\nsubsampling explicitly.\n#27636\nby\nRalph Urlus\n.\nsklearn.tree\n#\nEnhancement\nPlotting trees in matplotlib via\ntree.plot_tree\nnow\nshow a True/False label to indicate the directionality the samples traverse\ngiven the split condition.\n#28552\nby\nAdam Li\n.\nsklearn.utils\n#\nFix\n_safe_indexing\nnow works correctly for polars DataFrame when\naxis=0\nand supports indexing polars Series.\n#28521\nby\nYao Xiao\n.\nAPI Change\nutils.IS_PYPY\nis deprecated and will be removed in version 1.7.\n#28768\nby\nJ茅r茅mie du Boisberranger\n.\nAPI Change\nutils.tosequence\nis deprecated and will be removed in version 1.7.\n#28763\nby\nJ茅r茅mie du Boisberranger\n.\nAPI Change\nutils.parallel_backend\nand\nutils.register_parallel_backend\nare\ndeprecated and will be removed in version 1.7. Use\njoblib.parallel_backend\nand\njoblib.register_parallel_backend\ninstead.\n#28847\nby\nJ茅r茅mie du Boisberranger\n.\nAPI Change\nRaise informative warning message in\ntype_of_target\nwhen represented as bytes. For classifiers and classification metrics, labels encoded\nas bytes is deprecated and will raise an error in v1.7.\n#18555\nby\nKaushik Amar Das\n.\nAPI Change\nutils.estimator_checks.check_estimator_sparse_data\nwas split into two\nfunctions:\nutils.estimator_checks.check_estimator_sparse_matrix\nand\nutils.estimator_checks.check_estimator_sparse_array\n.\n#27576\nby\nStefanie Senger\n.\nCode and documentation contributors\nThanks to everyone who has contributed to the maintenance and improvement of\nthe project since version 1.4, including:\n101AlexMartin, Abdulaziz Aloqeely, Adam J. Stewart, Adam Li, Adarsh Wase,\nAdeyemi Biola, Aditi Juneja, Adrin Jalali, Advik Sinha, Aisha, Akash\nSrivastava, Akihiro Kuno, Alan Guedes, Alberto Torres, Alexis IMBERT, alexqiao,\nAna Paula Gomes, Anderson Nelson, Andrei Dzis, Arif Qodari, Arnaud Capitaine,\nArturo Amor, Aswathavicky, Audrey Flanders, awwwyan, baggiponte, Bharat\nRaghunathan, bme-git, brdav, Brendan Lu, Brigitta Sipcz, Bruno, Cailean\nCarter, Cemlyn, Christian Lorentzen, Christian Veenhuis, Cindy Liang, Claudio\nSalvatore Arcidiacono, Connor Boyle, Conrad Stevens, crispinlogan, David\nMatthew Cherney, Davide Chicco, davidleon123, dependabot[bot], DerWeh, dinga92,\nDipan Banik, Drew Craeton, Duarte S茫o Jos茅, DUONG, Eddie Bergman, Edoardo\nAbati, Egehan Gunduz, Emad Izadifar, EmilyXinyi, Erich Schubert, Evelyn, Filip\nKarlo Do拧ilovi, Franck Charras, Gael Varoquaux, G枚n眉l Ayc谋, Guillaume\nLemaitre, Gyeongjae Choi, Harmanan Kohli, Hong Xiang Yue, Ian Faust, Ilya\nKomarov, itsaphel, Ivan Wiryadi, Jack Bowyer, Javier Marin Tur, J茅r茅mie du\nBoisberranger, J茅r么me Dock猫s, Jiawei Zhang, Jo茫o Morais, Joe Cainey, Joel\nNothman, Johanna Bayer, John Cant, John Enblom, John Hopfensperger, jpcars,\njpienaar-tuks, Julian Chan, Julian Libiseller-Egger, Julien Jerphanion,\nKanchiMoe, Kaushik Amar Das, keyber, Koustav Ghosh, kraktus, Krsto Prorokovi,\nLars, ldwy4, LeoGrin, lihaitao, Linus Sommer, Loic Esteve, Lucy Liu, Lukas\nGeiger, m-maggi, manasimj, Manuel Labb茅, Manuel Morales, Marco Edward Gorelli,\nMarco Wolsza, Maren Westermann, Marija Vlajic, Mark Elliot, Martin Helm,\nMateusz Sok贸, mathurinm, Mavs, Michael Dawson, Michael Higgins, Michael Mayer,\nmiguelcsilva, Miki Watanabe, Mohammed Hamdy, myenugula, Nathan Goldbaum, Naziya\nMahimkar, nbrown-ScottLogic, Neto, Nithish Bolleddula, notPlancha, Olivier\nGrisel, Omar Salman, ParsifalXu, Patrick Wang, Pierre de Fr茅minville, Piotr,\nPriyank Shroff, Priyansh Gupta, Priyash Shah, Puneeth K, Rahil Parikh, raisadz,\nRaj Pulapakura, Ralf Gommers, Ralph Urlus, Randolf Scholz, renaissance0ne,\nReshama Shaikh, Richard Barnes, Robert Pollak, Roberto Rosati, Rodrigo Romero,\nrwelsch427, Saad Mahmood, Salim Dohri, Sandip Dutta, SarahRemus,\nscikit-learn-bot, Shaharyar Choudhry, Shubham, sperret6, Stefanie Senger,\nSteffen Schneider, Suha Siddiqui, Thanh Lam DANG, thebabush, Thomas, Thomas J.\nFan, Thomas Lazarus, Tialo, Tim Head, Tuhin Sharma, Tushar Parimi,\nVarunChaduvula, Vineet Joshi, virchan, Wa毛l Boukhobza, Weyb, Will Dean, Xavier\nBeltran, Xiao Yuan, Xuefeng Xu, Yao Xiao, yareyaredesuyo, Ziad Amerr, tp谩n\nSr拧e\nprevious\nVersion 1.6\nnext\nVersion 1.4\nOn this page\nVersion 1.5.2\nChanges impacting many modules\nChangelog\nsklearn.calibration\nsklearn.compose\nsklearn.decomposition\nsklearn.metrics\nsklearn.svm\nVersion 1.5.1\nChanges impacting many modules\nChangelog\nsklearn.compose\nsklearn.metrics\nsklearn.model_selection\nsklearn.tree\nsklearn.utils\nVersion 1.5.0\nSecurity\nChanged models\nChanges impacting many modules\nSupport for Array API\nSupport for building with Meson\nMetadata Routing\nChangelog\nsklearn.calibration\nsklearn.cluster\nsklearn.compose\nsklearn.cross_decomposition\nsklearn.datasets\nsklearn.decomposition\nsklearn.dummy\nsklearn.ensemble\nsklearn.feature_extraction\nsklearn.feature_selection\nsklearn.impute\nsklearn.inspection\nsklearn.linear_model\nsklearn.manifold\nsklearn.metrics\nsklearn.mixture\nsklearn.model_selection\nsklearn.multioutput\nsklearn.neighbors\nsklearn.pipeline\nsklearn.preprocessing\nsklearn.tree\nsklearn.utils\nThis Page\nShow Source",
    "crawl_status": "success"
  },
  {
    "library_name": "Flask",
    "url": "https://flask.palletsprojects.com/en/3.0.x/changes/#version-3-1-2",
    "version": "v3.1.2",
    "title": "Changes  Flask Documentation (3.1.x)",
    "release_date": "Unknown release date",
    "content": "Version 3.1.2\n露\nReleased 2025-08-19\nstream_with_context\ndoes not fail inside async views.\n#5774\nWhen using\nfollow_redirects\nin the test client, the final state\nof\nsession\nis correct.\n#5786\nRelax type hint for passing bytes IO to\nsend_file\n.\n#5776",
    "crawl_status": "success"
  },
  {
    "library_name": "Flask",
    "url": "https://flask.palletsprojects.com/en/3.0.x/changes/#version-3-0-0",
    "version": "v3.0.0",
    "title": "Changes  Flask Documentation (3.1.x)",
    "release_date": "Unknown release date",
    "content": "Version 3.0.0\n露\nReleased 2023-09-30\nRemove previously deprecated code.\n#5223\nDeprecate the\n__version__\nattribute. Use feature detection, or\nimportlib.metadata.version(\"flask\")\n, instead.\n#5230\nRestructure the code such that the Flask (app) and Blueprint\nclasses have Sans-IO bases.\n#5127\nAllow self as an argument to url_for.\n#5264\nRequire Werkzeug >= 3.0.0.",
    "crawl_status": "success"
  },
  {
    "library_name": "Flask",
    "url": "https://flask.palletsprojects.com/en/3.0.x/changes/#version-3-1-0",
    "version": "v3.1.0",
    "title": "Changes  Flask Documentation (3.1.x)",
    "release_date": "Unknown release date",
    "content": "Version 3.1.0\n露\nReleased 2024-11-13\nDrop support for Python 3.8.\n#5623\nUpdate minimum dependency versions to latest feature releases.\nWerkzeug >= 3.1, ItsDangerous >= 2.2, Blinker >= 1.9.\n#5624,5633\nProvide a configuration option to control automatic option\nresponses.\n#5496\nFlask.open_resource\n/\nopen_instance_resource\nand\nBlueprint.open_resource\ntake an\nencoding\nparameter to use when\nopening in text mode. It defaults to\nutf-8\n.\n#5504\nRequest.max_content_length\ncan be customized per-request instead of only\nthrough the\nMAX_CONTENT_LENGTH\nconfig. Added\nMAX_FORM_MEMORY_SIZE\nand\nMAX_FORM_PARTS\nconfig. Added documentation\nabout resource limits to the security page.\n#5625\nAdd support for the\nPartitioned\ncookie attribute (CHIPS), with the\nSESSION_COOKIE_PARTITIONED\nconfig.\n#5472\n-e\npath\ntakes precedence over default\n.env\nand\n.flaskenv\nfiles.\nload_dotenv\nloads default files in addition to a path unless\nload_defaults=False\nis passed.\n#5628\nSupport key rotation with the\nSECRET_KEY_FALLBACKS\nconfig, a list of old\nsecret keys that can still be used for unsigning. Extensions will need to\nadd support.\n#5621\nFix how setting\nhost_matching=True\nor\nsubdomain_matching=False\ninteracts with\nSERVER_NAME\n. Setting\nSERVER_NAME\nno longer restricts\nrequests to only that domain.\n#5553\nRequest.trusted_hosts\nis checked during routing, and can be set through\nthe\nTRUSTED_HOSTS\nconfig.\n#5636",
    "crawl_status": "success"
  },
  {
    "library_name": "Matplotlib",
    "url": "https://github.com/matplotlib/matplotlib/releases/tag/v3.9.0",
    "version": "v3.9.0",
    "title": "Release REL: 3.9.0 路 matplotlib/matplotlib 路 GitHub",
    "release_date": "2024-05-15T23:51:33Z",
    "content": "Highlights of this release include:\nPlotting and Annotation improvements\nAxes.inset_axes is no longer experimental\nLegend support for Boxplot\nPercent sign in pie labels auto-escaped with usetex=True\nhatch parameter for stackplot\nAdd option to plot only one half of violin plot\naxhline and axhspan on polar axes\nSubplot titles can now be automatically aligned\naxisartist can now be used together with standard Formatters\nToggle minorticks on Axis\nStrMethodFormatter now respects axes.unicode_minus\nFigure, Axes, and Legend Layout\nSubfigures now have controllable zorders\nGetters for xmargin, ymargin and zmargin\nMathtext improvements\nmathtext documentation improvements\nmathtext spacing corrections\nWidget Improvements\nCheck and Radio Button widgets support clearing\n3D plotting improvements\nSetting 3D axis limits now set the limits exactly\nOther improvements\nNew BackendRegistry for plotting backends\nAdd widths, heights and angles setter to EllipseCollection\nimage.interpolation_stage rcParam\nArrow patch position is now modifiable\nNonUniformImage now has mouseover support",
    "crawl_status": "success"
  },
  {
    "library_name": "Matplotlib",
    "url": "https://github.com/matplotlib/matplotlib/releases/tag/v3.7.0",
    "version": "v3.7.0",
    "title": "Release REL: v3.7.0 路 matplotlib/matplotlib 路 GitHub",
    "release_date": "2023-02-13T22:22:08Z",
    "content": "Highlights of this release include:\nPlotting and Annotation improvements\nhatch\nparameter for pie\nPolar plot errors drawn in polar coordinates\nAdditional format string options in\n~matplotlib.axes.Axes.bar_label\nellipse\nboxstyle option for annotations\nThe\nextent\nof\nimshow\ncan now be expressed with units\nReversed order of legend entries\npcolormesh\naccepts RGB(A) colors\nView current appearance settings for ticks, tick labels, and gridlines\nStyle files can be imported from third-party packages\nImprovements to 3D Plotting\n3D plot pan and zoom buttons\nadjustable\nkeyword argument for setting equal aspect ratios in 3D\nPoly3DCollection\nsupports shading\nrcParam for 3D pane color\nFigure and Axes Layout\ncolorbar\nnow has a\nlocation\nkeyword argument\nFigure legends can be placed outside figures using constrained_layout\nPer-subplot keyword arguments  in\nsubplot_mosaic\nsubplot_mosaic\nno longer provisional\nWidget Improvements\nCustom styling of button widgets\nBlitting in Button widgets\nOther Improvements\nSource links can be shown or hidden for each Sphinx plot directive\nFigure hooks\nNew & Improved Narrative Documentation\nBrand new :doc:\nAnimations </tutorials/introductory/animation_tutorial>\ntutorial.\nNew grouped and stacked\nbar chart <../../gallery/index.html#lines_bars_and_markers>\n_ examples.\nNew section for new contributors and reorganized git instructions in the :ref:\ncontributing guide<contributing>\n.\nRestructured :doc:\n/tutorials/text/annotations\ntutorial.",
    "crawl_status": "success"
  },
  {
    "library_name": "Matplotlib",
    "url": "https://github.com/matplotlib/matplotlib/releases/tag/v3.10.1",
    "version": "v3.10.1",
    "title": "Release REL: v3.10.1 路 matplotlib/matplotlib 路 GitHub",
    "release_date": "2025-02-27T18:57:43Z",
    "content": "This is the first bugfix release of the 3.10.x series.\nThis release contains several bug-fixes and adjustments:\nRespect array alpha with interpolation_stage='rgba' in _Imagebase::_make_image\nRemove md5 usage to prevent issues on FIPS enabled systems\nFix pyplot.matshow figure handling\nFix modifying Axes' position also alters the original Bbox object used for initialization\nFix title position for polar plots\nAdd version gate to GTK4 calls when necessary\nRaise warning if both c and facecolors are used in scatter plot\nAs well as several documentation improvements and corrections.",
    "crawl_status": "success"
  },
  {
    "library_name": "SQLAlchemy",
    "url": "https://github.com/sqlalchemy/sqlalchemy/releases/tag/rel_2_0_0",
    "version": "rel_2_0_0",
    "title": "Release 2.0.0 路 sqlalchemy/sqlalchemy 路 GitHub",
    "release_date": "2023-01-26T22:58:12Z",
    "content": "2.0.0\nReleased: January 26, 2023\norm\n[orm] [bug]\nImproved the notification of warnings that are emitted within the configure\nmappers or flush process, which are often invoked as part of a different\noperation, to add additional context to the message that indicates one of\nthese operations as the source of the warning within operations that may\nnot be obviously related.\nReferences:\n#7305\norm extensions\n[feature] [orm extensions]\nAdded new option to horizontal sharding API\n_horizontal.set_shard_id\nwhich sets the effective shard identifier\nto query against, for both the primary query as well as for all secondary\nloaders including relationship eager loaders as well as relationship and\ncolumn lazy loaders.\nReferences:\n#7226\n[usecase] [orm extensions]\nAdded new feature to\nAutomapBase\nfor autoload of classes across\nmultiple schemas which may have overlapping names, by providing a\nAutomapBase.prepare.modulename_for_table\nparameter which\nallows customization of the\n__module__\nattribute of newly generated\nclasses, as well as a new collection\nAutomapBase.by_module\n, which\nstores a dot-separated namespace of module names linked to classes based on\nthe\n__module__\nattribute.\nAdditionally, the\nAutomapBase.prepare()\nmethod may now be invoked\nany number of times, with or without reflection enabled; only newly\nadded tables that were not previously mapped will be processed on each\ncall.   Previously, the\nMetaData.reflect()\nmethod would need to be\ncalled explicitly each time.\nReferences:\n#5145\nsql\n[sql] [bug]\nFixed stringify for a the\nCreateSchema\nDDL construct, which would\nfail with an\nAttributeError\nwhen stringified without a dialect.\nThis change is also\nbackported\nto: 1.4.47\nReferences:\n#7664\ntyping\n[typing] [bug]\nAdded typing for the built-in generic functions that are available from the\n:data:\n_sql.func\nnamespace, which accept a particular set of arguments and\nreturn a particular type, such as for\n_sql.count\n,\n_sql.current_timestamp\n, etc.\nUnknown interpreted text role \"data\".\nReferences:\n#9129\n[typing] [bug]\nCorrected the type passed for \"lambda statements\" so that a plain lambda is\naccepted by mypy, pyright, others without any errors about argument types.\nAdditionally implemented typing for more of the public API for lambda\nstatements and ensured\nStatementLambdaElement\nis part of the\nExecutable\nhierarchy so it's typed as accepted by\n_engine.Connection.execute()\n.\nReferences:\n#9120\n[typing] [bug]\nThe\n_sql.ColumnOperators.in_()\nand\n_sql.ColumnOperators.not_in()\nmethods are typed to include\nIterable[Any]\nrather than\nSequence[Any]\nfor more flexibility in\nargument type.\nReferences:\n#9122\n[typing] [bug]\nThe\n_sql.or_()\nand\n_sql.and_()\nfrom a typing perspective\nrequire the first argument to be present, however these functions still\naccept zero arguments which will emit a deprecation warning at runtime.\nTyping is also added to support sending the fixed literal\nFalse\nfor\n_sql.or_()\nand\nTrue\nfor\n_sql.and_()\nas the first argument\nonly, however the documentation now indicates sending the\n_sql.false()\nand\n_sql.true()\nconstructs in these cases as a\nmore explicit approach.\nReferences:\n#9123\n[typing] [bug]\nFixed typing issue where iterating over a\n_orm.Query\nobject\nwas not correctly typed.\nReferences:\n#9125\n[typing] [bug]\nFixed typing issue where the object type when using\n_engine.Result\nas a context manager were not preserved, indicating\n_engine.Result\nin all cases rather than the specific\n_engine.Result\nsub-type.\nPull request courtesy Martin Bal谩啪.\nReferences:\n#9136\n[typing] [bug]\nFixed issue where using the\n_orm.relationship.remote_side\nand similar parameters, passing an annotated declarative object typed as\n_orm.Mapped\n, would not be accepted by the type checker.\nReferences:\n#9150\n[typing] [bug]\nAdded typing to legacy operators such as\nisnot()\n,\nnotin_()\n, etc.\nwhich previously were referencing the newer operators but were not\nthemselves typed.\nReferences:\n#9148\nmssql\n[mssql] [bug]\nFixed bug where a schema name given with brackets, but no dots inside the\nname, for parameters such as\n_schema.Table.schema\nwould not be\ninterpreted within the context of the SQL Server dialect's documented\nbehavior of interpreting explicit brackets as token delimiters, first added\nin 1.2 for\n#2626\n, when referring to the schema name in reflection\noperations. The original assumption for\n#2626\n's behavior was that the\nspecial interpretation of brackets was only significant if dots were\npresent, however in practice, the brackets are not included as part of the\nidentifier name for all SQL rendering operations since these are not valid\ncharacters within regular or delimited identifiers.  Pull request courtesy\nShan.\nThis change is also\nbackported\nto: 1.4.47\nReferences:\n#9133\n[mssql] [bug]\nFixed bug where a schema name given with brackets, but no dots inside the\nname, for parameters such as\n_schema.Table.schema\nwould not be\ninterpreted within the context of the SQL Server dialect's documented\nbehavior of interpreting explicit brackets as token delimiters, first added\nin 1.2 for\n#2626\n, when referring to the schema name in reflection\noperations. The original assumption for\n#2626\n's behavior was that the\nspecial interpretation of brackets was only significant if dots were\npresent, however in practice, the brackets are not included as part of the\nidentifier name for all SQL rendering operations since these are not valid\ncharacters within regular or delimited identifiers.  Pull request courtesy\nShan.\nThis change is also\nbackported\nto: 1.4.47\nReferences:\n#9133\n[mssql] [bug] [regression]\nThe newly added comment reflection and rendering capability of the MSSQL\ndialect, added in\n#7844\n, will now be disabled by default if it\ncannot be determined that an unsupported backend such as Azure Synapse may\nbe in use; this backend does not support table and column comments and does\nnot support the SQL Server routines in use to generate them as well as to\nreflect them. A new parameter\nsupports_comments\nis added to the dialect\nwhich defaults to\nNone\n, indicating that comment support should be\nauto-detected. When set to\nTrue\nor\nFalse\n, the comment support is\neither enabled or disabled unconditionally.\nReferences:\n#9142\noracle\n[oracle] [bug]\nAdded\n_oracle.ROWID\nto reflected types as this type may be used in\na \"CREATE TABLE\" statement.\nThis change is also\nbackported\nto: 1.4.47\nReferences:\n#5047",
    "crawl_status": "success"
  },
  {
    "library_name": "SQLAlchemy",
    "url": "https://github.com/sqlalchemy/sqlalchemy/releases/tag/rel_2_0_37",
    "version": "rel_2_0_37",
    "title": "Release 2.0.37 路 sqlalchemy/sqlalchemy 路 GitHub",
    "release_date": "2025-01-09T22:43:36Z",
    "content": "2.0.37\nReleased: January 9, 2025\norm\n[orm] [bug]\nFixed issue regarding\nUnion\ntypes that would be present in the\n_orm.registry.type_annotation_map\nof a\n_orm.registry\nor declarative base class, where a\nMapped\nelement that included\none of the subtypes present in that\nUnion\nwould be matched to that\nentry, potentially ignoring other entries that matched exactly.   The\ncorrect behavior now takes place such that an entry should only match in\n_orm.registry.type_annotation_map\nexactly, as a\nUnion\ntype\nis a self-contained type. For example, an attribute with\nMapped[float]\nwould previously match to a\n_orm.registry.type_annotation_map\nentry\nUnion[float, Decimal]\n; this will no longer match and will now\nonly match to an entry that states\nfloat\n. Pull request courtesy Frazer\nMcLean.\nReferences:\n#11370\n[orm] [bug]\nFixed bug in how type unions were handled within\n_orm.registry.type_annotation_map\nas well as\n_orm.Mapped\nthat made the lookup behavior of\na | b\ndifferent\nfrom that of\nUnion[a, b]\n.\nReferences:\n#11944\n[orm] [bug]\nConsistently handle\nTypeAliasType\n(defined in PEP 695) obtained with\nthe\ntype X = int\nsyntax introduced in python 3.12. Now in all cases one\nsuch alias must be explicitly added to the type map for it to be usable\ninside\nMapped\n. This change also revises the approach added in\n#11305\n, now requiring the\nTypeAliasType\nto be added to the\ntype map. Documentation on how unions and type alias types are handled by\nSQLAlchemy has been added in the\norm_declarative_mapped_column_type_map\nsection of the documentation.\nReferences:\n#11955\n[orm] [bug]\nFixed regression caused by an internal code change in response to recent\nMypy releases that caused the very unusual case of a list of ORM-mapped\nattribute expressions passed to\nColumnOperators.in_()\nto no longer\nbe accepted.\nReferences:\n#12019\n[orm] [bug]\nFixed issues in type handling within the\n_orm.registry.type_annotation_map\nfeature which prevented the\nuse of unions, using either pep-604 or\nUnion\nsyntaxes under future\nannotations mode, which contained multiple generic types as elements from\nbeing correctly resolvable.\nReferences:\n#12207\n[orm] [bug]\nFixed issue in event system which prevented an event listener from being\nattached and detached from multiple class-like objects, namely the\nsessionmaker\nor\nscoped_session\ntargets that assign to\nSession\nsubclasses.\nReferences:\n#12216\nsql\n[sql] [bug]\nFixed issue in \"lambda SQL\" feature where the tracking of bound parameters\ncould be corrupted if the same lambda were evaluated across multiple\ncompile phases, including when using the same lambda across multiple engine\ninstances or with statement caching disabled.\nReferences:\n#12084\npostgresql\n[postgresql] [usecase]\nThe\n_postgresql.Range\ntype now supports\n_postgresql.Range.__contains__()\n. Pull request courtesy of Frazer\nMcLean.\nReferences:\n#12093\n[postgresql] [bug]\nFixes issue in\nDialect.get_multi_indexes()\nin the PostgreSQL\ndialect, where an error would be thrown when attempting to use alembic with\na vector index from the pgvecto.rs extension.\nReferences:\n#11724\n[postgresql] [bug]\nFixed issue where creating a table with a primary column of\n_sql.SmallInteger\nand using the asyncpg driver would result in\nthe type being compiled to\nSERIAL\nrather than\nSMALLSERIAL\n.\nReferences:\n#12170\n[postgresql] [bug]\nAdjusted the asyncpg dialect so that an empty SQL string, which is valid\nfor PostgreSQL server, may be successfully processed at the dialect level,\nsuch as when using\nConnection.exec_driver_sql()\n. Pull request\ncourtesy Andrew Jackson.\nReferences:\n#12220\nmysql\n[mysql] [usecase] [mariadb]\nAdded support for the\nLIMIT\nclause with\nDELETE\nfor the MySQL and\nMariaDB dialects, to complement the already present option for\nUPDATE\n. The\nDelete.with_dialect_options()\nmethod of the\ndelete()\nconstruct accepts parameters for\nmysql_limit\nand\nmariadb_limit\n, allowing users to specify a limit on the number of rows\ndeleted. Pull request courtesy of Pablo Nicol谩s Estevez.\nReferences:\n#11764\n[mysql] [bug] [mariadb]\nAdded logic to ensure that the\nmysql_limit\nand\nmariadb_limit\nparameters of\nUpdate.with_dialect_options()\nand\nDelete.with_dialect_options()\nwhen compiled to string will only\ncompile if the parameter is passed as an integer; a\nValueError\nis\nraised otherwise.\nmariadb\n[mariadb] [usecase]\nAdded sql types\nINET4\nand\nINET6\nin the MariaDB dialect.  Pull\nrequest courtesy Adam 沤urek.\nReferences:\n#10720\nsqlite\n[sqlite] [usecase]\nAdded SQLite table option to enable\nSTRICT\ntables. Pull request\ncourtesy of Guilherme Crocetti.\nReferences:\n#7398\noracle\n[oracle] [feature]\nAdded new table option\noracle_tablespace\nto specify the\nTABLESPACE\noption when creating a table in Oracle. This allows users to define the\ntablespace in which the table should be created. Pull request courtesy of\nMiguel Grillo.\nReferences:\n#12016\n[oracle] [usecase]\nUse the connection attribute\nmax_identifier_length\navailable\nin oracledb since version 2.5 when determining the identifier length\nin the Oracle dialect.\nReferences:\n#12032\n[oracle] [bug]\nFixed compilation of\nTABLE\nfunction when used in a\nFROM\nclause in\nOracle Database dialect.\nReferences:\n#12100\n[oracle] [bug]\nFixed issue in oracledb / cx_oracle dialects where output type handlers for\nCLOB\nwere being routed to\nNVARCHAR\nrather than\nVARCHAR\n, causing\na double conversion to take place.\nReferences:\n#12150",
    "crawl_status": "success"
  },
  {
    "library_name": "SQLAlchemy",
    "url": "https://github.com/sqlalchemy/sqlalchemy/releases/tag/rel_2_0_29",
    "version": "rel_2_0_29",
    "title": "Release 2.0.29 路 sqlalchemy/sqlalchemy 路 GitHub",
    "release_date": "2024-03-23T21:53:32Z",
    "content": "2.0.29\nReleased: March 23, 2024\norm\n[orm] [usecase]\nAdded support for the\nPEP 695\nTypeAliasType\nconstruct as well as the\npython 3.12 native\ntype\nkeyword to work with ORM Annotated Declarative\nform when using these constructs to link to a\nPEP 593\nAnnotated\ncontainer, allowing the resolution of the\nAnnotated\nto proceed when\nthese constructs are used in a\n_orm.Mapped\ntyping container.\nReferences:\n#11130\n[orm] [bug]\nFixed Declarative issue where typing a relationship using\n_orm.Relationship\nrather than\n_orm.Mapped\nwould\ninadvertently pull in the \"dynamic\" relationship loader strategy for that\nattribute.\nReferences:\n#10611\n[orm] [bug]\nFixed issue in ORM annotated declarative where using\n_orm.mapped_column()\nwith an\n_orm.mapped_column.index\nor\n_orm.mapped_column.unique\nsetting of False would be\noverridden by an incoming\nAnnotated\nelement that featured that\nparameter set to\nTrue\n, even though the immediate\n_orm.mapped_column()\nelement is more specific and should take\nprecedence.  The logic to reconcile the booleans has been enhanced to\naccommodate a local value of\nFalse\nas still taking precedence over an\nincoming\nTrue\nvalue from the annotated element.\nReferences:\n#11091\n[orm] [bug] [regression]\nFixed regression from version 2.0.28 caused by the fix for\n#11085\nwhere the newer method of adjusting post-cache bound parameter values would\ninterefere with the implementation for the\n_orm.subqueryload()\nloader\noption, which has some more legacy patterns in use internally, when\nthe additional loader criteria feature were used with this loader option.\nReferences:\n#11173\nengine\n[engine] [bug]\nFixed issue in\nengine_insertmanyvalues\nfeature where using a primary\nkey column with an \"inline execute\" default generator such as an explicit\nSequence\nwith an explcit schema name, while at the same time\nusing the\n_engine.Connection.execution_options.schema_translate_map\nfeature would fail to render the sequence or the parameters properly,\nleading to errors.\nReferences:\n#11157\n[engine] [bug]\nMade a change to the adjustment made in version 2.0.10 for\n#9618\n,\nwhich added the behavior of reconciling RETURNING rows from a bulk INSERT\nto the parameters that were passed to it.  This behavior included a\ncomparison of already-DB-converted bound parameter values against returned\nrow values that was not always \"symmetrical\" for SQL column types such as\nUUIDs, depending on specifics of how different DBAPIs receive such values\nversus how they return them, necessitating the need for additional\n\"sentinel value resolver\" methods on these column types.  Unfortunately\nthis broke third party column types such as UUID/GUID types in libraries\nlike SQLModel which did not implement this special method, raising an error\n\"Can't match sentinel values in result set to parameter sets\".  Rather than\nattempt to further explain and document this implementation detail of the\n\"insertmanyvalues\" feature including a public version of the new\nmethod, the approach is intead revised to no longer need this extra\nconversion step, and the logic that does the comparison now works on the\npre-converted bound parameter value compared to the post-result-processed\nvalue, which should always be of a matching datatype.  In the unusual case\nthat a custom SQL column type that also happens to be used in a \"sentinel\"\ncolumn for bulk INSERT is not receiving and returning the same value type,\nthe \"Can't match\" error will be raised, however the mitigation is\nstraightforward in that the same Python datatype should be passed as that\nreturned.\nReferences:\n#11160\nsql\n[sql] [bug] [regression]\nFixed regression from the 1.4 series where the refactor of the\n_types.TypeEngine.with_variant()\nmethod introduced at\nchange_6980\nfailed to accommodate for the\n.copy()\nmethod, which\nwill lose the variant mappings that are set up. This becomes an issue for\nthe very specific case of a \"schema\" type, which includes types such as\nEnum\nand\nARRAY\n, when they are then used in the context\nof an ORM Declarative mapping with mixins where copying of types comes into\nplay.  The variant mapping is now copied as well.\nReferences:\n#11176\ntyping\n[typing] [bug]\nFixed typing issue allowing asyncio\nrun_sync()\nmethods to correctly\ntype the parameters according to the callable that was passed, making use\nof\nPEP 612\nParamSpec\nvariables.  Pull request courtesy Francisco R.\nDel Roio.\nReferences:\n#11055\npostgresql\n[postgresql] [usecase]\nThe PostgreSQL dialect now returns\n_postgresql.DOMAIN\ninstances\nwhen reflecting a column that has a domain as type. Previously, the domain\ndata type was returned instead. As part of this change, the domain\nreflection was improved to also return the collation of the text types.\nPull request courtesy of Thomas Stephenson.\nReferences:\n#10693\ntests\n[tests] [bug]\nBackported to SQLAlchemy 2.0 an improvement to the test suite with regards\nto how asyncio related tests are run, now using the newer Python 3.11\nasyncio.Runner\nor a backported equivalent, rather than relying on the\nprevious implementation based on\nasyncio.get_running_loop()\n.  This\nshould hopefully prevent issues with large suite runs on CPU loaded\nhardware where the event loop seems to become corrupted, leading to\ncascading failures.\nReferences:\n#11187",
    "crawl_status": "success"
  },
  {
    "library_name": "Pytest",
    "url": "https://github.com/pytest-dev/pytest/releases/tag/9.0.0",
    "version": "9.0.0",
    "title": "Release 9.0.0 路 pytest-dev/pytest 路 GitHub",
    "release_date": "2025-11-08T17:37:52Z",
    "content": "pytest 9.0.0 (2025-11-05)\nNew features\n#1367\n:\nSupport for subtests\nhas been added.\nsubtests <subtests>\nare an alternative to parametrization, useful in situations where the parametrization values are not all known at collection time.\nExample:\ndef\ncontains_docstring\n(\np\n:\nPath\n)\n->\nbool\n:\n\"\"\"Return True if the given Python file contains a top-level docstring.\"\"\"\n...\ndef\ntest_py_files_contain_docstring\n(\nsubtests\n:\npytest\n.\nSubtests\n)\n->\nNone\n:\nfor\npath\nin\nPath\n.\ncwd\n().\nglob\n(\n\"*.py\"\n):\nwith\nsubtests\n.\ntest\n(\npath\n=\nstr\n(\npath\n)):\nassert\ncontains_docstring\n(\npath\n)\nEach assert failure or error is caught by the context manager and reported individually, giving a clear picture of all files that are missing a docstring.\nIn addition,\nunittest.TestCase.subTest\nis now also supported.\nThis feature was originally implemented as a separate plugin in\npytest-subtests\n, but since then has been merged into the core.\n[!NOTE]\nThis feature is experimental and will likely evolve in future releases. By that we mean that we might change how subtests are reported on failure, but the functionality and how to use it are stable.\n#13743\n: Added support for\nnative TOML configuration files\n.\nWhile pytest, since version 6, supports configuration in\npyproject.toml\nfiles under\n[tool.pytest.ini_options]\n,\nit does so in an \"INI compatibility mode\", where all configuration values are treated as strings or list of strings.\nNow, pytest supports the native TOML data model.\nIn\npyproject.toml\n, the native TOML configuration is under the\n[tool.pytest]\ntable.\n#\npyproject.toml\n[\ntool\n.\npytest\n]\nminversion\n=\n\"\n9.0\n\"\naddopts\n= [\n\"\n-ra\n\"\n,\n\"\n-q\n\"\n]\ntestpaths\n= [\n\"\ntests\n\"\n,\n\"\nintegration\n\"\n,\n]\nThe\n[tool.pytest.ini_options]\ntable remains supported, but both tables cannot be used at the same time.\nIf you prefer to use a separate configuration file, or don't use\npyproject.toml\n, you can use\npytest.toml\nor\n.pytest.toml\n:\n#\npytest.toml or .pytest.toml\n[\npytest\n]\nminversion\n=\n\"\n9.0\n\"\naddopts\n= [\n\"\n-ra\n\"\n,\n\"\n-q\n\"\n]\ntestpaths\n= [\n\"\ntests\n\"\n,\n\"\nintegration\n\"\n,\n]\nThe documentation now (sometimes) shows configuration snippets in both TOML and INI formats, in a tabbed interface.\nSee\nconfig file formats\nfor full details.\n#13823\n: Added a\n\"strict mode\"\nenabled by the\nstrict\nconfiguration option.\nWhen set to\ntrue\n, the\nstrict\noption currently enables\nstrict_config\nstrict_markers\nstrict_parametrization_ids\nstrict_xfail\nThe individual strictness options can be explicitly set to override the global\nstrict\nsetting.\nThe previously-deprecated\n--strict\ncommand-line flag now enables strict mode.\nIf pytest adds new strictness options in the future, they will also be enabled in strict mode.\nTherefore, you should only enable strict mode if you use a pinned/locked version of pytest,\nor if you want to proactively adopt new strictness options as they are added.\nSee\nstrict mode\nfor more details.\n#13737\n: Added the\nstrict_parametrization_ids\nconfiguration option.\nWhen set, pytest emits an error if it detects non-unique parameter set IDs,\nrather than automatically making the IDs unique by adding\n0\n,\n1\n, ... to them.\nThis can be particularly useful for catching unintended duplicates.\n#13072\n: Added support for displaying test session\nprogress in the terminal tab\nusing the\nOSC 9;4;\nANSI sequence.\nWhen pytest runs in a supported terminal emulator like ConEmu, Gnome Terminal, Ptyxis, Windows Terminal, Kitty or Ghostty,\nyou'll see the progress in the terminal tab or window,\nallowing you to monitor pytest's progress at a glance.\nThis feature is automatically enabled when running in a TTY. It is implemented as an internal plugin. If needed, it can be disabled as follows:\nOn a user level, using\n-p no:terminalprogress\non the command line or via an environment variable\nPYTEST_ADDOPTS='-p no:terminalprogress'\n.\nOn a project configuration level, using\naddopts = \"-p no:terminalprogress\"\n.\n#478\n: Support PEP420 (implicit namespace packages) as\n--pyargs\ntarget when\nconsider_namespace_packages\nis\ntrue\nin the config.\nPreviously, this option only impacted package imports, now it also impacts tests discovery.\n#13678\n: Added a new\nfaulthandler_exit_on_timeout\nconfiguration option set to \"false\" by default to let\nfaulthandler\ninterrupt the\npytest\nprocess after a timeout in case of deadlock.\nPreviously, a\nfaulthandler\ntimeout would only dump the traceback of all threads to stderr, but would not interrupt the\npytest\nprocess.\n-- by\nogrisel\n.\n#13829\n: Added support for configuration option aliases via the\naliases\nparameter in\nParser.addini() <pytest.Parser.addini>\n.\nPlugins can now register alternative names for configuration options,\nallowing for more flexibility in configuration naming and supporting backward compatibility when renaming options.\nThe canonical name always takes precedence if both the canonical name and an alias are specified in the configuration file.\nImprovements in existing functionality\n#13330\n: Having pytest configuration spread over more than one file (for example having both a\npytest.ini\nfile and\npyproject.toml\nwith a\n[tool.pytest.ini_options]\ntable) will now print a warning to make it clearer to the user that only one of them is actually used.\n-- by\nsgaist\n#13574\n: The single argument\n--version\nno longer loads the entire plugin infrastructure, making it faster and more reliable when displaying only the pytest version.\nPassing\n--version\ntwice (e.g.,\npytest --version --version\n) retains the original behavior, showing both the pytest version and plugin information.\n[!NOTE]\nSince\n--version\nis now processed early, it only takes effect when passed directly via the command line. It will not work if set through other mechanisms, such as\nPYTEST_ADDOPTS\nor\naddopts\n.\n#13823\n: Added\nstrict_xfail\nas an alias to the\nxfail_strict\noption,\nstrict_config\nas an alias to the\n--strict-config\nflag,\nand\nstrict_markers\nas an alias to the\n--strict-markers\nflag.\nThis makes all strictness options consistently have configuration options with the prefix\nstrict_\n.\n#13700\n:\n--junitxml\nno longer prints the\ngenerated xml file\nsummary at the end of the pytest session when\n--quiet\nis given.\n#13732\n: Previously, when filtering warnings, pytest would fail if the filter referenced a class that could not be imported. Now, this only outputs a message indicating the problem.\n#13859\n: Clarify the error message for\npytest.raises()\nwhen a regex\nmatch\nfails.\n#13861\n: Better sentence structure in a test's expected error message. Previously, the error message would be \"expected exception must be <expected>, but got <actual>\". Now, it is \"Expected <expected>, but got <actual>\".\nRemovals and backward incompatible breaking changes\n#12083\n: Fixed a bug where an invocation such as\npytest a/ a/b\nwould cause only tests from\na/b\nto run, and not other tests under\na/\n.\nThe fix entails a few breaking changes to how such overlapping arguments and duplicates are handled:\npytest a/b a/\nor\npytest a/ a/b\nare equivalent to\npytest a\n; if an argument overlaps another arguments, only the prefix remains.\npytest x.py x.py\nis equivalent to\npytest x.py\n; previously such an invocation was taken as an explicit request to run the tests from the file twice.\nIf you rely on these behaviors, consider using\n--keep-duplicates <duplicate-paths>\n, which retains its existing behavior (including the bug).\n#13719\n: Support for Python 3.9 is dropped following its end of life.\n#13766\n: Previously, pytest would assume it was running in a CI/CD environment if either of the environment variables\n$CI\nor\n$BUILD_NUMBER\nwas defined;\nnow, CI mode is only activated if at least one of those variables is defined and set to a\nnon-empty\nvalue.\n#13779\n:\nPytestRemovedIn9Warning deprecation warnings are now errors by default.\nFollowing our plan to remove deprecated features with as little disruption as\npossible, all warnings of type\nPytestRemovedIn9Warning\nnow generate errors\ninstead of warning messages by default.\nThe affected features will be effectively removed in pytest 9.1\n, so please consult the\ndeprecations\nsection in the docs for directions on how to update existing code.\nIn the pytest\n9.0.X\nseries, it is possible to change the errors back into warnings as a\nstopgap measure by adding this to your\npytest.ini\nfile:\n[pytest]\nfilterwarnings\n=\n    ignore::pytest.PytestRemovedIn9Warning\nBut this will stop working when pytest\n9.1\nis released.\nIf you have concerns\nabout the removal of a specific feature, please add a\ncomment to\n13779\n.\nDeprecations (removal in next major release)\n#13807\n:\nmonkeypatch.syspath_prepend() <pytest.MonkeyPatch.syspath_prepend>\nnow issues a deprecation warning when the prepended path contains legacy namespace packages (those using\npkg_resources.declare_namespace()\n).\nUsers should migrate to native namespace packages (\n420\n).\nSee\nmonkeypatch-fixup-namespace-packages\nfor details.\nBug fixes\n#13445\n: Made the type annotations of\npytest.skip\nand friends more spec-complaint to have them work across more type checkers.\n#13537\n: Fixed a bug in which\nExceptionGroup\nwith only\nSkipped\nexceptions in teardown was not handled correctly and showed as error.\n#13598\n: Fixed possible collection confusion on Windows when short paths and symlinks are involved.\n#13716\n: Fixed a bug where a nonsensical invocation like\npytest x.py[a]\n(a file cannot be parametrized) was silently treated as\npytest x.py\n. This is now a usage error.\n#13722\n: Fixed a misleading assertion failure message when using\npytest.approx\non mappings with differing lengths.\n#13773\n: Fixed the static fixture closure calculation to properly consider transitive dependencies requested by overridden fixtures.\n#13816\n: Fixed\npytest.approx\nwhich now returns a clearer error message when comparing mappings with different keys.\n#13849\n: Hidden\n.pytest.ini\nfiles are now picked up as the config file even if empty.\nThis was an inconsistency with non-hidden\npytest.ini\n.\n#13865\n: Fixed\n--show-capture\nwith\n--tb=line\n.\n#13522\n: Fixed\npytester\nin subprocess mode ignored all :attr`pytester.plugins <pytest.Pytester.plugins>` except the first.\nFixed\npytester\nin subprocess mode silently ignored non-str\npytester.plugins <pytest.Pytester.plugins>\n.\nNow it errors instead.\nIf you are affected by this, specify the plugin by name, or switch the affected tests to use\npytester.runpytest_inprocess <pytest.Pytester.runpytest_inprocess>\nexplicitly instead.\nPackaging updates and notes for downstreams\n#13791\n: Minimum requirements on\niniconfig\nand\npackaging\nwere bumped to\n1.0.1\nand\n22.0.0\n, respectively.\nContributor-facing changes\n#12244\n: Fixed self-test failures when\nTERM=dumb\n.\n#12474\n: Added scheduled GitHub Action Workflow to run Sphinx linkchecks in repo documentation.\n#13621\n: pytest's own testsuite now handles the\nlsof\ncommand hanging (e.g. due to unreachable network filesystems), with the affected selftests being skipped after 10 seconds.\n#13638\n: Fixed deprecated\ngh pr new\ncommand in\nscripts/prepare-release-pr.py\n.\nThe script now uses\ngh pr create\nwhich is compatible with GitHub CLI v2.0+.\n#13695\n: Flush\nstdout\nand\nstderr\nin\nPytester.run\nto avoid truncated outputs in\ntest_faulthandler.py::test_timeout\non CI -- by\nogrisel\n.\n#13771\n: Skip\ntest_do_not_collect_symlink_siblings\non Windows environments without symlink support to avoid false negatives.\n#13841\n:\ntox>=4\nis now required when contributing to pytest.\n#13625\n: Added missing docstrings to\npytest_addoption()\n,\npytest_configure()\n, and\ncacheshow()\nfunctions in\ncacheprovider.py\n.\nMiscellaneous internal changes\n#13830\n: Configuration overrides (\n-o\n/\n--override-ini\n) are now processed during startup rather than during\nconfig.getini() <pytest.Config.getini>\n.",
    "crawl_status": "success"
  },
  {
    "library_name": "Pytest",
    "url": "https://github.com/pytest-dev/pytest/releases/tag/7.4.0",
    "version": "7.4.0",
    "title": "Release Prepare release version 7.4.0 路 pytest-dev/pytest 路 GitHub",
    "release_date": "2023-06-23T11:18:06Z",
    "content": "pytest 7.4.0 (2023-06-23)\nFeatures\n#10901\n: Added\nExceptionInfo.from_exception() <pytest.ExceptionInfo.from_exception>\n{.interpreted-text role=\"func\"}, a simpler way to create an\n~pytest.ExceptionInfo\n{.interpreted-text role=\"class\"} from an exception.\nThis can replace\nExceptionInfo.from_exc_info() <pytest.ExceptionInfo.from_exc_info()>\n{.interpreted-text role=\"func\"} for most uses.\nImprovements\n#10872\n: Update test log report annotation to named tuple and fixed inconsistency in docs for\npytest_report_teststatus\n{.interpreted-text role=\"hook\"} hook.\n#10907\n: When an exception traceback to be displayed is completely filtered out (by mechanisms such as\n__tracebackhide__\n, internal frames, and similar), now only the exception string and the following message are shown:\n\"All traceback entries are hidden. Pass [--full-trace]{.title-ref} to see hidden and internal frames.\".\nPreviously, the last frame of the traceback was shown, even though it was hidden.\n#10940\n: Improved verbose output (\n-vv\n) of\nskip\nand\nxfail\nreasons by performing text wrapping while leaving a clear margin for progress output.\nAdded\nTerminalReporter.wrap_write()\nas a helper for that.\n#10991\n: Added handling of\n%f\ndirective to print microseconds in log format options, such as\nlog-date-format\n.\n#11005\n: Added the underlying exception to the cache provider's path creation and write warning messages.\n#11013\n: Added warning when\ntestpaths\n{.interpreted-text role=\"confval\"} is set, but paths are not found by glob. In this case, pytest will fall back to searching from the current directory.\n#11043\n: When [--confcutdir]{.title-ref} is not specified, and there is no config file present, the conftest cutoff directory ([--confcutdir]{.title-ref}) is now set to the\nrootdir <rootdir>\n{.interpreted-text role=\"ref\"}.\nPreviously in such cases, [conftest.py]{.title-ref} files would be probed all the way to the root directory of the filesystem.\nIf you are badly affected by this change, consider adding an empty config file to your desired cutoff directory, or explicitly set [--confcutdir]{.title-ref}.\n#11081\n: The\nnorecursedirs\n{.interpreted-text role=\"confval\"} check is now performed in a\npytest_ignore_collect\n{.interpreted-text role=\"hook\"} implementation, so plugins can affect it.\nIf after updating to this version you see that your [norecursedirs]{.title-ref} setting is not being respected,\nit means that a conftest or a plugin you use has a bad [pytest_ignore_collect]{.title-ref} implementation.\nMost likely, your hook returns [False]{.title-ref} for paths it does not want to ignore,\nwhich ends the processing and doesn't allow other plugins, including pytest itself, to ignore the path.\nThe fix is to return [None]{.title-ref} instead of [False]{.title-ref} for paths your hook doesn't want to ignore.\n#8711\n:\ncaplog.set_level() <pytest.LogCaptureFixture.set_level>\n{.interpreted-text role=\"func\"} and\ncaplog.at_level() <pytest.LogCaptureFixture.at_level>\n{.interpreted-text role=\"func\"}\nwill temporarily enable the requested\nlevel\nif\nlevel\nwas disabled globally via\nlogging.disable(LEVEL)\n.\nBug Fixes\n#10831\n: Terminal Reporting: Fixed bug when running in\n--tb=line\nmode where\npytest.fail(pytrace=False)\ntests report\nNone\n.\n#11068\n: Fixed the\n--last-failed\nwhole-file skipping functionality (\"skipped N files\") for\nnon-python test files <non-python tests>\n{.interpreted-text role=\"ref\"}.\n#11104\n: Fixed a regression in pytest 7.3.2 which caused to\ntestpaths\n{.interpreted-text role=\"confval\"} to be considered for loading initial conftests,\neven when it was not utilized (e.g. when explicit paths were given on the command line).\nNow the\ntestpaths\nare only considered when they are in use.\n#1904\n: Fixed traceback entries hidden with\n__tracebackhide__ = True\nstill being shown for chained exceptions (parts after \"... the above exception ...\" message).\n#7781\n: Fix writing non-encodable text to log file when using\n--debug\n.\nImproved Documentation\n#9146\n: Improved documentation for\ncaplog.set_level() <pytest.LogCaptureFixture.set_level>\n{.interpreted-text role=\"func\"}.\nTrivial/Internal Changes\n#11031\n: Enhanced the CLI flag for\n-c\nto now include\n--config-file\nto make it clear that this flag applies to the usage of a custom config file.",
    "crawl_status": "success"
  },
  {
    "library_name": "Pytest",
    "url": "https://github.com/pytest-dev/pytest/releases/tag/8.3.0",
    "version": "8.3.0",
    "title": "Release 8.3.0 路 pytest-dev/pytest 路 GitHub",
    "release_date": "2024-07-20T15:33:08Z",
    "content": "pytest 8.3.0 (2024-07-20)\nNew features\n#12231\n: Added [--xfail-tb]{.title-ref} flag, which turns on traceback output for XFAIL results.\nIf the [--xfail-tb]{.title-ref} flag is not given, tracebacks for XFAIL results are NOT shown.\nThe style of traceback for XFAIL is set with [--tb]{.title-ref}, and can be [auto|long|short|line|native|no]{.title-ref}.\nNote: Even if you have [--xfail-tb]{.title-ref} set, you won't see them if [--tb=no]{.title-ref}.\nSome history:\nWith pytest 8.0, [-rx]{.title-ref} or [-ra]{.title-ref} would not only turn on summary reports for xfail, but also report the tracebacks for xfail results. This caused issues with some projects that utilize xfail, but don't want to see all of the xfail tracebacks.\nThis change detaches xfail tracebacks from [-rx]{.title-ref}, and now we turn on xfail tracebacks with [--xfail-tb]{.title-ref}. With this, the default [-rx]{.title-ref}/ [-ra]{.title-ref} behavior is identical to pre-8.0 with respect to xfail tracebacks. While this is a behavior change, it brings default behavior back to pre-8.0.0 behavior, which ultimately was considered the better course of action.\n#12281\n: Added support for keyword matching in marker expressions.\nNow tests can be selected by marker keyword arguments.\nSupported values are\nint\n{.interpreted-text role=\"class\"}, (unescaped)\nstr\n{.interpreted-text role=\"class\"},\nbool\n{.interpreted-text role=\"class\"} &\nNone\n{.interpreted-text role=\"data\"}.\nSee\nmarker examples <marker_keyword_expression_example>\n{.interpreted-text role=\"ref\"} for more information.\n-- by\nlovetheguitar\n{.interpreted-text role=\"user\"}\n#12567\n: Added\n--no-fold-skipped\ncommand line option.\nIf this option is set, then skipped tests in short summary are no longer grouped\nby reason but all tests are printed individually with their nodeid in the same\nway as other statuses.\n-- by\npbrezina\n{.interpreted-text role=\"user\"}\nImprovements in existing functionality\n#12469\n: The console output now uses the \"third-party plugins\" terminology,\nreplacing the previously established but confusing and outdated\nreference to\nsetuptools <setuptools:index>\n{.interpreted-text role=\"std:doc\"}\n-- by\nwebknjaz\n{.interpreted-text role=\"user\"}.\n#12544\n,\n#12545\n: Python virtual environment detection was improved by\nchecking for a\npyvenv.cfg\n{.interpreted-text role=\"file\"} file, ensuring reliable detection on\nvarious platforms -- by\nzachsnickers\n{.interpreted-text role=\"user\"}.\n#2871\n: Do not truncate arguments to functions in output when running with [-vvv]{.title-ref}.\n#389\n: The readability of assertion introspection of bound methods has been enhanced\n-- by\nfarbodahm\n{.interpreted-text role=\"user\"},\nwebknjaz\n{.interpreted-text role=\"user\"},\nobestwalter\n{.interpreted-text role=\"user\"},\nflub\n{.interpreted-text role=\"user\"}\nand\nglyphack\n{.interpreted-text role=\"user\"}.\nEarlier, it was like:\n=================================== FAILURES ===================================\n_____________________________________ test _____________________________________\ndef test():\n>\nassert\nHelp().fun\n() == 2\nE       assert 1 == 2\nE        +  where 1 = <bound method Help.fun of <example.Help instance at 0x256a830>>()\nE        +    where <bound method Help.fun of <example.Help instance at 0x256a830>> = <example.Help instance at 0x256a830>.fun\nE        +      where <example.Help instance at 0x256a830> = Help()\nexample.py:7: AssertionError\n=========================== 1 failed in 0.03 seconds ===========================\nAnd now it's like:\n=================================== FAILURES ===================================\n_____________________________________ test _____________________________________\ndef test():\n>\nassert\nHelp().fun\n() == 2\nE       assert 1 == 2\nE        +  where 1 = fun()\nE        +    where fun = <test_local.Help object at 0x1074be230>.fun\nE        +      where <test_local.Help object at 0x1074be230> = Help()\ntest_local.py:13: AssertionError\n=========================== 1 failed in 0.03 seconds ===========================\n#7662\n: Added timezone information to the testsuite timestamp in the JUnit XML report.\nBug fixes\n#11706\n: Fixed reporting of teardown errors in higher-scoped fixtures when using [--maxfail]{.title-ref} or [--stepwise]{.title-ref}.\nOriginally added in pytest 8.0.0, but reverted in 8.0.2 due to a regression in pytest-xdist.\nThis regression was fixed in pytest-xdist 3.6.1.\n#11797\n:\npytest.approx\n{.interpreted-text role=\"func\"} now correctly handles\nSequence <collections.abc.Sequence>\n{.interpreted-text role=\"class\"}-like objects.\n#12204\n,\n#12264\n: Fixed a regression in pytest 8.0 where tracebacks get longer and longer when multiple\ntests fail due to a shared higher-scope fixture which raised -- by\nbluetech\n{.interpreted-text role=\"user\"}.\nAlso fixed a similar regression in pytest 5.4 for collectors which raise during setup.\nThe fix necessitated internal changes which may affect some plugins:\nFixtureDef.cached_result[2]\nis now a tuple\n(exc, tb)\ninstead of\nexc\n.\nSetupState.stack\nfailures are now a tuple\n(exc, tb)\ninstead of\nexc\n.\n#12275\n: Fixed collection error upon encountering an\nabstract <abc>\n{.interpreted-text role=\"mod\"} class, including abstract [unittest.TestCase]{.title-ref} subclasses.\n#12328\n: Fixed a regression in pytest 8.0.0 where package-scoped parameterized items were not correctly reordered to minimize setups/teardowns in some cases.\n#12424\n: Fixed crash with [assert testcase is not None]{.title-ref} assertion failure when re-running unittest tests using plugins like pytest-rerunfailures. Regressed in 8.2.2.\n#12472\n: Fixed a crash when returning category\n\"error\"\nor\n\"failed\"\nwith a custom test status from\npytest_report_teststatus\n{.interpreted-text role=\"hook\"} hook --\npbrezina\n{.interpreted-text role=\"user\"}.\n#12505\n: Improved handling of invalid regex patterns in\npytest.raises(match=r'...') <pytest.raises>\n{.interpreted-text role=\"func\"} by providing a clear error message.\n#12580\n: Fixed a crash when using the cache class on Windows and the cache directory was created concurrently.\n#6962\n: Parametrization parameters are now compared using [==]{.title-ref} instead of [is]{.title-ref} ([is]{.title-ref} is still used as a fallback if the parameter does not support [==]{.title-ref}).\nThis fixes use of parameters such as lists, which have a different [id]{.title-ref} but compare equal, causing fixtures to be re-computed instead of being cached.\n#7166\n: Fixed progress percentages (the\n[ 87%]\nat the edge of the screen) sometimes not aligning correctly when running with pytest-xdist\n-n\n.\nImproved documentation\n#12153\n: Documented using\nPYTEST_VERSION\n{.interpreted-text role=\"envvar\"} to detect if code is running from within a pytest run.\n#12469\n: The external plugin mentions in the documentation now avoid mentioning\nsetuptools entry-points <setuptools:index>\n{.interpreted-text role=\"std:doc\"} as the concept is\nmuch more generic nowadays. Instead, the terminology of \"external\",\n\"installed\", or \"third-party\" plugins (or packages) replaces that.\n-- by\nwebknjaz\n{.interpreted-text role=\"user\"}\n#12577\n: [CI]{.title-ref} and [BUILD_NUMBER]{.title-ref} environment variables role is discribed in\nthe reference doc. They now also appear when doing [pytest -h]{.title-ref}\n-- by\nMarcBresson\n{.interpreted-text role=\"user\"}.\nContributor-facing changes\n#12467\n: Migrated all internal type-annotations to the python3.10+ style by using the [annotations]{.title-ref} future import.\n-- by\nRonnyPfannschmidt\n{.interpreted-text role=\"user\"}\n#11771\n,\n#12557\n: The PyPy runtime version has been updated to 3.9 from 3.8 that introduced\na flaky bug at the garbage collector which was not expected to fix there\nas the 3.8 is EoL.\n-- by\nx612skm\n{.interpreted-text role=\"user\"}\n#12493\n: The change log draft preview integration has been refactored to use a\nthird party extension\nsphinxcontib-towncrier\n. The previous in-repo\nscript was putting the change log preview file at\ndoc/en/_changelog_towncrier_draft.rst\n{.interpreted-text role=\"file\"}. Said file is no longer\nignored in Git and might show up among untracked files in the\ndevelopment environments of the contributors. To address that, the\ncontributors can run the following command that will clean it up:\n$\ngit clean -x -i -- doc/en/_changelog_towncrier_draft.rst\n-- by\nwebknjaz\n{.interpreted-text role=\"user\"}\n#12498\n: All the undocumented\ntox\nenvironments now have descriptions.\nThey can be listed in one's development environment by invoking\ntox -av\nin a terminal.\n-- by\nwebknjaz\n{.interpreted-text role=\"user\"}\n#12501\n: The changelog configuration has been updated to introduce more accurate\naudience-tailored categories. Previously, there was a\ntrivial\nchange log fragment type with an unclear and broad meaning. It was\nremoved and we now have\ncontrib\n,\nmisc\nand\npackaging\nin\nplace of it.\nThe new change note types target the readers who are downstream\npackagers and project contributors. Additionally, the miscellaneous\nsection is kept for unspecified updates that do not fit anywhere else.\n-- by\nwebknjaz\n{.interpreted-text role=\"user\"}\n#12502\n: The UX of the GitHub automation making pull requests to update the\nplugin list has been updated. Previously, the maintainers had to close\nthe automatically created pull requests and re-open them to trigger the\nCI runs. From now on, they only need to click the [Ready for review]{.title-ref}\nbutton instead.\n-- by\nwebknjaz\n{.interpreted-text role=\"user\"}\n#12522\n: The\n:pull:\nRST role has been replaced with a shorter\n:pr:\ndue to starting to use the implementation from\nthe third-party\nsphinx-issues\n{.interpreted-text role=\"pypi\"} Sphinx extension\n-- by\nwebknjaz\n{.interpreted-text role=\"user\"}.\n#12531\n: The coverage reporting configuration has been updated to exclude\npytest's own tests marked as expected to fail from the coverage\nreport. This has an effect of reducing the influence of flaky\ntests on the resulting number.\n-- by\nwebknjaz\n{.interpreted-text role=\"user\"}\n#12533\n: The\nextlinks\nSphinx extension is no longer enabled. The\n:bpo:\nrole it used to declare has been removed with that. BPO itself has\nmigrated to GitHub some years ago and it is possible to link the\nrespective issues by using their GitHub issue numbers and the\n:issue:\nrole that the\nsphinx-issues\nextension implements.\n-- by\nwebknjaz\n{.interpreted-text role=\"user\"}\n#12562\n: Possible typos in using the\n:user:\nRST role is now being linted\nthrough the pre-commit tool integration -- by\nwebknjaz\n{.interpreted-text role=\"user\"}.",
    "crawl_status": "success"
  },
  {
    "library_name": "Pydantic",
    "url": "https://github.com/pydantic/pydantic/releases/tag/v2.12.0",
    "version": "v2.12.0",
    "title": "Release v2.12.0 2025-10-07 路 pydantic/pydantic 路 GitHub",
    "release_date": "2025-10-07T15:57:20Z",
    "content": "v2.12.0 (2025-10-07)\nNote\nCheck out the\nblog post\nfor release highlights. Several minor\nchanges\n(considered non-breaking changes according to our\nversioning policy\n) are also included in this release. Make sure to look into them before upgrading.\nWarning\nThe core functionality of Pydantic V1 is\nnot\ncompatible with\nPython 3.14\nor greater.\nThis is the final 2.12 release. It features the work of 20 external contributors and provides useful new features, along with initial Python 3.14 support.\nChangelog (see the\n2.12.0a1\nand\n2.12.0b1\nreleases for additional changes since 2.11):\nPackaging\nUpdate V1 copy to v1.10.24 by\n@Viicos\nin\n#12338\nNew Features\nAdd\nextra\nparameter to the validate functions by\n@anvilpete\nin\n#12233\nAdd\nexclude_computed_fields\nserialization option by\n@Viicos\nin\n#12334\nAdd\npreverse_empty_path\nURL options by\n@Viicos\nin\n#12336\nAdd\nunion_format\nparameter to JSON Schema generation by\n@Viicos\nin\n#12147\nAdd\n__qualname__\nparameter for\ncreate_model\nby\n@Atry\nin\n#12001\nFixes\nDo not try to infer name from lambda definitions in pipelines API by\n@Viicos\nin\n#12289\nUse proper namespace for functions in\nTypeAdapter\nby\n@Viicos\nin\n#12324\nUse\nAny\nfor context type annotation in\nTypeAdapter\nby\n@inducer\nin\n#12279\nExpose\nFieldInfo\nin\npydantic.fields.__all__\nby\n@Viicos\nin\n#12339\nRespect\nvalidation_alias\nin\n@validate_call\nby\n@Viicos\nin\n#12340\nUse\nAny\nas context annotation in plugin API by\n@Viicos\nin\n#12341\nUse proper\nstacklevel\nin warnings when possible by\n@Viicos\nin\n#12342\nNew Contributors\n@anvilpete\nmade their first contribution in\n#12233\n@JonathanWindell\nmade their first contribution in\n#12327\n@inducer\nmade their first contribution in\n#12279\n@Atry\nmade their first contribution in\n#12001\nFull Changelog\n:\nv2.11.10...v2.12.0",
    "crawl_status": "success"
  },
  {
    "library_name": "Pydantic",
    "url": "https://github.com/pydantic/pydantic/releases/tag/v2.10.0",
    "version": "v2.10.0",
    "title": "Release v2.10.0 2024-11-20 路 pydantic/pydantic 路 GitHub",
    "release_date": "2024-11-20T20:32:21Z",
    "content": "The code released in v2.10.0 is practically identical to that of v2.10.0b2.\nSee the\nv2.10 release blog post\nfor the highlights!\nWhat's Changed\nPackaging\nBump\npydantic-core\nto\nv2.27.0\nby\n@sydney-runkle\nin\n#10825\nReplaced pdm with uv by\n@frfahim\nin\n#10727\nNew Features\nSupport\nfractions.Fraction\nby\n@sydney-runkle\nin\n#10318\nSupport\nHashable\nfor json validation by\n@sydney-runkle\nin\n#10324\nAdd a\nSocketPath\ntype for\nlinux\nsystems by\n@theunkn0wn1\nin\n#10378\nAllow arbitrary refs in JSON schema\nexamples\nby\n@sydney-runkle\nin\n#10417\nSupport\ndefer_build\nfor Pydantic dataclasses by\n@Viicos\nin\n#10313\nAdding v1 / v2 incompatibility warning for nested v1 model by\n@sydney-runkle\nin\n#10431\nAdd support for unpacked\nTypedDict\nto type hint variadic keyword arguments with\n@validate_call\nby\n@Viicos\nin\n#10416\nSupport compiled patterns in\nprotected_namespaces\nby\n@sydney-runkle\nin\n#10522\nAdd support for\npropertyNames\nin JSON schema by\n@FlorianSW\nin\n#10478\nAdding\n__replace__\nprotocol for Python 3.13+ support by\n@sydney-runkle\nin\n#10596\nExpose public\nsort\nmethod for JSON schema generation by\n@sydney-runkle\nin\n#10595\nAdd runtime validation of\n@validate_call\ncallable argument by\n@kc0506\nin\n#10627\nAdd\nexperimental_allow_partial\nsupport by\n@samuelcolvin\nin\n#10748\nSupport default factories taking validated data as an argument by\n@Viicos\nin\n#10678\nAllow subclassing\nValidationError\nand\nPydanticCustomError\nby\n@Youssefares\nin\npydantic/pydantic-core#1413\nAdd\ntrailing-strings\nsupport to\nexperimental_allow_partial\nby\n@sydney-runkle\nin\n#10825\nAdd\nrebuild()\nmethod for\nTypeAdapter\nand simplify\ndefer_build\npatterns by\n@sydney-runkle\nin\n#10537\nImprove\nTypeAdapter\ninstance repr by\n@sydney-runkle\nin\n#10872\nChanges\nDon't allow customization of\nSchemaGenerator\nuntil interface is more stable by\n@sydney-runkle\nin\n#10303\nCleanly\ndefer_build\non\nTypeAdapters\n, removing experimental flag by\n@sydney-runkle\nin\n#10329\nFix\nmro\nof generic subclass  by\n@kc0506\nin\n#10100\nStrip whitespaces on JSON Schema title generation by\n@sydney-runkle\nin\n#10404\nUse\nb64decode\nand\nb64encode\nfor\nBase64Bytes\ntype by\n@sydney-runkle\nin\n#10486\nRelax protected namespace config default by\n@sydney-runkle\nin\n#10441\nRevalidate parametrized generics if instance's origin is subclass of OG class by\n@sydney-runkle\nin\n#10666\nWarn if configuration is specified on the\n@dataclass\ndecorator and with the\n__pydantic_config__\nattribute by\n@sydney-runkle\nin\n#10406\nRecommend against using\nEllipsis\n(...) with\nField\nby\n@Viicos\nin\n#10661\nMigrate to subclassing instead of annotated approach for pydantic url types by\n@sydney-runkle\nin\n#10662\nChange JSON schema generation of\nLiteral\ns and\nEnums\nby\n@Viicos\nin\n#10692\nSimplify unions involving\nAny\nor\nNever\nwhen replacing type variables by\n@Viicos\nin\n#10338\nDo not require padding when decoding\nbase64\nbytes by\n@bschoenmaeckers\nin\npydantic/pydantic-core#1448\nSupport dates all the way to 1BC by\n@changhc\nin\npydantic/speedate#77\nPerformance\nSchema cleaning: skip unnecessary copies during schema walking by\n@Viicos\nin\n#10286\nRefactor namespace logic for annotations evaluation by\n@Viicos\nin\n#10530\nImprove email regexp on edge cases by\n@AlekseyLobanov\nin\n#10601\nCoreMetadata\nrefactor with an emphasis on documentation, schema build time performance, and reducing complexity by\n@sydney-runkle\nin\n#10675\nFixes\nRemove guarding check on\ncomputed_field\nwith\nfield_serializer\nby\n@nix010\nin\n#10390\nFix\nPredicate\nissue in\nv2.9.0\nby\n@sydney-runkle\nin\n#10321\nFixing\nannotated-types\nbound by\n@sydney-runkle\nin\n#10327\nTurn\ntzdata\ninstall requirement into optional\ntimezone\ndependency by\n@jakob-keller\nin\n#10331\nUse correct types namespace when building\nnamedtuple\ncore schemas by\n@Viicos\nin\n#10337\nFix evaluation of stringified annotations during namespace inspection by\n@Viicos\nin\n#10347\nFix\nIncEx\ntype alias definition by\n@Viicos\nin\n#10339\nDo not error when trying to evaluate annotations of private attributes by\n@Viicos\nin\n#10358\nFix nested type statement by\n@kc0506\nin\n#10369\nImprove typing of\nModelMetaclass.mro\nby\n@Viicos\nin\n#10372\nFix class access of deprecated\ncomputed_field\ns by\n@Viicos\nin\n#10391\nMake sure\ninspect.iscoroutinefunction\nworks on coroutines decorated with\n@validate_call\nby\n@MovisLi\nin\n#10374\nFix\nNameError\nwhen using\nvalidate_call\nwith PEP 695 on a class by\n@kc0506\nin\n#10380\nFix\nZoneInfo\nwith various invalid types by\n@sydney-runkle\nin\n#10408\nFix\nPydanticUserError\non empty\nmodel_config\nwith annotations by\n@cdwilson\nin\n#10412\nFix variance issue in\n_IncEx\ntype alias, only allow\nTrue\nby\n@Viicos\nin\n#10414\nFix serialization schema generation when using\nPlainValidator\nby\n@Viicos\nin\n#10427\nFix schema generation error when serialization schema holds references by\n@Viicos\nin\n#10444\nInline references if possible when generating schema for\njson_schema_input_type\nby\n@Viicos\nin\n#10439\nFix recursive arguments in\nRepresentation\nby\n@Viicos\nin\n#10480\nFix representation for builtin function types by\n@kschwab\nin\n#10479\nAdd python validators for decimal constraints (\nmax_digits\nand\ndecimal_places\n) by\n@sydney-runkle\nin\n#10506\nOnly fetch\n__pydantic_core_schema__\nfrom the current class during schema generation by\n@Viicos\nin\n#10518\nFix\nstacklevel\non deprecation warnings for\nBaseModel\nby\n@sydney-runkle\nin\n#10520\nFix warning\nstacklevel\nin\nBaseModel.__init__\nby\n@Viicos\nin\n#10526\nImprove error handling for in-evaluable refs for discriminator application by\n@sydney-runkle\nin\n#10440\nChange the signature of\nConfigWrapper.core_config\nto take the title directly by\n@Viicos\nin\n#10562\nDo not use the previous config from the stack for dataclasses without config by\n@Viicos\nin\n#10576\nFix serialization for IP types with\nmode='python'\nby\n@sydney-runkle\nin\n#10594\nSupport constraint application for\nBase64Etc\ntypes by\n@sydney-runkle\nin\n#10584\nFix\nvalidate_call\nignoring\nField\nin\nAnnotated\nby\n@kc0506\nin\n#10610\nRaise an error when\nSelf\nis invalid by\n@kc0506\nin\n#10609\nUsing\ncore_schema.InvalidSchema\ninstead of metadata injection + checks by\n@sydney-runkle\nin\n#10523\nTweak type alias logic by\n@kc0506\nin\n#10643\nSupport usage of\ntype\nwith\ntyping.Self\nand type aliases by\n@kc0506\nin\n#10621\nUse overloads for\nField\nand\nPrivateAttr\nfunctions by\n@Viicos\nin\n#10651\nClean up the\nmypy\nplugin implementation by\n@Viicos\nin\n#10669\nProperly check for\ntyping_extensions\nvariant of\nTypeAliasType\nby\n@Daraan\nin\n#10713\nAllow any mapping in\nBaseModel.model_copy()\nby\n@Viicos\nin\n#10751\nFix\nisinstance\nbehavior for urls by\n@sydney-runkle\nin\n#10766\nEnsure\ncached_property\ncan be set on Pydantic models by\n@Viicos\nin\n#10774\nFix equality checks for primitives in literals by\n@sydney-runkle\nin\npydantic/pydantic-core#1459\nProperly enforce\nhost_required\nfor URLs by\n@Viicos\nin\npydantic/pydantic-core#1488\nFix when\ncoerce_numbers_to_str\nenabled and string has invalid Unicode character by\n@andrey-berenda\nin\npydantic/pydantic-core#1515\nFix serializing\ncomplex\nvalues in\nEnum\ns by\n@changhc\nin\npydantic/pydantic-core#1524\nRefactor\n_typing_extra\nmodule by\n@Viicos\nin\n#10725\nSupport intuitive equality for urls by\n@sydney-runkle\nin\n#10798\nAdd\nbytearray\nto\nTypeAdapter.validate_json\nsignature by\n@samuelcolvin\nin\n#10802\nEnsure class access of method descriptors is performed when used as a default with\nField\nby\n@Viicos\nin\n#10816\nFix circular import with\nvalidate_call\nby\n@sydney-runkle\nin\n#10807\nFix error when using type aliases referencing other type aliases by\n@Viicos\nin\n#10809\nFix\nIncEx\ntype alias to be compatible with mypy by\n@Viicos\nin\n#10813\nMake\n__signature__\na lazy property, do not deepcopy defaults by\n@Viicos\nin\n#10818\nMake\n__signature__\nlazy for dataclasses, too by\n@sydney-runkle\nin\n#10832\nSubclass all single host url classes from\nAnyUrl\nto preserve behavior from v2.9 by\n@sydney-runkle\nin\n#10856\nNew Contributors\n@jakob-keller\nmade their first contribution in\n#10331\n@MovisLi\nmade their first contribution in\n#10374\n@joaopalmeiro\nmade their first contribution in\n#10405\n@theunkn0wn1\nmade their first contribution in\n#10378\n@cdwilson\nmade their first contribution in\n#10412\n@dlax\nmade their first contribution in\n#10421\n@kschwab\nmade their first contribution in\n#10479\n@santibreo\nmade their first contribution in\n#10453\n@FlorianSW\nmade their first contribution in\n#10478\n@tkasuz\nmade their first contribution in\n#10555\n@AlekseyLobanov\nmade their first contribution in\n#10601\n@NiclasvanEyk\nmade their first contribution in\n#10667\n@mschoettle\nmade their first contribution in\n#10677\n@Daraan\nmade their first contribution in\n#10713\n@k4nar\nmade their first contribution in\n#10736\n@UriyaHarpeness\nmade their first contribution in\n#10740\n@frfahim\nmade their first contribution in\n#10727\nFull Changelog\n:\nv2.9.2...v2.10.0",
    "crawl_status": "success"
  },
  {
    "library_name": "Pydantic",
    "url": "https://github.com/pydantic/pydantic/releases/tag/v2.0",
    "version": "v2.0",
    "title": "Release v2.0 2023-06-30 路 pydantic/pydantic 路 GitHub",
    "release_date": "2023-06-30T16:30:12Z",
    "content": "What's Changed\n Don't recomend to use\nTypeError\non validators by\n@Kludex\nin\n#6179\n Add docs about custom error messages by\n@Kludex\nin\n#6182\nChange allow mutation wording by\n@mark-todd\nin\n#6184\n Improve fields documentation by\n@Kludex\nin\n#6183\nIgnore deprecated methods of\npydantic.main\nin pydocstyle check by\n@hramezani\nin\n#6185\nAnother solution to custom getattr/delattr by\n@dmontagu\nin\n#6165\n Fix\nRootModel\ndefault values by\n@lig\nin\n#5949\nImprove conversion_table by\n@hramezani\nin\n#6186\nUncomment\nfrom_orm\ndeprecated\ndecorator by\n@hramezani\nin\n#6189\nComplete\npydantic/root_model.py\ndocstring by\n@hramezani\nin\n#6193\nComplete\npydantic/functional_validators.py\ndocstrings by\n@hramezani\nin\n#6191\nFix access of 'required' key for TypedDictField in GenerateJsonSchema by\n@adriangb\nin\n#6200\n Use the same conditions on\nsend_tweet\nas\nrelease\nby\n@Kludex\nin\n#6170\n Add migration reference to the \"Import Error\" section by\n@Kludex\nin\n#6208\nImprove\npydantic/mypy.py\ndocstring by\n@hramezani\nin\n#6207\n Update documentation about \"Number Types\" by\n@Kludex\nin\n#6211\nDon't sort model keys by\n@adriangb\nin\n#6212\nAdd documentation for strict mode by\n@tpdorsey\nin\n#6196\nAdd documentation for strict types by\n@tpdorsey\nin\n#6218\nUpdate serialization decorator documentation by\n@tpdorsey\nin\n#6216\nUpdate list and set docs by\n@dmontagu\nin\n#6142\nUpdate docs for sequence_iterable by\n@dmontagu\nin\n#6220\n Add Integration CI workflow for\npydantic-settings\nby\n@lig\nin\n#6221\n猬 Upgrade to pydantic-core 0.41.0 by\n@lig\nin\n#6219\nDocument Strict on Annotated fields by\n@tpdorsey\nin\n#6223\n Fix crash on serializing a union of RootModel and BaseModel by\n@lig\nin\n#6201\nRun docstring tests by\n@dmontagu\nin\n#6175\nAdd documentation for PlainSerializer and WrapSerializer by\n@tpdorsey\nin\n#6230\nImprove mypy documentation by\n@hramezani\nin\n#6226\n Improve error message when BaseSettings is imported by\n@Kludex\nin\n#6229\ncorrect deprecation warning for parse_file by\n@davidhewitt\nin\n#6228\nUpdate migration docs to include a note about\nparse_env_var\nremoval by\n@hramezani\nin\n#6235\nAdd warning about datamodel-code-generator to docs by\n@hramezani\nin\n#6236\nPYD-124: improve docs for\n__get_pydantic_core_schema__\nby\n@adriangb\nin\n#6224\nMinor edits from review of Enum docs by\n@tpdorsey\nin\n#6238\nUpdate and consolidate links in number types by\n@tpdorsey\nin\n#6239\nUpdate V2 vs V1 section in README.md by\n@adriangb\nin\n#6242\nAdd type key to enums by\n@adriangb\nin\n#6243\n Restrict range on Python version for\n_make_forward_ref\nby\n@Kludex\nin\n#6246\n Add timeout on\npublish_docs\njob by\n@Kludex\nin\n#6247\n Enable FastAPI tests by\n@Kludex\nin\n#6249\ndocs: use _pydantic_core.pyi as only docs source for now by\n@davidhewitt\nin\n#6257\nReorder basemodel methods by\n@dmontagu\nin\n#6260\nImprove file type docs by\n@hramezani\nin\n#6252\n Add\nassignees\nlist to the hooky config by\n@lig\nin\n#6264\nDocument \"wrap\" validators by\n@tpdorsey\nin\n#6258\nUpdate validate_call documentation by\n@tpdorsey\nin\n#6255\n Update docs about hypothesis by\n@Kludex\nin\n#6266\nUpdate docs for validation errors by\n@dmontagu\nin\n#6262\n Improve docstrings on\njson_schema.py\nby\n@Kludex\nin\n#6267\nUpdate internal links to be compatible with versions by\n@tpdorsey\nin\n#6271\nUpdate pydantic-core to 0.42.0 by\n@adriangb\nin\n#6272\n Add documentation on Special Types by\n@Kludex\nin\n#6269\nFix deduplication of Enum refs in CoreSchema by\n@adriangb\nin\n#6274\n Remove\nfinal\nkeyword from\nField\nby\n@Kludex\nin\n#6284\nFix relative links for logos by\n@tpdorsey\nin\n#6285\n Fix\nTypeError\non mixed discriminated unions by\n@lig\nin\n#6282\nDefer building discriminated unions until after all schemas are defined by\n@adriangb\nin\n#6288\nUpdate the return type for RootModel.model_dump and document how to override it by\n@dmontagu\nin\n#6290\n Fix\nRootModel.construct()\nand\nRootModel.__init__()\nresults aren't equal by\n@lig\nin\n#6283\nImprove the rendering of the conversion table by\n@dmontagu\nin\n#6275\nFix privateattr clobbering classvars with future annotations by\n@dmontagu\nin\n#6287\nAdd documentation of Strict Mode by\n@dmontagu\nin\n#6276\n Use custom\nPydanticDeprecationWarning\nwarning instead of the generic one by\n@lig\nin\n#6180\nPYD-140: Fix\nuse_enum_values\nconfig flag by\n@adriangb\nin\n#6294\nPYD-142: Fix use of Annotated + Field for dataclasses by\n@adriangb\nin\n#6293\nAdd missing metadata to computed field JSON schemas by\n@dmontagu\nin\n#6299\nMove export_models to serialization by\n@tpdorsey\nin\n#6303\nReview custom types by\n@tpdorsey\nin\n#6292\nImprove types dict mapping doc by\n@hramezani\nin\n#6265\nChange mypy tests to put comments in-line in a python module by\n@dmontagu\nin\n#6305\nUpdate installation for release by\n@tpdorsey\nin\n#6289\nBlog and announce bar for v2 release by\n@tpdorsey\nin\n#6291\nReview and update Standard Types  by\n@tpdorsey\nin\n#6240\nUpdate Pydantic V1 to 1.10.10 by\n@hramezani\nin\n#6311\nDocument validation context, and fix up some other issues with validators.md by\n@dmontagu\nin\n#6256\nadding page about version compatibility by\n@samuelcolvin\nin\n#6309\n Add note about page not up-to-date by\n@Kludex\nin\n#6312\npydantic-core 2.0.1 by\n@samuelcolvin\nin\n#6310\nUpdate mypy plugin by\n@dmontagu\nin\n#6306\nPYD-131 Links between API and usage docs by\n@samuelcolvin\nin\n#6307\nRemove warning on top of\ndocs/usage/types/callables.md\nby\n@hramezani\nin\n#6318\nIndex improvements by\n@samuelcolvin\nin\n#6314\nPrepare for release by\n@samuelcolvin\nin\n#6319\nNew Contributors\n@davidhewitt\nmade their first contribution in\n#6228\nFull Changelog\n:\nv2.0b3...v2.0",
    "crawl_status": "success"
  },
  {
    "library_name": "Celery",
    "url": "https://github.com/celery/celery/releases/tag/v5.4.0",
    "version": "v5.4.0",
    "title": "Release v5.4.0 路 celery/celery 路 GitHub",
    "release_date": "2024-04-17T20:32:41Z",
    "content": "Celery v5.4.0 and v5.3.x have consistently focused on enhancing the overall QA, both internally and externally.\nThis effort led to the new pytest-celery\nv1.0.0\nrelease, developed concurrently with v5.3.0 & v5.4.0.\nThis release introduces two significant QA enhancements:\nSmoke Tests\n: A new layer of automatic tests has been added to Celery's standard CI. These tests are designed to handle production scenarios and complex conditions efficiently. While new contributions will not be halted due to the lack of smoke tests, we will request smoke tests for advanced changes where appropriate.\nStandalone Bug Report Script\n: The new pytest-celery plugin now allows for encapsulating a complete Celery dockerized setup within a single pytest script. Incorporating these into new bug reports will enable us to reproduce reported bugs deterministically, potentially speeding up the resolution process.\nContrary to the positive developments above, there have been numerous reports about issues with the Redis broker malfunctioning upon restarts and disconnections. Our initial attempts to resolve this were not successful (\n#8796\n).\nWith our enhanced QA capabilities, we are now prepared to address the core issue with Redis (as a broker) again.\nThe rest of the changes for this release are grouped below, with the changes from the latest release candidate listed at the end.\nWhat's Changed\nAdd a Task class specialised for Django (\n#8491\n)\nAdd Google Cloud Storage (GCS) backend (\n#8868\n)\nAdded documentation to the smoke tests infra (\n#8970\n)\nAdded a checklist item for using pytest-celery in a bug report (\n#8971\n)\nBugfix: Missing id on chain (\n#8798\n)\nBugfix: Worker not consuming tasks after Redis broker restart (\n#8796\n)\nCatch UnicodeDecodeError when opening corrupt beat-schedule.db (\n#8806\n)\nchore(ci): Enhance CI with\nworkflow_dispatch\nfor targeted debugging and testing (\n#8826\n)\nDoc: Enhance \"Testing with Celery\" section (\n#8955\n)\nDocfix: pip install celery[sqs] -> pip install \"celery[sqs]\" (\n#8829\n)\nEnable efficient\nchord\nwhen using dynamicdb as backend store (\n#8783\n)\nfeat(daemon): allows daemonization options to be fetched from app settings (\n#8553\n)\nFix DeprecationWarning: datetime.datetime.utcnow() (\n#8726\n)\nFix recursive result parents on group in middle of chain (\n#8903\n)\nFix typos and grammar (\n#8915\n)\nFixed version documentation tag from\n#8553\nin configuration.rst (\n#8802\n)\nHotfix: Smoke tests didn't allow customizing the worker's command arguments, now it does (\n#8937\n)\nMake custom remote control commands available in CLI (\n#8489\n)\nPrint safe_say() to stdout for non-error flows (\n#8919\n)\nSupport moto 5.0 (\n#8838\n)\nUpdate contributing guide to use ssh upstream url (\n#8881\n)\nUpdate optimizing.rst (\n#8945\n)\nUpdated concurrency docs page. (\n#8753\n)\nDependencies Updates\nBump actions/setup-python from 4 to 5 (\n#8701\n)\nBump codecov/codecov-action from 3 to 4 (\n#8831\n)\nBump isort from 5.12.0 to 5.13.2 (\n#8772\n)\nBump msgpack from 1.0.7 to 1.0.8 (\n#8885\n)\nBump mypy from 1.8.0 to 1.9.0 (\n#8898\n)\nBump pre-commit to 3.6.1 (\n#8839\n)\nBump pre-commit/action from 3.0.0 to 3.0.1 (\n#8835\n)\nBump pytest from 8.0.2 to 8.1.1 (\n#8901\n)\nBump pytest-celery to v1.0.0 (\n#8962\n)\nBump pytest-cov to 5.0.0 (\n#8924\n)\nBump pytest-order from 1.2.0 to 1.2.1 (\n#8941\n)\nBump pytest-subtests from 0.11.0 to 0.12.1 (\n#8896\n)\nBump pytest-timeout from 2.2.0 to 2.3.1 (\n#8894\n)\nBump python-memcached from 1.59 to 1.61 (\n#8776\n)\nBump sphinx-click from 4.4.0 to 5.1.0 (\n#8774\n)\nUpdate cryptography to 42.0.5 (\n#8869\n)\nUpdate elastic-transport requirement from <=8.12.0 to <=8.13.0 (\n#8933\n)\nUpdate elasticsearch requirement from <=8.12.1 to <=8.13.0 (\n#8934\n)\nUpgraded Sphinx from v5.3.0 to v7.x.x (\n#8803\n)\nChanges since 5.4.0rc2\nUpdate elastic-transport requirement from <=8.12.0 to <=8.13.0 by\n@dependabot\nin\n#8933\nUpdate elasticsearch requirement from <=8.12.1 to <=8.13.0 by\n@dependabot\nin\n#8934\nHotfix: Smoke tests didn't allow customizing the worker's command arguments, now it does by\n@Nusnus\nin\n#8937\nBump pytest-celery to 1.0.0rc3 by\n@Nusnus\nin\n#8946\nUpdate optimizing.rst by\n@alexmclarty\nin\n#8945\nDoc: Enhance \"Testing with Celery\" section by\n@Nusnus\nin\n#8955\nBump pytest-celery to v1.0.0 by\n@Nusnus\nin\n#8962\nBump pytest-order from 1.2.0 to 1.2.1 by\n@dependabot\nin\n#8941\nAdded documentation to the smoke tests infra by\n@Nusnus\nin\n#8970\nAdded a checklist item for using pytest-celery in a bug report by\n@Nusnus\nin\n#8971\nAdded changelog for v5.4.0 by\n@Nusnus\nin\n#8973\nBump version: 5.4.0rc2  5.4.0 by\n@Nusnus\nin\n#8974\nNew Contributors\n@danyi1212\nmade their first contribution in\n#8690\n@Mulugruntz\nmade their first contribution in\n#8696\n@Viicos\nmade their first contribution in\n#8743\n@em1le\nmade their first contribution in\n#8747\n@robotrapta\nmade their first contribution in\n#8753\n@amweiss\nmade their first contribution in\n#8791\n@andyzickler\nmade their first contribution in\n#8806\n@dingxiong\nmade their first contribution in\n#8783\n@Watkurem\nmade their first contribution in\n#8825\n@50-Course\nmade their first contribution in\n#8826\n@s-t-e-v-e-n-k\nmade their first contribution in\n#8838\n@murrple-1\nmade their first contribution in\n#8841\n@hann-wang\nmade their first contribution in\n#8663\n@tobinus\nmade their first contribution in\n#8489\n@haimjether\nmade their first contribution in\n#8868\n@hsujeremy\nmade their first contribution in\n#8881\n@beneltayar\nmade their first contribution in\n#8903\n@carlosp420\nmade their first contribution in\n#8915\n@lukasz-leszczuk-airspace-intelligence\nmade their first contribution in\n#8919\n@alexmclarty\nmade their first contribution in\n#8945\nFull Changelog\n:\nv5.3.6...v5.4.0",
    "crawl_status": "success"
  },
  {
    "library_name": "Celery",
    "url": "https://github.com/celery/celery/releases/tag/v5.5.0",
    "version": "v5.5.0",
    "title": "Release v5.5.0 路 celery/celery 路 GitHub",
    "release_date": "2025-03-31T20:25:24Z",
    "content": "Celery v5.5.0 is now available.\nKey Highlights\nSee\nWhat's new in Celery 5.5\nfor a complete overview or read the main highlights below.\nRedis Broker Stability Improvements\nLong-standing disconnection issues with the Redis broker have been identified and resolved in Kombu 5.5.0, which is included with this release. These improvements significantly enhance stability when using Redis as a broker.\nAdditionally, the Redis backend now has better exception handling with the new\nexception_safe_to_retry\nfeature, which improves resilience during temporary Redis connection issues. See\nRedis backend settings\nfor complete documentation.\nContributed by\n@drienkop\nin\n#9614\n.\npycurl\nreplaced with\nurllib3\nReplaced the\npycurl\ndependency with\nurllib3\n.\nWe're monitoring the performance impact of this change and welcome feedback from users who notice any significant differences in their environments.\nContributed by\n@spawn-guy\nin Kombu\n#2134\nand integrated in Celery via\n#9526\n.\nRabbitMQ Quorum Queues Support\nAdded support for RabbitMQ's new\nQuorum Queues\nfeature, including compatibility with ETA tasks. This implementation has some limitations compared to classic queues, so please refer to the documentation for details.\nNative Delayed Delivery\nis automatically enabled when quorum queues are detected to implement the ETA mechanism.\nSee\nUsing Quorum Queues\nfor complete documentation.\nConfiguration options:\nbroker_native_delayed_delivery_queue_type\n: Specifies the queue type for delayed delivery (default:\nquorum\n)\ntask_default_queue_type\n: Sets the default queue type for tasks (default:\nclassic\n)\nworker_detect_quorum_queues\n: Controls automatic detection of quorum queues (default:\nTrue\n)\nContributed in\n#9207\n,\n#9121\n, and\n#9599\n.\nFor details regarding the 404 errors, see\nNew Year's Security Incident\n.\nSoft Shutdown Mechanism\nSoft shutdown is a time limited warm shutdown, initiated just before the cold shutdown. The worker will allow\nworker_soft_shutdown_timeout\nseconds for all currently executing tasks to finish before it terminates. If the time limit is reached, the worker will initiate a cold shutdown and cancel all currently executing tasks.\nThis feature is particularly valuable when using brokers with visibility timeout mechanisms, such as Redis or SQS. It allows the worker enough time to re-queue tasks that were not completed before exiting, preventing task loss during worker shutdown.\nSee\nStopping the worker\nfor complete documentation on worker shutdown types.\nConfiguration options:\nworker_soft_shutdown_timeout\n: Sets the duration in seconds for the soft shutdown period (default:\n0.0\n, disabled)\nworker_enable_soft_shutdown_on_idle\n: Controls whether soft shutdown should be enabled even when the worker is idle (default:\nFalse\n)\nContributed by\n@Nusnus\nin\n#9213\n,\n#9231\n, and\n#9238\n.\nPydantic Support\nNew native support for Pydantic models in tasks. This integration allows you to leverage Pydantic's powerful data validation and serialization capabilities directly in your Celery tasks.\nExample usage:\nfrom\npydantic\nimport\nBaseModel\nfrom\ncelery\nimport\nCelery\napp\n=\nCelery\n(\n'tasks'\n)\nclass\nArgModel\n(\nBaseModel\n):\nvalue\n:\nint\nclass\nReturnModel\n(\nBaseModel\n):\nvalue\n:\nstr\n@\napp\n.\ntask\n(\npydantic\n=\nTrue\n)\ndef\nx\n(\narg\n:\nArgModel\n)\n->\nReturnModel\n:\n# args/kwargs type hinted as Pydantic model will be converted\nassert\nisinstance\n(\narg\n,\nArgModel\n)\n# The returned model will be converted to a dict automatically\nreturn\nReturnModel\n(\nvalue\n=\nf\"example:\n{\narg\n.\nvalue\n}\n\"\n)\nSee\nArgument validation with Pydantic\nfor complete documentation.\nConfiguration options:\npydantic=True\n: Enables Pydantic integration for the task\npydantic_strict=True/False\n: Controls whether strict validation is enabled (default:\nFalse\n)\npydantic_context={...}\n: Provides additional context for validation\npydantic_dump_kwargs={...}\n: Customizes serialization behavior\nContributed by\n@mathiasertl\nin\n#9023\n,\n#9319\n, and\n#9393\n.\nGoogle Pub/Sub Transport\nNew support for Google Cloud Pub/Sub as a message transport, expanding Celery's cloud integration options.\nSee\nGoogle Pub/Sub Transport\nfor complete documentation.\nFor the Google Pub/Sub support you have to install additional dependencies:\n$ pip install\n\"\ncelery[gcpubsub]\n\"\nThen configure your Celery application to use the Google Pub/Sub transport:\nbroker_url\n=\n'gcpubsub://projects/project-id'\nContributed by\n@haimjether\nin\n#9351\n.\nPython 3.13 Support\nOfficial support for Python 3.13. All core dependencies have been updated to ensure compatibility, including Kombu and py-amqp.\nThis release maintains compatibility with Python 3.8 through 3.13, as well as PyPy 3.10+.\nContributed by\n@Nusnus\nin\n#9309\nand\n#9350\n.\nREMAP_SIGTERM Support\nThe \"REMAP_SIGTERM\" feature, previously undocumented, has been tested, documented, and is now officially supported. This feature allows you to remap the SIGTERM signal to SIGQUIT, enabling you to initiate a soft or cold shutdown using TERM instead of QUIT.\nThis is particularly useful in containerized environments where SIGTERM is the standard signal for graceful termination.\nSee\nCold Shutdown documentation\nfor more info.\nTo enable this feature, set the environment variable:\nexport\nREMAP_SIGTERM=\n\"\nSIGQUIT\n\"\nContributed by\n@Nusnus\nin\n#9461\n.\nDatabase Backend Improvements\nNew\ncreate_tables_at_setup\noption for the database backend. This option controls when database tables are created, allowing for non-lazy table creation.\nBy default (\ncreate_tables_at_setup=True\n), tables are created during backend initialization. Setting this to\nFalse\ndefers table creation until they are actually needed, which can be useful in certain deployment scenarios where you want more control over database schema management.\nSee\nDatabase backend settings\nfor complete documentation.\nConfiguration:\napp\n.\nconf\n.\nresult_backend\n=\n'db+sqlite:///results.db'\napp\n.\nconf\n.\ndatabase_create_tables_at_setup\n=\nFalse\nContributed by\n@MarcBresson\nin\n#9228\n.\nWhat's Changed\n(docs): use correct version celery v.5.4.x by\n@FraCata00\nin\n#8975\nUpdate mypy to 1.10.0 by\n@pyup-bot\nin\n#8977\nLimit pymongo<4.7 when Python <= 3.10 due to breaking changes in 4.7 by\n@Nusnus\nin\n#8988\nBump pytest from 8.1.1 to 8.2.0 by\n@dependabot\nin\n#8987\nUpdate README to Include FastAPI in Framework Integration Section by\n@pedroimpulcetto\nin\n#8978\nClarify return values of ..._on_commit methods by\n@browniebroke\nin\n#8984\nadd kafka broker docs by\n@thuibr\nin\n#8935\nLimit pymongo<4.7 regardless of Python version by\n@Nusnus\nin\n#8999\nUpdate pymongo[srv] requirement from <4.7,>=4.0.2 to >=4.0.2,<4.8 by\n@dependabot\nin\n#9000\nUpdate elasticsearch requirement from <=8.13.0 to <=8.13.1 by\n@dependabot\nin\n#9004\nsecurity: SecureSerializer: support generic low-level serializers by\n@shirsa\nin\n#8982\ndon't kill if pid same as file (\n#8997\n) by\n@lewijw\nin\n#8998\nUpdate cryptography to 42.0.6 by\n@pyup-bot\nin\n#9005\nBump cryptography from 42.0.6 to 42.0.7 by\n@dependabot\nin\n#9009\ndon't kill if pid same as file (\n#8997\n) (\n#8998\n) by\n@lewijw\nin\n#9007\nAdded -vv to unit, integration and smoke tests by\n@Nusnus\nin\n#9014\nSecuritySerializer: ensure pack separator will not be conflicted with serialized fields by\n@shirsa\nin\n#9010\nUpdate sphinx-click to 5.2.2 by\n@pyup-bot\nin\n#9025\nBump sphinx-click from 5.2.2 to 6.0.0 by\n@dependabot\nin\n#9029\nFix a typo to display the help message in first-steps-with-django by\n@ppawlak\nin\n#9036\nPinned requests to v2.31.0 due to docker-py bug\n#3256\nby\n@Nusnus\nin\n#9039\nFix certificate validity check by\n@SPKorhonen\nin\n#9037\nRevert \"Pinned requests to v2.31.0 due to docker-py bug\n#3256\n\" by\n@Nusnus\nin\n#9043\nBump pytest from 8.2.0 to 8.2.1 by\n@dependabot\nin\n#9035\nUpdate elasticsearch requirement from <=8.13.1 to <=8.13.2 by\n@dependabot\nin\n#9045\nFix detection of custom task set as class attribute with Django by\n@browniebroke\nin\n#9038\nUpdate elastic-transport requirement from <=8.13.0 to <=8.13.1 by\n@dependabot\nin\n#9050\nBump pycouchdb from 1.14.2 to 1.16.0 by\n@dependabot\nin\n#9052\nUpdate pytest to 8.2.2 by\n@pyup-bot\nin\n#9060\nBump cryptography from 42.0.7 to 42.0.8 by\n@dependabot\nin\n#9061\nUpdate elasticsearch requirement from <=8.13.2 to <=8.14.0 by\n@dependabot\nin\n#9069\n[enhance feature] Crontab schedule: allow using month names by\n@farahats9\nin\n#9068\nEnhance tox environment: [testenv:clean] by\n@Nusnus\nin\n#9072\nClarify docs about Reserve one task at a time by\n@quique0194\nin\n#9073\nGCS docs fixes by\n@benglewis\nin\n#9075\nUse hub.remove_writer instead of hub.remove for write fds (\n#4185\n) by\n@IdanHaim\nin\n#9055\nClass method to process crontab string by\n@jayeff\nin\n#9079\nFixed smoke tests env bug when using integration tasks that rely on Redis by\n@Nusnus\nin\n#9090\nBugfix - a task will run multiple times when chaining chains with groups by\n@DorSSS\nin\n#9021\nBump mypy from 1.10.0 to 1.10.1 by\n@dependabot\nin\n#9096\nDon't add a separator to global_keyprefix if it already has one by\n@naktinis\nin\n#9080\nUpdate pymongo[srv] requirement from <4.8,>=4.0.2 to >=4.0.2,<4.9 by\n@dependabot\nin\n#9111\nAdded missing import in examples for Django by\n@giovanniacg\nin\n#9099\nBump Kombu to v5.4.0rc1 by\n@Nusnus\nin\n#9117\nRemoved skipping Redis in t/smoke/tests/test_consumer.py tests by\n@Nusnus\nin\n#9118\nUpdate pytest-subtests to 0.13.0 by\n@pyup-bot\nin\n#9120\nIncreased smoke tests CI timeout by\n@Nusnus\nin\n#9122\nBump Kombu to v5.4.0rc2 by\n@Nusnus\nin\n#9127\nUpdate zstandard to 0.23.0 by\n@pyup-bot\nin\n#9129\nUpdate pytest-subtests to 0.13.1 by\n@pyup-bot\nin\n#9130\nChanged retry to tenacity in smoke tests by\n@Nusnus\nin\n#9133\nBump mypy from 1.10.1 to 1.11.0 by\n@dependabot\nin\n#9135\nUpdate cryptography to 43.0.0 by\n@pyup-bot\nin\n#9138\nUpdate pytest to 8.3.1 by\n@pyup-bot\nin\n#9137\nAdded support for Quorum Queues by\n@Nusnus\nin\n#9121\nBump Kombu to v5.4.0rc3 by\n@Nusnus\nin\n#9139\nCleanup in Changelog.rst by\n@Nusnus\nin\n#9141\nUpdate Django docs for CELERY_CACHE_BACKEND by\n@tylerlwsmith\nin\n#9143\nAdded missing docs to previous releases by\n@Nusnus\nin\n#9144\nFixed a few documentation build warnings by\n@Nusnus\nin\n#9145\ndocs(README): link invalid by\n@MerleLiuKun\nin\n#9148\nPrepare for (pre) release: v5.5.0b1 by\n@Nusnus\nin\n#9146\nBump pytest from 8.3.1 to 8.3.2 by\n@dependabot\nin\n#9153\nRemove setuptools deprecated test command from setup.py by\n@sevdog\nin\n#9159\nPin pre-commit to latest version 3.8.0 from Python 3.9 by\n@pyup-bot\nin\n#9156\nBump mypy from 1.11.0 to 1.11.1 by\n@dependabot\nin\n#9164\nChange \"docker-compose\" to \"docker compose\" in Makefile by\n@Nusnus\nin\n#9169\nupdate python versions and docker compose by\n@mathiasertl\nin\n#9171\nAdd support for Pydantic model validation/serialization (fixes\n#8751\n) by\n@mathiasertl\nin\n#9023\nAllow local dynamodb to be installed on another host than localhost by\n@peerjakobsen\nin\n#8965\nTerminate job implementation for gevent concurrency backend by\n@ldsink\nin\n#9083\nBump Kombu to v5.4.0 by\n@Nusnus\nin\n#9177\nAdd check for soft_time_limit and time_limit values by\n@ashm-dev\nin\n#9173\nPrepare for (pre) release: v5.5.0b2 by\n@Nusnus\nin\n#9178\nAdded SQS (localstack) broker to canvas smoke tests by\n@Nusnus\nin\n#9179\nPin elastic-transport to <= latest version 8.15.0 by\n@pyup-bot\nin\n#9182\nUpdate elasticsearch requirement from <=8.14.0 to <=8.15.0 by\n@dependabot\nin\n#9186\nimprove formatting by\n@Bonifacio2\nin\n#9188\nAdd basic helm chart for celery by\n@necromancerthedark\nin\n#9181\nUpdate kafka.rst by\n@lokot0k\nin\n#9194\nUpdate pytest-order to 1.3.0 by\n@pyup-bot\nin\n#9198\nUpdate mypy to 1.11.2 by\n@pyup-bot\nin\n#9206\nall added to routes by\n@dhruvji\nin\n#9204\nFix typos discovered by codespell by\n@cclauss\nin\n#9212\nUse tzdata extras with zoneinfo backports by\n@auvipy\nin\n#8286\nUse\ndocker compose\nin Contributing's doc build section by\n@KeisukeYamashita\nin\n#9219\nFailing test for issue\n#9119\nby\n@mgedmin\nin\n#9215\nFix date_done timezone issue by\n@FKgk\nin\n#8385\nCI Fixes to smoke tests by\n@Nusnus\nin\n#9223\nfix: passes current request context when pushing to request_stack by\n@nikatlas\nin\n#9208\nFix broken link in the Using RabbitMQ docs page by\n@thedrow\nin\n#9226\nAdded Soft Shutdown Mechanism by\n@Nusnus\nin\n#9213\nAdded worker_enable_soft_shutdown_on_idle by\n@Nusnus\nin\n#9231\nBump cryptography from 43.0.0 to 43.0.1 by\n@dependabot\nin\n#9233\nAdded docs regarding the relevancy of soft shutdown and ETA tasks by\n@Nusnus\nin\n#9238\nShow broker_connection_retry_on_startup warning only if it evaluates as False by\n@serl\nin\n#9227\nFixed docker-docs CI failure by\n@Nusnus\nin\n#9240\nAdded docker cleanup auto-fixture to improve smoke tests stability by\n@Nusnus\nin\n#9243\nprint is not thread-safe, so should not be used in signal handler by\n@Zhong-z\nin\n#9222\nPrepare for (pre) release: v5.5.0b3 by\n@Nusnus\nin\n#9244\nCorrect the error description in exception message when validate soft_time_limit by\n@narasux\nin\n#9246\nUpdate msgpack to 1.1.0 by\n@pyup-bot\nin\n#9249\nchore(utils/time.py): rename\n_is_ambigious\n->\n_is_ambiguous\nby\n@pachewise\nin\n#9248\nReduced Smoke Tests to min/max supported python (3.8/3.12) by\n@Nusnus\nin\n#9252\nUpdate pytest to 8.3.3 by\n@pyup-bot\nin\n#9253\nUpdate elasticsearch requirement from <=8.15.0 to <=8.15.1 by\n@dependabot\nin\n#9255\nupdate mongodb without deprecated\n[srv]\nextra requirement by\n@fmigneault\nin\n#9258\nblacksmith.sh: Migrate workflows to Blacksmith by @blacksmith-sh in\n#9261\nFixes\n#9119\n: inject dispatch_uid for retry-wrapped receivers by\n@pachewise\nin\n#9247\nRun all smoke tests CI jobs together by\n@Nusnus\nin\n#9263\nImprove documentation on visibility timeout by\n@kylez-ithaka\nin\n#9264\nBump pytest-celery to 1.1.2 by\n@Nusnus\nin\n#9267\nAdded missing \"app.conf.visibility_timeout\" in smoke tests by\n@Nusnus\nin\n#9266\nImproved stability with t/smoke/tests/test_consumer.py by\n@Nusnus\nin\n#9268\nImproved Redis container stability in the smoke tests by\n@Nusnus\nin\n#9271\nDisabled EXHAUST_MEMORY tests in Smoke-tasks by\n@Nusnus\nin\n#9272\nMarked xfail for test_reducing_prefetch_count with Redis - flaky test by\n@Nusnus\nin\n#9273\nFixed pypy unit tests random failures in the CI by\n@Nusnus\nin\n#9275\nFixed more pypy unit tests random failures in the CI by\n@Nusnus\nin\n#9278\nFix Redis container from aborting randomly by\n@Nusnus\nin\n#9276\nRun Integration & Smoke CI tests together after unit tests passes by\n@Nusnus\nin\n#9280\nAdded \"loglevel verbose\" to Redis containers in smoke tests by\n@Nusnus\nin\n#9282\nFixed Redis error in the smoke tests: \"Possible SECURITY ATTACK detected\" by\n@Nusnus\nin\n#9284\nRefactored the smoke tests github workflow by\n@Nusnus\nin\n#9285\nIncreased --reruns 3->4 in smoke tests by\n@Nusnus\nin\n#9286\nImprove stability of smoke tests (CI and Local) by\n@Nusnus\nin\n#9287\nFixed Smoke tests CI \"test-case\" lables (specific instead of general) by\n@Nusnus\nin\n#9288\nUse assert_log_exists instead of wait_for_log in worker smoke tests by\n@Nusnus\nin\n#9290\nOptimized t/smoke/tests/test_worker.py by\n@Nusnus\nin\n#9291\nEnable smoke tests dockers check before each test starts by\n@Nusnus\nin\n#9292\nRelaxed smoke tests flaky tests mechanism by\n@Nusnus\nin\n#9293\nUpdated quorum queue detection to handle multiple broker instances by\n@bkienker\nin\n#9294\nNon-lazy table creation for database backend by\n@MarcBresson\nin\n#9228\nPin pymongo to latest version 4.9 by\n@pyup-bot\nin\n#9297\nBump pymongo from 4.9 to 4.9.1 by\n@dependabot\nin\n#9298\nBump Kombu to v5.4.2 by\n@Nusnus\nin\n#9304\nUse rabbitmq:3 in stamping smoke tests by\n@Nusnus\nin\n#9307\nBump pytest-celery to 1.1.3 by\n@Nusnus\nin\n#9308\nAdded Python 3.13 Support by\n@Nusnus\nin\n#9309\nAdd log when global qos is disabled by\n@thedrow\nin\n#9296\nAdded official release docs (whatsnew) for v5.5 by\n@Nusnus\nin\n#9312\nEnable Codespell autofix by\n@Nusnus\nin\n#9313\nPydantic typehints: Fix optional, allow generics by\n@mathiasertl\nin\n#9319\nPrepare for (pre) release: v5.5.0b4 by\n@Nusnus\nin\n#9322\nAdded Blacksmith.sh to the Sponsors section in the README by\n@Nusnus\nin\n#9323\nRevert \"Added Blacksmith.sh to the Sponsors section in the README\" by\n@Nusnus\nin\n#9324\nAdded Blacksmith.sh to the Sponsors section in the README by\n@Nusnus\nin\n#9325\nAdded missing \" |oc-sponsor-3| in README by\n@Nusnus\nin\n#9326\nUse Blacksmith SVG logo by\n@Nusnus\nin\n#9327\nUpdated Blacksmith SVG logo by\n@Nusnus\nin\n#9328\nRevert \"Updated Blacksmith SVG logo\" by\n@Nusnus\nin\n#9329\nUpdate pymongo to 4.10.0 by\n@pyup-bot\nin\n#9330\nUpdate pymongo to 4.10.1 by\n@pyup-bot\nin\n#9332\nUpdate user guide to recommend delay_on_commit by\n@browniebroke\nin\n#9333\nPin pre-commit to latest version 4.0.0 (Python 3.9+) by\n@pyup-bot\nin\n#9334\nUpdate ephem to 4.1.6 by\n@pyup-bot\nin\n#9336\nUpdated Blacksmith SVG logo by\n@Nusnus\nin\n#9337\nPrepare for (pre) release: v5.5.0rc1 by\n@Nusnus\nin\n#9341\nFix: Treat dbm.error as a corrupted schedule file by\n@stumpylog\nin\n#9331\nPin pre-commit to latest version 4.0.1 by\n@pyup-bot\nin\n#9343\nAdded Python 3.13 to Dockerfiles by\n@Nusnus\nin\n#9350\nSkip test_pool_restart_import_modules on PyPy due to test issue by\n@Nusnus\nin\n#9352\nUpdate elastic-transport requirement from <=8.15.0 to <=8.15.1 by\n@dependabot\nin\n#9347\nadded dragonfly logo by\n@auvipy\nin\n#9353\nUpdate README.rst by\n@auvipy\nin\n#9354\nUpdate README.rst by\n@auvipy\nin\n#9355\nUpdate mypy to 1.12.0 by\n@pyup-bot\nin\n#9356\nBump Kombu to v5.5.0rc1 by\n@Nusnus\nin\n#9357\nFix\ncelery --loader\noption parsing by\n@0x2b3bfa0\nin\n#9361\nAdd support for Google Pub/Sub transport by\n@haimjether\nin\n#9351\nAdd native incr support for GCSBackend by\n@haimjether\nin\n#9302\nfix(perform_pending_operations): prevent task duplication on shutdown by\n@moaddib666\nin\n#9348\nUpdate grpcio to 1.67.0 by\n@pyup-bot\nin\n#9365\nUpdate google-cloud-firestore to 2.19.0 by\n@pyup-bot\nin\n#9364\nAnnotate celery/utils/timer2.py by\n@hmnfalahi\nin\n#9362\nUpdate cryptography to 43.0.3 by\n@pyup-bot\nin\n#9366\nUpdate mypy to 1.12.1 by\n@pyup-bot\nin\n#9368\nBump mypy from 1.12.1 to 1.13.0 by\n@dependabot\nin\n#9373\nPass timeout and confirm_timeout to producer.publish() by\n@thedrow\nin\n#9374\nBump Kombu to v5.5.0rc2 by\n@Nusnus\nin\n#9382\nBump pytest-cov from 5.0.0 to 6.0.0 by\n@dependabot\nin\n#9388\ndefault strict to False for pydantic tasks by\n@mathiasertl\nin\n#9393\nOnly log that global QoS is disabled if using amqp by\n@thedrow\nin\n#9395\nchore: update sponsorship logo by\n@Niennienzz\nin\n#9398\nAllow custom hostname for celery_worker in celery.contrib.pytest / celery.contrib.testing.worker by\n@SlowMo24\nin\n#9405\nRemoved docker-docs from CI (optional job, malfunctioning) by\n@Nusnus\nin\n#9406\nAdded a utility to format changelogs from the auto-generated GitHub release notes by\n@Nusnus\nin\n#9408\nBump codecov/codecov-action from 4 to 5 by\n@dependabot\nin\n#9412\nUpdate elasticsearch requirement from <=8.15.1 to <=8.16.0 by\n@dependabot\nin\n#9410\nNative Delayed Delivery in RabbitMQ by\n@thedrow\nin\n#9207\nPrepare for (pre) release: v5.5.0rc2 by\n@Nusnus\nin\n#9416\nDocument usage of broker_native_delayed_delivery_queue_type by\n@thedrow\nin\n#9419\nAdjust section in what's new document regarding quorum queues support by\n@thedrow\nin\n#9420\nUpdate pytest-rerunfailures to 15.0 by\n@pyup-bot\nin\n#9422\nDocument group unrolling by\n@thedrow\nin\n#9421\nfix small typo acces -> access by\n@sharuzzaman\nin\n#9434\nUpdate cryptography to 44.0.0 by\n@pyup-bot\nin\n#9437\nAdded pypy to Dockerfile by\n@Nusnus\nin\n#9438\nSkipped flaky tests on pypy (all pass after ~10 reruns) by\n@Nusnus\nin\n#9439\nAllowing managed credentials for azureblockblob by\n@PieterBlomme\nin\n#9430\nAllow passing Celery objects to the Click entry point by\n@0x2b3bfa0\nin\n#9426\nsupport Request termination for gevent by\n@woutdenolf\nin\n#9440\nPrevent event_mask from being overwritten. by\n@Androidown\nin\n#9432\nUpdate pytest to 8.3.4 by\n@pyup-bot\nin\n#9444\nPrepare for (pre) release: v5.5.0rc3 by\n@Nusnus\nin\n#9450\nBugfix: SIGQUIT not initiating cold shutdown when\ntask_acks_late=False\nby\n@Nusnus\nin\n#9461\nFixed pycurl dep with Python 3.8 by\n@Nusnus\nin\n#9471\nUpdate elasticsearch requirement from <=8.16.0 to <=8.17.0 by\n@dependabot\nin\n#9469\nBump pytest-subtests from 0.13.1 to 0.14.1 by\n@dependabot\nin\n#9459\ndocumentation: Added a type annotation to the periodic task example by\n@Avamander\nin\n#9473\nPrepare for (pre) release: v5.5.0rc4 by\n@Nusnus\nin\n#9474\nBump mypy from 1.13.0 to 1.14.0 by\n@dependabot\nin\n#9476\nFix cassandra backend port settings not working by\n@kairi003\nin\n#9465\nUnroll group when a group with a single item is chained using the | operator by\n@thedrow\nin\n#9456\nfix(django): catch the right error when trying to close db connection by\n@Lotram\nin\n#9392\nReplacing a task with a chain which contains a group now returns a result instead of hanging by\n@thedrow\nin\n#9484\nAvoid using a group of one as it is now unrolled into a chain by\n@thedrow\nin\n#9510\nLink to the correct IRC network by\n@yigitsever\nin\n#9509\nBump pytest-github-actions-annotate-failures from 0.2.0 to 0.3.0 by\n@dependabot\nin\n#9504\nUpdate canvas.rst to fix output result from chain object by\n@kamalfarahani\nin\n#9502\nUnauthorized Changes Cleanup by\n@Nusnus\nin\n#9528\n[RE-APPROVED] fix(django): catch the right error when trying to close db connection by\n@Nusnus\nin\n#9529\n[RE-APPROVED] Link to the correct IRC network by\n@Nusnus\nin\n#9531\n[RE-APPROVED] Update canvas.rst to fix output result from chain object by\n@Nusnus\nin\n#9532\nUpdate test-ci-base.txt by\n@auvipy\nin\n#9539\nUpdate install-pyenv.sh by\n@auvipy\nin\n#9540\nUpdate elasticsearch requirement from <=8.17.0 to <=8.17.1 by\n@dependabot\nin\n#9518\nBump google-cloud-firestore from 2.19.0 to 2.20.0 by\n@dependabot\nin\n#9493\nBump mypy from 1.14.0 to 1.14.1 by\n@dependabot\nin\n#9483\nUpdate elastic-transport requirement from <=8.15.1 to <=8.17.0 by\n@dependabot\nin\n#9490\nRevert \"[pre-commit.ci] pre-commit autoupdate\" by\n@Nusnus\nin\n#9545\nUpdate Dockerfile by adding missing Python version 3.13 by\n@auvipy\nin\n#9549\nFix typo for default of sig by\n@daveisfera\nin\n#9495\nfix(crontab): resolve constructor type conflicts by\n@pcrock-thmdo\nin\n#9551\nworker_max_memory_per_child: kilobyte is 1024 bytes by\n@mksm\nin\n#9553\nFix formatting in quorum queue docs by\n@HenrikOssipoff\nin\n#9555\nBump cryptography from 44.0.0 to 44.0.1 by\n@dependabot\nin\n#9556\nFix the send_task method when detecting if the native delayed delivery approach is available by\n@mikhaillazko\nin\n#9552\nReverted PR\n#7814\n& minor code improvement by\n@MehrazRumman\nin\n#9494\nImproved donation and sponsorship visibility by\n@Nusnus\nin\n#9558\nUpdated the Getting Help section, replacing deprecated with new resources by\n@Nusnus\nin\n#9559\nFixed django example by\n@Nusnus\nin\n#9562\nBump Kombu to v5.5.0rc3 by\n@Nusnus\nin\n#9564\nBump ephem from 4.1.6 to 4.2 by\n@dependabot\nin\n#9565\nBump pytest-celery to v1.2.0 by\n@Nusnus\nin\n#9568\nRemove dependency on\npycurl\nby\n@jmsmkn\nin\n#9526\nSet TestWorkController.\ntest\nby\n@WilliamDEdwards\nin\n#9574\nFixed bug when revoking by stamped headers a stamp that does not exist by\n@Nusnus\nin\n#9575\nCanvas Stamping Doc Fixes by\n@Nusnus\nin\n#9578\nBugfix: Chord with a chord in header doesn't invoke error callback on inner chord header failure (default config) by\n@Nusnus\nin\n#9580\nPrepare for (pre) release: v5.5.0rc5 by\n@Nusnus\nin\n#9582\nBump google-cloud-firestore from 2.20.0 to 2.20.1 by\n@dependabot\nin\n#9584\nFix tests with Click 8.2 by\n@cjwatson\nin\n#9590\nBump cryptography from 44.0.1 to 44.0.2 by\n@dependabot\nin\n#9591\nUpdate elasticsearch requirement from <=8.17.1 to <=8.17.2 by\n@dependabot\nin\n#9594\nBump pytest from 8.3.4 to 8.3.5 by\n@dependabot\nin\n#9598\nRefactored and Enhanced DelayedDelivery bootstep by\n@Nusnus\nin\n#9599\nImprove docs about acks_on_failure_or_timeout by\n@ya-pekatoros\nin\n#9577\nUpdate SECURITY.md by\n@Nusnus\nin\n#9609\nremove flake8plus as not needed anymore by\n@auvipy\nin\n#9610\nremove [bdist_wheel] universal = 0  from setup.cfg as not needed by\n@auvipy\nin\n#9611\nremove importlib-metadata as not needed in python3.8 anymore by\n@auvipy\nin\n#9612\nfeat: define exception_safe_to_retry for redisbackend by\n@drienkop\nin\n#9614\nBump Kombu to v5.5.0 by\n@Nusnus\nin\n#9615\nUpdate elastic-transport requirement from <=8.17.0 to <=8.17.1 by\n@dependabot\nin\n#9616\n[docs] fix first-steps by\n@isidroas\nin\n#9618\nRevert \"Improve docs about acks_on_failure_or_timeout\" by\n@auvipy\nin\n#9606\nImprove CI stability and performance by\n@Nusnus\nin\n#9624\nImproved explanation for Database transactions at user guide for tasks by\n@Soham7777777\nin\n#9617\nupdate tests to use python 3.8 codes only by\n@auvipy\nin\n#9627\n#9597\n: Ensure surpassing Hard Timeout limit when task_acks_on_failure_or_timeout is False rejects the task by\n@JacksonKontny\nin\n#9626\nLock Kombu to v5.5.x (using urllib3 instead of pycurl) by\n@Nusnus\nin\n#9632\nLock pytest-celery to v1.2.x (using urllib3 instead of pycurl) by\n@Nusnus\nin\n#9633\nAdd Codecov Test Analytics by\n@JerrySentry\nin\n#9635\nBump Kombu to v5.5.2 by\n@Nusnus\nin\n#9643\nPrepare for release: v5.5.0 by\n@Nusnus\nin\n#9644\nNew Contributors\n@FraCata00\nmade their first contribution in\n#8975\n@pedroimpulcetto\nmade their first contribution in\n#8978\n@thuibr\nmade their first contribution in\n#8935\n@shirsa\nmade their first contribution in\n#8982\n@lewijw\nmade their first contribution in\n#8998\n@ppawlak\nmade their first contribution in\n#9036\n@SPKorhonen\nmade their first contribution in\n#9037\n@farahats9\nmade their first contribution in\n#9068\n@quique0194\nmade their first contribution in\n#9073\n@benglewis\nmade their first contribution in\n#9075\n@IdanHaim\nmade their first contribution in\n#9055\n@jayeff\nmade their first contribution in\n#9079\n@DorSSS\nmade their first contribution in\n#9021\n@naktinis\nmade their first contribution in\n#9080\n@giovanniacg\nmade their first contribution in\n#9099\n@tylerlwsmith\nmade their first contribution in\n#9143\n@MerleLiuKun\nmade their first contribution in\n#9148\n@sevdog\nmade their first contribution in\n#9159\n@peerjakobsen\nmade their first contribution in\n#8965\n@ldsink\nmade their first contribution in\n#9083\n@ashm-dev\nmade their first contribution in\n#9173\n@Bonifacio2\nmade their first contribution in\n#9188\n@necromancerthedark\nmade their first contribution in\n#9181\n@lokot0k\nmade their first contribution in\n#9194\n@dhruvji\nmade their first contribution in\n#9204\n@KeisukeYamashita\nmade their first contribution in\n#9219\n@mgedmin\nmade their first contribution in\n#9215\n@FKgk\nmade their first contribution in\n#8385\n@nikatlas\nmade their first contribution in\n#9208\n@serl\nmade their first contribution in\n#9227\n@narasux\nmade their first contribution in\n#9246\n@fmigneault\nmade their first contribution in\n#9258\n@blacksmith-sh made their first contribution in\n#9261\n@kylez-ithaka\nmade their first contribution in\n#9264\n@bkienker\nmade their first contribution in\n#9294\n@MarcBresson\nmade their first contribution in\n#9228\n@0x2b3bfa0\nmade their first contribution in\n#9361\n@hmnfalahi\nmade their first contribution in\n#9362\n@Niennienzz\nmade their first contribution in\n#9398\n@SlowMo24\nmade their first contribution in\n#9405\n@sharuzzaman\nmade their first contribution in\n#9434\n@PieterBlomme\nmade their first contribution in\n#9430\n@Avamander\nmade their first contribution in\n#9473\n@kairi003\nmade their first contribution in\n#9465\n@Lotram\nmade their first contribution in\n#9392\n@yigitsever\nmade their first contribution in\n#9509\n@kamalfarahani\nmade their first contribution in\n#9502\n@pcrock-thmdo\nmade their first contribution in\n#9551\n@mksm\nmade their first contribution in\n#9553\n@HenrikOssipoff\nmade their first contribution in\n#9555\n@mikhaillazko\nmade their first contribution in\n#9552\n@MehrazRumman\nmade their first contribution in\n#9494\n@jmsmkn\nmade their first contribution in\n#9526\n@ya-pekatoros\nmade their first contribution in\n#9577\n@drienkop\nmade their first contribution in\n#9614\n@isidroas\nmade their first contribution in\n#9618\n@Soham7777777\nmade their first contribution in\n#9617\n@JacksonKontny\nmade their first contribution in\n#9626\n@JerrySentry\nmade their first contribution in\n#9635\nFull Changelog\n:\nv5.4.0...v5.5.0",
    "crawl_status": "success"
  },
  {
    "library_name": "Celery",
    "url": "https://github.com/celery/celery/releases/tag/v5.3.0",
    "version": "v5.3.0",
    "title": "Release v5.3.0 路 celery/celery 路 GitHub",
    "release_date": "2023-06-06T06:02:33Z",
    "content": "Release date: 2023-06-06 12:00 P.M GMT+6\nRelease by: Asif Saif Uddin\nWhat's Changed\nupdate docs by\n@auvipy\nin\n#7196\n[pre-commit.ci] pre-commit autoupdate by\n@pre-commit-ci\nin\n#7197\nRemove Python 3.4 compatibility code by\n@thedrow\nin\n#7205\nupdate docs to fix\n#7203\nby\n@auvipy\nin\n#7209\ncall ping to set connection for avoiding error (take place of\n#7215\n) by\n@uuip\nin\n#7220\nDocumentation updates related to task names by\n@idahogray\nin\n#7223\nUse importlib instead of discouraged pkg_resources by\n@nijel\nin\n#7218\nClarify relation between visibility timeout & predefined queues in SQS by\n@browniebroke\nin\n#7234\nfix\n#7245\nremove duplicated uid in command params by\n@Smixi\nin\n#7246\nfix typo in exception by\n@Sygmei\nin\n#7262\nAnnotate test failures in PRs by\n@thedrow\nin\n#7243\nSet max_line_length in .editorconfig to match flake8 config. by\n@atombrella\nin\n#7263\nFix typo in CELERY_SERIALIZER docs by\n@eldamir\nin\n#7267\nUpdate link to exponential backoff and jitter by\n@DmytroLitvinov\nin\n#7271\nFix subscribed_to maybe empty by\n@uuip\nin\n#7232\nfixed slight comment typo in celery/app/amqp.py by\n@imdark\nin\n#7297\nFix: Celery beat sleeps 300 seconds sometimes even when it should run a task within a few seconds (e.g. 13 seconds)\n#7290\nby\n@rubgombar1\nin\n#7291\nUpdate def tsum references in canvas.rst by\n@mycaule\nin\n#7298\nMake instances of\nparse_page\nconsistent by\n@goldstar611\nin\n#7301\nAdd\nsecurity_key_password\noption by\n@tibotix\nin\n#7292\nSmall documentation update:\ntask\n->\nworker\nby\n@mbyrnepr2\nin\n#7307\nUpdate example in docs by\n@VojtechH\nin\n#7279\ntry new major release of pytest 7 by\n@auvipy\nin\n#7330\nFix typo in feature request issue template. by\n@atombrella\nin\n#7331\nRemove unneeded from\nfuture\nimports in celery.contrib.abortable. by\n@atombrella\nin\n#7332\nbroker_connection_retry\nshould no longer apply on startup by\n@thedrow\nin\n#7300\nRemove\nne\nmethods by\n@atombrella\nin\n#7257\nfix\n#7200\nuid and gid by\n@Smixi\nin\n#7244\nworker: Fix warm shutdown hanging due to timing of signal handler by\n@scottp-dpaw\nin\n#7339\n[pre-commit.ci] pre-commit autoupdate by\n@pre-commit-ci\nin\n#7352\nupdate website url in README by\n@dulmandakh\nin\n#7354\nFix Get Started links by\n@gitdoluquita\nin\n#7359\ndoc: fix broken reference to schedule.is_due method by\n@hoefling\nin\n#7357\nUpdate the package links. by\n@mvaled\nin\n#7373\nUpdate remaining website URL in README by\n@jlost\nin\n#7374\nAdd\nmypy\nto the pipeline by\n@Kludex\nin\n#7383\nFix typo in comment by\n@Exifers\nin\n#7397\nAnnotate\ncelery/states.py\nby\n@Kludex\nin\n#7395\nIgnore coverage on\nTYPE_CHECKING\nby\n@Kludex\nin\n#7400\nExpose more debugging information when receiving unkown tasks by\n@thedrow\nin\n#7405\nUpdate sphinx-click to 3.1.0 by\n@pyup-bot\nin\n#7411\nPin pytest-subtests to latest version 0.7.0 by\n@pyup-bot\nin\n#7415\nPin pre-commit to latest version 2.18.1 by\n@pyup-bot\nin\n#7417\nPin msgpack to latest version 1.0.3 by\n@pyup-bot\nin\n#7418\nPin sqlalchemy to latest version 1.4.34 by\n@pyup-bot\nin\n#7412\nPin pycouchdb to latest version 1.14.1 by\n@pyup-bot\nin\n#7421\nUpdate sphinx-testing to 1.0.1 by\n@pyup-bot\nin\n#7410\nPin pytest to latest version 7.1.1 by\n@pyup-bot\nin\n#7413\nPin cryptography to latest version 36.0.2 by\n@pyup-bot\nin\n#7419\nUpdate pydocumentdb to 2.3.5 by\n@pyup-bot\nin\n#7420\nPin pyro4 to latest version 4.82 by\n@pyup-bot\nin\n#7425\nPin pylibmc to latest version 1.6.1 by\n@pyup-bot\nin\n#7423\nPin python-memcached to latest version 1.59 by\n@pyup-bot\nin\n#7424\nPin codecov to latest version 2.1.12 by\n@pyup-bot\nin\n#7428\nPin kombu to latest version 5.2.4 by\n@pyup-bot\nin\n#7427\nPin ephem to latest version 4.1.3 by\n@pyup-bot\nin\n#7430\nBackport\n#7406\nto 5.2 by\n@thedrow\nin\n#7431\nRevert \"Backport\n#7406\nto 5.2\" by\n@thedrow\nin\n#7432\nUpdate documentation on docs/userguide/application.rst file by\n@krauss\nin\n#7438\nUpdated logo url in readme by\n@thejeshgn\nin\n#7439\nUpdate sphinx-click to 4.0.0 by\n@pyup-bot\nin\n#7440\nAvoid importing buf_t from billiard's compat module as it was removed. by\n@thedrow\nin\n#7446\nAvoid negating a constant in a loop. by\n@thedrow\nin\n#7443\nEnsure expiration is of float type when migrating tasks by\n@damjankuznar\nin\n#7385\n[pre-commit.ci] pre-commit autoupdate by\n@pre-commit-ci\nin\n#7450\nAnnotate\ncelery/fixups\nby\n@Kludex\nin\n#7399\nFix: code block formatting for task deprecation by\n@marksweb\nin\n#7453\nUpdate sphinx-click to 4.0.1 by\n@pyup-bot\nin\n#7454\nceleryproject.org links in github templates by\n@tisdall\nin\n#7442\nfix userguide deamonizing by changing the systemd --version by system by\n@simon-mazenoux\nin\n#7457\nUpdate sphinx-click to 4.0.2 by\n@pyup-bot\nin\n#7459\nload_extension_class_names - correct module_name by\n@DamianZaremba\nin\n#7406\nIntegration test fix by\n@dobosevych\nin\n#7460\ndocs: Move task sidebar blocks into main column [\n#7449\n] by\n@marksweb\nin\n#7463\ntry pymongo[srv]>=4.0.2 by\n@auvipy\nin\n#7469\nEnsure task compression actually happens when setting\ntask_compression\nby\n@thedrow\nin\n#7470\nRabbitmq CI integration by\n@dobosevych\nin\n#7472\nUpdate sphinx-click to 4.0.3 by\n@pyup-bot\nin\n#7473\nUse inspect.getgeneratorstate in asynpool.gen_not_started by\n@colesbury\nin\n#7476\nExtend cassandra to cover AstraDB as well by\n@hemidactylus\nin\n#7356\nupdate actions v3+ by\n@auvipy\nin\n#7477\ndocs: fix userguide test with missing .get() by\n@simon-mazenoux\nin\n#7479\nConfig file for pyup.io by\n@pyup-bot\nin\n#7142\nMissing\nf\nprefix on f-strings fix by\n@code-review-doctor\nin\n#7481\nFix eventlet example from not running. by\n@Galdanwing\nin\n#7487\nazure-storage-blob>=12.11.0 by\n@auvipy\nin\n#7494\nUpdate old link to new website by\n@imapanda\nin\n#7499\nmodify libs and os by\n@auvipy\nin\n#7504\nMake start_worker, setup_default_app reusable outside of pytest by\n@yonran\nin\n#7503\nfix undefined variable in retry example code by\n@tisdall\nin\n#7514\nrevert\n#5941\nso note below makes sense again by\n@tisdall\nin\n#7441\nFix incompability with new couchbase version by\n@dobosevych\nin\n#7518\n[pre-commit.ci] pre-commit autoupdate by\n@pre-commit-ci\nin\n#7520\ndocs: Linking a task to a group does\nnot\nguarantee all group tasks will finish first by\n@ymorgenstern\nin\n#7522\nUpdate error message to link to celeryq.dev by\n@troyswanson\nin\n#7521\nEnsure a proper error message is raised when id for key is empty by\n@thedrow\nin\n#7447\nUpdate setup.py by removing comma by\n@auvipy\nin\n#7534\nAdd notes about ignore_result attribute regarding canvas by\n@Aktan-A\nin\n#7541\npytest-subtests==0.8.0 by\n@auvipy\nin\n#7545\nredis>=4.2.2 by\n@auvipy\nin\n#7493\ncryptography~=37.0.1 by\n@auvipy\nin\n#7492\nCrontab string representation does not match UNIX crontab expression by\n@espoirMur\nin\n#7259\nWorker should exit with ctx.exit to get the right exitcode for non-zero cases by\n@palfrey\nin\n#7544\nboto3>=1.22.2 by\n@auvipy\nin\n#7496\ncassandra-driver>=3.25.0,<4 by\n@auvipy\nin\n#7495\npyArango>=2.0.1 by\n@auvipy\nin\n#7491\nFix expiration check by\n@dobosevych\nin\n#7552\nUse\ncallable\nbuilt-in by\n@gabrielsoldani\nin\n#7553\nInclude\ndont_autoretry_for\noption in tasks. by\n@dobosevych\nin\n#7556\nonly pull requests and some other updates by\n@auvipy\nin\n#7559\nsetup-python v4 by\n@auvipy\nin\n#7558\nfix: Syntax error in arango query by\n@aquiline\nin\n#7554\nFix custom headers propagation on task retries by\n@shedar\nin\n#7555\n[pre-commit.ci] pre-commit autoupdate by\n@pre-commit-ci\nin\n#7567\nbilliard & other update by\n@auvipy\nin\n#7489\nScheduled weekly dependency update for week 24 by\n@pyup-bot\nin\n#7566\ndocs: assorted fixes by\n@atiabbz\nin\n#7572\n[Documentation] Fix order of arguments for clarity by\n@EricAtORS\nin\n#7543\nRemoved Flower monitor screenshot by\n@javad94\nin\n#7579\nScheduled weekly dependency update for week 25 by\n@pyup-bot\nin\n#7589\nSilence backend warning when eager results are stored by\n@kwikwag\nin\n#7268\nReduce prefetch count on restart and gradually restore it by\n@thedrow\nin\n#7350\nUpdate CONTRIBUTORS.txt by\n@alekibango\nin\n#7590\nModify example debug_task to ignore result by\n@wieczorek1990\nin\n#7594\nMinor refactors, found by static analysis by\n@gabrielsoldani\nin\n#7587\nImprove workflow primitive subclassing by\n@EricAtORS\nin\n#7593\ntest kombu>=5.3.0a1,<6.0 by\n@auvipy\nin\n#7598\nCanvas Header Stamping by\n@dobosevych\nin\n#7384\nUpdate task-rejected signature by\n@kackyt\nin\n#7599\nasync chords should pass it's kwargs to the group/body by\n@EricAtORS\nin\n#7597\nbeat: Suppress banner output with the quiet option by\n@gabrielsoldani\nin\n#7608\nFix honor Django's TIME_ZONE setting by\n@vanschelven\nin\n#7613\nFix link to open source tripwire in docs by\n@charlax\nin\n#7621\nDon't warn about DEBUG=True for Django by\n@vanschelven\nin\n#7626\nScheduled weekly dependency update for week 29 by\n@pyup-bot\nin\n#7638\nFixed the\non_after_finalize\ncannot access\ntasks\ndue to deadlock(Fixes\n#3589\n) by\n@954-Ivory\nin\n#7652\nUpdate tasks.rst by\n@denys-pidlisnyi\nin\n#7653\nFix errors on code blocks rendering in docs by\n@hoefling\nin\n#7655\nkombu>=5.3.0b1,<6.0 by\n@auvipy\nin\n#7659\nupdate docs website link by\n@xncbf\nin\n#7660\nfix doc rendering issues, part I by\n@hoefling\nin\n#7656\nMake default worker state limits configurable by\n@gabrielsoldani\nin\n#7609\nOnly clear the cache if there are no active writers. by\n@naomielst\nin\n#7273\nBLM-2: Adding unit tests to chord clone by\n@Nusnus\nin\n#7668\nFix unknown task error typo by\n@dcecile\nin\n#7675\nrename redis integration test class so that tests are executed by\n@wochinge\nin\n#7684\nCheck certificate/private key type when loading them by\n@qrmt\nin\n#7680\nAdded integration test_chord_header_id_duplicated_on_rabbitmq_msg_duplication() by\n@Nusnus\nin\n#7692\nNew feature flag: allow_error_cb_on_chord_header - allowing setting an error callback on chord header by\n@Nusnus\nin\n#7712\nUpdate README.rst sorting Python/Celery versions by\n@andrebr\nin\n#7714\nFixed a bug where stamping a chord body would not use the correct stamping method by\n@Nusnus\nin\n#7722\nFixed doc duplication typo for Signature.stamp() by\n@Nusnus\nin\n#7725\nFix issue 7726: variable used in finally block may not be instantiated by\n@woutdenolf\nin\n#7727\nFixed bug in chord stamping with another chord as a body + unit test by\n@Nusnus\nin\n#7730\nUse \"describe_table\" not \"create_table\" to check for existence of DynamoDB table by\n@maxfirman\nin\n#7734\nEnhancements for task_allow_error_cb_on_chord_header tests and docs by\n@Nusnus\nin\n#7744\nImproved custom stamping visitor documentation by\n@Nusnus\nin\n#7745\nImproved the coverage of test_chord_stamping_body_chord() by\n@Nusnus\nin\n#7748\nbilliard >= 3.6.3.0,<5.0 for rpm by\n@auvipy\nin\n#7764\n[pre-commit.ci] pre-commit autoupdate by\n@pre-commit-ci\nin\n#7625\nFixed memory leak with ETA tasks at connection error when worker_cancel_long_running_tasks_on_connection_loss is enabled  by\n@Nusnus\nin\n#7771\nFixed bug where a chord with header of type\ntuple\nwas not supported in the link_error flow for task_allow_error_cb_on_chord_header flag by\n@Nusnus\nin\n#7772\nScheduled weekly dependency update for week 38 by\n@pyup-bot\nin\n#7767\nrecreate_module: set\nspec\nto the new module by\n@skshetry\nin\n#7773\n[pre-commit.ci] pre-commit autoupdate by\n@pre-commit-ci\nin\n#7775\nOverride integration test config using integration-tests-config.json by\n@thedrow\nin\n#7778\nFixed error handling bugs due to upgrade to a newer version of billiard by\n@Nusnus\nin\n#7781\nDo not recommend using easy_install anymore by\n@jugmac00\nin\n#7789\nGitHub Workflows security hardening by\n@sashashura\nin\n#7768\nUpdate ambiguous acks_late doc by\n@Zhong-z\nin\n#7728\n[pre-commit.ci] pre-commit autoupdate by\n@pre-commit-ci\nin\n#7799\nbilliard >=4.0.2,<5.0 by\n@auvipy\nin\n#7720\nimportlib_metadata remove deprecated entry point interfaces by\n@woutdenolf\nin\n#7785\nScheduled weekly dependency update for week 41 by\n@pyup-bot\nin\n#7798\npyzmq>=22.3.0 by\n@auvipy\nin\n#7497\nRemove\namqp\nfrom the\nBACKEND_ALISES\nlist by\n@Kludex\nin\n#7805\nReplace\nprint\nby\nlogger.debug\nby\n@Kludex\nin\n#7809\nIgnore coverage on\nexcept ImportError\nby\n@Kludex\nin\n#7812\nAdd mongodb dependencies to test.txt by\n@Kludex\nin\n#7810\nFix grammar typos on the whole project by\n@Kludex\nin\n#7815\nRemove\nisatty\nwrapper function by\n@Kludex\nin\n#7814\nRemove unused variable\n_range\nby\n@Kludex\nin\n#7813\nAdd type annotation on\nconcurrency/threads.py\nby\n@Kludex\nin\n#7808\nFix linter workflow by\n@Kludex\nin\n#7816\n[pre-commit.ci] pre-commit autoupdate by\n@pre-commit-ci\nin\n#7822\nScheduled weekly dependency update for week 42 by\n@pyup-bot\nin\n#7821\nRemove\n.cookiecutterrc\nby\n@Kludex\nin\n#7830\nRemove\n.coveragerc\nfile by\n@Kludex\nin\n#7826\nkombu>=5.3.0b2 by\n@auvipy\nin\n#7834\nFix readthedocs build failure by\n@woutdenolf\nin\n#7835\nFixed bug in group, chord, chain stamp() method, where the visitor overrides the previously stamps in tasks of these objects by\n@Nusnus\nin\n#7825\nStabilized test_mutable_errback_called_by_chord_from_group_fail_multiple by\n@Nusnus\nin\n#7837\nUse SPDX license expression in project metadata by\n@RazerM\nin\n#7845\nNew control command\nrevoke_by_stamped_headers\nby\n@Nusnus\nin\n#7838\nClarify wording in Redis priority docs by\n@strugee\nin\n#7853\nFix non working example of using celery_worker pytest fixture by\n@paradox-lab\nin\n#7857\nRemoved the mandatory requirement to include\nstamped_headers\nkey when implementing\non_signature()\nby\n@Nusnus\nin\n#7856\nUpdate serializer docs by\n@sondrelg\nin\n#7858\nRemove reference to old Python version by\n@Kludex\nin\n#7829\nAdded on_replace() to Task to allow manipulating the replaced sig with custom changes at the end of the task.replace() by\n@Nusnus\nin\n#7860\n[pre-commit.ci] pre-commit autoupdate by\n@pre-commit-ci\nin\n#7869\nAdd clarifying information to completed_count documentation by\n@hankehly\nin\n#7873\nStabilized\ntest_revoked_by_headers_complex_canvas\nby\n@Nusnus\nin\n#7877\nStampingVisitor will visit the callbacks and errbacks of the signature by\n@Nusnus\nin\n#7867\nFix \"rm: no operand\" error in clean-pyc script by\n@hankehly\nin\n#7878\nAdd --skip-checks flag to bypass django core checks by\n@mudetz\nin\n#7859\nScheduled weekly dependency update for week 44 by\n@pyup-bot\nin\n#7868\nAdded two new unit tests to callback stamping by\n@Nusnus\nin\n#7882\nSphinx extension: use inspect.signature to make it Python 3.11 compatible by\n@mathiasertl\nin\n#7879\ncryptography==38.0.3 by\n@auvipy\nin\n#7886\nCanvas.py doc enhancement by\n@Nusnus\nin\n#7889\nFix typo by\n@sondrelg\nin\n#7890\nfix typos in optional tests by\n@hsk17\nin\n#7876\nCanvas.py doc enhancement by\n@Nusnus\nin\n#7891\nFix revoke by headers tests stability by\n@Nusnus\nin\n#7892\nfeat: add global keyprefix for backend result keys by\n@kaustavb12\nin\n#7620\nCanvas.py doc enhancement by\n@Nusnus\nin\n#7897\nfix(sec): upgrade sqlalchemy to 1.2.18 by\n@chncaption\nin\n#7899\nCanvas.py doc enhancement by\n@Nusnus\nin\n#7902\n[pre-commit.ci] pre-commit autoupdate by\n@pre-commit-ci\nin\n#7904\nFix test warnings by\n@ShaheedHaque\nin\n#7906\nSupport for out-of-tree worker pool implementations by\n@ShaheedHaque\nin\n#7880\nCanvas.py doc enhancement by\n@Nusnus\nin\n#7907\nUse bound task in base task example. Closes\n#7909\nby\n@WilliamDEdwards\nin\n#7910\nAllow the stamping visitor itself to set the stamp value type instead of casting it to a list by\n@Nusnus\nin\n#7914\nStamping a task left the task properties dirty by\n@Nusnus\nin\n#7916\n[pre-commit.ci] pre-commit autoupdate by\n@pre-commit-ci\nin\n#7917\nFixed bug when chaining a chord with a group by\n@Nusnus\nin\n#7919\nFixed bug in the stamping visitor mechanism where the request was lacking the stamps in the 'stamps' property by\n@Nusnus\nin\n#7928\nFixed bug in task_accepted() where the request was not added to the\nrequests\nbut only to the\nactive_requests\nby\n@Nusnus\nin\n#7929\nFix bug in TraceInfo._log_error() where the real exception obj was hiding behind 'ExceptionWithTraceback' by\n@Nusnus\nin\n#7930\nAdded integration test: test_all_tasks_of_canvas_are_stamped() by\n@Nusnus\nin\n#7931\nAdded new example for the stamping mechanism: examples/stamping by\n@Nusnus\nin\n#7933\nFixed a bug where replacing a stamped task and stamping it again by\n@Nusnus\nin\n#7934\nBugfix for nested group stamping on task replace by\n@Nusnus\nin\n#7935\nAdded integration test test_stamping_example_canvas() by\n@Nusnus\nin\n#7937\nFixed a bug in losing chain links when unchaining an inner chain with links by\n@Nusnus\nin\n#7938\nRemoving as not mandatory by\n@auvipy\nin\n#7885\nHousekeeping for Canvas.py by\n@Nusnus\nin\n#7942\n[pre-commit.ci] pre-commit autoupdate by\n@pre-commit-ci\nin\n#7927\nScheduled weekly dependency update for week 50 by\n@pyup-bot\nin\n#7954\ntry pypy 3.9 in CI by\n@auvipy\nin\n#7956\nsqlalchemy==1.4.45 by\n@auvipy\nin\n#7943\nbilliard>=4.1.0,<5.0 by\n@auvipy\nin\n#7957\nfeat(typecheck): allow changing type check behavior on the app level; by\n@moaddib666\nin\n#7952\nAdd broker_channel_error_retry option by\n@nkns165\nin\n#7951\nAdd beat_cron_starting_deadline_seconds to prevent unwanted cron runs by\n@asnoeyink\nin\n#7945\n[pre-commit.ci] pre-commit autoupdate by\n@pre-commit-ci\nin\n#7966\nScheduled weekly dependency update for week 51 by\n@pyup-bot\nin\n#7965\nAdded doc to \"retry_errors\" newly supported field of \"publish_retry_policy\" of the task namespace by\n@Nusnus\nin\n#7967\nRenamed from master to main in the docs and the CI workflows by\n@Nusnus\nin\n#7968\nFix docs for the exchange to use with worker_direct by\n@alessio-b2c2\nin\n#7973\nPin redis==4.3.4 by\n@auvipy\nin\n#7974\nreturn list of nodes to make sphinx extension compatible with Sphinx 6.0 by\n@mathiasertl\nin\n#7978\nuse version range redis>=4.2.2,<4.4.0 by\n@auvipy\nin\n#7980\n[pre-commit.ci] pre-commit autoupdate by\n@pre-commit-ci\nin\n#7982\nScheduled weekly dependency update for week 01 by\n@pyup-bot\nin\n#7987\nAdd annotations to minimise differences with celery-aio-pool's tracer.py. by\n@ShaheedHaque\nin\n#7925\nFixed bug where linking a stamped task did not add the stamp to the link's options by\n@Nusnus\nin\n#7992\nsqlalchemy==1.4.46 by\n@auvipy\nin\n#7995\npytz by\n@auvipy\nin\n#8002\nFix few typos, provide configuration + workflow for codespell to catch any new by\n@yarikoptic\nin\n#8023\nRabbitMQ links update by\n@arnisjuraga\nin\n#8031\nIgnore files generated by tests by\n@Kludex\nin\n#7846\nRevert \"sqlalchemy==1.4.46 (\n#7995\n)\" by\n@Nusnus\nin\n#8033\n[pre-commit.ci] pre-commit autoupdate by\n@pre-commit-ci\nin\n#8039\nFixed bug with replacing a stamped task with a chain or a group (inc. links/errlinks) by\n@Nusnus\nin\n#8034\nFixed formatting in setup.cfg that caused flake8 to misbehave by\n@Nusnus\nin\n#8044\nRemoved duplicated import Iterable by\n@Nusnus\nin\n#8046\nFix docs by\n@Nusnus\nin\n#8047\nDocument --logfile default by\n@strugee\nin\n#8057\nStamping Mechanism Refactoring by\n@Nusnus\nin\n#8045\nresult_backend_thread_safe config shares backend across threads by\n@CharlieTruong\nin\n#8058\nFix cronjob that use day of month and negative UTC timezone by\n@pkyosx\nin\n#8053\nStamping Mechanism Examples Refactoring by\n@Nusnus\nin\n#8060\nFixed bug in Task.on_stamp_replaced() by\n@Nusnus\nin\n#8061\n[pre-commit.ci] pre-commit autoupdate by\n@pre-commit-ci\nin\n#8065\nStamping Mechanism Refactoring 2 by\n@Nusnus\nin\n#8064\nChanged default append_stamps from True to False (meaning duplicates  by\n@Nusnus\nin\n#8068\ntypo in comment: mailicious => malicious by\n@yanick\nin\n#8072\nFix command for starting flower with specified broker URL by\n@ShukantPal\nin\n#8071\nImprove documentation on ETA/countdown tasks (\n#8069\n) by\n@norbertcyran\nin\n#8075\n[pre-commit.ci] pre-commit autoupdate by\n@pre-commit-ci\nin\n#8079\nfix functiom name by\n@cuishuang\nin\n#8087\nUpdate CELERY_TASK_EAGER setting in user guide by\n@thebalaa\nin\n#8085\nStamping documentation fixes & cleanups by\n@Nusnus\nin\n#8092\nswitch to maintained pyro5 by\n@auvipy\nin\n#8093\nudate dependencies of tests by\n@auvipy\nin\n#8095\ncryptography==39.0.1 by\n@auvipy\nin\n#8096\nAnnotate\ncelery/security/certificate.py\nby\n@Kludex\nin\n#7398\nDeprecate parse_iso8601 in favor of fromisoformat by\n@stumpylog\nin\n#8098\npytest==7.2.2 by\n@auvipy\nin\n#8106\nType annotations for\ncelery/utils/text.py\nby\n@max-muoto\nin\n#8107\nUpdate web framework URLs by\n@sblondon\nin\n#8112\nFix contribution URL by\n@sblondon\nin\n#8111\nTrying to clarify CERT_REQUIRED by\n@pamelafox\nin\n#8113\nFix potential AttributeError on 'stamps' by\n@Darkheir\nin\n#8115\nType annotations for\ncelery/apps/beat.py\nby\n@max-muoto\nin\n#8108\nFixed bug where retrying a task loses its stamps by\n@Nusnus\nin\n#8120\nType hints for\ncelery/schedules.py\nby\n@max-muoto\nin\n#8114\n[pre-commit.ci] pre-commit autoupdate by\n@pre-commit-ci\nin\n#8122\nReference Gopher Celery in README by\n@marselester\nin\n#8131\nUpdate sqlalchemy.txt by\n@auvipy\nin\n#8136\nazure-storage-blob 12.15.0 by\n@auvipy\nin\n#8137\ntest kombu 5.3.0b3 by\n@auvipy\nin\n#8138\nfix: add expire string parse. by\n@Bidaya0\nin\n#8134\nFix worker crash on un-pickleable exceptions by\n@youtux\nin\n#8133\nCLI help output: avoid text rewrapping by click by\n@woutdenolf\nin\n#8152\nWarn when an unnamed periodic task override another one. by\n@iurisilvio\nin\n#8143\nFix\nTask.handle_ignore\nnot wrapping exceptions properly by\n@youtux\nin\n#8149\nHotfix for (\n#8120\n) - Stamping bug with retry by\n@Nusnus\nin\n#8158\nFix integration test by\n@youtux\nin\n#8156\nFixed bug in revoke_by_stamped_headers where impl did not match doc by\n@Nusnus\nin\n#8162\nAlign revoke and revoke_by_stamped_headers return values (terminate=True) by\n@Nusnus\nin\n#8163\nUpdate & simplify GHA pip caching by\n@stumpylog\nin\n#8164\nUpdate auth.txt by\n@auvipy\nin\n#8167\nUpdate test.txt versions by\n@auvipy\nin\n#8173\nremove extra = from test.txt by\n@auvipy\nin\n#8179\nUpdate sqs.txt kombu[sqs]>=5.3.0b3 by\n@auvipy\nin\n#8174\nAdded signal triggered before fork by\n@jaroslawporada\nin\n#8177\nUpdate documentation on SQLAlchemy by\n@max-muoto\nin\n#8188\nDeprecate pytz and use zoneinfo by\n@max-muoto\nin\n#8159\n[pre-commit.ci] pre-commit autoupdate by\n@pre-commit-ci\nin\n#8191\nUpdate dev.txt by\n@auvipy\nin\n#8192\nUpdate test.txt by\n@auvipy\nin\n#8193\nUpdate test-integration.txt by\n@auvipy\nin\n#8194\nUpdate zstd.txt by\n@auvipy\nin\n#8195\nUpdate s3.txt by\n@auvipy\nin\n#8196\nUpdate msgpack.txt by\n@auvipy\nin\n#8199\nUpdate solar.txt by\n@auvipy\nin\n#8198\nAdd Semgrep to CI by\n@Nusnus\nin\n#8201\nAdded semgrep to README.rst by\n@Nusnus\nin\n#8202\nUpdate django.txt by\n@auvipy\nin\n#8197\nUpdate redis.txt 4.3.6 by\n@auvipy\nin\n#8161\nstart removing codecov from pypi by\n@auvipy\nin\n#8206\nUpdate test.txt dependencies by\n@auvipy\nin\n#8205\nImproved doc for: worker_deduplicate_successful_tasks by\n@Nusnus\nin\n#8209\nRenamed revoked_headers to revoked_stamps by\n@Nusnus\nin\n#8210\n[pre-commit.ci] pre-commit autoupdate by\n@pre-commit-ci\nin\n#8223\nEnsure argument for\nmap\nis JSON serializable by\n@candleindark\nin\n#8229\n[pre-commit.ci] pre-commit autoupdate by\n@pre-commit-ci\nin\n#8239\nChangelog hotfix by\n@Nusnus\nin\n#8245\nadd missing dependency by\n@woutdenolf\nin\n#8247\nchore(build): clean\nsetup.py\nby\n@stegayet\nin\n#8248\n[pre-commit.ci] pre-commit autoupdate by\n@pre-commit-ci\nin\n#8252\nUpdate test-ci-base.txt by\n@auvipy\nin\n#8255\nUpdate test.txt dependencies by\n@auvipy\nin\n#8263\nFix exc_type being exception instance rather than type by\n@Mapiarz\nin\n#8257\nUpdate default.txt to 5.3.0rc1 by\n@auvipy\nin\n#8264\nFixed revoking tasks by stamped headers by\n@Nusnus\nin\n#8269\nstart adding sqla v 2.0 compatibility by\n@auvipy\nin\n#8050\nSupport sqlalchemy 2.0 in tests by\n@danigm\nin\n#8271\nUpdate test-ci-base.txt by\n@auvipy\nin\n#8273\nUpdate sqs.txt kombu 5.3.0rc1 by\n@auvipy\nin\n#8274\nFix docker by\n@Nusnus\nin\n#8275\nUpdate default.txt by\n@auvipy\nin\n#8277\nUpdate redis.txt 4.5 by\n@auvipy\nin\n#8278\nUpdate pkgutils.txt by\n@auvipy\nin\n#8279\nremove python 3.7 from tests by\n@auvipy\nin\n#8280\nugrade syntax to py3.8 by\n@auvipy\nin\n#8281\nUpdate setup.cfg by\n@auvipy\nin\n#8287\nUpdate dynamodb.txt deps by\n@auvipy\nin\n#8291\nUpdate auth.txt 41.0.1 by\n@auvipy\nin\n#8290\nUpdate librabbitmq.txt > 2.0.0 by\n@auvipy\nin\n#8292\ntest kombu 5.3.0 & minor doc update by\n@auvipy\nin\n#8294\nWhatsnew in Celery 5.3.0 by\n@auvipy\nin\n#8300\nNew Contributors\n@uuip\nmade their first contribution in\n#7220\n@idahogray\nmade their first contribution in\n#7223\n@Smixi\nmade their first contribution in\n#7246\n@Sygmei\nmade their first contribution in\n#7262\n@eldamir\nmade their first contribution in\n#7267\n@imdark\nmade their first contribution in\n#7297\n@rubgombar1\nmade their first contribution in\n#7291\n@mycaule\nmade their first contribution in\n#7298\n@goldstar611\nmade their first contribution in\n#7301\n@tibotix\nmade their first contribution in\n#7292\n@mbyrnepr2\nmade their first contribution in\n#7307\n@VojtechH\nmade their first contribution in\n#7279\n@scottp-dpaw\nmade their first contribution in\n#7339\n@gitdoluquita\nmade their first contribution in\n#7359\n@hoefling\nmade their first contribution in\n#7357\n@jlost\nmade their first contribution in\n#7374\n@Kludex\nmade their first contribution in\n#7383\n@Exifers\nmade their first contribution in\n#7397\n@krauss\nmade their first contribution in\n#7438\n@thejeshgn\nmade their first contribution in\n#7439\n@damjankuznar\nmade their first contribution in\n#7385\n@marksweb\nmade their first contribution in\n#7453\n@tisdall\nmade their first contribution in\n#7442\n@simon-mazenoux\nmade their first contribution in\n#7457\n@DamianZaremba\nmade their first contribution in\n#7406\n@colesbury\nmade their first contribution in\n#7476\n@hemidactylus\nmade their first contribution in\n#7356\n@code-review-doctor\nmade their first contribution in\n#7481\n@Galdanwing\nmade their first contribution in\n#7487\n@imapanda\nmade their first contribution in\n#7499\n@yonran\nmade their first contribution in\n#7503\n@ymorgenstern\nmade their first contribution in\n#7522\n@troyswanson\nmade their first contribution in\n#7521\n@Aktan-A\nmade their first contribution in\n#7541\n@espoirMur\nmade their first contribution in\n#7259\n@palfrey\nmade their first contribution in\n#7544\n@gabrielsoldani\nmade their first contribution in\n#7553\n@aquiline\nmade their first contribution in\n#7554\n@shedar\nmade their first contribution in\n#7555\n@atiabbz\nmade their first contribution in\n#7572\n@EricAtORS\nmade their first contribution in\n#7543\n@javad94\nmade their first contribution in\n#7579\n@kwikwag\nmade their first contribution in\n#7268\n@alekibango\nmade their first contribution in\n#7590\n@wieczorek1990\nmade their first contribution in\n#7594\n@kackyt\nmade their first contribution in\n#7599\n@vanschelven\nmade their first contribution in\n#7613\n@charlax\nmade their first contribution in\n#7621\n@954-Ivory\nmade their first contribution in\n#7652\n@denys-pidlisnyi\nmade their first contribution in\n#7653\n@dcecile\nmade their first contribution in\n#7675\n@wochinge\nmade their first contribution in\n#7684\n@qrmt\nmade their first contribution in\n#7680\n@andrebr\nmade their first contribution in\n#7714\n@maxfirman\nmade their first contribution in\n#7734\n@skshetry\nmade their first contribution in\n#7773\n@jugmac00\nmade their first contribution in\n#7789\n@sashashura\nmade their first contribution in\n#7768\n@strugee\nmade their first contribution in\n#7853\n@sondrelg\nmade their first contribution in\n#7858\n@hankehly\nmade their first contribution in\n#7873\n@mudetz\nmade their first contribution in\n#7859\n@hsk17\nmade their first contribution in\n#7876\n@kaustavb12\nmade their first contribution in\n#7620\n@chncaption\nmade their first contribution in\n#7899\n@nkns165\nmade their first contribution in\n#7951\n@asnoeyink\nmade their first contribution in\n#7945\n@alessio-b2c2\nmade their first contribution in\n#7973\n@yarikoptic\nmade their first contribution in\n#8023\n@arnisjuraga\nmade their first contribution in\n#8031\n@CharlieTruong\nmade their first contribution in\n#8058\n@pkyosx\nmade their first contribution in\n#8053\n@yanick\nmade their first contribution in\n#8072\n@ShukantPal\nmade their first contribution in\n#8071\n@norbertcyran\nmade their first contribution in\n#8075\n@cuishuang\nmade their first contribution in\n#8087\n@thebalaa\nmade their first contribution in\n#8085\n@max-muoto\nmade their first contribution in\n#8107\n@sblondon\nmade their first contribution in\n#8112\n@pamelafox\nmade their first contribution in\n#8113\n@marselester\nmade their first contribution in\n#8131\n@Bidaya0\nmade their first contribution in\n#8134\n@youtux\nmade their first contribution in\n#8133\n@iurisilvio\nmade their first contribution in\n#8143\n@jaroslawporada\nmade their first contribution in\n#8177\n@candleindark\nmade their first contribution in\n#8229\n@stegayet\nmade their first contribution in\n#8248\n@Mapiarz\nmade their first contribution in\n#8257\n@danigm\nmade their first contribution in\n#8271\nFull Changelog\n:\nv5.2.7...v5.3.0",
    "crawl_status": "success"
  },
  {
    "library_name": "Pillow",
    "url": "https://github.com/python-pillow/Pillow/releases/tag/12.0.0",
    "version": "12.0.0",
    "title": "Release 12.0.0 路 python-pillow/Pillow 路 GitHub",
    "release_date": "2025-10-15T18:27:27Z",
    "content": "https://pillow.readthedocs.io/en/stable/releasenotes/12.0.0.html\nRemovals\nRemove support for FreeType <= 2.9.0\n#9159\n[\n@radarhere\n]\nDrop support for Python 3.9\n#9119\n[\n@hugovk\n]\nRemove deprecations for Pillow 12.0.0\n#9053\n[\n@radarhere\n]\nDeprecations\nDeprecate Image._show\n#9186\n[\n@radarhere\n]\nDeprecate ImageCmsProfile product_name and product_info\n#8995\n[\n@lukegb\n]\nDocumentation\nImagingHistogramInstance can use two bands\n#9251\n[\n@radarhere\n]\nUpdate 12.0.0 release notes\n#9247\n[\n@hugovk\n]\nAdded ImageDraw alpha channel examples\n#9201\n[\n@radarhere\n]\nUpdate Python version\n#9230\n[\n@radarhere\n]\nUpdated macOS tested Pillow versions\n#9209\n[\n@radarhere\n]\nAdd GitHub profile link to release notes\n#9197\n[\n@radarhere\n]\nSplit versionadded info\n#9190\n[\n@radarhere\n]\nDocument ImageFile.MAXBLOCK\n#9163\n[\n@radarhere\n]\nUpdated macOS version in CI targets\n#9157\n[\n@radarhere\n]\nFix typos\n#9135\n[\n@radarhere\n]\nAdded \"Colors\" to concepts\n#9067\n[\n@radarhere\n]\nUpdate macOS tested Pillow versions\n#9068\n[\n@radarhere\n]\nThanks, folks!\n#9056\n[\n@aclark4life\n]\nSetup nit: \"fork\" should be lowercased\n#9055\n[\n@aclark4life\n]\nDependencies\nUpdate dependency cibuildwheel to v3.2.1\n#9246\n[@\nrenovate[bot]\n]\n[pre-commit.ci] pre-commit autoupdate\n#9233\n[@\npre-commit-ci[bot]\n]\nUpdate harfbuzz to 12.1.0\n#9218\n[\n@radarhere\n]\nUpdate libtiff to 4.7.1\n#9222\n[\n@radarhere\n]\nUpdate FreeType to 2.14.1 on macOS and Linux wheels\n#9217\n[\n@radarhere\n]\nUpdate dependency cibuildwheel to v3.2.0\n#9219\n[@\nrenovate[bot]\n]\nUpdate Ghostscript to 10.6.0\n#9202\n[\n@radarhere\n]\nUpdate openjpeg to 2.5.4\n#9215\n[\n@radarhere\n]\nUpdate harfbuzz to 11.5.0\n#9203\n[\n@radarhere\n]\nUpdate dependency mypy to v1.18.2\n#9213\n[@\nrenovate[bot]\n]\nUpdate dependency mypy to v1.18.1\n#9207\n[@\nrenovate[bot]\n]\nUpdate github-actions\n#9194\n[@\nrenovate[bot]\n]\nUpdated harfbuzz to 11.4.5\n#9150\n[\n@radarhere\n]\nUpdate zlib-ng to 2.2.5\n#9140\n[\n@radarhere\n]\nUpdate raqm to 0.10.3\n#9137\n[\n@radarhere\n]\nUpdate libjpeg-turbo to 3.1.2\n#9188\n[\n@radarhere\n]\n[pre-commit.ci] pre-commit autoupdate\n#9180\n[@\npre-commit-ci[bot]\n]\nUpdate dependency cibuildwheel to v3.1.4\n#9164\n[@\nrenovate[bot]\n]\nUpdate actions/checkout action to v5\n#9156\n[@\nrenovate[bot]\n]\nUpdate actions/download-artifact action to v5\n#9141\n[@\nrenovate[bot]\n]\nUpdated harfbuzz to 11.3.3\n#9103\n[\n@radarhere\n]\n[pre-commit.ci] pre-commit autoupdate\n#9131\n[@\npre-commit-ci[bot]\n]\nUpdated libimagequant to 4.4.0\n#9074\n[\n@radarhere\n]\nUpdate dependency mypy to v1.17.1\n#9130\n[@\nrenovate[bot]\n]\nUpdate dependency cibuildwheel to v3.1.3\n#9129\n[@\nrenovate[bot]\n]\nUpdate dependency cibuildwheel to v3.1.2\n#9118\n[@\nrenovate[bot]\n]\nUpdated libpng to 1.6.50\n#9058\n[\n@radarhere\n]\nUpdate cygwin/cygwin-install-action action to v6\n#9108\n[@\nrenovate[bot]\n]\nUpdate dependency mypy to v1.17.0\n#9092\n[@\nrenovate[bot]\n]\nUpdated libwebp to 1.6.0\n#9082\n[\n@radarhere\n]\nUpdate dependency cibuildwheel to v3.0.1\n#9075\n[@\nrenovate[bot]\n]\n[pre-commit.ci] pre-commit autoupdate\n#9073\n[@\npre-commit-ci[bot]\n]\nTesting\nCheck return types\n#9045\n[\n@radarhere\n]\nUpgrade from macos-13\n#9212\n[\n@radarhere\n]\nWheels CI: Check number of expected dists\n#9239\n[\n@hugovk\n]\nAssert image type\n#8845\n[\n@radarhere\n]\nTest GD transparency\n#9196\n[\n@radarhere\n]\nTest mode when saving PPM images\n#9195\n[\n@radarhere\n]\nTest unsupported BMP bitfields layout\n#9193\n[\n@radarhere\n]\nUpdate Ghostscript to 10.6.0\n#9202\n[\n@radarhere\n]\nUse monkeypatch\n#9192\n[\n@radarhere\n]\nAlways check XMLPacket value\n#9113\n[\n@radarhere\n]\nRename variable to not shadow import\n#9124\n[\n@radarhere\n]\nRemoved unused code\n#9182\n[\n@radarhere\n]\nAdd has_feature_version helper\n#9172\n[\n@radarhere\n]\nReplace print with assert\n#9171\n[\n@radarhere\n]\nAdd Debian 13 Trixie\n#9147\n[\n@hugovk\n]\nDo not import from Tests directory in checks\n#9143\n[\n@radarhere\n]\nImprove features test coverage\n#9077\n[\n@radarhere\n]\nRemove WebP feature handling\n#9096\n[\n@radarhere\n]\nUpdate for pyroma 5.0\n#9093\n[\n@radarhere\n]\nImprove WmfImagePlugin test coverage\n#9090\n[\n@radarhere\n]\nImprove DdsImagePlugin test coverage\n#9091\n[\n@radarhere\n]\nImprove ImageMath test coverage\n#9087\n[\n@radarhere\n]\nFix unclosed file warning\n#9065\n[\n@radarhere\n]\nPyroma now supports PEP 639\n#9064\n[\n@radarhere\n]\nType hints\nInstall arro3 dependencies when type checking\n#9254\n[\n@radarhere\n]\nCheck return types\n#9045\n[\n@radarhere\n]\nAssert image type\n#8845\n[\n@radarhere\n]\nMove imports into TYPE_CHECKING\n#9123\n[\n@radarhere\n]\nRemove support for NumPy 1.20 when type checking\n#9125\n[\n@radarhere\n]\nOther changes\nUse macos-14 for iOS arm64 simulator\n#9258\n[\n@hugovk\n]\nUse enums for Modes and RawModes in C\n#9256\n[\n@radarhere\n]\nAdd ImageText\n#9098\n[\n@radarhere\n]\nShift bits before making value negative\n#9255\n[\n@radarhere\n]\nSupport saving variable length rational TIFF tags by default\n#9241\n[\n@radarhere\n]\nAdded four private SGI TIFF tags\n#9245\n[\n@radarhere\n]\nBand names for arrow exported images\n#9099\n[\n@wiredfool\n]\nUse macos-latest for iOS arm64 simulator\n#9250\n[\n@radarhere\n]\nIf pasting an image onto itself at a lower position, copy from bottom\n#8882\n[\n@radarhere\n]\nRemoved unused access for I;32L and I;32B\n#9238\n[\n@radarhere\n]\nCorrected scientific-python-nightly-wheels pattern\n#9252\n[\n@radarhere\n]\nRun sdist when scheduled, but do not upload to scientific-python-nightly-wheels index\n#9248\n[\n@radarhere\n]\nRemoved shebang lines and executable flags\n#9179\n[\n@radarhere\n]\nRemove Pillow version from PDF comment\n#9176\n[\n@radarhere\n]\nSupport saving variable length rational TIFF tags\n#9111\n[\n@radarhere\n]\nBuild Python 3.14 on macOS 10.15\n#9234\n[\n@radarhere\n]\nTest largest CUR cursor\n#9191\n[\n@radarhere\n]\nDo not unnecessarily update FLI __offset\n#9184\n[\n@radarhere\n]\nFill alpha channel when quantizing RGB images\n#9133\n[\n@radarhere\n]\nAllow RGBA palettes to work with ImageOps.expand()\n#9138\n[\n@radarhere\n]\nFixed loading rotated PCD images\n#9177\n[\n@radarhere\n]\nCast before shifting bits\n#9236\n[\n@radarhere\n]\nUse _ensure_mutable()\n#9200\n[\n@radarhere\n]\nSeek past BeginBinary data when parsing EPS metadata\n#9211\n[\n@radarhere\n]\nDo not allow negative offset with memory mapping\n#9235\n[\n@radarhere\n]\nClear C image when MPO frame image size changes\n#9208\n[\n@radarhere\n]\nWhen converting RGBA to PA, use RGB to P quantization\n#9153\n[\n@radarhere\n]\nRemove use of sudo from libavif and raqm install scripts\n#9231\n[\n@radarhere\n]\nLoad image palette into Python after converting to PA\n#9152\n[\n@radarhere\n]\nCheck all reserved bytes in FLI header\n#9183\n[\n@radarhere\n]\nLimit length of read operation in ImageFont._load_pilfont_data()\n#9181\n[\n@radarhere\n]\nPython 3.9 wheels are no longer needed\n#9214\n[\n@radarhere\n]\nRemove unused Image _expand()\n#9227\n[\n@radarhere\n]\nUpdated FreeType to 2.14.1 on Windows\n#9206\n[\n@radarhere\n]\nOnly deprecate fromarray mode for changing data types\n#9063\n[\n@radarhere\n]\nFix reading RGB and CMYK IPTC images\n#9088\n[\n@radarhere\n]\nInstall zstd for libtiff on Linux wheels\n#9097\n[\n@radarhere\n]\nImprove WalImageFile test coverage\n#9189\n[\n@radarhere\n]\nImageMorph operations must have length 1\n#9102\n[\n@radarhere\n]\nSet correct size for rotated PCD images after opening\n#9086\n[\n@radarhere\n]\nSimplify check for GBR width and height\n#9089\n[\n@radarhere\n]\nMake in parallel when building libjpeg-turbo and openjpeg for macOS and Linux wheels\n#9144\n[\n@radarhere\n]\nFix ZeroDivisionError in ImageStat\n#9105\n[\n@radarhere\n]\nWhen deleting EXIF IFD tag, delete IFD data\n#9083\n[\n@radarhere\n]\nAllow alpha_composite to use LA images\n#9066\n[\n@radarhere\n]\nImprove _accept length check\n#9170\n[\n@radarhere\n]\nDo not set core to DeferredError\n#9166\n[\n@radarhere\n]\nUse macos-14 for iOS arm64 simulator\n#9161\n[\n@radarhere\n]\nMake in parallel when building brotli and libavif for macOS and Linux wheels\n#9142\n[\n@radarhere\n]\nUse Python 3.14 for gcc problem matching\n#9134\n[\n@radarhere\n]\nAdd libavif support for iOS\n#9117\n[\n@freakboy3742\n]\nRestore pyroma test for iOS\n#9116\n[\n@freakboy3742\n]\nUse correct bands for two band histograms\n#9054\n[\n@radarhere\n]\nAdd support for Python 3.14\n#9120\n[\n@hugovk\n]\nDrop support for PyPy3.10\n#9112\n[\n@radarhere\n]\nAdd parallel compile from pybind11\n#8990\n[\n@wiredfool\n]\nRemove unused _save_cjpeg\n#9084\n[\n@radarhere\n]\nEnsure dynamic libjpeg libraries are not linked\n#9081\n[\n@freakboy3742\n]\nRemove reference to libtiff 3.x\n#9072\n[\n@radarhere\n]\nRestored manylinux2014 wheels\n#9059\n[\n@radarhere\n]",
    "crawl_status": "success"
  },
  {
    "library_name": "Pillow",
    "url": "https://github.com/python-pillow/Pillow/releases/tag/10.0.0",
    "version": "10.0.0",
    "title": "Release 10.0.0 路 python-pillow/Pillow 路 GitHub",
    "release_date": "2023-07-01T14:57:17Z",
    "content": "https://pillow.readthedocs.io/en/stable/releasenotes/10.0.0.html\nRemovals\nRemove deprecated ImageFont.getsize and related functions for Pillow 10.0.0\n#7080\n[\n@radarhere\n]\nRemove deprecations for Pillow 10.0.0\n#7059\n[\n@hugovk\n]\nDrop support for soon-EOL Python 3.7\n#7058\n[\n@hugovk\n]\nDeprecations\nDo not use CFFI access by default on PyPy\n#7236\n[\n@radarhere\n]\nChanges\nFixed deallocating mask images\n#7246\n[\n@radarhere\n]\nAdded ImageFont.MAX_STRING_LENGTH\n#7244\n[\n@radarhere\n]\nFix Windows build with pyproject.toml\n#7230\n[\n@nulano\n]\nDo not close provided file handles with libtiff\n#7199\n[\n@radarhere\n]\nConvert to HSV if mode is HSV in getcolor()\n#7226\n[\n@radarhere\n]\nAdded alpha_only argument to getbbox()\n#7123\n[\n@radarhere\n]\nPrioritise speed in\nrepr_png\n#7242\n[\n@radarhere\n]\nLimit size even if one dimension is zero in decompression bomb check\n#7235\n[\n@radarhere\n]\nRestored 32-bit support\n#7234\n[\n@radarhere\n]\nRemoved deleted file from codecov.yml and increased coverage threshold\n#7232\n[\n@radarhere\n]\nRemoved support for 32-bit\n#7228\n[\n@radarhere\n]\nUse --config-settings instead of deprecated --global-option\n#7171\n[\n@radarhere\n]\nBetter C integer definitions\n#6645\n[\n@Yay295\n]\nFixed finding dependencies on Cygwin\n#7175\n[\n@radarhere\n]\nImproved checks in font_render\n#7218\n[\n@radarhere\n]\nChange\ngrabclipboard()\nto use PNG compression on macOS\n#7219\n[\n@abey79\n]\nAdded PyPy 3.10 and removed PyPy 3.8\n#7216\n[\n@radarhere\n]\nAdded in_place argument to ImageOps.exif_transpose()\n#7092\n[\n@radarhere\n]\nCorrected error code\n#7177\n[\n@radarhere\n]\nUse \"not in\"\n#7174\n[\n@radarhere\n]\nOnly call text_layout once in getmask2\n#7206\n[\n@radarhere\n]\nFixed calling putpalette() on L and LA images before load()\n#7187\n[\n@radarhere\n]\nRemoved unused INT64 definition\n#7180\n[\n@radarhere\n]\nUpdated xz to 5.4.3\n#7136\n[\n@radarhere\n]\nFixed saving TIFF multiframe images with LONG8 tag types\n#7078\n[\n@radarhere\n]\nDo not set size unnecessarily if image fails to open\n#7056\n[\n@radarhere\n]\nRemoved unused code\n#7210\n[\n@radarhere\n]\nRemoved unused variables\n#7205\n[\n@radarhere\n]\nFixed signedness comparison warning\n#7203\n[\n@radarhere\n]\nFixed combining single duration across duplicate APNG frames\n#7146\n[\n@radarhere\n]\nRemove temporary file when error is raised\n#7148\n[\n@radarhere\n]\nDo not use temporary file when grabbing clipboard on Linux\n#7200\n[\n@radarhere\n]\nIf the clipboard fails to open on Windows, wait and try again\n#7141\n[\n@radarhere\n]\nFixed saving multiple 1 mode frames to GIF\n#7181\n[\n@radarhere\n]\nReplaced absolute PIL import with relative import\n#7173\n[\n@radarhere\n]\nRemoved files and types override\n#7194\n[\n@radarhere\n]\nRemoved duplicate config\n#7193\n[\n@radarhere\n]\nReplaced deprecated Py_FileSystemDefaultEncoding for Python >= 3.12\n#7192\n[\n@radarhere\n]\nImproved wl-paste mimetype handling in ImageGrab\n#7094\n[\n@rrcgat\n]\nUpdated redirected URLs\n#7178\n[\n@radarhere\n]\nAdded\nrepr_jpeg\n() for IPython display_jpeg\n#7135\n[\n@n3011\n]\nUse \"/sbin/ldconfig\" if ldconfig is not found\n#7068\n[\n@radarhere\n]\nPrefer screenshots using XCB over gnome-screenshot\n#7143\n[\n@nulano\n]\nFixed joined corners for ImageDraw rounded_rectangle() odd dimensions\n#7151\n[\n@radarhere\n]\nSupport reading signed 8-bit TIFF images\n#7111\n[\n@radarhere\n]\nAdded width argument to ImageDraw regular_polygon\n#7132\n[\n@radarhere\n]\nSupport I mode for ImageFilter.BuiltinFilter\n#7108\n[\n@radarhere\n]\nRaise error from stderr of Linux ImageGrab.grabclipboard() command\n#7112\n[\n@radarhere\n]\nUpdated libimagequant to 4.2.0\n#7128\n[\n@radarhere\n]\nAdded unpacker from I;16B to I;16\n#7125\n[\n@radarhere\n]\nUse stdlib for setuptools on MinGW\n#7131\n[\n@radarhere\n]\n[pre-commit.ci] pre-commit autoupdate\n#7129\n[\n@pre-commit-ci\n]\nSupport float font sizes\n#7107\n[\n@radarhere\n]\nUse later value for duplicate xref entries in PdfParser\n#7102\n[\n@radarhere\n]\nLoad before getting size in\ngetstate\n#7105\n[\n@bigcat88\n]\nAdded Fedora 38\n#7109\n[\n@radarhere\n]\nRemoved duplicate code\n#7106\n[\n@radarhere\n]\nRemove use of deprecated OpenJPEG \"bpp\" member\n#7090\n[\n@radarhere\n]\nSelect Python version in Cygwin\n#7091\n[\n@radarhere\n]\nUpdated nasm to 2.16.01\n#7089\n[\n@radarhere\n]\nUpdate vendored Raqm to 0.10.1\n#7087\n[\n@nulano\n]\n10.0.0.dev0 version bump\n#7057\n[\n@radarhere\n]\nFixed type handling for include and lib directories\n#7069\n[\n@adisbladis\n]\nDo not install PyQt6-Qt6 6.5.0\n#7081\n[\n@radarhere\n]\nRemoved FIXME comment\n#7072\n[\n@radarhere\n]\n[pre-commit.ci] pre-commit autoupdate\n#7063\n[\n@pre-commit-ci\n]\nDependencies\nUpdated libtiff to 4.5.1\n#7233\n[\n@radarhere\n]\nUpdated libwebp to 1.3.1\n#7238\n[\n@radarhere\n]\nUpdated freetype to 2.13.1\n#7231\n[\n@radarhere\n]\nUpdated fribidi to 1.0.13\n#7166\n[\n@radarhere\n]\nUpdated harfbuzz to 7.3.0\n#7152\n[\n@radarhere\n]\nUpdated harfbuzz to 7.2.0\n#7118\n[\n@radarhere\n]\nUpdate cygwin/cygwin-install-action action to v4\n#7099\n[\n@renovate\n]\nUpdated raqm to 0.10.1\n#7088\n[\n@radarhere\n]\nDocumentation\nAdded release notes for\n#7123\n#7243\n[\n@radarhere\n]\nImage.open()\nseeks to the start of file objects\n#7097\n[\n@radarhere\n]\nAdded release notes for\n#7235\n#7239\n[\n@radarhere\n]\nUpdate Image.show docs to list all viewers used on Linux\n#7229\n[@RoziePlaysPython]\nDocument how to install on MinGW when setuptools >= 60\n#7224\n[\n@radarhere\n]\nClarify that the changelog should not be updated in PRs\n#7220\n[\n@radarhere\n]\nMoved QOI from Write-Only to Read-Only\n#7212\n[\n@radarhere\n]\nImproved documention of \"corners\" argument for rounded_rectangle\n#7211\n[\n@radarhere\n]\nRemoved rectangle example from co-ordinate system documentation\n#7169\n[\n@radarhere\n]\nDocument order of kernel weights\n#7204\n[\n@radarhere\n]\nBuild only PDF in addition to default html\n#7164\n[\n@hugovk\n]\nImageGrab grabclipboard() is supported on Linux\n#7160\n[\n@radarhere\n]\nClarify that line() and polygon() include xy pixels\n#7142\n[\n@radarhere\n]\nUpdated redirected URL\n#7157\n[\n@radarhere\n]\nUpdated ImagePath tolist() default\n#7138\n[\n@radarhere\n]\nAdded release notes for\n#7132\n#7134\n[\n@radarhere\n]\nBuild all readthedocs formats\n#7116\n[\n@radarhere\n]\nUpdated macOS tested Pillow versions\n#7103\n[\n@radarhere\n]\nFix typo\n#7101\n[\n@hugovk\n]\nRelease refinement\n#7074\n[\n@hugovk\n]\nImprove ImageEnhance factor documentation\n#7065\n[\n@radarhere\n]\nTesting\nbench_cffi_access print formatting\n#7227\n[\n@Yay295\n]\nAdd Debian 12 Bookworm\n#7208\n[\n@hugovk\n]\nFix Python 3.12 failures\n#7188\n[\n@radarhere\n]\nTest lists and tuples\n#6949\n[\n@Yay295\n]\nTest both lists and tuples as qtables arguments\n#6900\n[\n@Yay295\n]\nMore ImagePath tests\n#6904\n[\n@Yay295\n]\nRemoved Ubuntu 18.04 docker image\n#7115\n[\n@radarhere\n]\nRemoved Fedora 36\n#7098\n[\n@radarhere\n]\nFix codecov after they deleted the Python package from PyPI\n#7085\n[\n@hugovk\n]\nInstall libxcb-cursor0\n#7083\n[\n@radarhere\n]\nAdd release check to make sure no TODOs remain in release notes\n#7075\n[\n@hugovk\n]",
    "crawl_status": "success"
  },
  {
    "library_name": "Pillow",
    "url": "https://github.com/python-pillow/Pillow/releases/tag/10.4.0",
    "version": "10.4.0",
    "title": "Release 10.4.0 路 python-pillow/Pillow 路 GitHub",
    "release_date": "2024-07-01T09:51:39Z",
    "content": "https://pillow.readthedocs.io/en/stable/releasenotes/10.4.0.html\nDeprecations\nDeprecate non-image ImageCms modes\n#8031\n[\n@radarhere\n]\nDeprecate ImageDraw.getdraw hints parameter\n#8124\n[\n@radarhere\n]\nDeprecate BGR;15, BGR;16 and BGR;24 modes\n#7978\n[\n@radarhere\n]\nDeprecate support for libtiff < 4\n#7998\n[\n@radarhere\n]\nChanges\nRaise FileNotFoundError if show_file() path does not exist\n#8178\n[\n@radarhere\n]\nImproved reading 16-bit TGA images with colour\n#7965\n[\n@Yay295\n]\nFixed processing multiple JPEG EXIF markers\n#8127\n[\n@radarhere\n]\nDo not preserve EXIFIFD tag by default when saving TIFF images\n#8110\n[\n@radarhere\n]\nAdded ImageFont.load_default_imagefont()\n#8086\n[\n@radarhere\n]\nAdded Image.WARN_POSSIBLE_FORMATS\n#8063\n[\n@radarhere\n]\nDo not presume \"xmp\" info simply because \"XML:com.adobe.xmp\" info exists\n#8173\n[\n@radarhere\n]\nRemove zero-byte end padding when parsing any XMP data\n#8171\n[\n@radarhere\n]\nDo not detect Ultra HDR images as MPO\n#8056\n[\n@radarhere\n]\nRaise SyntaxError specific to JP2\n#8146\n[\n@Yay295\n]\nDo not use first frame duration for other frames when saving APNG images\n#8104\n[\n@radarhere\n]\nConsider I;16 pixel size when using a 1 mode mask\n#8112\n[\n@radarhere\n]\nWhen saving multiple PNG frames, convert to mode rather than raw mode\n#8087\n[\n@radarhere\n]\nAdded byte support to FreeTypeFont\n#8141\n[\n@radarhere\n]\nAllow float center for rotate operations\n#8114\n[\n@radarhere\n]\nDo not read layers immediately when opening PSD images\n#8039\n[\n@radarhere\n]\nRestore original thread state\n#8065\n[\n@radarhere\n]\nRead IM and TIFF images as RGB, rather than RGBX\n#7997\n[\n@radarhere\n]\nOnly preserve TIFF IPTC_NAA_CHUNK tag if type is BYTE or UNDEFINED\n#7948\n[\n@radarhere\n]\nPrevent extra EPS header validations\n#8144\n[\n@Yay295\n]\nClarify ImageDraw2 error message when size is missing\n#8165\n[\n@radarhere\n]\nSupport unpacking more rawmodes to RGBA palettes\n#7966\n[\n@radarhere\n]\nRemoved support for Qt 5\n#8159\n[\n@radarhere\n]\nImprove\nImageFont.freetype\nsupport for XDG directories on Linux\n#8135\n[\n@mamg22\n]\nImproved consistency of XMP handling\n#8069\n[\n@radarhere\n]\nUse pkg-config to help find libwebp and raqm\n#8142\n[\n@radarhere\n]\nRenamed C transform2 to transform\n#8113\n[\n@radarhere\n]\nUpdated nasm to 2.16.03\n#7990\n[\n@radarhere\n]\n[pre-commit.ci] pre-commit autoupdate\n#8100\n[\n@pre-commit-ci\n]\nUpdated ImageCms.createProfile colorTemp default and docstring\n#8096\n[\n@radarhere\n]\nAdded ImageDraw circle()\n#8085\n[\n@void4\n]\nDon't reuse variable name\n#8082\n[\n@Yay295\n]\nUse functools.cached_property in GifImagePlugin\n#8037\n[\n@radarhere\n]\nAdd mypy target to Makefile\n#8077\n[\n@Yay295\n]\nAdded Python 3.13 beta wheels\n#8071\n[\n@radarhere\n]\nParse _version contents instead of using exec()\n#8050\n[\n@radarhere\n]\nLint fixes\n#8068\n[\n@radarhere\n]\nFix type errors\n#8064\n[\n@radarhere\n]\nAdded MPEG accept function\n#7999\n[\n@radarhere\n]\nAdded more modes to Image.MODES\n#7984\n[\n@radarhere\n]\n[pre-commit.ci] pre-commit autoupdate\n#8044\n[\n@pre-commit-ci\n]\nDo not use percent format in strings\n#8045\n[\n@radarhere\n]\nChanged string formatting to f-strings\n#8043\n[\n@mrKazzila\n]\nRemoved direct invocation of setup.py\n#8027\n[\n@radarhere\n]\nUpdate ExifTags.py\n#8020\n[\n@CTimmerman\n]\nFix ImagingAccess for I;16N on big-endian\n#7921\n[\n@Yay295\n]\nCombined conditions\n#8011\n[\n@radarhere\n]\nSimplified RGB to I;16, I;16L and I;16B conversion\n#8008\n[\n@radarhere\n]\nExtract band count check\n#8006\n[\n@Yay295\n]\nRemove unused variable\n#8005\n[\n@Yay295\n]\nRemove semicolon after function definition\n#8004\n[\n@Yay295\n]\nSupport reading P mode TIFF images with padding\n#7996\n[\n@radarhere\n]\nCorrected ImageShow UnixViewer command\n#7987\n[\n@radarhere\n]\nRemoved CentOS Stream 8\n#7977\n[\n@radarhere\n]\nRemoved CentOS 7\n#7976\n[\n@radarhere\n]\ndist directory is no longer created\n#7974\n[\n@radarhere\n]\nAdd support for reading BITMAPV2INFOHEADER and BITMAPV3INFOHEADER\n#7956\n[\n@cirras\n]\nUpdate\nmake release-test\n: no more eggs\n#7957\n[\n@hugovk\n]\nMake ModeDescriptor a NamedTuple\n#7951\n[\n@Yay295\n]\nSupport reading CMYK JPEG2000 images\n#7947\n[\n@radarhere\n]\nRemove unused CMS properties and fix documentation\n#7931\n[\n@Yay295\n]\n[pre-commit.ci] pre-commit autoupdate\n#7932\n[\n@pre-commit-ci\n]\nDependencies\nUpdate dependency mypy to v1.10.1\n#8177\n[\n@renovate\n]\nUpdate dependency cibuildwheel to v2.19.1\n#8143\n[\n@renovate\n]\nUpdate dependency cibuildwheel to v2.19.0\n#8131\n[\n@renovate\n]\nUpdated libjpeg-turbo to 3.0.3\n#8048\n[\n@radarhere\n]\nUpdated fribidi to 1.0.15\n#8014\n[\n@radarhere\n]\nUpdated libwebp to 1.4.0\n#7973\n[\n@radarhere\n]\nUpdated libxcb and xcb-proto to 1.17.0\n#7982\n[\n@radarhere\n]\nUpdated libimagequant to 4.3.1\n#8025\n[\n@radarhere\n]\nUpdated harfbuzz to 8.5.0\n#8059\n[\n@radarhere\n]\nUpdated Ghostscript to 10.3.1\n#8078\n[\n@radarhere\n]\nchore(deps): update dependency cibuildwheel to v2.18.1\n#8070\n[\n@renovate\n]\nchore(deps): update dependency cibuildwheel to v2.18.0\n#8054\n[\n@renovate\n]\nUpdate dependency mypy to v1.10.0\n#8013\n[\n@renovate\n]\nDocumentation\nConverted example images to WebP\n#7963\n[\n@radarhere\n]\nUse latest Ubuntu on Read The Docs\n#8136\n[\n@radarhere\n]\nUse Sphinx long options in\nMakefile\n#8109\n[\n@hugovk\n]\nRemoved documentation of unused argument\n#8079\n[\n@radarhere\n]\nUpdated CI targets table\n#8028\n[\n@radarhere\n]\nAutomatically add dates to release notes\n#8001\n[\n@hugovk\n]\nRemove sphinx-removed-in, now Sphinx 7.3 adds versionremoved\n#7988\n[\n@hugovk\n]\nRemoved nitpick_ignore by updating Sphinx to 7.3\n#7985\n[\n@radarhere\n]\nUpdated installation links\n#7981\n[\n@radarhere\n]\nCorrected packer comments\n#7964\n[\n@Yay295\n]\nRelease checklist: inline the 'Source and Binary Distributions' step\n#7959\n[\n@hugovk\n]\nRemoved outdated comment\n#7955\n[\n@radarhere\n]\nDocument that QoiImagePlugin uses Python for decoding\n#7937\n[\n@radarhere\n]\nUpdated macOS tested Pillow versions\n#7934\n[\n@radarhere\n]\nFix ImageMath documentation parameter names\n#7933\n[\n@jbjd\n]\nTesting\nUse more specific error\n#8168\n[\n@radarhere\n]\nIgnore brew dependencies for libraqm on macOS 13\n#8140\n[\n@radarhere\n]\nCorrected AppVeyor Ghostscript path\n#8138\n[\n@radarhere\n]\nAccept 't' suffix for libtiff version\n#8129\n[\n@radarhere\n]\nAccept 't' suffix for libtiff version\n#8126\n[\n@radarhere\n]\nAdd ClangFormat to pre-commit\n#8015\n[\n@hugovk\n]\nRemoved helper.py modes\n#8053\n[\n@radarhere\n]\nUpdated codecov/codecov-action to v4\n#8041\n[\n@radarhere\n]\nAdded Ubuntu 24.04\n#8023\n[\n@radarhere\n]\nCorrected big-endian check\n#8022\n[\n@radarhere\n]\nUse LAB hopper file if conversion is not supported\n#7979\n[\n@radarhere\n]\nRemoved Fedora 38 and added Fedora 40\n#8012\n[\n@radarhere\n]\nUpdate tests to allow for zlib-ng\n#8009\n[\n@radarhere\n]\nGitHub Actions: use\nmacos-13\nor\nmacos-14\ninstead of\nmacos-latest\n#8010\n[\n@hugovk\n]\nCorrected check for libtiff feature\n#8000\n[\n@radarhere\n]\nCorrected check for libtiff feature\n#7975\n[\n@radarhere\n]\nFix test error message grammar\n#7967\n[\n@Yay295\n]\nReplace ImageMath.eval with ImageMath.lambda_eval in selftest.py\n#7960\n[\n@radarhere\n]\nRename test_roundtrip() to test_mode()\n#7950\n[\n@Yay295\n]\nUpdated pattern for skipping builds based on file changes\n#7938\n[\n@radarhere\n]\nCorrected ImageCms test\n#7930\n[\n@radarhere\n]\nType hints\nSimplified casts\n#8169\n[\n@radarhere\n]\nAdded type hints\n#8167\n[\n@radarhere\n]\nAdded type hints for PixelAccess related methods and others\n#8032\n[\n@nulano\n]\nAdded type hints to additional tests\n#8163\n[\n@radarhere\n]\nUpdated type hints\n#8153\n[\n@radarhere\n]\nAdded type hints to ImageFilter\n#8156\n[\n@radarhere\n]\nAdded type hints to ImageDraw shape methods\n#8151\n[\n@radarhere\n]\nAdded type hints to Image\n#8150\n[\n@radarhere\n]\nAdded type hints\n#8134\n[\n@radarhere\n]\nAdded type hints to additional tests\n#8118\n[\n@radarhere\n]\nAdded type hints\n#8132\n[\n@radarhere\n]\nAdded type hints to GifImagePlugin\n#8128\n[\n@radarhere\n]\nAdded type hints\n#8125\n[\n@radarhere\n]\nAdded type hints\n#8117\n[\n@radarhere\n]\nAdded type hints\n#8108\n[\n@radarhere\n]\nAdded type hints to ImageColor\n#8115\n[\n@radarhere\n]\nAdd various type annotations\n#8046\n[\n@srittau\n]\nAdded type hints\n#8107\n[\n@radarhere\n]\nAdded type hints\n#8105\n[\n@radarhere\n]\nAdded type hints\n#8066\n[\n@radarhere\n]\nAdded type hints\n#8099\n[\n@radarhere\n]\nCorrected type hint\n#8098\n[\n@radarhere\n]\nUpdated type hints for tests\n#8095\n[\n@radarhere\n]\nAdded type hints to additional tests\n#8093\n[\n@radarhere\n]\nAdded type hints to additional tests\n#8091\n[\n@radarhere\n]\nAdded type hints to additional tests\n#8090\n[\n@radarhere\n]\nAdded type hints\n#8061\n[\n@radarhere\n]\nAdded type hints\n#8055\n[\n@radarhere\n]\nAdded type hints\n#8051\n[\n@radarhere\n]\nAdded type hints\n#8042\n[\n@radarhere\n]\nAdded type hints\n#8030\n[\n@radarhere\n]\nRemoved type hint ignores\n#7989\n[\n@radarhere\n]\nfromarray: add type hints\n#7936\n[\n@adamjstewart\n]\nUse functools.cached_property in ImageStat\n#7952\n[\n@nulano\n]\nAdd type hints for\nImage.open\n,\nImage.init\n, and\nImage.Image.save\n#7944\n[\n@nulano\n]",
    "crawl_status": "success"
  },
  {
    "library_name": "TensorFlow",
    "url": "https://github.com/tensorflow/tensorflow/releases/tag/v2.18.0",
    "version": "v2.18.0",
    "title": "Release TensorFlow 2.18.0 路 tensorflow/tensorflow 路 GitHub",
    "release_date": "2024-10-24T23:51:36Z",
    "content": "Release 2.18.0\nTensorFlow\nBreaking Changes\ntf.lite\nC API:\nAn optional, fourth parameter was added\nTfLiteOperatorCreate\nas a step forward towards a cleaner API for\nTfLiteOperator\n. Function\nTfLiteOperatorCreate\nwas added recently, in TensorFlow Lite version 2.17.0, released on 7/11/2024, and we do not expect there will be much code using this function yet. Any code breakages can be easily resolved by passing nullptr as the new, 4th parameter.\nTensorRT support is disabled in CUDA builds for code health improvement.\nHermetic CUDA support is added.\nHermetic CUDA uses a specific downloadable version of CUDA instead of the users locally installed CUDA. Bazel will download CUDA, CUDNN and NCCL distributions, and then use CUDA libraries and tools as dependencies in various Bazel targets. This enables more reproducible builds for Google ML projects and supported CUDA versions.\nKnown Caveats\nMajor Features and Improvements\nTensorFlow now supports and is compiled with NumPy 2.0 by default. Please see the\nNumPy 2 release notes\nand the\nNumPy 2 migration guide\n.\nNote that NumPy's type promotion rules have been changed(See\nNEP 50\nfor details). This may change the precision at which computations happen, leading either to type errors or to numerical changes to results.\nTensorflow will continue to support NumPy 1.26 until 2025, aligning with community standard deprecation timeline\nhere\n.\ntf.lite\n:\nThe LiteRT\nrepo\nis live (see\nannouncement\n), which means that in the coming months there will be changes to the development experience for TFLite. The TF Lite Runtime source will be moved later this year, and sometime after that we will start accepting contributions through that repo.\nSignatureRunner is now supported for models with no signatures.\nBug Fixes and Other Changes\ntf.data\nAdd optional\nsynchronous\nargument to\nmap\n, to specify that the\nmap\nshould run synchronously, as opposed to be parallelizable when\noptions.experimental_optimization.map_parallelization=True\n. This saves memory compared to setting\nnum_parallel_calls=1\n.\nAdd optional\nuse_unbounded_threadpool\nargument to\nmap\n, to specify that the\nmap\nshould use an unbounded threadpool instead of the default pool that is based on the number of cores on the machine. This can improve throughput for map functions which perform IO or otherwise release the CPU.\nAdd\ntf.data.experimental.get_model_proto\nto allow users to peek into the analytical model inside of a dataset iterator.\ntf.lite\nDequantize\nop supports\nTensorType_INT4\n.\nThis change includes per-channel dequantization.\nAdd support for\nstablehlo.composite\n.\nEmbeddingLookup\nop supports per-channel quantization and\nTensorType_INT4\nvalues.\nFullyConnected\nop supports\nTensorType_INT16\nactivation and\nTensorType_Int4\nweight per-channel quantization.\ntf.tensor_scatter_update\n,\ntf.tensor_scatter_add\nand of other reduce types.\nSupport\nbad_indices_policy\n.\nThanks to our Contributors\nThis release contains contributions from many people at Google, as well as:\nAkhil Goel, akhilgoe, Alexander Pivovarov, Amir Samani, Andrew Goodbody, Andrey Portnoy, Anthony Platanios, bernardoArcari, Brett Taylor, buptzyb, Chao, Christian Clauss, Cocoa, Daniil Kutz, Darya Parygina, dependabot[bot], Dimitris Vardoulakis, Dragan Mladjenovic, Elfie Guo, eukub, Faijul Amin, flyingcat, Fr茅d茅ric Bastien, ganyu.08, Georg Stefan Schmid, Grigory Reznikov, Harsha H S, Harshit Monish, Heiner, Ilia Sergachev, Jan, Jane Liu, Jaroslav Sevcik, Kaixi Hou, Kanvi Khanna, Kristof Maar, Krist贸f Ma谩r, LakshmiKalaKadali, Lbertho-Gpsw, lingzhi98, MarcoFalke, Masahiro Hiramori, Mmakevic-Amd, mraunak, Nobuo Tsukamoto, Notheisz57, Olli Lupton, Pearu Peterson, pemeliya, Peyara Nando, Philipp Hack, Phuong Nguyen, Pol Dellaiera, Rahul Batra, Ruturaj Vaidya, sachinmuradi, Sergey Kozub, Shanbin Ke, Sheng Yang, shengyu, Shraiysh, Shu Wang, Surya, sushreebarsa, Swatheesh-Mcw, syzygial, Tai Ly, terryysun, tilakrayal, Tj Xu, Trevor Morris, Tzung-Han Juang, wenchenvincent, wondertx, Xuefei Jiang, Ye Huang, Yimei Sun, Yunlong Liu, Zahid Iqbal, Zhan Lu, Zoranjovanovic-Ns, Zuri Obozuwa",
    "crawl_status": "success"
  },
  {
    "library_name": "TensorFlow",
    "url": "https://github.com/tensorflow/tensorflow/releases/tag/v2.20.0",
    "version": "v2.20.0",
    "title": "Release TensorFlow 2.20.0 路 tensorflow/tensorflow 路 GitHub",
    "release_date": "2025-08-13T17:45:14Z",
    "content": "Release 2.20.0\nTensorFlow\nBreaking Changes\nThe\ntensorflow-io-gcs-filesystem\npackage is now optional, due its uncertain, and limited support. To install it alongside\ntensorflow\n, run\npip install \"tensorflow[gcs-filesystem]\"\n.\nMajor Features and Improvements\ntf.data\nAdds\nautotune.min_parallelism\nto\ntf.data.Options\nto enable faster input pipeline warm up.\ntf.lite\ntf.lite will be deprecated, in favor of the new repo\nhttps://github.com/google-ai-edge/LiteRT\n.\nThe duplicated source will also be removed from the TF repo.\nThanks to our Contributors\nThis release contains contributions from many people at Google, as well as:\n1ndig0, 372046933, abhinav, afzpatel, Akhil Goel, Alain Carlucci, Aleksei, Alen Huang, Alex, Amrinfathima-Mcw, Aravindh Balaji, Armand Picard, Aseem Athale, Ashiq Imran, Assoap, Chao, Chase Riley Roberts, Chenhao Jiang, chunhsue, chuntl, Chunyu Jin, Corentin Kerisit, Crefeda Rodrigues, dependabot[bot], Dragan Mladjenovic, Elen Kalda, Felix Thomasmathibalan, gabeweisz, Gauri Deshpande, Georg Stefan Schmid, Guozhong Zhuang, Harsha H S, Harshith_N, Hugo Mano, Ian Tayler Lessa, Jack Wolfard, James Ward, Jane Liu, Jaroslav Sevcik, JD, Jerry-Ge, Jian Li, Jinzhe Zeng, jiunkaiy, Johannes Reifferscheid, johnnkp, junweifu, Kanvi Khanna, Kasper Nielsen, Linzb-Xyz, Luke Hutton, Mahmoud Abuzaina, Mathew Odden, Michael Platings, misterBart, Mitchell Ludwig, Mmakevic-Amd, mraunak, NamanAgarwal0905, Namrata-Ibm, Neuropilot-Captain, nhatle, Nicholas Wilson, Nikhil Shinde, Olli Lupton, Patrick J. Lopresti, Pavel Emeliyanenko, Pearu Peterson, pemeliya, Peng Sun, Philipp Hack, Pratham-Mcw, RahulSudarMCW, RakshithGB, Rakshithgb-Fujitsu, RuslanSemchenko, Ruturaj Vaidya, Sachin Muradi, sandeepgupta12, SaoirseARM, Sergey Kozub, Sevin Fide Varoglu, Shanbin Ke, Shaogang Wang, Shraiysh Vaishay, Siddhartha Menon, spiao, Swatheesh Muralidharan, Tai Ly, Terry Sun, Thibaut Goetghebuer-Planchon, Thomas Dickerson, Tilak, Tj Xu, Trevor Morris, tyb0807, vfdev, Wei Wang, wokron, wondertx, Xuefei Jiang, Yaowei Zhou, Zentrik, Ziyun Cheng, Zoranjovanovic-Ns",
    "crawl_status": "success"
  },
  {
    "library_name": "TensorFlow",
    "url": "https://github.com/tensorflow/tensorflow/releases/tag/v2.13.0",
    "version": "v2.13.0",
    "title": "Release TensorFlow 2.13.0 路 tensorflow/tensorflow 路 GitHub",
    "release_date": "2023-07-05T17:32:13Z",
    "content": "Release 2.13.0\nTensorFlow\nBreaking Changes\nThe LMDB kernels have been changed to return an error. This is in preparation for completely removing them from TensorFlow. The LMDB dependency that these kernels are bringing to TensorFlow has been dropped, thus making the build slightly faster and more secure.\nMajor Features and Improvements\ntf.lite\nAdded 16-bit and 64-bit float type support for built-in op\ncast\n.\nThe Python TF Lite Interpreter bindings now have an option\nexperimental_disable_delegate_clustering\nto turn-off delegate clustering.\nAdded int16x8 support for the built-in op\nexp\nAdded int16x8 support for the built-in op\nmirror_pad\nAdded int16x8 support for the built-in ops\nspace_to_batch_nd\nand\nbatch_to_space_nd\nAdded 16-bit int type support for built-in op\nless\n,\ngreater_than\n,\nequal\nAdded 8-bit and 16-bit support for\nfloor_div\nand\nfloor_mod\n.\nAdded 16-bit and 32-bit int support for the built-in op\nbitcast\n.\nAdded 8-bit/16-bit/32-bit int/uint support for the built-in op\nbitwise_xor\nAdded int16 indices support for built-in op\ngather\nand\ngather_nd\n.\nAdded 8-bit/16-bit/32-bit int/uint support for the built-in op\nright_shift\nAdded reference implementation for 16-bit int unquantized\nadd\n.\nAdded reference implementation for 16-bit int and 32-bit unsigned int unquantized\nmul\n.\nadd_op\nsupports broadcasting up to 6 dimensions.\nAdded 16-bit support for\ntop_k\n.\ntf.function\nConcreteFunction (\ntf.types.experimental.ConcreteFunction\n) as generated through\nget_concrete_function\nnow performs holistic input validation similar to calling\ntf.function\ndirectly. This can cause breakages where existing calls pass Tensors with the wrong shape or omit certain non-Tensor arguments (including default values).\ntf.nn\ntf.nn.embedding_lookup_sparse\nand\ntf.nn.safe_embedding_lookup_sparse\nnow support ids and weights described by\ntf.RaggedTensor\ns.\nAdded a new boolean argument\nallow_fast_lookup\nto\ntf.nn.embedding_lookup_sparse\nand\ntf.nn.safe_embedding_lookup_sparse\n, which enables a simplified and typically faster lookup procedure.\ntf.data\ntf.data.Dataset.zip\nnow supports Python-style zipping, i.e.\nDataset.zip(a, b, c)\n.\ntf.data.Dataset.shuffle\nnow supports\ntf.data.UNKNOWN_CARDINALITY\nWhen doing a \"full shuffle\" using\ndataset = dataset.shuffle(dataset.cardinality())\n. But remember, a \"full shuffle\" will load the full dataset into memory so that it can be shuffled, so make sure to only use this with small datasets or datasets of small objects (like filenames).\ntf.math\ntf.nn.top_k\nnow supports specifying the output index type via parameter\nindex_type\n.  Supported types are\ntf.int16\n,\ntf.int32\n(default), and\ntf.int64\n.\ntf.SavedModel\nIntroduced class method\ntf.saved_model.experimental.Fingerprint.from_proto(proto)\n, which can be used to construct a\nFingerprint\nobject directly from a protobuf.\nIntroduced member method\ntf.saved_model.experimental.Fingerprint.singleprint()\n, which provides a convenient way to uniquely identify a SavedModel.\nBug Fixes and Other Changes\ntf.Variable\nChanged resource variables to inherit from\ntf.compat.v2.Variable\ninstead of\ntf.compat.v1.Variable\n. Some checks for\nisinstance(v, tf compat.v1.Variable)\nthat previously returned True may now return False.\ntf.distribute\nOpened an experimental API,\ntf.distribute.experimental.coordinator.get_current_worker_index\n, for retrieving the worker index from within a worker, when using parameter server training with a custom training loop.\ntf.experimental.dtensor\nDeprecated\ndtensor.run_on\nin favor of\ndtensor.default_mesh\nto correctly indicate that the context does not override the mesh that the ops and functions will run on, it only sets a fallback default mesh.\nList of members of\ndtensor.Layout\nand\ndtensor.Mesh\nhave slightly changed as part of efforts to consolidate the C++ and Python source code with pybind11. Most notably,\ndtensor.Layout.serialized_string\nis removed.\nMinor API changes to represent Single Device Layout for non-distributed Tensors inside DTensor functions. Runtime support will be added soon.\ntf.experimental.ExtensionType\ntf.experimental.ExtensionType\nnow supports Python\ntuple\nas the type annotation of its fields.\ntf.nest\nDeprecated API\ntf.nest.is_sequence\nhas now been deleted. Please use\ntf.nest.is_nested\ninstead.\nKeras\nKeras is a framework built on top of the TensorFlow. See more details on the\nKeras website\n.\nBreaking Changes\nRemoved the Keras scikit-learn API wrappers (\nKerasClassifier\nand\nKerasRegressor\n), which had been deprecated in August 2021. We recommend using\nSciKeras\ninstead.\nThe default Keras model saving format is now the Keras v3 format: calling\nmodel.save(\"xyz.keras\")\nwill no longer create a H5 file, it will create a native Keras model file. This will only be breaking for you if you were manually inspecting or modifying H5 files saved by Keras under a\n.keras\nextension. If this breaks you, simply add\nsave_format=\"h5\"\nto your\n.save()\ncall to revert back to the prior behavior.\nAdded\nkeras.utils.TimedThread\nutility to run a timed thread every x seconds. It can be used to run a threaded function alongside model training or any other snippet of code.\nIn the\nkeras\nPyPI package, accessible symbols are now restricted to symbols that are intended to be public. This may affect your code if you were using\nimport keras\nand you used\nkeras\nfunctions that were not public APIs, but were accessible in earlier versions with direct imports. In those cases, please use the following guideline:\n-  The API may be available in the public Keras API under a different name, so make sure to look for it on keras.io or TensorFlow docs and switch to the public version.\n-  It could also be a simple python or TF utility that you could easily copy over to your own codebase. In those case, just make it your own!\n-  If you believe it should definitely be a public Keras API, please open a feature request in keras GitHub repo.\n-  As a workaround, you could import the same private symbol keras\nkeras.src\n, but keep in mind the\nsrc\nnamespace is not stable and those APIs may change or be removed in the future.\nMajor Features and Improvements\nAdded F-Score metrics\ntf.keras.metrics.FBetaScore\n,\ntf.keras.metrics.F1Score\n, and\ntf.keras.metrics.R2Score\n.\nAdded activation function\ntf.keras.activations.mish\n.\nAdded experimental\nkeras.metrics.experimental.PyMetric\nAPI for metrics that run Python code on the host CPU (compiled outside of the TensorFlow graph). This can be used for integrating metrics from external Python libraries (like sklearn or pycocotools) into Keras as first-class Keras metrics.\nAdded\ntf.keras.optimizers.Lion\noptimizer.\nAdded\ntf.keras.layers.SpectralNormalization\nlayer wrapper to perform spectral normalization on the weights of a target layer.\nThe\nSidecarEvaluatorModelExport\ncallback has been added to Keras as\nkeras.callbacks.SidecarEvaluatorModelExport\n. This callback allows for exporting the model the best-scoring model as evaluated by a\nSidecarEvaluator\nevaluator. The evaluator regularly evaluates the model and exports it if the user-defined comparison function determines that it is an improvement.\nAdded warmup capabilities to\ntf.keras.optimizers.schedules.CosineDecay\nlearning rate scheduler. You can now specify an initial and target learning rate, and our scheduler will perform a linear interpolation between the two after which it will begin a decay phase.\nAdded experimental support for an exactly-once visitation guarantee for evaluating Keras models trained with\ntf.distribute ParameterServerStrategy\n, via the\nexact_evaluation_shards\nargument in\nModel.fit\nand\nModel.evaluate\n.\nAdded\ntf.keras.__internal__.KerasTensor\n,\ntf.keras.__internal__.SparseKerasTensor\n, and\ntf.keras.__internal__.RaggedKerasTensor\nclasses. You can use these classes to do instance type checking and type annotations for layer/model inputs and outputs.\nAll the\ntf.keras.dtensor.experimental.optimizers\nclasses have been merged with\ntf.keras.optimizers\n. You can migrate your code to use\ntf.keras.optimizers\ndirectly. The API namespace for\ntf.keras.dtensor.experimental.optimizers\nwill be removed in future releases.\nAdded support for\nclass_weight\nfor 3+ dimensional targets (e.g. image segmentation masks) in\nModel.fit\n.\nAdded a new loss,\nkeras.losses.CategoricalFocalCrossentropy\n.\nRemove the\ntf.keras.dtensor.experimental.layout_map_scope()\n. You can user the\ntf.keras.dtensor.experimental.LayoutMap.scope()\ninstead.\nSecurity\nFixes correct values rank in UpperBound and LowerBound\nCVE-2023-33976\nThanks to our Contributors\nThis release contains contributions from many people at Google, as well as:\n103yiran, 8bitmp3, Aakar, Aakar Dwivedi, Abinash Satapathy, Aditya Kane, ag.ramesh, Alexander Grund, Andrei Pikas, andreii, Andrew Goodbody, angerson, Anthony_256, Ashay Rane, Ashiq Imran, Awsaf, Balint Cristian, Banikumar Maiti (Intel Aipg), Ben Barsdell, bhack, cfRod, Chao Chen, chenchongsong, Chris Mc, Daniil Kutz, David Rubinstein, dianjiaogit, dixr, Dongfeng Yu, dongfengy, drah, Eric Kunze, Feiyue Chen, Frederic Bastien, Gauri1 Deshpande, guozhong.zhuang, hDn248, HYChou, ingkarat, James Hilliard, Jason Furmanek, Jaya, Jens Glaser, Jerry Ge, Jiao Dian'S Power Plant, Jie Fu, Jinzhe Zeng, Jukyy, Kaixi Hou, Kanvi Khanna, Karel Ha, karllessard, Koan-Sin Tan, Konstantin Beluchenko, Kulin Seth, Kun Lu, Kyle Gerard Felker, Leopold Cambier, Lianmin Zheng, linlifan, liuyuanqiang, Lukas Geiger, Luke Hutton, Mahmoud Abuzaina, Manas Mohanty, Mateo Fidabel, Maxiwell S. Garcia, Mayank Raunak, mdfaijul, meatybobby, Meenakshi Venkataraman, Michael Holman, Nathan John Sircombe, Nathan Luehr, nitins17, Om Thakkar, Patrice Vignola, Pavani Majety, per1234, Philipp Hack, pollfly, Prianka Liz Kariat, Rahul Batra, rahulbatra85, ratnam.parikh, Rickard Hallerb盲ck, Roger Iyengar, Rohit Santhanam, Roman Baranchuk, Sachin Muradi, sanadani, Saoirse Stewart, seanshpark, Shawn Wang, shuw, Srinivasan Narayanamoorthy, Stewart Miles, Sunita Nadampalli, SuryanarayanaY, Takahashi Shuuji, Tatwai Chong, Thibaut Goetghebuer-Planchon, tilakrayal, Tirumalesh, TJ, Tony Sung, Trevor Morris, unda, Vertexwahn, venkat2469, William Muir, Xavier Bonaventura, xiang.zhang, Xiao-Yong Jin, yleeeee, Yong Tang, Yuriy Chernyshov, Zhang, Xiangze, zhaozheng09",
    "crawl_status": "success"
  },
  {
    "library_name": "Click",
    "url": "https://click.palletsprojects.com/en/stable/changes/#version-8-2-0",
    "version": "v8.2.0",
    "title": "Changes  Click Documentation (8.3.x)",
    "release_date": "Unknown release date",
    "content": "Version 8.2.0\n露\nReleased 2025-05-10\nDrop support for Python 3.7, 3.8, and 3.9.\n#2588\n#2893\nUse modern packaging metadata with\npyproject.toml\ninstead of\nsetup.cfg\n.\n#2438\nUse\nflit_core\ninstead of\nsetuptools\nas build backend.\n#2543\nDeprecate the\n__version__\nattribute. Use feature detection, or\nimportlib.metadata.version(\"click\")\n, instead.\n#2598\nBaseCommand\nis deprecated.\nCommand\nis the base class for all\ncommands.\n#2589\nMultiCommand\nis deprecated.\nGroup\nis the base class for all group\ncommands.\n#2590\nThe current parser and related classes and methods, are deprecated.\n#2205\nOptionParser\nand the\nparser\nmodule, which is a modified copy of\noptparse\nin the standard library.\nContext.protected_args\nis unneeded.\nContext.args\ncontains any\nremaining arguments while parsing.\nParameter.add_to_parser\n(on both\nArgument\nand\nOption\n) is\nunneeded. Parsing works directly without building a separate parser.\nsplit_arg_string\nis moved from\nparser\nto\nshell_completion\n.\nEnable deferred evaluation of annotations with\nfrom\n__future__\nimport\nannotations\n.\n#2270\nWhen generating a commands name from a decorated functions name, the\nsuffixes\n_command\n,\n_cmd\n,\n_group\n, and\n_grp\nare removed.\n#2322\nShow the\ntypes.ParamType.name\nfor\ntypes.Choice\noptions within\n--help\nmessage if\nshow_choices=False\nis specified.\n#2356\nDo not display default values in prompts when\nOption.show_default\nis\nFalse\n.\n#2509\nAdd\nget_help_extra\nmethod on\nOption\nto fetch the generated extra\nitems used in\nget_help_record\nto render help text.\n#2516\n#2517\nKeep stdout and stderr streams independent in\nCliRunner\n. Always\ncollect stderr output and never raise an exception. Add a new\noutput stream to simulate what the user sees in its terminal. Removes\nthe\nmix_stderr\nparameter in\nCliRunner\n.\n#2522\n#2523\nOption.show_envvar\nnow also shows environment variable in error messages.\n#2695\n#2696\nContext.close\nwill be called on exit. This results in all\nContext.call_on_close\ncallbacks and context managers added via\nContext.with_resource\nto be closed on exit as well.\n#2680\nAdd\nProgressBar(hidden:\nbool)\nto allow hiding the progressbar.\n#2609\nA\nUserWarning\nwill be shown when multiple parameters attempt to use the\nsame name.\n#2396\nWhen using\nOption.envvar\nwith\nOption.flag_value\n, the\nflag_value\nwill always be used instead of the value of the environment variable.\n#2746\n#2788\nAdd\nChoice.get_invalid_choice_message\nmethod for customizing the\ninvalid choice message.\n#2621\n#2622\nIf help is shown because\nno_args_is_help\nis enabled (defaults to\nTrue\nfor groups,\nFalse\nfor commands), the exit code is 2 instead of 0.\n#1489\n#1489\nContexts created during shell completion are closed properly, fixing\na\nResourceWarning\nwhen using\nclick.File\n.\n#2644\n#2800\n#2767\nclick.edit(filename)\nnow supports passing an iterable of filenames in\ncase the editor supports editing multiple files at once. Its return type\nis now also typed:\nAnyStr\nif\ntext\nis passed, otherwise\nNone\n.\n#2067\n#2068\nSpecialized typing of\nprogressbar(length=...)\nas\nProgressBar[int]\n.\n#2630\nImprove\necho_via_pager\nbehaviour in face of errors.\n#2674\nTerminate the pager in case a generator passed to\necho_via_pager\nraises an exception.\nEnsure to always close the pipe to the pager process and wait for it\nto terminate.\necho_via_pager\nwill not ignore\nKeyboardInterrupt\nanymore. This\nallows the user to search for future output of the generator when\nusing less and then aborting the program using ctrl-c.\ndeprecated:\nbool\n|\nstr\ncan now be used on options and arguments. This\npreviously was only available for\nCommand\n. The message can now also be\ncustomised by using a\nstr\ninstead of a\nbool\n.\n#2263\n#2271\nCommand.deprecated\nformatting in\n--help\nchanged from\n(Deprecated)\nhelp\nto\nhelp\n(DEPRECATED)\n.\nParameters cannot be required nor prompted or an error is raised.\nA warning will be printed when something deprecated is used.\nAdd a\ncatch_exceptions\nparameter to\nCliRunner\n. If\ncatch_exceptions\nis not passed to\nCliRunner.invoke\n, the value\nfrom\nCliRunner\nis used.\n#2817\n#2818\nOption.flag_value\nwill no longer have a default value set based on\nOption.default\nif\nOption.is_flag\nis\nFalse\n. This results in\nOption.default\nnot needing to implement\n__bool__\n.\n#2829\nIncorrect\nclick.edit\ntyping has been corrected.\n#2804\nChoice\nis now generic and supports any iterable value.\nThis allows you to use enums and other non-\nstr\nvalues.\n#2796\n#605\nFix setup of help options defaults when using a custom class on its\ndecorator. Removes\nHelpOption\n.\n#2832\n#2840",
    "crawl_status": "success"
  },
  {
    "library_name": "Click",
    "url": "https://click.palletsprojects.com/en/stable/changes/#version-8-1-8",
    "version": "v8.1.8",
    "title": "Changes  Click Documentation (8.3.x)",
    "release_date": "Unknown release date",
    "content": "Version 8.1.8\n露\nReleased 2024-12-19\nFix an issue with type hints for\nclick.open_file()\n.\n#2717\nFix issue where error message for invalid\nclick.Path\ndisplays on\nmultiple lines.\n#2697\nFixed issue that prevented a default value of\n\"\"\nfrom being displayed in\nthe help for an option.\n#2500\nThe test runner handles stripping color consistently on Windows.\n#2705\nShow correct value for flag default when using\ndefault_map\n.\n#2632\nFix\nclick.echo(color=...)\npassing\ncolor\nto coloroma so it can be\nforced on Windows.\n#2606\n.\nMore robust bash version check, fixing problem on Windows with git-bash.\n#2638\nCache the help option generated by the\nhelp_option_names\nsetting to\nrespect its eagerness.\n#2811\nReplace uses of\nos.system\nwith\nsubprocess.Popen\n.\n#1476\nExceptions generated during a command will use the contexts\ncolor\nsetting when being displayed.\n#2193\nError message when defining option with invalid name is more descriptive.\n#2452\nRefactor code generating default\n--help\noption to deduplicate code.\n#2563\nTest\nCLIRunner\nresets patched\n_compat.should_strip_ansi\n.\n#2732",
    "crawl_status": "success"
  },
  {
    "library_name": "Click",
    "url": "https://click.palletsprojects.com/en/stable/changes/#version-8-1-4",
    "version": "v8.1.4",
    "title": "Changes  Click Documentation (8.3.x)",
    "release_date": "Unknown release date",
    "content": "Version 8.1.4\n露\nReleased 2023-07-06\nReplace all\ntyping.Dict\noccurrences to\ntyping.MutableMapping\nfor\nparameter hints.\n#2255\nImprove type hinting for decorators and give all generic types parameters.\n#2398\nFix return value and type signature of\nshell_completion.add_completion_class\nfunction.\n#2421\nBash version detection doesnt fail on Windows.\n#2461\nCompletion works if there is a dot (\n.\n) in the program name.\n#2166\nImprove type annotations for pyright type checker.\n#2268\nImprove responsiveness of\nclick.clear()\n.\n#2284\nImprove command name detection when using Shiv or PEX.\n#2332\nAvoid showing empty lines if command help text is empty.\n#2368\nZSH completion script works when loaded from\nfpath\n.\n#2344\n.\nEOFError\nand\nKeyboardInterrupt\ntracebacks are not suppressed when\nstandalone_mode\nis disabled.\n#2380\n@group.command\ndoes not fail if the group was created with a custom\ncommand_class\n.\n#2416\nmultiple=True\nis allowed for flag options again and does not require\nsetting\ndefault=()\n.\n#2246, 2292, 2295\nMake the decorators returned by\n@argument()\nand\n@option()\nreusable when the\ncls\nparameter is used.\n#2294\nDont fail when writing filenames to streams with strict errors. Replace invalid\nbytes with the replacement character (\n锟\n).\n#2395\nRemove unnecessary attempt to detect MSYS2 environment.\n#2355\nRemove outdated and unnecessary detection of App Engine environment.\n#2554\necho()\ndoes not fail when no streams are attached, such as with\npythonw\non\nWindows.\n#2415\nArgument with\nexpose_value=False\ndo not cause completion to fail.\n#2336",
    "crawl_status": "success"
  },
  {
    "library_name": "Python-dotenv",
    "url": "https://github.com/theskumar/python-dotenv/releases/tag/v0.21.1",
    "version": "v0.21.1",
    "title": "Release Version 0.21.1 路 theskumar/python-dotenv 路 GitHub",
    "release_date": "2023-01-21T10:22:25Z",
    "content": "Added\nUse Python 3.11 non-beta in CI (\n#438\nby\n@bbc2\n)\nModernize variables code (\n#434\nby\n@Nougat-Waffle\n)\nModernize main.py and parser.py code (\n#435\nby\n@Nougat-Waffle\n)\nImprove conciseness of cli.py and\ninit\n.py (\n#439\nby\n@Nougat-Waffle\n)\nImprove error message for\nget\nand\nlist\ncommands when env file can't be opened (\n#441\nby\n@bbc2\n)\nUpdated Licence to align with BSD OSI template (\n#433\nby\n@lsmith77\n)\nFixed\nFix Out-of-scope error when \"dest\" variable is undefined (\n#413\nby\n@theGOTOguy\n)\nFix IPython test warning about deprecated\nmagic\n(\n#440\nby\n@bbc2\n)\nFix type hint for dotenv_path var, add StrPath alias (\n#432\nby\n@eaf\n)\nNew Contributors\n@saimehsan\nmade their first contribution in\n#426\n@Praveensenpai\nmade their first contribution in\n#437\n@Nougat-Waffle\nmade their first contribution in\n#434\n@mivade\nmade their first contribution in\n#442\n@lsmith77\nmade their first contribution in\n#433\n@eaftan\nmade their first contribution in\n#432\nFull Changelog\n:\nv0.21.0...v0.21.1",
    "crawl_status": "success"
  },
  {
    "library_name": "Python-dotenv",
    "url": "https://github.com/theskumar/python-dotenv/releases/tag/v1.0.1",
    "version": "v1.0.1",
    "title": "Release v1.0.1 路 theskumar/python-dotenv 路 GitHub",
    "release_date": "2024-01-23T06:32:36Z",
    "content": "What's Changed\nFIx year in release date in changelog.md by\n@jankislinger\nin\n#453\nGracefully handle code which has been imported from a zipfile by\n@samwyma\nin\n#456\nUse pathlib.Path in tests by\n@eumiro\nin\n#466\nfixes\n#473\nUse https in README links by\n@Nicals\nin\n#474\nAllow modules using load_dotenv to be reloaded when launched in a separate thread by\n@freddyaboulton\nin\n#497\nFix error handling in the rewrite function by\n@Qwerty-133\nin\n#468\nAdd python 3.12 and pypy3.10 to test suite by\n@theskumar\nin\n#498\nNew Contributors\n@jankislinger\nmade their first contribution in\n#453\n@samwyma\nmade their first contribution in\n#456\n@eumiro\nmade their first contribution in\n#466\n@Nicals\nmade their first contribution in\n#474\n@freddyaboulton\nmade their first contribution in\n#497\n@Qwerty-133\nmade their first contribution in\n#468\nFull Changelog\n:\nv1.0.0...v1.0.1",
    "crawl_status": "success"
  },
  {
    "library_name": "Python-dotenv",
    "url": "https://github.com/theskumar/python-dotenv/releases/tag/v1.1.0",
    "version": "v1.1.0",
    "title": "Release v1.1.0 路 theskumar/python-dotenv 路 GitHub",
    "release_date": "2025-03-25T10:56:50Z",
    "content": "What's Changed\nAdd a security policy by\n@bbc2\nin\n#512\nKeep GitHub Actions up to date with GitHub's Dependabot by\n@cclauss\nin\n#506\nci: fix multiline string in test.yml & use fail-fast strategy by\n@cclauss\nin\n#514\nEnhance dotenv run: Switch to execvpe for better resource management and signal handling by\n@eekstunt\nin\n#523\nci: add py3.13 to test.yml by\n@waketzheng\nin\n#527\nAdd Python 3.13 trove classifier by\n@edgarrmondragon\nin\n#535\nBump the github-actions group with 2 updates by\n@dependabot\nin\n#529\nAdd support for python 3.13 and drop 3.8 by\n@theskumar\nin\n#551\ndocs: Update README.md by\n@chapeupreto\nin\n#516\nSome more s/Python-dotenv/python-dotenv/ by\n@theskumar\nin\n#552\nadd _is_debugger so load_dotenv will work in pdb by\n@randomseed42\nin\n#553\nNew Contributors\n@eekstunt\nmade their first contribution in\n#523\n@waketzheng\nmade their first contribution in\n#527\n@edgarrmondragon\nmade their first contribution in\n#535\n@dependabot\nmade their first contribution in\n#529\n@chapeupreto\nmade their first contribution in\n#516\n@randomseed42\nmade their first contribution in\n#553\nFull Changelog\n:\nv1.0.1...v1.1.0",
    "crawl_status": "success"
  },
  {
    "library_name": "Redis-py",
    "url": "https://github.com/redis/redis-py/releases/tag/v5.0.0",
    "version": "v5.0.0",
    "title": "Release 5.0.0 路 redis/redis-py 路 GitHub",
    "release_date": "2023-08-15T09:57:30Z",
    "content": "What's new?\nTriggers and Functions support\nTriggers and Functions allow you to execute server-side functions triggered when key values are modified or created in Redis, a stream entry arrival, or explicitly calling them. Simply put, you can replace Lua scripts with easy-to-develop JavaScript or TypeScript code. Move your business logic closer to the data to ensure a lower latency, and forget about updating dependent key values manually in your code.\nTry it for yourself with Quick start\nFull\nRedis 7.2\nand\nRESP3 support\nPython 3.7 End-of-Life\nPython 3.7 has reached its end-of-life (EOL) as of June 2023\n. This means that starting from this date, Python 3.7 will no longer receive any updates, including security patches, bug fixes, or improvements. If you continue to use Python 3.7 post-EOL, you may expose your projects and systems to potential security vulnerabilities. We ended its support in this version and strongly recommend migrating to Python 3.10.\n Bug Fixes\nFix timeout retrying on pipeline execution (\n#2812\n)\nFix socket garbage collection (\n#2859\n)\nО Maintenance\nUpdating client license to clear, MIT (\n#2884\n)\nAdd py.typed in accordance with PEP-561 (\n#2738\n)\nDependabot label change (\n#2880\n)\nFix type hints in SearchCommands (\n#2817\n)\nAdd sync modules (except search) tests to cluster CI (\n#2850\n)\nFix a duplicate word in\nCONTRIBUTING.md\n(\n#2848\n)\nFixing doc builds (\n#2869\n)\nChange cluster docker to edge and enable debug command (\n#2853\n)\nContributors\nWe'd like to thank all the contributors who worked on this release!\n@JoanFM\n,\n@Ovsyanka83\n,\n@chayim\n,\n@dependabot\n,\n@dependabot\n[bot],\n@dvora-h\n,\n@kristjanvalur\n,\n@kurtmckee\n,\n@pall-j\nand\n@shacharPash",
    "crawl_status": "success"
  },
  {
    "library_name": "Redis-py",
    "url": "https://github.com/redis/redis-py/releases/tag/v7.0.0",
    "version": "v7.0.0",
    "title": "Release 7.0.0 路 redis/redis-py 路 GitHub",
    "release_date": "2025-10-22T15:38:01Z",
    "content": "Changes\nOne of the main features introduced in this release is a new type of client\nMultiDBClient\n. The purpose of this client is a communication with multiple databases that are eventually consistent (Active-Active setup) and handling failures by failover across databases.\nMore information could be found in docs.\n New Features\nSupport for maintenance push notifications handling during server upgrade or maintenance procedures. (\n#3756\n#3777\n#3778\n#3779\n#3785\n)\nAdding WITHATTRIBS option to vector set's vsim command. (\n#3746\n)\nAdding ssl_verify_flags_config argument for ssl connection configuration (\n#3772\n)\nAdding new ExternalAuthProviderError that will be raised when we receive 'problem with LDAP service' response from server. (\n#3808\n)\nИ Experimental Features\nMulti-database client implementation (\n#3784\n#3811\n)\n Breaking changes\nAdding abstract method declaration for cache property setter in EvictionPolicyInterface(\n#3732\n)\nRemove unused parse_list_to_dict function from helpers (\n#3733\n)\nRemoving synchronous context manager handling from async RedisCluster. (\n#3679\n)\nRedis Search/Aggregate improved type annotations (\n#3676\n)\nRemoving the threading.Lock locks and replacing them with RLock objects to avoid deadlocks. (\n#3677\n)\nUpdate ping command docstrings and method return type hint (\n#3789\n)\nFixing several *arg type hints in core.py and json module commands (\n#3793\n)\nFixing errors reported by mypy in search module files - query.py, commands.py and aggregation.py. (\n#3666\n)\nAdding score_cast_func argument to zrank, zrevrank and zunion - for consistency with the other sorted sets commands (\n#3795\n)\nChanging the timeout typehint in async BlockingConnectionPool from int to float (\n#3801\n)\n Bug Fixes\nRemoving the threading.Lock locks and replacing them with RLock objects to avoid deadlocks. (\n#3677\n)\nО Maintenance\nBump actions/checkout from 4 to 5 (\n#3760\n)\nFix docstring for ssl_check_hostname (\n#3761\n)\nTypos in vectorset commands.py (\n#3719\n)\nFixing typos in query.py (\n#3718\n)\nTypos in cluster.py (\n#3717\n)\nFixing typos in core.py (\n#3720\n)\nUpdate Redis image versions for GH pipeline actions. (\n#3740\n)\nSupport the customization of the timeout parameter when using a blocking connection pool with a redis cluster (\n#3724\n)\nFix async clients safety when used as an async context manager (\n#3512\n)\ndocs: fix zadd command parameter description (\n#3727\n)\nFault injector boilerplate (\n#3749\n)\nAdding e2e scenario tests for maintenance push notifications handling. (\n#3758\n)\nAdding more e2e tests related to maintenance notifications. Extracting specific tests that validate notifications are received in new connections (\n#3770\n)\nRenaming of classes and configuration arguments related to maintenance push notifications handling during server upgrade or maintenance procedures (\n#3777\n#3778\n)\nDOC-5743 BITOP examples (\n#3776\n)\nImprove stale issue management workflow (\n#3773\n)\n[DOC] Add complex chaining example using pipelines with builder pattern (\n#3774\n)\nFix automation scenario maint notification (\n#3788\n)\nAdd redis 8.4-M01-pre to tested redis versions (\n#3790\n)\nAdd handling of empty spaces during CLIENT LIST response parsing (\n#3797\n)\nDOC-5821 update index/query example for runnable notebook (\n#3807\n)\nFixing SORTABLE, INDEXEMPTY and INDEXMISSING order when using RediSearch fields (\n#3810\n)\nFixing argument type hints for evalsha and similar commands. (\n#3794\n)\nUpdate Python version to 3.14 in hiredis CI workflow (\n#3798\n)\nFixing sync BlockingConnectionPool's disconnect method to follow the definition in ConnectionPoolInterface (\n#3802\n)\nWe'd like to thank all the contributors who worked on this release!\n@scovetta\n@mengxunQAQ\n@abrookins\n@VincentHokie\n@sobolevn\n@hunterhogan\n@luka-mikec\n@zion-off\n@peperon\n@andy-stark-redis\n@uglide\n@elena-kolevska\n@kiryazovi-redis\n@vladvildanov\n@petyaslavova",
    "crawl_status": "success"
  },
  {
    "library_name": "Redis-py",
    "url": "https://github.com/redis/redis-py/releases/tag/v5.1.0",
    "version": "v5.1.0",
    "title": "Release 5.1.0 路 redis/redis-py 路 GitHub",
    "release_date": "2024-09-27T16:17:37Z",
    "content": "Changes\n New Features\nClient-side caching (\n#3350\n,\n#3110\n,\n#3102\n,\n#3099\n,\n#3089\n,\n#3038\n)\nHow to start with Client-side caching?\nInstall redis-py 5.1.0\nUse the following code snippet:\nr\n=\nRedis\n(\nprotocol\n=\n3\n,\ncache_config\n=\nCacheConfig\n())\ncache\n=\nr\n.\nget_cache\n()\nr\n.\nset\n(\n\"foo\"\n,\n\"bar\"\n)\n# get key from redis and save in local cache\nprint\n(\nr\n.\nget\n(\n\"foo\"\n))\n# get key from local cache\nprint\n(\ncache\n.\nget\n(\nCacheKey\n(\ncommand\n=\n\"GET\"\n,\nredis_keys\n=\n(\n\"foo\"\n,))).\ncache_value\n)\n# change key in redis (cause invalidation)\nr\n.\nset\n(\n\"foo\"\n,\n\"barbar\"\n)\n# Retrieves a new value from server and cache it\nprint\n(\nr\n.\nget\n(\n\"foo\"\n))\n# Make sure that new value was cached\nprint\n(\ncache\n.\nget\n(\nCacheKey\n(\ncommand\n=\n\"GET\"\n,\nredis_keys\n=\n(\n\"foo\"\n,))).\ncache_value\n)\nCheck\ndocumentation\nto get more examples\n Breaking Changes\nTimeseries insertion filters for close samples (\n#3228\n)\nEnhanced classes string representation (\n#3001\n)\nPartial clean up of Python 3.7 compatibility (\n#2928\n)\nHandle RESP3 sets as Python lists (\n#3324\n)\n Bug Fixes\nHandle RESP3 sets as Python lists (\n#3324\n)\nPrevent async ClusterPipeline instances from becoming \"false-y\" (\n#3068\n)\nAdd hostname field to _parse_node_line (\n#3343\n)\nMore docs fixes (\n#3326\n)\nDelete the first-defined (and thus \"duplicate\") Script class (\n#3333\n)\nCatch a known DeprecationWarning when calling .close() (\n#3335\n)\nAdd missed redismod at test_commands.py (\n#3369\n)\nО Maintenance\nUpdate README.md - mentioning redis 7.4 support (\n#3375\n)\nUpdate PyPy 3.8 to 3.10 in CI (\n#3370\n)\nUpdated commands from docker-compose to docker compose (\n#3352\n)\nAdded version restrictions for pytest-asyncio (\n#3362\n)\nDocumentation examples (\n#3361\n,\n#3372\n,\n#3374\n,\n#3377\n,\n#3378\n)\nContributors\nWe'd like to thank all the contributors who worked on this release!\n@AYMENJD\n,\n@AniketP04\n,\n@BackflipPenguin\n,\n@ING-XIAOJIAN\n,\n@MrDenkoV\n,\n@Pedram-Parsian\n,\n@TheBlusky\n,\n@TomerHekmati\n,\n@Wh1isper\n,\n@Zaczero\n,\n@ahmedabdou14\n,\n@akx\n,\n@andy-stark-redis\n,\n@catap\n,\n@chayim\n,\n@d184230\n,\n@danielzhangau\n,\n@daveisfera\n,\n@dependabot\n,\n@dependabot\n[bot],\n@dkuser\n,\n@dmaier-redislabs\n,\n@dmkulazhenko\n,\n@dudizimber\n,\n@dvora-h\n,\n@dwdougherty\n,\n@enjoy-binbin\n,\n@gerzse\n,\n@hongqn\n,\n@jakob-keller\n,\n@kristjanvalur\n,\n@kurtmckee\n,\n@matrey\n,\n@mattwang44\n,\n@max-muoto\n,\n@parmenashp\n,\n@poiuj\n,\n@r0ro\n,\n@sjpotter\n,\n@tbbream\n,\n@trkwyk\n,\n@uglide\n,\n@vladvildanov\n,\n@w-miller\n,\n@wKollendorf\n,\n@willfrey\n,\n@willianmrs\n,\n@zakaf\n,\n@zware\nand\n@zxjlm",
    "crawl_status": "success"
  },
  {
    "library_name": "Jinja2",
    "url": "https://jinja.palletsprojects.com/en/stable/changes/#version-3-1-5",
    "version": "v3.1.5",
    "title": "Changes  Jinja Documentation (3.1.x)",
    "release_date": "Unknown release date",
    "content": "Version 3.1.5\n露\nReleased 2024-12-21\nThe sandboxed environment handles indirect calls to\nstr.format\n, such as\nby passing a stored reference to a filter that calls its argument.\nGHSA-q2x7-8rv6-6q7h\nEscape template name before formatting it into error messages, to avoid\nissues with names that contain f-string syntax.\n#1792\n,\nGHSA-gmj6-6f8f-6699\nSandbox does not allow\nclear\nand\npop\non known mutable sequence\ntypes.\n#2032\nCalling sync\nrender\nfor an async template uses\nasyncio.run\n.\n#1952\nAvoid unclosed\nauto_aiter\nwarnings.\n#1960\nReturn an\naclose\n-able\nAsyncGenerator\nfrom\nTemplate.generate_async\n.\n#1960\nAvoid leaving\nroot_render_func()\nunclosed in\nTemplate.generate_async\n.\n#1960\nAvoid leaving async generators unclosed in blocks, includes and extends.\n#1960\nThe runtime uses the correct\nconcat\nfunction for the current environment\nwhen calling block references.\n#1701\nMake\n|unique\nasync-aware, allowing it to be used after another\nasync-aware filter.\n#1781\n|int\nfilter handles\nOverflowError\nfrom scientific notation.\n#1921\nMake compiling deterministic for tuple unpacking in a\n{%\nset\n...\n%}\ncall.\n#2021\nFix dunder protocol (\ncopy\n/\npickle\n/etc) interaction with\nUndefined\nobjects.\n#2025\nFix\ncopy\n/\npickle\nsupport for the internal\nmissing\nobject.\n#2027\nEnvironment.overlay(enable_async)\nis applied correctly.\n#2061\nThe error message from\nFileSystemLoader\nincludes the paths that were\nsearched.\n#1661\nPackageLoader\nshows a clearer error message when the package does not\ncontain the templates directory.\n#1705\nImprove annotations for methods returning copies.\n#1880\nurlize\ndoes not add\nmailto:\nto values like\n@a@b\n.\n#1870\nTests decorated with\n@pass_context`\ncan be used with the\n|select\nfilter.\n#1624\nUsing\nset\nfor multiple assignment (\na,\nb\n=\n1,\n2\n) does not fail when the\ntarget is a namespace attribute.\n#1413\nUsing\nset\nin all branches of\n{%\nif\n%}{%\nelif\n%}{%\nelse\n%}\nblocks\ndoes not cause the variable to be considered initially undefined.\n#1253",
    "crawl_status": "success"
  },
  {
    "library_name": "Jinja2",
    "url": "https://jinja.palletsprojects.com/en/stable/changes/#version-3-1-3",
    "version": "v3.1.3",
    "title": "Changes  Jinja Documentation (3.1.x)",
    "release_date": "Unknown release date",
    "content": "Version 3.1.3\n露\nReleased 2024-01-10\nFix compiler error when checking if required blocks in parent templates are\nempty.\n#1858\nxmlattr\nfilter does not allow keys with spaces.\nGHSA-h5c8-rqwp-cp95\nMake error messages stemming from invalid nesting of\n{%\ntrans\n%}\nblocks\nmore helpful.\n#1918",
    "crawl_status": "success"
  },
  {
    "library_name": "Jinja2",
    "url": "https://jinja.palletsprojects.com/en/stable/changes/#version-3-1-0",
    "version": "v3.1.0",
    "title": "Changes  Jinja Documentation (3.1.x)",
    "release_date": "Unknown release date",
    "content": "Version 3.1.0\n露\nReleased 2022-03-24\nDrop support for Python 3.6.\n#1534\nRemove previously deprecated code.\n#1544\nWithExtension\nand\nAutoEscapeExtension\nare built-in now.\ncontextfilter\nand\ncontextfunction\nare replaced by\npass_context\n.\nevalcontextfilter\nand\nevalcontextfunction\nare replaced by\npass_eval_context\n.\nenvironmentfilter\nand\nenvironmentfunction\nare replaced\nby\npass_environment\n.\nMarkup\nand\nescape\nshould be imported from MarkupSafe.\nCompiled templates from very old Jinja versions may need to be\nrecompiled.\nLegacy resolve mode for\nContext\nsubclasses is no longer\nsupported. Override\nresolve_or_missing\ninstead of\nresolve\n.\nunicode_urlencode\nis renamed to\nurl_quote\n.\nAdd support for native types in macros.\n#1510\nThe\n{%\ntrans\n%}\ntag can use\npgettext\nand\nnpgettext\nby\npassing a context string as the first token in the tag, like\n{%\ntrans\n\"title\"\n%}\n.\n#1430\nUpdate valid identifier characters from Python 3.6 to 3.7.\n#1571\nFilters and tests decorated with\n@async_variant\nare pickleable.\n#1612\nAdd\nitems\nfilter.\n#1561\nSubscriptions (\n[0]\n, etc.) can be used after filters, tests, and\ncalls when the environment is in async mode.\n#1573\nThe\ngroupby\nfilter is case-insensitive by default, matching\nother comparison filters. Added the\ncase_sensitive\nparameter to\ncontrol this.\n#1463\nWindows drive-relative path segments in template names will not\nresult in\nFileSystemLoader\nand\nPackageLoader\nloading from\ndrive-relative paths.\n#1621",
    "crawl_status": "success"
  },
  {
    "library_name": "Black",
    "url": "https://github.com/psf/black/releases/tag/24.10.0",
    "version": "24.10.0",
    "title": "Release 24.10.0 路 psf/black 路 GitHub",
    "release_date": "2024-10-07T19:20:06Z",
    "content": "24.10.0\nHighlights\nBlack is now officially tested with Python 3.13 and provides Python 3.13\nmypyc-compiled wheels. (\n#4436\n) (\n#4449\n)\nBlack will issue an error when used with Python 3.12.5, due to an upstream memory\nsafety issue in Python 3.12.5 that can cause Black's AST safety checks to fail. Please\nuse Python 3.12.6 or Python 3.12.4 instead. (\n#4447\n)\nBlack no longer supports running with Python 3.8 (\n#4452\n)\nStable style\nFix crashes involving comments in parenthesised return types or\nX | Y\nstyle unions.\n(\n#4453\n)\nFix skipping Jupyter cells with unknown\n%%\nmagic (\n#4462\n)\nPreview style\nFix type annotation spacing between * and more complex type variable tuple (i.e.\ndef fn(*args: *tuple[*Ts, T]) -> None: pass\n) (\n#4440\n)\nCaching\nFix bug where the cache was shared between runs with and without\n--unstable\n(\n#4466\n)\nPackaging\nUpgrade version of mypyc used to 1.12 beta (\n#4450\n) (\n#4449\n)\nblackd\nnow requires a newer version of aiohttp. (\n#4451\n)\nOutput\nAdded Python target version information on parse error (\n#4378\n)\nAdd information about Black version to internal error messages (\n#4457\n)",
    "crawl_status": "success"
  },
  {
    "library_name": "Black",
    "url": "https://github.com/psf/black/releases/tag/25.9.0",
    "version": "25.9.0",
    "title": "Release 25.9.0 路 psf/black 路 GitHub",
    "release_date": "2025-09-19T00:27:15Z",
    "content": "Highlights\nRemove support for pre-python 3.7\nawait/async\nas soft keywords/variable names\n(\n#4676\n)\nStable style\nFix crash while formatting a long\ndel\nstatement containing tuples (\n#4628\n)\nFix crash while formatting expressions using the walrus operator in complex\nwith\nstatements (\n#4630\n)\nHandle\n# fmt: skip\nfollowed by a comment at the end of file (\n#4635\n)\nFix crash when a tuple appears in the\nas\nclause of a\nwith\nstatement (\n#4634\n)\nFix crash when tuple is used as a context manager inside a\nwith\nstatement (\n#4646\n)\nFix crash when formatting a\n\\\nfollowed by a\n\\r\nfollowed by a comment (\n#4663\n)\nFix crash on a\n\\\\r\\n\n(\n#4673\n)\nFix crash on\nawait ...\n(where\n...\nis a literal\nEllipsis\n) (\n#4676\n)\nFix crash on parenthesized expression inside a type parameter bound (\n#4684\n)\nFix crash when using line ranges excluding indented single line decorated items\n(\n#4670\n)\nPreview style\nFix a bug where one-liner functions/conditionals marked with\n# fmt: skip\nwould still\nbe formatted (\n#4552\n)\nImprove\nmultiline_string_handling\nwith ternaries and dictionaries (\n#4657\n)\nFix a bug where\nstring_processing\nwould not split f-strings directly after\nexpressions (\n#4680\n)\nWrap the\nin\nclause of comprehensions across lines if necessary (\n#4699\n)\nRemove parentheses around multiple exception types in\nexcept\nand\nexcept*\nwithout\nas\n. (\n#4720\n)\nAdd\n\\r\nstyle newlines to the potential newlines to normalize file newlines both from\nand to (\n#4710\n)\nParser\nRewrite tokenizer to improve performance and compliance (\n#4536\n)\nFix bug where certain unusual expressions (e.g., lambdas) were not accepted in type\nparameter bounds and defaults. (\n#4602\n)\nPerformance\nAvoid using an extra process when running with only one worker (\n#4734\n)\nIntegrations\nFix the version check in the vim file to reject Python 3.8 (\n#4567\n)\nEnhance GitHub Action\npsf/black\nto read Black version from an additional section in\npyproject.toml:\n[project.dependency-groups]\n(\n#4606\n)\nBuild gallery docker image with python3-slim and reduce image size (\n#4686\n)\nDocumentation\nAdd FAQ entry for windows emoji not displaying (\n#4714\n)",
    "crawl_status": "success"
  },
  {
    "library_name": "Black",
    "url": "https://github.com/psf/black/releases/tag/23.7.0",
    "version": "23.7.0",
    "title": "Release 23.7.0 路 psf/black 路 GitHub",
    "release_date": "2023-07-11T00:20:37Z",
    "content": "23.7.0\nHighlights\nRuntime support for Python 3.7 has been removed. Formatting 3.7 code will still be\nsupported until further notice (\n#3765\n)\nStable style\nFix a bug where an illegal trailing comma was added to return type annotations using\nPEP 604 unions (\n#3735\n)\nFix several bugs and crashes where comments in stub files were removed or mishandled\nunder some circumstances (\n#3745\n)\nFix a crash with multi-line magic comments like\ntype: ignore\nwithin parentheses\n(\n#3740\n)\nFix error in AST validation when\nBlack\nremoves trailing whitespace in a type comment\n(\n#3773\n)\nPreview style\nImplicitly concatenated strings used as function args are no longer wrapped inside\nparentheses (\n#3640\n)\nRemove blank lines between a class definition and its docstring (\n#3692\n)\nConfiguration\nThe\n--workers\nargument to\nBlack\ncan now be specified via the\nBLACK_NUM_WORKERS\nenvironment variable (\n#3743\n)\n.pytest_cache\n,\n.ruff_cache\nand\n.vscode\nare now excluded by default (\n#3691\n)\nFix\nBlack\nnot honouring\npyproject.toml\nsettings when running\n--stdin-filename\nand the\npyproject.toml\nfound isn't in the current working directory (\n#3719\n)\nBlack\nwill now error if\nexclude\nand\nextend-exclude\nhave invalid data types in\npyproject.toml\n, instead of silently doing the wrong thing (\n#3764\n)\nPackaging\nUpgrade mypyc from 0.991 to 1.3 (\n#3697\n)\nRemove patching of Click that mitigated errors on Python 3.6 with\nLANG=C\n(\n#3768\n)\nParser\nAdd support for the new PEP 695 syntax in Python 3.12 (\n#3703\n)\nPerformance\nSpeed up\nBlack\nsignificantly when the cache is full (\n#3751\n)\nAvoid importing\nIPython\nin a case where we wouldn't need it (\n#3748\n)\nOutput\nUse aware UTC datetimes internally, avoids deprecation warning on Python 3.12 (\n#3728\n)\nChange verbose logging to exactly mirror\nBlack\n's logic for source discovery (\n#3749\n)\nBlackd\nThe\nblackd\nargument parser now shows the default values for options in their help\ntext (\n#3712\n)\nIntegrations\nBlack is now tested with\nPYTHONWARNDEFAULTENCODING = 1\n(\n#3763\n)\nUpdate GitHub Action to display black output in the job summary (\n#3688\n)\nDocumentation\nAdd a CITATION.cff file to the root of the repository, containing metadata on how to\ncite this software (\n#3723\n)\nUpdate the\nclasses\nand\nexceptions\ndocumentation in Developer reference to match\nthe latest code base (\n#3755\n)",
    "crawl_status": "success"
  },
  {
    "library_name": "Coverage",
    "url": "https://github.com/nedbat/coveragepy/releases/tag/7.2.0",
    "version": "7.2.0",
    "title": "Release 7.2.0 路 coveragepy/coveragepy 路 GitHub",
    "release_date": "2024-10-13T23:36:29Z",
    "content": "Version 7.2.0  2023-02-22\nAdded a new setting\n[report] exclude_also\nto let you add more exclusions without overwriting the defaults. Thanks,\nAlpha Chen\n, closing\nissue 1391\n.\nAdded a\nCoverageData.purge_files()\nmethod to remove recorded data for a particular file. Contributed by\nStephan Deibel\n.\nFix: when reporting commands fail, they will no longer congratulate themselves with messages like Wrote XML report to file.xml before spewing a traceback about their failure.\nFix: arguments in the public API that name file paths now accept pathlib.Path objects. This includes the\ndata_file\nand\nconfig_file\narguments to the Coverage constructor and the\nbasename\nargument to CoverageData. Closes\nissue 1552\n.\nFix: In some embedded environments, an IndexError could occur on stop() when the originating thread exits before completion. This is now fixed, thanks to\nRussell Keith-Magee\n, closing\nissue 1542\n.\nAdded a\npy.typed\nfile to announce our type-hintedness. Thanks,\nKotlinIsland\n.\n★ PyPI page:\ncoverage 7.2.0\n.\n★ To install:\npython3 -m pip install coverage==7.2.0",
    "crawl_status": "success"
  },
  {
    "library_name": "Coverage",
    "url": "https://github.com/nedbat/coveragepy/releases/tag/7.12.0",
    "version": "7.12.0",
    "title": "Release 7.12.0 路 coveragepy/coveragepy 路 GitHub",
    "release_date": "2025-11-18T11:37:56Z",
    "content": "Version 7.12.0  2025-11-18\nThe HTML report now shows separate coverage totals for statements and branches, as well as the usual combined coverage percentage. Thanks to Ryuta Otsuka for the\ndiscussion\nand the\nimplementation\n.\nThe JSON report now includes separate coverage totals for statements and branches, thanks to\nRyuta Otsuka\n.\nFix:\nexcept*\nclauses were not handled properly under the sysmon measurement core, causing KeyError exceptions as described in\nissue 2086\n. This is now fixed.\nFix: we now defend against aggressive mocking of\nopen()\nthat could cause errors inside coverage.py. An example of a failure is in\nissue 2083\n.\nFix: in unusual cases where a test suite intentionally exhausts the systems file descriptors to test handling errors in\nopen()\n, coverage.py would fail when trying to open source files, as described in\nissue 2091\n. This is now fixed.\nA small tweak to the HTML report: file paths now use thin spaces around slashes to make them easier to read.\n★ PyPI page:\ncoverage 7.12.0\n.\n★ To install:\npython3 -m pip install coverage==7.12.0",
    "crawl_status": "success"
  },
  {
    "library_name": "Coverage",
    "url": "https://github.com/nedbat/coveragepy/releases/tag/7.5.0",
    "version": "7.5.0",
    "title": "Release 7.5.0 路 coveragepy/coveragepy 路 GitHub",
    "release_date": "2024-10-13T23:37:30Z",
    "content": "Version 7.5.0  2024-04-23\nAdded initial support for function and class reporting in the HTML report. There are now three index pages which link to each other: files, functions, and classes. Other reports dont yet have this information, but it will be added in the future where it makes sense. Feedback gladly accepted! Finishes\nissue 780\n.\nOther HTML report improvements:\nThere is now a hide covered checkbox to filter out 100% files, finishing\nissue 1384\n.\nThe index page is always sorted by one of its columns, with clearer indications of the sorting.\nThe previous file shortcut key didnt work on the index page, but now it does, fixing\nissue 1765\n.\nThe debug output showing which configuration files were tried now shows absolute paths to help diagnose problems where settings arent taking effect, and is renamed from attempted_config_files to the more logical config_files_attempted.\nPython 3.13.0a6 is supported.\n★ PyPI page:\ncoverage 7.5.0\n.\n★ To install:\npython3 -m pip install coverage==7.5.0",
    "crawl_status": "success"
  },
  {
    "library_name": "Polars",
    "url": "https://github.com/pola-rs/polars/releases/tag/py-1.30.0",
    "version": "py-1.30.0",
    "title": "Release Python Polars 1.30.0 路 pola-rs/polars 路 GitHub",
    "release_date": "2025-05-21T13:33:59Z",
    "content": " Performance improvements\nSwitch eligible casts to non-strict in optimizer (\n#22850\n)\nAllow predicate passing set_sorted (\n#22797\n)\nIncrease default cross-file parallelism limit for new-streaming multiscan (\n#22700\n)\nAdd elementwise execution mode for\nlist.eval\n(\n#22715\n)\nSupport optimised init from non-dict\nMapping\nobjects in\nfrom_records\nand frame/series constructors (\n#22638\n)\nAdd streaming cross-join node (\n#22581\n)\nSwitch off\nmaintain_order\nin group-by followed by sort (\n#22492\n)\n Enhancements\nLoad AWS\nendpoint_url\nusing boto3 (\n#22851\n)\nImplemented\nlist.filter\n(\n#22749\n)\nSupport binaryoffset in search sorted (\n#22786\n)\nAdd\nnulls_equal\nflag to\nlist/arr.contains\n(\n#22773\n)\nImplement\nLazyFrame.match_to_schema\n(\n#22726\n)\nImproved time-string parsing and inference (generally, and via the SQL interface) (\n#22606\n)\nAllow for\n.over\nto be called without\npartition_by\n(\n#22712\n)\nSupport\nAnyValue\ntranslation from\nPyMapping\nvalues (\n#22722\n)\nSupport optimised init from non-dict\nMapping\nobjects in\nfrom_records\nand frame/series constructors (\n#22638\n)\nSupport inference of\nInt128\ndtype from databases that support it (\n#22682\n)\nAdd options to write Parquet field metadata (\n#22652\n)\nAdd\ncast_options\nparameter to control type casting in\nscan_parquet\n(\n#22617\n)\nAllow casting\nList<UInt8>\nto\nBinary\n(\n#22611\n)\nAllow setting of regex size limit using\nPOLARS_REGEX_SIZE_LIMIT\n(\n#22651\n)\nSupport use of literal values as \"other\" when evaluating\nSeries.zip_with\n(\n#22632\n)\nAllow to read and write custom file-level parquet metadata (\n#21806\n)\nSupport PEP702\n@deprecated\ndecorator behaviour (\n#22594\n)\nSupport grouping by\npl.Array\n(\n#22575\n)\nPreserve exception type and traceback for errors raised from Python (\n#22561\n)\nUse fixed-width font in streaming phys plan graph (\n#22540\n)\n Bug fixes\nFix RuntimeError when serializing the same DataFrame from multiple threads (\n#22844\n)\nFix map_elements predicate pushdown (\n#22833\n)\nFix reverse list type (\n#22832\n)\nDon't require numpy for search_sorted (\n#22817\n)\nAdd type equality checking for relevant methods (\n#22802\n)\nInvalid output for\nfill_null\nafter\nwhen.then\non structs (\n#22798\n)\nDon't panic for cross join with misaligned chunking (\n#22799\n)\nPanic on quantile over nulls in rolling window (\n#22792\n)\nRespect BinaryOffset metadata (\n#22785\n)\nCorrect the output order of\nPartitionByKey\nand\nPartitionParted\n(\n#22778\n)\nFallback to non-strict casting for deprecated casts (\n#22760\n)\nClippy on new stable version (\n#22771\n)\nHandle sliced out remainder for bitmaps (\n#22759\n)\nDon't merge\nEnum\ncategories on append (\n#22765\n)\nFix unnest() not working on empty struct columns (\n#22391\n)\nFix the default value type in\nSchema\ninit (\n#22589\n)\nCorrect name in\nunnest\nerror message (\n#22740\n)\nProvide \"schema\" to\nDataFrame\n, even if empty JSON (\n#22739\n)\nProperly account for nulls in the\nis_not_nan\ncheck made in\ndrop_nans\n(\n#22707\n)\nIncorrect result from SQL\ncount(*)\nwith\npartition by\n(\n#22728\n)\nFix deadlock joining scanned tables with low thread count (\n#22672\n)\nDon't allow deserializing incompatible DSL (\n#22644\n)\nIncorrect null dtype from binary ops in empty group_by (\n#22721\n)\nDon't mark\nstr.replace_many\nwith Mapping as deprecated (\n#22697\n)\nGzip has maximum compression of 9, not 10 (\n#22685\n)\nFix predicate pushdown of fallible expressions (\n#22669\n)\nFix\nindex out of bounds\npanic when scanning hugging face (\n#22661\n)\nPanic on\ngroup_by\nwith literal and empty rows (\n#22621\n)\nReturn input instead of panicking if empty subset in\ndrop_nulls()\nand\ndrop_nans()\n(\n#22469\n)\nBump argminmax to 0.6.3 (\n#22649\n)\nDSL version deserialization endianness (\n#22642\n)\nAllow Expr.round() to be called on integer dtypes (\n#22622\n)\nFix panic when filtering based on row index column in parquet (\n#22616\n)\nWASM and PyOdide compile (\n#22613\n)\nResolve\nget()\nSchemaMismatch panic (\n#22350\n)\nPanic in group_by_dynamic on single-row df with group_by (\n#22597\n)\nAdd\nnew_streaming\nfeature to\npolars\ncrate (\n#22601\n)\nConsistently use Unix epoch as origin for\ndt.truncate\n(except weekly buckets which start on Mondays) (\n#22592\n)\nFix interpolate on dtype Decimal (\n#22541\n)\nCSV count rows skipped last line if file did not end with newline (\n#22577\n)\nMake nested strict casting actually strict (\n#22497\n)\nMake\nreplace\nand\nreplace_strict\nmapping use list literals (\n#22566\n)\nAllow pivot on\nTime\ncolumn (\n#22550\n)\nFix error when providing CSV schema with extra columns (\n#22544\n)\nPanic on bitwise op between Series and Expr (\n#22527\n)\nMulti-selector regex expansion (\n#22542\n)\n Documentation\nAdd pre-release policy (\n#22808\n)\nFix broken link to service account page in Polars Cloud docs (\n#22762\n)\nAdd\nmatch_to_schema\nto API reference (\n#22777\n)\nProvide additional explanation and examples for the\nvalue_counts\n\"normalize\" parameter (\n#22756\n)\nRework documentation for\ndrop\n/\nfill\nfor nulls/nans (\n#22657\n)\nAdd documentation to new\nRoundMode\nparameter in\nround\n(\n#22555\n)\nAdd missing\nrepeat_by\nto API reference, fixup\nlist.get\n(\n#22698\n)\nFix non-rendering bullet points in\nscan_iceberg\n(\n#22694\n)\nImprove\ninsert_column\ndocstring (description and examples) (\n#22551\n)\nImprove\njoin\ndocumentation (\n#22556\n)\n Build system\nFix building\npolars-lazy\nwith certain features (\n#22846\n)\nAdd missing features (\n#22839\n)\nPatch pyo3 to disable recompilation (\n#22796\n)\n锔 Other improvements\nUpdate Rust Polars versions (\n#22854\n)\nAdd basic smoke test for free-threaded python (\n#22481\n)\nUpdate Polars Rust versions (\n#22834\n)\nFix\nnix build\n(\n#22809\n)\nFix flake.nix to work on macos (\n#22803\n)\nUnused variables on release build (\n#22800\n)\nUpdate cloud docs (\n#22624\n)\nFix unstable\nlist.eval\nperformance test (\n#22729\n)\nAdd proptest implementations for all Array types (\n#22711\n)\nDispatch\n.write_*\nto\n.lazy().sink_*(engine='in-memory')\n(\n#22582\n)\nMove to all optimization flags to\nQueryOptFlags\n(\n#22680\n)\nAdd test for\nstr.replace_many\n(\n#22615\n)\nStabilize\nsink_*\n(\n#22643\n)\nAdd proptest for row-encode (\n#22626\n)\nUpdate rust version in nix flake (\n#22627\n)\nAdd a nix flake with a devShell and package (\n#22246\n)\nUse a wrapper struct to store time zone (\n#22523\n)\nAdd\nproptest\ntesting for for parquet decoding kernels (\n#22608\n)\nInclude equiprobable as valid quantile method (\n#22571\n)\nRemove confusing error context calling\n.collect(_eager=True)\n(\n#22602\n)\nFix test_truncate_path test case (\n#22598\n)\nUnify function flags into 1 bitset (\n#22573\n)\nDisplay the operation behind\nin-memory-map\n(\n#22552\n)\nThank you to all our contributors for making this release possible!\n@IvanIsCoding\n,\n@JakubValtar\n,\n@Julian-J-S\n,\n@LucioFranco\n,\n@MarcoGorelli\n,\n@WH-2099\n,\n@alexander-beedie\n,\n@borchero\n,\n@bschoenmaeckers\n,\n@cmdlineluser\n,\n@coastalwhite\n,\n@etiennebacher\n,\n@florian-klein\n,\n@itamarst\n,\n@kdn36\n,\n@mcrumiller\n,\n@nameexhaustion\n,\n@nikaltipar\n,\n@orlp\n,\n@pavelzw\n,\n@r-brink\n,\n@ritchie46\n,\n@stijnherfst\n,\n@teotwaki\n,\n@timkpaine\nand\n@wence-",
    "crawl_status": "success"
  },
  {
    "library_name": "Polars",
    "url": "https://github.com/pola-rs/polars/releases/tag/py-0.18.0",
    "version": "py-0.18.0",
    "title": "Release Python Polars 0.18.0 路 pola-rs/polars 路 GitHub",
    "release_date": "2023-05-29T20:01:39Z",
    "content": " Highlights\nRename list namespace accesor from\n.arr\nto\n.list\n(\n#8999\n)\n锔\nBreaking changes\npropagate null in equality comparisons (\n#9053\n)\nformalize implode -> explode relation (\n#9038\n)\nDrop subclassing support for\nDataFrame\n/\nLazyFrame\n(\n#9008\n)\nconsistently return list of date/datetime from lazy date_range (\n#8513\n)\nDefault\ndate_range\n/\nones\n/\nzeros\nto\neager=False\n(\n#9007\n)\nRename list namespace accesor from\n.arr\nto\n.list\n(\n#8999\n)\ndisallow time zones other than those in zoneinfo.available_timezones() (\n#8993\n)\nremove window expression magic (\n#8992\n)\nraise error when sorted flag not set (\n#8994\n)\nDrop subclassing support for GroupBy (\n#7746\n)\nin Series constructor, if inputs are time-zone-aware datetimes, convert to UTC (\n#8881\n)\nparse offset-naive date time strings as Timestamp(time_unit), offset-aware datetime strings as Timestamp(time_unit, \"UTC\"), and remove the utc argument (\n#8714\n)\nRemove deprecated tz_aware argument (\n#8696\n)\n Performance improvements\nspeed up write_csv for time-zone-aware columns (\n#9093\n)\nparallelize rolling_window group materialization (\n#9095\n)\nelide hot loop in hash joins (\n#9075\n)\n Enhancements\nconversion from\nUtf8\nto\nDecimal\n. (\n#9090\n)\ndefault to checking sortedness in groupby_rolling (\n#9063\n)\npropagate null in equality comparisons (\n#9053\n)\nwarn if constructing Series with time-zone-aware datetimes (\n#9058\n)\nimplement apply for rolling/dynamic_groupby (\n#9049\n)\nSupport more data types in lazy\nrepeat\n(\n#9046\n)\nimplement strategy=nearest for join_asof (\n#9024\n)\narr.sum expression (\n#9041\n)\nformalize implode -> explode relation (\n#9038\n)\nadd array namespace and min/max expression (\n#9032\n)\nimprove error message on row-wise overflow (\n#9021\n)\nproperly apply slice at UNION level (\n#9018\n)\nconsistently return list of date/datetime from lazy date_range (\n#8513\n)\nDefault\ndate_range\n/\nones\n/\nzeros\nto\neager=False\n(\n#9007\n)\ndisallow time zones other than those in zoneinfo.available_timezones() (\n#8993\n)\nraise error when sorted flag not set (\n#8994\n)\nin Series constructor, if inputs are time-zone-aware datetimes, convert to UTC (\n#8881\n)\nparse offset-naive date time strings as Timestamp(time_unit), offset-aware datetime strings as Timestamp(time_unit, \"UTC\"), and remove the utc argument (\n#8714\n)\n Bug fixes\nrolling_groupy was returning incorrect results when offset was positive (\n#9082\n)\ndon't underflow on list.tail (\n#9089\n)\nfix null/empty in List::take_unchecked (\n#9074\n)\nrepeat by (\n#9023\n)\nraise in to_datetime/strptime if format contains hour but not minute directive (\n#9044\n)\nOrder of pl.Array arguments in docstring (\n#9059\n)\npropagate nulls in broadcasting of order comparisons (\n#9050\n)\nImprove read_parquet missing column error message (\n#8961\n)\nfix apply with passed date/datetime return_dtype (\n#9035\n)\nrespect inner type in Array construction (\n#9020\n)\nraise error on invalid aggregation (\n#9013\n)\nfix fused arithmetic in window functions (\n#9012\n)\ndon't allow silent init of\nSeries\ndeclared as int/temporal with floating point values (\n#9004\n)\ndeprecate\ntime_unit\nproperty from\nSeries\n(\n#8990\n)\n锔 Other improvements\nImprove expression parsing utils (\n#9094\n)\nRefactor expression input parsing util (\n#9085\n)\nOrganize \"as_datatype\" functions (\n#9080\n)\nChange eager path for\nrepeat\n(\n#9048\n)\nClean up\narange\n/\ndate_range\n/\ntime_range\n(\n#9027\n)\nDrop subclassing support for\nDataFrame\n/\nLazyFrame\n(\n#9008\n)\nminor\nSQLContext\ndocstring cleanups (\n#9005\n)\nRename list namespace accesor from\n.arr\nto\n.list\n(\n#8999\n)\nremove window expression magic (\n#8992\n)\nDrop subclassing support for GroupBy (\n#7746\n)\nrefactor!(python): Remove old deprecated functionality (\n#8995\n)\nRemove deprecated tz_aware argument (\n#8696\n)\nThank you to all our contributors for making this release possible!\n@CloseChoice\n,\n@MarcoGorelli\n,\n@alexander-beedie\n,\n@charliegallop\n,\n@jonashaag\n,\n@mcrumiller\n,\n@raymead\n,\n@ritchie46\n,\n@sorhawell\n,\n@stinodego\n, @tim-habitat and\n@universalmind303",
    "crawl_status": "success"
  },
  {
    "library_name": "Polars",
    "url": "https://github.com/pola-rs/polars/releases/tag/py-1.0.0",
    "version": "py-1.0.0",
    "title": "Release Python Polars 1.0.0 路 pola-rs/polars 路 GitHub",
    "release_date": "2024-07-01T10:40:00Z",
    "content": "This is the first major release for Python Polars. Please check out the\nupgrade guide\nfor help navigating the breaking changes when upgrading to this version.\n Breaking changes\nChange default engine for\nread_excel\nto\n\"calamine\"\n(\n#17263\n)\nImplement binary serialization of LazyFrame/DataFrame/Expr and set it as the default format (\n#17223\n)\nStreamline optional dependency definitions in\npyproject.toml\n(\n#17168\n)\nUpdate\nread/scan_parquet\nto disable Hive partitioning by default for file inputs (\n#17106\n)\nSplit\nreplace\nfunctionality into two separate methods (\n#16921\n)\nDefault to writing binview data to IPC, mark\ncompression\nargument as keyword-only (\n#17084\n)\nRemove re-export of type aliases (\n#17032\n)\nRename\nModuleUpgradeRequired\nand\nPolarsPanicError\nerror, remove\nInvalidAssert\nerror (\n#17033\n)\nChange data orientation inference logic for DataFrame construction and warn when row orientation is inferred (\n#16976\n)\nProperly apply\nstrict\nparameter in Series constructor (\n#16939\n)\nRemove supertype definition of List and non-List types (\n#16918\n)\nConsistently convert to given time zone in Series constructor  (\n#16828\n)\nUpdate\nreshape\nto return Array types instead of List types (\n#16825\n)\nDefault to raising on out-of-bounds indices in all\nget\n/\ngather\noperations (\n#16841\n)\nNative\nselector\nXOR set operation, guarantee consistent selector column-order (\n#16833\n)\nSet\ninfer_schema_length\nas keyword-only argument in\nstr.json_decode\n(\n#16835\n)\nUpdate\nset_sorted\nto only accept a single column (\n#16800\n)\nRemove deprecated parameters in\nSeries.cut/qcut\nand update struct field names (\n#16741\n)\nExpedited removal of certain deprecated functionality (\n#16754\n)\nUpdate some error types to more appropriate variants (\n#15030\n)\nScheduled removal of deprecated functionality (\n#16715\n)\nChange default\noffset\nin\ngroup_by_dynamic\nfrom 'negative\nevery\n' to 'zero' (\n#16658\n)\nConstrain access to globals from\nDataFrame.sql\nin favor of top-level\npl.sql\n(\n#16598\n)\nRead 2D NumPy arrays as\nArray\ntype instead of\nList\n(\n#16710\n)\nUpdate\nclip\nto no longer propagate nulls in the given bounds (\n#14413\n)\nChange\nstr.to_datetime\nto default to microsecond precision for format specifiers\n\"%f\"\nand\n\"%.f\"\n(\n#13597\n)\nUpdate resulting column names in\npivot\nwhen pivoting by multiple values (\n#16439\n)\nPreserve nulls in\newm_mean\n,\newm_std\n, and\newm_var\n(\n#15503\n)\nRestrict casting for temporal data types (\n#14142\n)\nSupport Decimal types by default when converting from Arrow (\n#15324\n)\nRemove serde functionality from\npl.read_json\nand\nDataFrame.write_json\n(\n#16550\n)\nUpdate function signature of\nnth\nto allow positional input of indices, remove\ncolumns\nparameter (\n#16510\n)\nRename struct fields of\nrle\noutput to\nlen\n/\nvalue\nand update data type of\nlen\nfield (\n#15249\n)\nRemove class variables from some DataTypes (\n#16524\n)\nAdd\ncheck_names\nparameter to\nSeries.equals\nand default to\nFalse\n(\n#16610\n)\n锔\nDeprecations\nDeprecate\nLazyFrame.fetch\n(\n#17278\n)\nDeprecate\nsize\nparameter in parametric testing strategies in favor of\nmin_size\n/\nmax_size\n(\n#17128\n)\nSplit\nreplace\nfunctionality into two separate methods (\n#16921\n)\nRename\nDataFrame.melt\nto\nunpivot\nand make parameters consistent with\npivot\n(\n#17095\n)\nRemove re-export of exceptions at top-level (\n#17059\n)\nDeprecate\ndt.mean\n/\ndt.median\nin favor of\nmean\n/\nmedian\n(\n#16888\n)\nDeprecate\nLazyFrame.with_context\nin favor of horizontal concatenation (\n#16860\n)\nRename parameter\ndescending\nto\nreverse\nin\ntop_k\nmethods (\n#16817\n)\nRename\nstr.concat\nto\nstr.join\nand update default delimiter (\n#16790\n)\nDeprecate\narctan2d\nin favor of\narctan2(...).degrees()\n(\n#16786\n)\n Performance improvements\nRechunk before\ngroup_by\n`iteration (\n#17302\n)\nImprove\nunique\nperformance by adding RangedUniqueKernel for primitive arrays (\n#17166\n)\nImprove\nunique\nperformance by creating UniqueKernel and improve bool implementation (\n#17160\n)\nDefault to writing binview data to IPC, mark\ncompression\nargument as keyword-only (\n#17084\n)\nParallelize arrow conversion if binview -> large_bin (\n#17083\n)\nGarbage collect buffers in\nif-then-else\nview kernel (\n#16993\n)\nDesugar\nAND\nfilter into multiple nodes (\n#16992\n)\nOptimize generic\narg_sort\nof row-encoding (\n#16894\n)\nImprove\nrle_id\niteration performance and set sorted flags (\n#16893\n)\nOptimize\nsort\nfor String and Binary types (\n#16871\n)\nUse\nsplit_at\nin\nsplit\n(\n#16865\n)\nUse\nsplit_at\ninstead of double slice in chunk splits. (\n#16856\n)\nDon't rechunk in\nalign_\nif arrays are aligned (\n#16850\n)\nDon't create small chunks in parallel collect. (\n#16845\n)\nAdd dedicated no-null branch in\narg_sort\n(\n#16808\n)\nSpeed up\ndt.offset_by\n2x for constant durations (\n#16728\n)\nToggle coalesce in\njoin\nif non-coalesced key isn't projected (\n#16677\n)\nMake\ndt.truncate\n1.5x faster when\nevery\nis just a single duration (and not an expression) (\n#16666\n)\nAlways prune unused columns in semi/anti join (\n#16665\n)\n Enhancements\nAdd SQL support for\nNATURAL\njoins and the\nCOLUMNS\nfunction (\n#17295\n)\nAdd\nstr.extract_many\nexpression (\n#17304\n)\nChange default engine for\nread_excel\nto\n\"calamine\"\n(\n#17263\n)\nDeprecate\nLazyFrame.fetch\n(\n#17278\n)\nSupport '%' in pathnames for async scan (\n#17271\n)\nSupport\nSQL\nStruct/JSON field access operators (\n#17226\n)\nExclude directories from glob expansion result (\n#17174\n)\nSupport SQL\nORDER BY ALL\nsyntax (\n#17212\n)\nSupport PostgreSQL\n^@\n(\"starts with\"), and\n~~\n,\n~~*\n,\n!~~\n,\n!~~*\n(\"like\", \"ilike\") string-matching operators (\n#17251\n)\nSupport SQL\nSELECT * ILIKE\nwildcard syntax (\n#17169\n)\nSupport\nSQL\ntemporal functions\nSTRFTIME\nand\nSTRPTIME\n, and typed literal syntax (\n#17245\n)\nSupport date/datetime for hive parts (\n#17256\n)\nImplement binary serialization of LazyFrame/DataFrame/Expr and set it as the default format (\n#17223\n)\nAllow no-op\nround/ceil/floor\non integer types (\n#17241\n)\nSupport loading from datasets where the hive columns are also stored in the file (\n#17203\n)\nImplement serde for Null columns (\n#17218\n)\nSupport Decimal types in\nwrite_csv/write_json\n(\n#14209\n)\nAdd optional \"default\" to\nget_column\nDataFrame method (\n#17176\n)\nImprove SQL support for array indexing, increase test coverage (\n#16972\n)\nSupport reading byte stream split encoded floats and doubles in parquet (\n#17099\n)\nAdd\nfloat_scientific\noption to\nwrite_csv\n/\nsink_csv\n(\n#17111\n)\nSupport\nStruct\nfield selection in the SQL engine,\nRENAME\nand\nREPLACE\nselect wildcard options (\n#17109\n)\nUpdate\nDataFrame.pivot\nto allow\nindex=None\nwhen\nvalues\nis set (\n#17126\n)\nUpdate\nread/scan_parquet\nto disable Hive partitioning by default for file inputs (\n#17106\n)\nImprove ipython autocomplete for LazyFrame and DataFrame (\n#17091\n)\nSplit\nreplace\nfunctionality into two separate methods (\n#16921\n)\nImprove schema inference for hive partitions (\n#17079\n)\nRename\nDataFrame.melt\nto\nunpivot\nand make parameters consistent with\npivot\n(\n#17095\n)\nPrint row index in\nexplain\nand\nshow_graph\n(\n#17074\n)\nSupport top-level\npl.col\nautocompletion for iPython (\n#17080\n)\nRemove re-export of exceptions at top-level (\n#17059\n)\nImplement predicate and projection pushdown for\nread_ndjson\n(\n#17068\n)\nAllow (non-)coalescing in join_asof (\n#17066\n)\nTurn of coalescing and fix mutation of join on expressions (\n#17061\n)\nExpand NDJson glob into one SCAN (\n#17063\n)\nDo not parse hive partitions from user provided base directory path (\n#17055\n)\nSupport directory paths in scans for Parquet, IPC and CSV (\n#17017\n)\nImplement general array equality checks (\n#17043\n)\nAdd\nstrict\nparameter to\nDataFrame/LazyFrame.drop\nand fix behavior to default to True (\n#17044\n)\nRename\nModuleUpgradeRequired\nand\nPolarsPanicError\nerror, remove\nInvalidAssert\nerror (\n#17033\n)\nAdd\nrechunk\nparameter to\nread_delta\n(\n#16991\n)\nallow experimental metadata use on release (\n#17005\n)\nAdd simple version of\njson_normalize\n(\n#17015\n)\nChange data orientation inference logic for DataFrame construction and warn when row orientation is inferred (\n#16976\n)\nDesugar\nAND\nfilter into multiple nodes (\n#16992\n)\nHandle textio even if not correct (\n#16971\n)\nProperly apply\nstrict\nparameter in Series constructor (\n#16939\n)\nAdd SQL support for\nINTERSECT\nand\nEXCEPT\nops (\n#16960\n)\nAdd\nPerformanceWarning\nto LazyFrame properties (\n#16964\n)\nAdd\ncollect_schema\nmethod to\nLazyFrame\nand\nDataFrame\n(\n#16929\n)\nAllow setting file cache TTL on a per-file basis (\n#16891\n)\nSupport Decimal inputs for\nlit\n(\n#16950\n)\nImplement multiply and division for lhs duration (\n#16948\n)\nRaise on invalid temporal arithmetic (\n#16934\n)\nAlways end with a in-memory sink on collect (\n#16928\n)\nAdd\nDataFrame.style\nnamespace (\n#16809\n)\nAdd\nSchema\nclass (\n#16873\n)\nNormalize\nvalue_counts\n(\n#16917\n)\nImplement equality for more Array types (\n#16902\n)\nSet up some of the infrastructure for new streaming engine (\n#16900\n)\nCache downloaded cloud IPC files (\n#16892\n)\nConsistently convert to given time zone in Series constructor  (\n#16828\n)\nImprove\nread_csv\nSQL table reading function defaults (better handle dates) (\n#16866\n)\nSupport SQL\nVALUES\nclause and inline renaming of columns in CTE & derived table definitions (\n#16851\n)\nSupport Python\nEnum\nvalues in\nlit\n(\n#16858\n)\nConvert to given time zone in\n.str.to_datetime\nwhen values are offset-aware (\n#16742\n)\nUpdate\nreshape\nto return Array types instead of List types (\n#16825\n)\nDefault to raising on out-of-bounds indices in all\nget\n/\ngather\noperations (\n#16841\n)\nSupport\nSQL\n\"SELECT\" with no tables, optimise registration of globals (\n#16836\n)\nNative\nselector\nXOR set operation, guarantee consistent selector column-order (\n#16833\n)\nExtend recognised\nEXTRACT\nand\nDATE_PART\nSQL part abbreviations (\n#16767\n)\nImprove error message when raising integers to negative integers, improve docs (\n#16827\n)\nReturn datetime for mean/median of Date colum (\n#16795\n)\nUpdate\nset_sorted\nto only accept a single column (\n#16800\n)\nExpose overflowing cast (\n#16805\n)\nUpdate\ngroup_by\niteration and\npartition_by\nto always return tuple keys (\n#16793\n)\nSupport array arithmetic for equally sized shapes (\n#16791\n)\nExpedited removal of certain deprecated functionality (2) (\n#16779\n)\nRemoval of\nread_database_uri\npassthrough from\nread_database\n(\n#16783\n)\nRemove\npyxlsb\nengine from\nread_excel\n(\n#16784\n)\nAdd\ncheck_order\nparameter to\nassert_series_equal\n(\n#16778\n)\nEnforce deprecation of keyword arguments as positional (\n#16755\n)\nSupport cloud storage in\nscan_csv\n(\n#16674\n)\nStreamline SQL\nINTERVAL\nhandling and improve related error messages, update\nsqlparser-rs\nlib (\n#16744\n)\nSupport use of ordinal values in SQL\nORDER BY\nclause (\n#16745\n)\nSupport executing polars SQL against\npandas\nand\npyarrow\nobjects (\n#16746\n)\nRemove deprecated parameters in\nSeries.cut/qcut\nand update struct field names (\n#16741\n)\nExpedited removal of certain deprecated functionality (\n#16754\n)\nRemove deprecated functionality from rolling methods (\n#16750\n)\nUpdate\ndate_range\nto no longer produce datetime ranges (\n#16734\n)\nMark\nmin_periods\nas keyword-only for\nrolling\nmethods (\n#16738\n)\nRemove deprecated\ntop_k\nparameters\nnulls_last\n,\nmaintain_order\n, and\nmultithreaded\n(\n#16599\n)\nSupport order-by in window functions (\n#16743\n)\nAdd SQL support for\nNULLS FIRST/LAST\nordering (\n#16711\n)\nUpdate some error types to more appropriate variants (\n#15030\n)\nInitial SQL support for\nINTERVAL\nstrings (\n#16732\n)\nScheduled removal of deprecated functionality (2) (\n#16724\n)\nScheduled removal of deprecated functionality (\n#16715\n)\nEnforce deprecation of\noffset\narg in\ntruncate\nand\nround\n(\n#16655\n)\nChange default\noffset\nin\ngroup_by_dynamic\nfrom 'negative\nevery\n' to 'zero' (\n#16658\n)\nConstrain access to globals from\nDataFrame.sql\nin favor of top-level\npl.sql\n(\n#16598\n)\nRead 2D NumPy arrays as\nArray\ntype instead of\nList\n(\n#16710\n)\nUpdate\nclip\nto no longer propagate nulls in the given bounds (\n#14413\n)\nChange\nstr.to_datetime\nto default to microsecond precision for format specifiers\n\"%f\"\nand\n\"%.f\"\n(\n#13597\n)\nUpdate resulting column names in\npivot\nwhen pivoting by multiple values (\n#16439\n)\nPreserve nulls in\newm_mean\n,\newm_std\n, and\newm_var\n(\n#15503\n)\nRestrict casting for temporal data types (\n#14142\n)\nAdd many more auto-inferable datetime formats for\nstr.to_datetime\n(\n#16634\n)\nSupport Decimal types by default when converting from Arrow (\n#15324\n)\nRemove serde functionality from\npl.read_json\nand\nDataFrame.write_json\n(\n#16550\n)\nUpdate function signature of\nnth\nto allow positional input of indices, remove\ncolumns\nparameter (\n#16510\n)\nRename struct fields of\nrle\noutput to\nlen\n/\nvalue\nand update data type of\nlen\nfield (\n#15249\n)\nRemove class variables from some DataTypes (\n#16524\n)\nAdd\ncheck_names\nparameter to\nSeries.equals\nand default to\nFalse\n(\n#16610\n)\nDedicated\nSQLInterface\nand\nSQLSyntax\nerrors (\n#16635\n)\nAdd\nDIV\nfunction support to the SQL interface (\n#16678\n)\nSupport non-coalescing streaming left join (\n#16672\n)\nAllow wildcard and exclude before struct expansions (\n#16671\n)\n Bug fixes\nRaise on invalid shape dataframe arithmetic (\n#17322\n)\nFix panic in window case (\n#17320\n)\nRaise errors instead of panicking when\nsink_csv\nfails (\n#17313\n)\nRaise if join keys are passed to cross join (\n#17305\n)\nEnsure we don't close extant\nadbc\nconnections in\nwrite_database\n(\n#17298\n)\nDon't null on oob in\nlist.get\nfor column index (\n#17276\n)\nFix issue where sliced PyArrow record batches were not handled correctly (\n#17058\n)\nDon't oob on nulls in\nlist.get\n(\n#17262\n)\nFix list getter with nulls (\n#17261\n)\nRespect\nnulls_last\nparameter in aggregate\nsort_by\n(\n#17249\n)\nFix literal slice in group by (\n#17242\n)\nFix\nDataFrame.top_k\nnot handling nulls correctly (\n#17239\n)\nUpdate implementation of Enum support in\nlit\nto address spurious test failure (\n#17187\n)\nUse explicit turbofish to help rustc (\n#17159\n)\nRaise on invalid set dtypes (\n#17157\n)\nFix corrupted reads for hive parts from cloud and projection pushdown failure on hive parts (\n#17152\n)\nSet intersection supertype (\n#17154\n)\nChainedWhen\nshould not inherit\nExpr\n(\n#17142\n)\nFix decompress_impl for csv with n_rows set (\n#17118\n)\nFix incorrect window std for chunked series (\n#17110\n)\nFix panic when using\nfold\nin certain situations (\n#17114\n)\nFix melt panic (\n#17088\n)\nFix expression autocomplete in IPython (\n#17072\n)\nExclude index from expansion in rolling/group_by_dynamic (\n#17086\n)\nUpdate some\nSeries\ndunder method type signatures (\n#17053\n)\nFix oob of join with literals and empty table (\n#17047\n)\nDon't silently accept multi-table FROM clauses (implicit JOIN syntax) (\n#17028\n)\nDon't split up ANDed filters that are group-aware (\n#17031\n)\nHarden \"async\" check for users with out-of-date\nsqlalchemy\nlibraries (\n#17029\n)\nError when\nsort_by\nof unequal length (\n#17026\n)\nProperly catch not found explode cols (\n#17020\n)\nCorrectly convert data frames to NumPy for C index order (\n#17000\n)\nRaise on invalid arithmetic shapes (\n#16986\n)\nDon't pushdown predicates in cross join if the refer to both tables (\n#16983\n)\nFix projection pushdown with literal joins (\n#16981\n)\nFix edge case in DataFrame constructor data orientation inference (\n#16975\n)\nRaise on list of objects (\n#16959\n)\nHandle strictness for Decimal Series construction (\n#15309\n)\nDon't panic in object to anyvalue (\n#16957\n)\nProperly set\nFAST_EXPLODE_LIST\nmetadata (\n#16951\n)\nRaise informative error when writing object to file (\n#16954\n)\nRemove supertype definition of List and non-List types (\n#16918\n)\nRemove unwrap in\nextend()\n(\n#16890\n)\nFix\nshould_rechunk\ncheck (\n#16852\n)\nEnsure\nread_excel\nand\nread_ods\nreturn identical frames across all engines when given empty spreadsheet tables (\n#16802\n)\nConsistent behaviour when \"infer_schema_length=0\" for\nread_excel\n(\n#16840\n)\nStandardised additional SQL interface errors (\n#16829\n)\nEnsure that splitted ChunkedArray also flattens chunks (\n#16837\n)\nReduce needless panics in comparisons (\n#16831\n)\nReset if next caller clones inner series (\n#16812\n)\nRaise on non-positive json schema inference (\n#16770\n)\nRewrite implementation of\ntop_k/bottom_k\nand fix a variety of bugs (\n#16804\n)\nFix comparison of UInt64 with zero (\n#16799\n)\nFix incorrect parquet statistics written for UInt64 values > Int64::MAX (\n#16766\n)\nFix boolean distinct (\n#16765\n)\nDATE_PART\nSQL syntax/parsing, improve some error messages (\n#16761\n)\nInclude\npl.\nqualifier for inner dtypes in\nto_init_repr\n(\n#16235\n)\nColumn selection wasn't applied when reading CSV with no rows (\n#16739\n)\nPanic on empty df / null List(Categorical) (\n#16730\n)\nOnly flush if operator can flush in streaming outer join (\n#16723\n)\nRaise unsupported cat array (\n#16717\n)\nAssert SQLInterfaceError is raised (\n#16713\n)\nRestrict casting for temporal data types (\n#14142\n)\nHandle nested categoricals in\nassert_series_equal\nwhen\ncategorical_as_str=True\n(\n#16700\n)\nImprove\nread_database\ncheck for SQLAlchemy async Session objects (\n#16680\n)\nReduce scope of multi-threaded numpy conversion (\n#16686\n)\nFull null on dyn int (\n#16679\n)\nFix filter shape on empty null (\n#16670\n)\n Documentation\nUpdate version switcher for 1.0.0 final release (\n#16848\n)\nFinish upgrade guide for 1.0.0 (\n#17257\n)\nMinor layout/terminology improvement for\nselector\nset ops (\n#17299\n)\nMark hypothesis testing functionality as unstable (\n#17258\n)\nAdd SQL docs for the\nCAST\nand\nTRY_CAST\nfunctions (\n#17214\n)\nMark\nplot\nnamespace as unstable (\n#17205\n)\nBump docs dependencies (\n#17199\n)\nMore accurate and helpful docs for user defined functions (\n#15194\n)\nAdd doc examples to\nconcat_list\n(\n#17127\n)\nAdd \"coming from pandas\" note to\nDataFrame.unique\ndocstring (\n#17119\n)\nFix some warnings during doc build (\n#17077\n)\nProperly expose\nInProcessQuery\nin docs, mark as unstable (\n#17097\n)\nAdd upgrade guide for Python Polars 1.0.0 (\n#16914\n)\nLots of additions to the SQL reference docs (\n#16990\n)\nMinor doctest fixes (\n#17002\n)\nInclude a doc entry for every exception type (\n#17001\n)\nFixup bullet points in\nwrite_parquet\ndocstring (\n#16909\n)\nUpdate version switcher for 1.0.0 prereleases (\n#16847\n)\nUpdate link from Python API reference to user guide (\n#16849\n)\nUpdate docstring/test/etc usage of\nselect\nand\nwith_columns\nto idiomatic form (\n#16801\n)\nUpdate versioning docs for 1.0.0 (\n#16757\n)\nAdd docstring example for\nDataFrame.limit\n(\n#16753\n)\nFix incorrect stated value of\ninclude_nulls\nin\nDataFrame.update\ndocstring (\n#16701\n)\nUpdate deprecation docs in the user guide (\n#14315\n)\nAdd example for index count in\nDataFrame.rolling\n(\n#16600\n)\nImprove docstring of\nExpr/Series.map_elements\n(\n#16079\n)\nAdd missing\npolars.sql\ndocs entry and small docstring update (\n#16656\n)\n Build system\nUpdate Cargo.lock (\n#17284\n)\nStreamline optional dependency definitions in\npyproject.toml\n(\n#17168\n)\nUpdate rustc 2024-06-23 (\n#17135\n)\nDo not set environment variable on import (\n#17101\n)\nFix config flag for Tracemalloc (\n#17098\n)\nPin optional NumPy dependency to\n< 2.0.0\nfor now (\n#17060\n)\n锔 Other improvements\nFix typo in join validation error message (\n#17296\n)\nFix linting issue in docs (\n#17292\n)\nUse typed\niter\nin\nlist.get\n(\n#17286\n)\nRename\ntype_aliases\nmodule to\n_typing\n(\n#17282\n)\nadd ability to have pipeline blockers in new streaming engine (\n#17247\n)\nSupport date/datetime for hive parts (\n#17256\n)\nRefactor serde tests, add hypothesis tests (\n#17216\n)\nRefactor parsing of data type inputs to Polars data types (\n#17164\n)\nSkip all moto AWS tests for now (\n#17178\n)\nAdd missing spaces in\ncargo.toml\n(\n#17145\n)\nMinor test refactor for\nconcat_list\n(\n#17120\n)\nRemove re-export of data type groups (\n#17073\n)\nAdd pivot test\n#17081\n(\n#17090\n)\nMinor cleanup to better define boundaries of public API (\n#17051\n)\nSupport directory paths in scans for Parquet, IPC and CSV (\n#17017\n)\nRemove re-export of type aliases (\n#17032\n)\nRemove file cache test (\n#17038\n)\nUpdate exception imports in test suite (\n#17035\n)\nPoint polars-stream to crates/ again (\n#17024\n)\nFix failing file cache test in CI (\n#17014\n)\nAdd some parametric tests for sort functionality (\n#17008\n)\nPin NumPy to <2.0 for now (\n#16999\n)\nUse proper join type in test (\n#16994\n)\nFix file cache verbose logging leakage during pytest (\n#16984\n)\nSkip another intermitently failing AWS test (\n#16980\n)\nUpdate test suite to explicitly use\norient=\"row\"\nin DataFrame constructor when applicable (\n#16977\n)\nRemove redundant projection attribute in IR::DataFrameScan (\n#16952\n)\nFactor out some apply calls in duration namespace (\n#16941\n)\nSkip intermittently failing AWS test (\n#16908\n)\nRefactor expression parsing utils (\n#16906\n)\nSet up some of the infrastructure for new streaming engine (\n#16900\n)\nRefactor parts of IR. (\n#16899\n)\nAdd fundamentals for new async-based streaming execution engine (\n#16884\n)\nMove around some existing tests (\n#16877\n)\nRemove inner\nArc\nfrom\nFileCacheEntry\n(\n#16870\n)\nDo not update stable API reference on prerelease (\n#16846\n)\nUpdate links to API references (\n#16843\n)\nPrepare update of API reference URLs (\n#16816\n)\nRename allow_overflow to wrap_numerical (\n#16807\n)\nSet\ninfer_schema_length\nas keyword-only argument in\nstr.json_decode\n(\n#16835\n)\nDon't enter streaming engine for groupby-> agg mean/median  (\n#16810\n)\nImprove safety of amortized_iter (\n#16820\n)\nRemove needless inner type clone (\n#16718\n)\nFix incorrect debug assertion in\nChunkedArray::from_chunks_and_dtype\n(\n#16697\n)\nUpdate version resolver for\n1.0.0\nrelease (\n#16705\n)\nAvoid AWS pinning to outdated crc32c version (\n#16681\n)\nThank you to all our contributors for making this release possible!\n@IvanIsCoding\n,\n@JamesCE2001\n, @JulianCologne,\n@KDruzhkin\n,\n@Kylea650\n,\n@MarcoGorelli\n,\n@Mottl\n,\n@Object905\n,\n@SeanTater\n,\n@adamreeve\n,\n@alexander-beedie\n,\n@bertiewooster\n,\n@borchero\n,\n@c-peters\n,\n@coastalwhite\n,\n@datapythonista\n,\n@datenzauberai\n,\n@dependabot\n,\n@dependabot\n[bot],\n@eitsupi\n,\n@flisky\n,\n@henryharbeck\n,\n@itamarst\n,\n@jqnatividad\n,\n@lukeshingles\n,\n@machow\n,\n@marenwestermann\n,\n@mcrumiller\n,\n@montanarograziano\n,\n@nameexhaustion\n,\n@orlp\n,\n@p3i0t\n,\n@ritchie46\n,\n@sherlockbeard\n,\n@stinodego\n,\n@tkellogg\n,\n@universalmind303\nand\n@wence-",
    "crawl_status": "success"
  },
  {
    "library_name": "Ruff",
    "url": "https://github.com/astral-sh/ruff/releases/tag/0.13.0",
    "version": "0.13.0",
    "title": "Release 0.13.0 路 astral-sh/ruff 路 GitHub",
    "release_date": "2025-09-10T16:31:51Z",
    "content": "Release Notes\nCheck out the\nblog post\nfor a migration guide and overview of the changes!\nBreaking changes\nSeveral rules can now add\nfrom __future__ import annotations\nautomatically\nTC001\n,\nTC002\n,\nTC003\n,\nRUF013\n, and\nUP037\nnow add\nfrom __future__ import annotations\nas part of their fixes when the\nlint.future-annotations\nsetting is enabled. This allows the rules to move more imports into\nTYPE_CHECKING\nblocks (\nTC001\n,\nTC002\n, and\nTC003\n), use PEP 604 union syntax on Python versions before 3.10 (\nRUF013\n), and unquote more annotations (\nUP037\n).\nFull module paths are now used to verify first-party modules\nRuff now checks that the full path to a module exists on disk before categorizing it as a first-party import. This change makes first-party import detection more accurate, helping to avoid false positives on local directories with the same name as a third-party dependency, for example. See the\nFAQ section\non import categorization for more details.\nDeprecated rules must now be selected by exact rule code\nRuff will no longer activate deprecated rules selected by their group name or prefix. As noted below, the two remaining deprecated rules were also removed in this release, so this won't affect any current rules, but it will still affect any deprecations in the future.\nThe deprecated macOS configuration directory fallback has been removed\nRuff will no longer look for a user-level configuration file at\n~/Library/Application Support/ruff/ruff.toml\non macOS. This feature was deprecated in v0.5 in favor of using the\nXDG specification\n(usually resolving to\n~/.config/ruff/ruff.toml\n), like on Linux. The fallback and accompanying deprecation warning have now been removed.\nRemoved Rules\nThe following rules have been removed:\npandas-df-variable-name\n(\nPD901\n)\nnon-pep604-isinstance\n(\nUP038\n)\nStabilization\nThe following rules have been stabilized and are no longer in preview:\nairflow-dag-no-schedule-argument\n(\nAIR002\n)\nairflow3-removal\n(\nAIR301\n)\nairflow3-moved-to-provider\n(\nAIR302\n)\nairflow3-suggested-update\n(\nAIR311\n)\nairflow3-suggested-to-move-to-provider\n(\nAIR312\n)\nlong-sleep-not-forever\n(\nASYNC116\n)\nf-string-number-format\n(\nFURB116\n)\nos-symlink\n(\nPTH211\n)\ngeneric-not-last-base-class\n(\nPYI059\n)\nredundant-none-literal\n(\nPYI061\n)\npytest-raises-ambiguous-pattern\n(\nRUF043\n)\nunused-unpacked-variable\n(\nRUF059\n)\nuseless-class-metaclass-type\n(\nUP050\n)\nThe following behaviors have been stabilized:\nassert-raises-exception\n(\nB017\n) now checks for direct calls to\nunittest.TestCase.assert_raises\nand\npytest.raises\ninstead of only the context manager forms.\nmissing-trailing-comma\n(\nCOM812\n) and\nprohibited-trailing-comma\n(\nCOM819\n) now check for trailing commas in PEP 695 type parameter lists.\nraw-string-in-exception\n(\nEM101\n) now also checks for byte strings in exception messages.\ninvalid-mock-access\n(\nPGH005\n) now checks for\nAsyncMock\nmethods like\nnot_awaited\nin addition to the synchronous variants.\nuseless-import-alias\n(\nPLC0414\n) no longer applies to\n__init__.py\nfiles, where it conflicted with one of the suggested fixes for\nunused-import\n(\nF401\n).\nbidirectional-unicode\n(\nPLE2502\n) now also checks for U+061C (Arabic Letter Mark).\nThe fix for\nmultiple-with-statements\n(\nSIM117\n) is now marked as always safe.\nPreview features\n[\npyupgrade\n] Enable\nUP043\nin stub files (\n#20027\n)\nBug fixes\n[\npyupgrade\n] Apply\nUP008\nonly when the\n__class__\ncell exists (\n#19424\n)\n[\nruff\n] Fix empty f-string detection in\nin-empty-collection\n(\nRUF060\n) (\n#20249\n)\nServer\nAdd support for using uv as an alternative formatter backend (\n#19665\n)\nDocumentation\n[\npep8-naming\n] Fix formatting of\n__all__\n(\nN816\n) (\n#20301\n)\nContributors\n@AlexWaygood\n@BurntSushi\n@CodeMan62\n@IDrokin117\n@JelleZijlstra\n@LoicRiegel\n@Renkai\n@Renkai\n@TaKO8Ki\n@amyreese\n@carljm\n@dcreager\n@ericmarkmartin\n@ferdnyc\n@ibraheemdev\n@mtshiba\n@ntBre\n@onerandomusername\n@renovate\n@sharkdp\n@thejchap\n@zanieb\nInstall ruff 0.13.0\nInstall prebuilt binaries via shell script\ncurl --proto\n'\n=https\n'\n--tlsv1.2 -LsSf https://github.com/astral-sh/ruff/releases/download/0.13.0/ruff-installer.sh\n|\nsh\nInstall prebuilt binaries via powershell script\npowershell -ExecutionPolicy Bypass -c\n\"\nirm https://github.com/astral-sh/ruff/releases/download/0.13.0/ruff-installer.ps1 | iex\n\"\nDownload ruff 0.13.0\nFile\nPlatform\nChecksum\nruff-aarch64-apple-darwin.tar.gz\nApple Silicon macOS\nchecksum\nruff-x86_64-apple-darwin.tar.gz\nIntel macOS\nchecksum\nruff-aarch64-pc-windows-msvc.zip\nARM64 Windows\nchecksum\nruff-i686-pc-windows-msvc.zip\nx86 Windows\nchecksum\nruff-x86_64-pc-windows-msvc.zip\nx64 Windows\nchecksum\nruff-aarch64-unknown-linux-gnu.tar.gz\nARM64 Linux\nchecksum\nruff-i686-unknown-linux-gnu.tar.gz\nx86 Linux\nchecksum\nruff-powerpc64-unknown-linux-gnu.tar.gz\nPPC64 Linux\nchecksum\nruff-powerpc64le-unknown-linux-gnu.tar.gz\nPPC64LE Linux\nchecksum\nruff-riscv64gc-unknown-linux-gnu.tar.gz\nRISCV Linux\nchecksum\nruff-s390x-unknown-linux-gnu.tar.gz\nS390x Linux\nchecksum\nruff-x86_64-unknown-linux-gnu.tar.gz\nx64 Linux\nchecksum\nruff-armv7-unknown-linux-gnueabihf.tar.gz\nARMv7 Linux\nchecksum\nruff-aarch64-unknown-linux-musl.tar.gz\nARM64 MUSL Linux\nchecksum\nruff-i686-unknown-linux-musl.tar.gz\nx86 MUSL Linux\nchecksum\nruff-x86_64-unknown-linux-musl.tar.gz\nx64 MUSL Linux\nchecksum\nruff-arm-unknown-linux-musleabihf.tar.gz\nARMv6 MUSL Linux (Hardfloat)\nchecksum\nruff-armv7-unknown-linux-musleabihf.tar.gz\nARMv7 MUSL Linux\nchecksum",
    "crawl_status": "success"
  },
  {
    "library_name": "Ruff",
    "url": "https://github.com/astral-sh/ruff/releases/tag/v0.1.0",
    "version": "v0.1.0",
    "title": "Release v0.1.0 路 astral-sh/ruff 路 GitHub",
    "release_date": "2023-10-16T19:51:17Z",
    "content": "Read the\nblog post\nabout this release.\nRead Ruff's new\nversioning policy\n.\nThis is the first release which uses the\nCHANGELOG\nfile  change entries will be listed there and in each GitHub Release.\nChanges\nBreaking changes\nUnsafe fixes are no longer displayed or applied without opt-in (\n#7769\n)\nDrop formatting specific rules from the default set (\n#7900\n)\nThe deprecated\nformat\nsetting has been removed (\n#7984\n)\nThe\nformat\nsetting cannot be used to configure the output format, use\noutput-format\ninstead\nThe\nRUFF_FORMAT\nenvironment variable is ignored, use\nRUFF_OUTPUT_FORMAT\ninstead\nThe\n--format\noption has been removed from\nruff check\n, use\n--output-format\ninstead\nRule changes\nExtend\nreimplemented-starmap\n(\nFURB140\n) to catch calls with a single and starred argument (\n#7768\n)\nImprove cases covered by\nRUF015\n(\n#7848\n)\nUpdate\nSIM15\nto allow\nopen\nfollowed by\nclose\n(\n#7916\n)\nRespect\nmsgspec.Struct\ndefault-copy semantics in\nRUF012\n(\n#7786\n)\nAdd\nsqlalchemy\nmethods to `flake8-boolean-trap`` exclusion list (\n#7874\n)\nAdd fix for\nPLR1714\n(\n#7910\n)\nAdd fix for\nPIE804\n(\n#7884\n)\nAdd fix for\nPLC0208\n(\n#7887\n)\nAdd fix for\nPYI055\n(\n#7886\n)\nUpdate\nnon-pep695-type-alias\nto require\n--unsafe-fixes\noutside of stub files (\n#7836\n)\nImprove fix message for\nUP018\n(\n#7913\n)\nUpdate\nPLW3201\nto support\nEnum\nsunder names\n(\n#7987\n)\nPreview features\nOnly show warnings for empty preview selectors when enabling rules (\n#7842\n)\nAdd\nunnecessary-key-check\nto simplify\nkey in dct and dct[key]\nto\ndct.get(key)\n(\n#7895\n)\nAdd\nassignment-in-assert\nto prevent walrus expressions in assert statements (\n#7856\n)\n[\nrefurb\n] Add\nsingle-item-membership-test\n(\nFURB171\n) (\n#7815\n)\n[\npylint\n] Add\nand-or-ternary\n(\nR1706\n) (\n#7811\n)\nNew rules are added in\npreview\n.\nConfiguration\nAdd\nunsafe-fixes\nsetting (\n#7769\n)\nAdd\nextend-safe-fixes\nand\nextend-unsafe-fixes\nfor promoting and demoting fixes (\n#7841\n)\nCLI\nAdded\n--unsafe-fixes\noption for opt-in to display and apply unsafe fixes (\n#7769\n)\nFix use of deprecated\n--format\noption in warning (\n#7837\n)\nShow changed files when running under\n--check\n(\n#7788\n)\nWrite summary messages to stderr when fixing via stdin instead of omitting them (\n#7838\n)\nUpdate fix summary message in\ncheck --diff\nto include unsafe fix hints (\n#7790\n)\nAdd notebook\ncell\nfield to JSON output format (\n#7664\n)\nRename applicability levels to\nSafe\n,\nUnsafe\n, and\nDisplay\n(\n#7843\n)\nBug fixes\nFix bug where f-strings were allowed in match pattern literal (\n#7857\n)\nFix\nSIM110\nwith a yield in the condition (\n#7801\n)\nPreserve trailing comments in\nC414\nfixes (\n#7775\n)\nCheck sequence type before triggering\nunnecessary-enumerate\nlen\nsuggestion (\n#7781\n)\nUse correct start location for class/function clause header (\n#7802\n)\nFix incorrect fixes for\nSIM101\n(\n#7798\n)\nFormat comment before parameter default correctly (\n#7870\n)\nFix\nE251\nfalse positive inside f-strings (\n#7894\n)\nAllow bindings to be created and referenced within annotations (\n#7885\n)\nShow per-cell diffs when analyzing notebooks over\nstdin\n(\n#7789\n)\nAvoid curly brace escape in f-string format spec (\n#7780\n)\nFix lexing single-quoted f-string with multi-line format spec (\n#7787\n)\nConsider nursery rules to be in-preview for\nruff rule\n(\n#7812\n)\nReport precise location for invalid conversion flag (\n#7809\n)\nVisit pattern match guard as a boolean test (\n#7911\n)\nRespect\n--unfixable\nin\nISC\nrules (\n#7917\n)\nFix edge case with\nPIE804\n(\n#7922\n)\nShow custom message in\nPTH118\nfor\nPath.joinpath\nwith starred arguments (\n#7852\n)\nFix false negative in\noutdated-version-block\nwhen using greater than comparisons (\n#7920\n)\nAvoid converting f-strings within Django\ngettext\ncalls (\n#7898\n)\nFix false positive in\nPLR6301\n(\n#7933\n)\nTreat type aliases as typing-only expressions e.g. resolves false positive in\nTCH004\n(\n#7968\n)\nResolve\ncache-dir\nrelative to project root (\n#7962\n)\nRespect subscripted base classes in type-checking rules e.g. resolves false positive in\nTCH003\n(\n#7954\n)\nFix JSON schema limit for\nline-length\n(\n#7883\n)\nFix commented-out\ncoalesce\nkeyword (\n#7876\n)\nDocumentation\nDocument\nreimplemented-starmap\nperformance effects (\n#7846\n)\nDefault to following the system dark/light mode (\n#7888\n)\nAdd documentation for fixes (\n#7901\n)\nFix typo in docs of\nPLR6301\n(\n#7831\n)\nUpdate\nUP038\ndocs to note that it results in slower code (\n#7872\n)\ncrlf -> cr-lf (\n#7766\n)\nAdd an example of an unsafe fix (\n#7924\n)\nFix documented examples for\nunnecessary-subscript-reversal\n(\n#7774\n)\nCorrect error in tuple example in ruff formatter docs (\n#7822\n)\nAdd versioning policy to documentation (\n#7923\n)\nFix invalid code in\nFURB177\nexample (\n#7832\n)\nFormatter\nLess scary\nruff format\nmessage (\n#7867\n)\nRemove spaces from import statements (\n#7859\n)\nFormatter quoting for f-strings with triple quotes (\n#7826\n)\nUpdate\nruff_python_formatter\ngenerate.py comment (\n#7850\n)\nDocument one-call chaining deviation (\n#7767\n)\nAllow f-string modifications in line-shrinking cases (\n#7818\n)\nAdd trailing comment deviation to README (\n#7827\n)\nAdd trailing zero between dot and exponential (\n#7956\n)\nForce parentheses for power operations in unary expressions (\n#7955\n)\nPlayground\nFix playground\nQuick Fix\naction (\n#7824\n)\nContributors\n@AlexWaygood\n@Hoxbro\n@JelleZijlstra\n@LaBatata101\n@T-256\n@bluthej\n@cberry31\n@charliermarsh\n@cnpryer\n@cosmojg\n@danbi2990\n@dhruvmanila\n@diceroll123\n@flying-sheep\n@harupy\n@henryiii\n@konstin\n@timobrembeck\n@tjkuson\n@zanieb",
    "crawl_status": "success"
  },
  {
    "library_name": "Ruff",
    "url": "https://github.com/astral-sh/ruff/releases/tag/0.7.0",
    "version": "0.7.0",
    "title": "Release 0.7.0 路 astral-sh/ruff 路 GitHub",
    "release_date": "2024-10-17T19:36:01Z",
    "content": "Release Notes\nCheck out the\nblog post\nfor a migration guide and overview of the changes!\nBreaking changes\nThe pytest rules\nPT001\nand\nPT023\nnow default to omitting the decorator parentheses when there are no arguments\n(\n#12838\n,\n#13292\n).\nThis was a change that we attempted to make in Ruff v0.6.0, but only partially made due to an error on our part.\nSee the\nblog post\nfor more details.\nThe\nuseless-try-except\nrule (in our\ntryceratops\ncategory) has been recoded from\nTRY302\nto\nTRY203\n(\n#13502\n). This ensures Ruff's code is consistent with\nthe same rule in the\ntryceratops\nlinter.\nThe\nlint.allow-unused-imports\nsetting has been removed (\n#13677\n). Use\nlint.pyflakes.allow-unused-imports\ninstead.\nFormatter preview style\nNormalize implicit concatenated f-string quotes per part (\n#13539\n)\nPreview linter features\n[\nrefurb\n] implement\nhardcoded-string-charset\n(FURB156) (\n#13530\n)\n[\nrefurb\n] Count codepoints not bytes for\nslice-to-remove-prefix-or-suffix (FURB188)\n(\n#13631\n)\nRule changes\n[\npylint\n] Mark\nPLE1141\nfix as unsafe (\n#13629\n)\n[\nflake8-async\n] Consider async generators to be \"checkpoints\" for\ncancel-scope-no-checkpoint\n(\nASYNC100\n) (\n#13639\n)\n[\nflake8-bugbear\n] Do not suggest setting parameter\nstrict=\nto\nFalse\nin\nB905\ndiagnostic message (\n#13656\n)\n[\nflake8-todos\n] Only flag the word \"TODO\", not words starting with \"todo\" (\nTD006\n) (\n#13640\n)\n[\npycodestyle\n] Fix whitespace-related false positives and false negatives inside type-parameter lists (\nE231\n,\nE251\n) (\n#13704\n)\n[\nflake8-simplify\n] Stabilize preview behavior for\nSIM115\nso that the rule can detect files\nbeing opened from a wider range of standard-library functions (\n#12959\n).\nCLI\nAdd explanation of fixable in\n--statistics\ncommand (\n#13774\n)\nBug fixes\n[\npyflakes\n] Allow\nipytest\ncell magic (\nF401\n) (\n#13745\n)\n[\nflake8-use-pathlib\n] Fix\nPTH123\nfalse positive when\nopen\nis passed a file descriptor (\n#13616\n)\n[\nflake8-bandit\n] Detect patterns from multi line SQL statements (\nS608\n) (\n#13574\n)\n[\nflake8-pyi\n] - Fix dropped expressions in\nPYI030\nautofix (\n#13727\n)\nContributors\n@AlexWaygood\n@DataEnggNerd\n@Lexxxzy\n@MichaReiser\n@Slyces\n@alex-700\n@autinerd\n@cake-monotone\n@carljm\n@dhruvmanila\n@diceroll123\n@dylwil3\n@github-actions\n@pilleye\n@qdegraaf\n@renovate\n@rtpg\n@sbrugman\n@sharkdp\n@zanieb\nInstall ruff 0.7.0\nInstall prebuilt binaries via shell script\ncurl --proto\n'\n=https\n'\n--tlsv1.2 -LsSf https://github.com/astral-sh/ruff/releases/download/0.7.0/ruff-installer.sh\n|\nsh\nInstall prebuilt binaries via powershell script\npowershell -ExecutionPolicy ByPass -c\n\"\nirm https://github.com/astral-sh/ruff/releases/download/0.7.0/ruff-installer.ps1 | iex\n\"\nDownload ruff 0.7.0\nFile\nPlatform\nChecksum\nruff-aarch64-apple-darwin.tar.gz\nApple Silicon macOS\nchecksum\nruff-x86_64-apple-darwin.tar.gz\nIntel macOS\nchecksum\nruff-aarch64-pc-windows-msvc.zip\nARM64 Windows\nchecksum\nruff-i686-pc-windows-msvc.zip\nx86 Windows\nchecksum\nruff-x86_64-pc-windows-msvc.zip\nx64 Windows\nchecksum\nruff-aarch64-unknown-linux-gnu.tar.gz\nARM64 Linux\nchecksum\nruff-i686-unknown-linux-gnu.tar.gz\nx86 Linux\nchecksum\nruff-powerpc64-unknown-linux-gnu.tar.gz\nPPC64 Linux\nchecksum\nruff-powerpc64le-unknown-linux-gnu.tar.gz\nPPC64LE Linux\nchecksum\nruff-s390x-unknown-linux-gnu.tar.gz\nS390x Linux\nchecksum\nruff-x86_64-unknown-linux-gnu.tar.gz\nx64 Linux\nchecksum\nruff-armv7-unknown-linux-gnueabihf.tar.gz\nARMv7 Linux\nchecksum\nruff-aarch64-unknown-linux-musl.tar.gz\nARM64 MUSL Linux\nchecksum\nruff-i686-unknown-linux-musl.tar.gz\nx86 MUSL Linux\nchecksum\nruff-x86_64-unknown-linux-musl.tar.gz\nx64 MUSL Linux\nchecksum\nruff-arm-unknown-linux-musleabihf.tar.gz\nARMv6 MUSL Linux (Hardfloat)\nchecksum\nruff-armv7-unknown-linux-musleabihf.tar.gz\nARMv7 MUSL Linux\nchecksum",
    "crawl_status": "success"
  },
  {
    "library_name": "Rich",
    "url": "https://github.com/Textualize/rich/releases/tag/v14.1.0",
    "version": "v14.1.0",
    "title": "Release The Lively Release 路 Textualize/rich 路 GitHub",
    "release_date": "2025-07-25T07:35:18Z",
    "content": "Live objects may now be nested. Previously a progress bar inside another progress context would fail. See the changelog below for this and other changes.\n[14.1.0] - 2025-06-25\nChanged\nRemoved\ntyping_extensions\nfrom runtime dependencies\n#3763\nLive objects (including Progress) may now be nested\n#3768\nAdded padding property to Syntax which returns a tuple of four integers\n#3782\nFixed\nFixed extraction of recursive exceptions\n#3772\nFixed padding applied to Syntax\n#3782\nFixed\nPanel\ntitle missing the panel background style\n#3569\nAdded\nAdded\nTTY_INTERACTIVE\nenvironment variable to force interactive mode off or on\n#3777",
    "crawl_status": "success"
  },
  {
    "library_name": "Rich",
    "url": "https://github.com/Textualize/rich/releases/tag/v13.8.0",
    "version": "v13.8.0",
    "title": "Release The Thanks for your patience Release 路 Textualize/rich 路 GitHub",
    "release_date": "2024-08-26T16:15:57Z",
    "content": "This is a fairly large update. Mostly an accumulation of small fixes and enhancements. Nothing qualifies as a *breaking change (for some definition), but there may be some subtly changes to output. Check below for anything that might affect you!\n[13.8.0] - 2024-08-26\nFixed\nFixed\nTable\nrendering of box elements so \"footer\" elements truly appear at bottom of table, \"mid\" elements in main table body.\nFixed styles in Panel when Text objects are used for title\n#3401\nFix pretty repr for\ncollections.deque\n#2864\nThread used in progress.track will exit if an exception occurs in a generator\n#3402\nProgress track thread is now a daemon thread\n#3402\nFixed cached hash preservation upon clearing meta and links\n#2942\nFixed overriding the\nbackground_color\nof\nSyntax\nnot including padding\n#3295\nFixed pretty printing of dataclasses with a default repr in Python 3.13\n#3455\nFixed selective enabling of highlighting when disabled in the\nConsole\n#3419\nFixed BrokenPipeError writing an error message\n#3468\nFixed superfluous space above Markdown tables\n#3469\nFixed issue with record and capture interaction\n#3470\nFixed control codes breaking in\nappend_tokens\n#3471\nFixed exception pretty printing a dataclass with missing fields\n#3472\nChanged\nRichHandler\nerrors and warnings will now use different colors (red and yellow)\n#2825\nRemoved the empty line printed in jupyter while using\nProgress\n#2616\nRunning tests in environment with\nFORCE_COLOR\nor\nNO_COLOR\nenvironment variables\nansi decoder will now strip problematic private escape sequences (like\n\\x1b7\n)\n#3278\nTree's ASCII_GUIDES and TREE_GUIDES constants promoted to class attributes\nAdded\nAdds a\ncase_sensitive\nparameter to\nprompt.Prompt\n. This determines if the\nresponse is treated as case-sensitive. Defaults to\nTrue\n.\nAdded\nConsole.on_broken_pipe\n#3468",
    "crawl_status": "success"
  },
  {
    "library_name": "Rich",
    "url": "https://github.com/Textualize/rich/releases/tag/v13.5.0",
    "version": "v13.5.0",
    "title": "Release Mostly cake, one or two puppies 路 Textualize/rich 路 GitHub",
    "release_date": "2023-07-29T16:19:45Z",
    "content": "https://textual.textualize.io/blog/2023/07/29/pull-requests-are-cake-or-puppies/\n[13.5.0] - 2023-07-29\nFixed\nFixed Text.expand_tabs not expanding spans.\nFixed TimeElapsedColumn from showing negative.\nFix for escaping strings with a trailing backslash\n#2987\nFixed exception in Markdown with partial table\n#3053\nFixed the HTML export template so that the\n<html>\ntag comes before the\n<head>\ntag\n#3021\nFixed issue with custom classes overwriting\n__eq__\n#2875\nFix rich.pretty.install breakage in iPython\n#3013\nAdded\nAdded Text.extend_style method.\nAdded Span.extend method.\nChanged\nText.tab_size now defaults to\nNone\nto indicate that Console.tab_size should be used.",
    "crawl_status": "success"
  },
  {
    "library_name": "Typer",
    "url": "https://github.com/fastapi/typer/releases/tag/0.8.0",
    "version": "0.8.0",
    "title": "Release 0.8.0 路 fastapi/typer 路 GitHub",
    "release_date": "2023-05-01T11:34:35Z",
    "content": "Features\n Add support for custom types and parsers. Initial PR\n#583\nby\n@jpurviance\n. Based on original PR\n#443\nby\n@paulo-raca\n.\nNew docs:\nCLI Parameter Types: Custom Types\n.\nUpgrades\n猬 Upgrade Rich, support 13.x. PR\n#524\nby\n@musicinmybrain\n.\nDocs\n Tweak docs, Custom Types path, main page and READAME colors, broken links. PR\n#588\nby\n@tiangolo\n.\n Fix spelling (shinny -> shiny). PR\n#586\nby\n@runofthemill\n.\n Update docs about helping Typer. PR\n#547\nby\n@tiangolo\n.\n锔 Fix typo in datetime docs. PR\n#495\nby\n@huxuan\n.\n锔 Add quotes to package name that includes brackets in docs. PR\n#475\nby\n@gjolga\n.\nInternal\n猬 Bump dawidd6/action-download-artifact from 2.24.2 to 2.26.0. PR\n#558\nby\n@dependabot[bot]\n.\n猬 [pre-commit.ci] pre-commit autoupdate. PR\n#549\nby\n@pre-commit-ci[bot]\n.\n Add\nexclude_lines\nto coverage configuration. PR\n#585\nby\n@dmontagu\n.\n猬锔 Upgrade analytics. PR\n#557\nby\n@tiangolo\n.\n Update new issue chooser to suggest GitHub Discussions. PR\n#544\nby\n@tiangolo\n.\n Add GitHub Discussion templates for questions. PR\n#541\nby\n@tiangolo\n.\n Update pre-commit, Python version, isort version. PR\n#542\nby\n@tiangolo\n.\n猬 [pre-commit.ci] pre-commit autoupdate. PR\n#512\nby\n@pre-commit-ci[bot]\n.\n猬 Bump nwtgck/actions-netlify from 1.2.4 to 2.0.0. PR\n#513\nby\n@dependabot[bot]\n.\n Refactor CI artifact upload/download for docs previews. PR\n#516\nby\n@tiangolo\n.\n猬 [pre-commit.ci] pre-commit autoupdate. PR\n#500\nby\n@pre-commit-ci[bot]\n.\n猬 Bump actions/cache from 2 to 3. PR\n#496\nby\n@dependabot[bot]\n.\n猬 Bump dawidd6/action-download-artifact from 2.24.1 to 2.24.2. PR\n#494\nby\n@dependabot[bot]\n.\n猬 Bump dawidd6/action-download-artifact from 2.9.0 to 2.24.1. PR\n#491\nby\n@dependabot[bot]\n.\n猬 Bump actions/setup-python from 2 to 4. PR\n#492\nby\n@dependabot[bot]\n.\n封锔 Consistently use\nsys.executable\nto run subprocesses, needed by OpenSUSE. PR\n#408\nby\n@theMarix\n.\n封锔 Ensure the\nPYTHONPATH\nis set properly when testing the tutorial scripts. PR\n#407\nby\n@theMarix\n.",
    "crawl_status": "success"
  },
  {
    "library_name": "Typer",
    "url": "https://github.com/fastapi/typer/releases/tag/0.13.0",
    "version": "0.13.0",
    "title": "Release 0.13.0 路 fastapi/typer 路 GitHub",
    "release_date": "2024-11-07T21:12:10Z",
    "content": "Features\n Handle\nKeyboardInterrupt\nseparately from other exceptions. PR\n#1039\nby\n@patrick91\n.\n Update\nlaunch\nto not print anything when opening urls. PR\n#1035\nby\n@patrick91\n.\n Show help items in order of definition. PR\n#944\nby\n@svlandeg\n.\nFixes\n Fix equality check for custom classes. PR\n#979\nby\n@AryazE\n.\n Allow colon in zsh autocomplete values and descriptions. PR\n#988\nby\n@snapbug\n.\nRefactors\n锔 Deprecate support for\nis_flag\nand\nflag_value\nparameters. PR\n#987\nby\n@svlandeg\n.\n Remove unused functionality from\n_typing.py\nfile. PR\n#805\nby\n@ivantodorovich\n.\n锔 Fix typo in function name\n_make_rich_text\n. PR\n#959\nby\n@svlandeg\n.\nInternal\n Only run completion installation tests when the env var\n_TYPER_RUN_INSTALL_COMPLETION_TESTS\nis set. PR\n#995\nby\n@svlandeg\n.\n Update the docstring of the\n_make_rich_text\nmethod. PR\n#972\nby\n@svlandeg\n.\n猬 [pre-commit.ci] pre-commit autoupdate. PR\n#1040\nby\n@pre-commit-ci[bot]\n.\n猬 Bump mkdocs-material from 9.5.42 to 9.5.44. PR\n#1042\nby\n@dependabot[bot]\n.\n猬 Bump ruff from 0.7.1 to 0.7.2. PR\n#1038\nby\n@dependabot[bot]\n.\n猬 Bump mkdocs-macros-plugin from 1.3.6 to 1.3.7. PR\n#1031\nby\n@dependabot[bot]\n.\n猬 [pre-commit.ci] pre-commit autoupdate. PR\n#1032\nby\n@pre-commit-ci[bot]\n.\n猬 Bump ruff from 0.7.0 to 0.7.1. PR\n#1029\nby\n@dependabot[bot]\n.\n猬 Bump pillow from 10.4.0 to 11.0.0. PR\n#1023\nby\n@dependabot[bot]\n.\n猬 Bump mkdocs-material from 9.5.35 to 9.5.42. PR\n#1027\nby\n@dependabot[bot]\n.\n猬 Bump ruff from 0.6.5 to 0.7.0. PR\n#1026\nby\n@dependabot[bot]\n.\n猬 Bump mkdocs-macros-plugin from 1.2.0 to 1.3.6. PR\n#1025\nby\n@dependabot[bot]\n.\n猬 Update pre-commit requirement from <4.0.0,>=2.17.0 to >=2.17.0,<5.0.0. PR\n#1012\nby\n@dependabot[bot]\n.\n猬 Bump pypa/gh-action-pypi-publish from 1.10.1 to 1.10.3. PR\n#1009\nby\n@dependabot[bot]\n.\n猬 [pre-commit.ci] pre-commit autoupdate. PR\n#1001\nby\n@pre-commit-ci[bot]\n.\n Update Deploy docs CI to use uv. PR\n#1021\nby\n@tiangolo\n.\n Fix smokeshow, checkout files on CI. PR\n#1020\nby\n@tiangolo\n.\n Use uv in CI. PR\n#1019\nby\n@tiangolo\n.\n Update\nlabeler.yml\n. PR\n#1014\nby\n@tiangolo\n.\n Update worfkow deploy-docs-notify URL. PR\n#1011\nby\n@tiangolo\n.\n Upgrade Cloudflare GitHub Action. PR\n#1010\nby\n@tiangolo\n.\n猬 Bump mkdocs-macros-plugin from 1.0.5 to 1.2.0. PR\n#992\nby\n@dependabot[bot]\n.\n猬 Bump ruff from 0.6.4 to 0.6.5. PR\n#991\nby\n@dependabot[bot]\n.\n猬 Bump mkdocs-material from 9.5.34 to 9.5.35. PR\n#996\nby\n@dependabot[bot]\n.\n猬 [pre-commit.ci] pre-commit autoupdate. PR\n#993\nby\n@pre-commit-ci[bot]\n.\n猬 [pre-commit.ci] pre-commit autoupdate. PR\n#982\nby\n@pre-commit-ci[bot]\n.\n猬 Bump tiangolo/issue-manager from 0.5.0 to 0.5.1. PR\n#980\nby\n@dependabot[bot]\n.\n Update\nissue-manager.yml\n. PR\n#978\nby\n@tiangolo\n.\n猬 Bump ruff from 0.6.3 to 0.6.4. PR\n#975\nby\n@dependabot[bot]\n.\n猬 Bump mkdocs-material from 9.5.33 to 9.5.34. PR\n#963\nby\n@dependabot[bot]\n.\n猬 Bump pypa/gh-action-pypi-publish from 1.9.0 to 1.10.1. PR\n#973\nby\n@dependabot[bot]\n.\n猬 [pre-commit.ci] pre-commit autoupdate. PR\n#966\nby\n@pre-commit-ci[bot]\n.\n Set\ninclude-hidden-files\nto\nTrue\nwhen using the\nupload-artifact\nGH action. PR\n#967\nby\n@svlandeg\n.\n猬 Bump ruff from 0.6.1 to 0.6.3. PR\n#961\nby\n@dependabot[bot]\n.\n猬 [pre-commit.ci] pre-commit autoupdate. PR\n#689\nby\n@pre-commit-ci[bot]\n.\n猬 Bump ruff from 0.2.0 to 0.6.1. PR\n#938\nby\n@dependabot[bot]\n.\n Update\nlatest-changes\nGitHub Action. PR\n#955\nby\n@tiangolo\n.",
    "crawl_status": "success"
  },
  {
    "library_name": "Typer",
    "url": "https://github.com/fastapi/typer/releases/tag/0.20.0",
    "version": "0.20.0",
    "title": "Release 0.20.0 路 fastapi/typer 路 GitHub",
    "release_date": "2025-10-20T17:03:20Z",
    "content": "Features\n Enable command suggestions on typo by default. PR\n#1371\nby\n@savannahostrowski\n.\nUpgrades\n猬锔 Add support for Python 3.14. PR\n#1372\nby\n@svlandeg\n.\nInternal\n Add nightly workflow to run tests against CPython main branch. PR\n#1374\nby\n@savannahostrowski\n.\n猬 Bump mkdocs-material from 9.6.21 to 9.6.22. PR\n#1377\nby\n@dependabot[bot]\n.\n Configure reminder for\nwaiting\nlabel in\nissue-manager\n. PR\n#1378\nby\n@YuriiMotov\n.\n猬 Bump ruff from 0.13.3 to 0.14.0. PR\n#1368\nby\n@dependabot[bot]\n.\n猬 [pre-commit.ci] pre-commit autoupdate. PR\n#1376\nby\n@pre-commit-ci[bot]\n.\n猬 Bump mkdocs-macros-plugin from 1.3.9 to 1.4.0. PR\n#1354\nby\n@dependabot[bot]\n.\n猬 Bump mkdocs-material from 9.6.20 to 9.6.21. PR\n#1360\nby\n@dependabot[bot]\n.\n猬 Bump mypy from 1.4.1 to 1.11.2. PR\n#957\nby\n@dependabot[bot]\n.\n猬 Bump astral-sh/setup-uv from 6 to 7. PR\n#1369\nby\n@dependabot[bot]\n.\n猬 Bump ruff from 0.13.2 to 0.13.3. PR\n#1366\nby\n@dependabot[bot]\n.\n猬 [pre-commit.ci] pre-commit autoupdate. PR\n#1367\nby\n@pre-commit-ci[bot]\n.\n猬 Bump tiangolo/issue-manager from 0.5.1 to 0.6.0. PR\n#1361\nby\n@dependabot[bot]\n.\n猬 Bump ruff from 0.13.1 to 0.13.2. PR\n#1357\nby\n@dependabot[bot]\n.\n猬 [pre-commit.ci] pre-commit autoupdate. PR\n#1358\nby\n@pre-commit-ci[bot]\n.\n Update docs previews comment, single comment, add failure status. PR\n#1359\nby\n@tiangolo\n.",
    "crawl_status": "success"
  },
  {
    "library_name": "Loguru",
    "url": "https://github.com/Delgan/loguru/releases/tag/0.7.1",
    "version": "0.7.1",
    "title": "Release 0.7.1 路 Delgan/loguru 路 GitHub",
    "release_date": "2023-09-04T13:15:14Z",
    "content": "Add a new\ncontext\noptional argument to\nlogger.add()\nspecifying\nmultiprocessing\ncontext (like\n\"spawn\"\nor\n\"fork\"\n) to be used internally instead of the default one (\n#851\n).\nAdd support for true colors on Windows using ANSI/VT console when available (\n#934\n, thanks\n@tunaflsh\n).\nFix possible deadlock when calling\nlogger.complete()\nwith concurrent logging of an asynchronous sink (\n#906\n).\nFix file possibly rotating too early or too late when re-starting an application around midnight (\n#894\n).\nFix inverted\n\"<hide>\"\nand\n\"<strike>\"\ncolor tags (\n#943\n, thanks\n@tunaflsh\n).\nFix possible untraceable errors raised when logging non-unpicklable\nException\ninstances while using\nenqueue=True\n(\n#329\n).\nFix possible errors raised when logging non-picklable\nException\ninstances while using\nenqueue=True\n(\n#342\n, thanks\n@ncoudene\n).\nFix missing seconds and microseconds when formatting timezone offset that requires such accuracy (\n#961\n).\nRaise\nValueError\nif an attempt to use nanosecond precision for time formatting is detected (\n#855\n).",
    "crawl_status": "success"
  },
  {
    "library_name": "Loguru",
    "url": "https://github.com/Delgan/loguru/releases/tag/0.7.3",
    "version": "0.7.3",
    "title": "Release 0.7.3 路 Delgan/loguru 路 GitHub",
    "release_date": "2024-12-06T11:25:42Z",
    "content": "Fix Cython incompatibility caused by the absence of underlying stack frames, which resulted in a\nValueError\nduring logging (\n#88\n).\nFix possible\nRuntimeError\nwhen removing all handlers with\nlogger.remove()\ndue to thread-safety issue (\n#1183\n, thanks\n@jeremyk\n).\nFix\ndiagnose=True\noption of exception formatting not working as expected with Python 3.13 (\n#1235\n, thanks\n@etianen\n).\nFix non-standard level names not fully compatible with\nlogging.Formatter()\n(\n#1231\n, thanks\n@yechielb2000\n).\nFix inability to display a literal\n\"\\\"\nimmediately before color markups (\n#988\n).\nFix possible infinite recursion when an exception is raised from a\n__repr__\nmethod decorated with\nlogger.catch()\n(\n#1044\n).\nImprove performance of\ndatetime\nformatting while logging messages (\n#1201\n, thanks\n@trim21\n).\nReduce startup time in the presence of installed but unused\nIPython\nthird-party library (\n#1001\n, thanks\n@zakstucke\n).",
    "crawl_status": "success"
  },
  {
    "library_name": "Loguru",
    "url": "https://github.com/Delgan/loguru/releases/tag/0.7.0",
    "version": "0.7.0",
    "title": "Release 0.7.0 路 Delgan/loguru 路 GitHub",
    "release_date": "2023-04-10T09:14:19Z",
    "content": "Update\nInterceptHandler\nrecipe to make it compatible with Python 3.11 (\n#654\n).\nAdd a new\nwatch\noptional argument to file sinks in order to automatically re-create possibly deleted or changed file (\n#471\n).\nMake\npatch()\ncalls cumulative instead of overriding the possibly existing patching function (\n#462\n).\nMake sinks added with\nenqueue=True\nand\ncatch=False\nstill process logged messages in case of internal exception (\n#833\n).\nAvoid possible deadlocks caused by re-using the logger inside a sink, a signal handler or a\n__del__\nmethod. Since the logger is not re-entrant, such misuse will be detected and will now generate a\nRuntimeError\n(\n#712\n, thanks\n@jacksmith15\n).\nFix file sink rotation using an aware\ndatetime.time\nfor which the timezone was ignored (\n#697\n).\nFix logs colorization not automatically enabled for Jupyter Notebook and Google Colab (\n#494\n).\nFix logs colorization not automatically enabled for Github Actions and others CI platforms (\n#604\n).\nFix\nlogger.complete()\npossibly hanging forever when\nenqueue=True\nand\ncatch=False\nif internal thread killed due to\nException\nraised by sink (\n#647\n).\nFix incompatibility with\nfreezegun\nlibrary used to simulate time (\n#600\n).\nRaise exception if\nlogger.catch()\nis used to wrap a class instead of a function to avoid unexpected behavior (\n#623\n).",
    "crawl_status": "success"
  },
  {
    "library_name": "Httpx",
    "url": "https://github.com/encode/httpx/releases/tag/0.26.0",
    "version": "0.26.0",
    "title": "Release Version 0.26.0 路 encode/httpx 路 GitHub",
    "release_date": "2023-12-20T11:01:16Z",
    "content": "0.26.0 (20th December, 2023)\nAdded\nThe\nproxy\nargument was added. You should use the\nproxy\nargument instead of the deprecated\nproxies\n, or use\nmounts=\nfor more complex configurations. (\n#2879\n)\nDeprecated\nThe\nproxies\nargument is now deprecated. It will still continue to work, but it will be removed in the future. (\n#2879\n)\nFixed\nFix cases of double escaping of URL path components. Allow / as a safe character in the query portion. (\n#2990\n)\nHandle\nNO_PROXY\nenvvar cases when a fully qualified URL is supplied as the value. (\n#2741\n)\nAllow URLs where username or password contains unescaped '@'. (\n#2986\n)\nEnsure ASGI\nraw_path\ndoes not include URL query component. (\n#2999\n)\nEnsure\nResponse.iter_text()\ncannot yield empty strings. (\n#2998\n)",
    "crawl_status": "success"
  },
  {
    "library_name": "Httpx",
    "url": "https://github.com/encode/httpx/releases/tag/0.28.0",
    "version": "0.28.0",
    "title": "Release Version 0.28.0 路 encode/httpx 路 GitHub",
    "release_date": "2024-11-28T14:53:50Z",
    "content": "0.28.0 (28th November, 2024)\nThe 0.28 release includes a limited set of deprecations.\nDeprecations\n:\nWe are working towards a simplified SSL configuration API.\nFor users of the standard\nverify=True\nor\nverify=False\ncases, or\nverify=<ssl_context>\ncase this should require no changes. The following cases have been deprecated...\nThe\nverify\nargument as a string argument is now deprecated and will raise warnings.\nThe\ncert\nargument is now deprecated and will raise warnings.\nOur revised\nSSL documentation\ncovers how to implement the same behaviour with a more constrained API.\nThe following changes are also included\n:\nThe deprecated\nproxies\nargument has now been removed.\nThe deprecated\napp\nargument has now been removed.\nJSON request bodies use a compact representation. (\n#3363\n)\nReview URL percent escape sets, based on WHATWG spec. (\n#3371\n,\n#3373\n)\nEnsure\ncertifi\nand\nhttpcore\nare only imported if required. (\n#3377\n)\nTreat\nsocks5h\nas a valid proxy scheme. (\n#3178\n)\nCleanup\nRequest()\nmethod signature in line with\nclient.request()\nand\nhttpx.request()\n. (\n#3378\n)\nBugfix: When passing\nparams={}\n, always strictly update rather than merge with an existing querystring. (\n#3364\n)",
    "crawl_status": "success"
  },
  {
    "library_name": "Httpx",
    "url": "https://github.com/encode/httpx/releases/tag/0.24.0",
    "version": "0.24.0",
    "title": "Release Version 0.24.0 路 encode/httpx 路 GitHub",
    "release_date": "2023-04-11T10:00:19Z",
    "content": "0.24.0 (6th April, 2023)\nChanged\nThe logging behaviour has been change to be more in-line with other standard Python logging usages. We no longer have a custom\nTRACE\nlog level, and we no longer use the\nHTTPX_LOG_LEVEL\nenvironment variable to auto-configure logging. We now have a significant amount of\nDEBUG\nlogging available at the network level. Full documentation is available at\nhttps://www.python-httpx.org/logging/\n(\n#2547\n,\nencode/httpcore#648\n)\nThe\nResponse.iter_lines()\nmethod now matches the stdlib behaviour and does not include the newline characters. It also resolves a performance issue. (\n#2423\n)\nQuery parameter encoding switches from using + for spaces and %2F for forward slash, to instead using %20 for spaces and treating forward slash as a safe, unescaped character. This differs from\nrequests\n, but is in line with browser behavior in Chrome, Safari, and Firefox. Both options are RFC valid. (\n#2543\n)\nNetRC authentication is no longer automatically handled, but is instead supported by an explicit\nhttpx.NetRCAuth()\nauthentication class. See the documentation at\nhttps://www.python-httpx.org/advanced/#netrc-support\n(\n#2525\n)\nRemoved\nThe\nrfc3986\ndependancy has been removed. (\n#2252\n)",
    "crawl_status": "success"
  },
  {
    "library_name": "Playwright-python",
    "url": "https://github.com/microsoft/playwright-python/releases/tag/v1.52.0",
    "version": "v1.52.0",
    "title": "Release v1.52.0 路 microsoft/playwright-python 路 GitHub",
    "release_date": "2025-04-30T09:04:16Z",
    "content": "Highlights\nNew method\nexpect(locator).to_contain_class()\nto ergonomically assert individual class names on the element.\nexpect\n(\npage\n.\nget_by_role\n(\n\"listitem\"\n,\nname\n=\n\"Ship v1.52\"\n)).\nto_contain_class\n(\n\"done\"\n)\nAria Snapshots\ngot two new properties:\n/children\nfor strict matching and\n/url\nfor links.\nexpect\n(\nlocator\n).\nto_match_aria_snapshot\n(\n\"\"\"\n- list\n- /children: equal\n- listitem: Feature A\n- listitem:\n- link \"Feature B\":\n- /url: \"https://playwright.dev\"\n\"\"\"\n)\nMiscellaneous\nNew option\nmax_redirects\nin\napiRequest.new_context()\nto control the maximum number of redirects.\nNew option\nref\nin\nlocator.aria_snapshot()\nto generate reference for each element in the snapshot which can later be used to locate the element.\nBreaking Changes\nMethod\nroute.continue()\ndoes not allow to override the\nCookie\nheader anymore. If a\nCookie\nheader is provided, it will be ignored, and the cookie will be loaded from the browser's cookie store. To set custom cookies, use\nbrowserContext.add_cookies()\n.\nmacOS 13 is now deprecated and will no longer receive WebKit updates. Please upgrade to a more recent macOS version to continue benefiting from the latest WebKit improvements.\nBrowser Versions\nChromium 136.0.7103.25\nMozilla Firefox 137.0\nWebKit 18.4\nThis version was also tested against the following stable channels:\nGoogle Chrome 135\nMicrosoft Edge 135",
    "crawl_status": "success"
  },
  {
    "library_name": "Playwright-python",
    "url": "https://github.com/microsoft/playwright-python/releases/tag/v1.45.0",
    "version": "v1.45.0",
    "title": "Release v1.45.0 路 microsoft/playwright-python 路 GitHub",
    "release_date": "2024-07-03T10:24:41Z",
    "content": "Clock\nUtilizing the new\nClock\nAPI allows to manipulate and control time within tests to verify time-related behavior. This API covers many common scenarios, including:\ntesting with predefined time;\nkeeping consistent time and timers;\nmonitoring inactivity;\nticking through time manually.\n# Initialize clock with some time before the test time and let the page load\n# naturally. `Date.now` will progress as the timers fire.\npage\n.\nclock\n.\ninstall\n(\ntime\n=\ndatetime\n.\ndatetime\n(\n2024\n,\n2\n,\n2\n,\n8\n,\n0\n,\n0\n))\npage\n.\ngoto\n(\n\"http://localhost:3333\"\n)\n# Pretend that the user closed the laptop lid and opened it again at 10am.\n# Pause the time once reached that point.\npage\n.\nclock\n.\npause_at\n(\ndatetime\n.\ndatetime\n(\n2024\n,\n2\n,\n2\n,\n10\n,\n0\n,\n0\n))\n# Assert the page state.\nexpect\n(\npage\n.\nget_by_test_id\n(\n\"current-time\"\n)).\nto_have_text\n(\n\"2/2/2024, 10:00:00 AM\"\n)\n# Close the laptop lid again and open it at 10:30am.\npage\n.\nclock\n.\nfast_forward\n(\n\"30:00\"\n)\nexpect\n(\npage\n.\nget_by_test_id\n(\n\"current-time\"\n)).\nto_have_text\n(\n\"2/2/2024, 10:30:00 AM\"\n)\nSee\nthe clock guide\nfor more details.\nMiscellaneous\nMethod\nlocator.setInputFiles()\nnow supports uploading a directory for\n<input type=file webkitdirectory>\nelements.\npage\n.\nget_by_label\n(\n\"Upload directory\"\n).\nset_input_files\n(\n'mydir'\n)\nMultiple methods like\nlocator.click()\nor\nlocator.press()\nnow support a\nControlOrMeta\nmodifier key. This key maps to\nMeta\non macOS and maps to\nControl\non Windows and Linux.\n# Press the common keyboard shortcut Control+S or Meta+S to trigger a \"Save\" operation.\npage\n.\nkeyboard\n.\npress\n(\n\"ControlOrMeta+S\"\n)\nNew property\nhttpCredentials.send\nin\napiRequest.newContext()\nthat allows to either always send the\nAuthorization\nheader or only send it in response to\n401 Unauthorized\n.\nPlaywright now supports Chromium, Firefox and WebKit on Ubuntu 24.04.\nv1.45 is the last release to receive WebKit update for macOS 12 Monterey. Please update macOS to keep using the latest WebKit.\nBrowser Versions\nChromium 127.0.6533.5\nMozilla Firefox 127.0\nWebKit 17.4\nThis version was also tested against the following stable channels:\nGoogle Chrome 126\nMicrosoft Edge 126",
    "crawl_status": "success"
  },
  {
    "library_name": "Playwright-python",
    "url": "https://github.com/microsoft/playwright-python/releases/tag/v1.35.0",
    "version": "v1.35.0",
    "title": "Release v1.35.0 路 microsoft/playwright-python 路 GitHub",
    "release_date": "2023-06-13T07:37:08Z",
    "content": "Highlights\nNew option\nmask_color\nfor methods\nPage.screenshot()\nand\nLocator.screenshot()\nto change default masking color.\nNew\nuninstall\nCLI command to uninstall browser binaries:\n$ playwright uninstall\n#\nremove browsers installed by this installation\n$ playwright uninstall --all\n#\nremove all ever-install Playwright browsers\nBrowser Versions\nChromium 115.0.5790.13\nMozilla Firefox 113.0\nWebKit 16.4\nThis version was also tested against the following stable channels:\nGoogle Chrome 114\nMicrosoft Edge 114",
    "crawl_status": "success"
  },
  {
    "library_name": "Tenacity",
    "url": "https://github.com/jd/tenacity/releases/tag/8.3.0",
    "version": "8.3.0",
    "title": "Release 8.3.0 路 jd/tenacity 路 GitHub",
    "release_date": "2024-05-07T08:47:50Z",
    "content": "New Features\nAdded a new stop function:\nstop_before_delay\n, which will stop execution if the next sleep time would cause overall delay to exceed the specified delay. Useful for use cases where you have some upper bound on retry times that you must not exceed, so returning before that timeout is preferable than returning after that timeout.\nBug Fixes\nPreserve\ndefaults\nand\nkwdefaults\nthrough retry decorator\nOther Notes\nAdd a \"test\" extra",
    "crawl_status": "success"
  },
  {
    "library_name": "Tenacity",
    "url": "https://github.com/jd/tenacity/releases/tag/9.0.0",
    "version": "9.0.0",
    "title": "Release tenacity 9.0.0 路 jd/tenacity 路 GitHub",
    "release_date": "2024-07-29T12:12:04Z",
    "content": "What's Changed\nRespects\nmin\nargument for\nwait_random_exponential\nby\n@yxtay\nin\n#425\nBump major version to warn API breakage on statistics attribute\nFull Changelog\n:\n8.5.0...9.0.0",
    "crawl_status": "success"
  },
  {
    "library_name": "Tenacity",
    "url": "https://github.com/jd/tenacity/releases/tag/9.1.1",
    "version": "9.1.1",
    "title": "Release 9.1.1 路 jd/tenacity 路 GitHub",
    "release_date": "2025-04-02T08:22:06Z",
    "content": "What's Changed\nTest with Python 3.13 by\n@edgarrmondragon\nin\n#480\nci: remove Python 3.8 support by\n@jd\nin\n#515\nfix: return \"Self\" from \"BaseRetrying.copy\" by @ThirVondukr in\n#518\nci: upload on PyPI using trusted publishing by\n@jd\nin\n#520\nAdd re.Pattern to allowed match types by\n@robertschweizer\nin\n#497\nNew Contributors\n@Young-Lord\nmade their first contribution in\n#491\n@edgarrmondragon\nmade their first contribution in\n#480\n@ThirVondukr made their first contribution in\n#518\n@robertschweizer\nmade their first contribution in\n#497\nFull Changelog\n:\n9.0.0...9.1.0",
    "crawl_status": "success"
  },
  {
    "library_name": "Poetry",
    "url": "https://github.com/python-poetry/poetry/releases/tag/2.2.0",
    "version": "2.2.0",
    "title": "Release 2.2.0 路 python-poetry/poetry 路 GitHub",
    "release_date": "2025-09-14T11:43:56Z",
    "content": "Added\nAdd support for nesting dependency groups\n(\n#10166\n).\nAdd support for PEP 735 dependency groups\n(\n#10130\n).\nAdd support for PEP 639 license clarity\n(\n#10413\n).\nAdd a\n--format\noption to\npoetry show\nto alternatively output json format (\n#10487\n).\nAdd official support for Python 3.14 (\n#10514\n).\nChanged\nNormalize dependency group names\n(\n#10387\n).\nChange\ninstaller.no-binary\nand\ninstaller.only-binary\nso that explicit package names will take precedence over\n:all:\n(\n#10278\n).\nImprove log output during\npoetry install\nwhen a wheel is built from source (\n#10404\n).\nImprove error message in case a file lock could not be acquired while cloning a git repository (\n#10535\n).\nRequire\ndulwich>=0.24.0\n(\n#10492\n).\nAllow\nvirtualenv>=20.33\nagain (\n#10506\n).\nAllow\nfindpython>=0.7\n(\n#10510\n).\nAllow\nimportlib-metadata>=8.7\n(\n#10511\n).\nFixed\nFix an issue where\npoetry new\ndid not create the project structure in an existing empty directory (\n#10431\n).\nFix an issue where a dependency that was required for a specific Python version was not installed into an environment of a pre-release Python version (\n#10516\n).\npoetry-core (\n2.2.0\n)\nDeprecate table values and values that are not valid SPDX expressions for\n[project.license]\n(\n#870\n).\nFix an issue where explicitly included files that are in\n.gitignore\nwere not included in the distribution (\n#874\n).\nFix an issue where marker operations could result in invalid markers (\n#875\n).",
    "crawl_status": "success"
  },
  {
    "library_name": "Poetry",
    "url": "https://github.com/python-poetry/poetry/releases/tag/1.5.0",
    "version": "1.5.0",
    "title": "Release 1.5.0 路 python-poetry/poetry 路 GitHub",
    "release_date": "2023-05-19T12:27:22Z",
    "content": "Added\nIntroduce the new source priorities\nexplicit\nand\nsupplemental\n(\n#7658\n,\n#6879\n).\nIntroduce the option to configure the priority of the implicit PyPI source\n(\n#7801\n).\nAdd handling for corrupt cache files (\n#7453\n).\nImprove caching of URL and git dependencies (\n#7693\n,\n#7473\n).\nAdd option to skip installing directory dependencies (\n#6845\n,\n#7923\n).\nAdd\n--executable\noption to\npoetry env info\n(\n#7547\n).\nAdd\n--top-level\noption to\npoetry show\n(\n#7415\n).\nAdd\n--lock\noption to\npoetry remove\n(\n#7917\n).\nAdd experimental\nPOETRY_REQUESTS_TIMEOUT\noption (\n#7081\n).\nImprove performance of wheel inspection by avoiding unnecessary file copy operations (\n#7916\n).\nChanged\nRemove the old deprecated installer and the corresponding setting\nexperimental.new-installer\n(\n#7356\n).\nIntroduce\npriority\nkey for sources and deprecate flags\ndefault\nand\nsecondary\n(\n#7658\n).\nDeprecate\npoetry run <entry point>\nif the entry point was not previously installed via\npoetry install\n(\n#7606\n).\nOnly write the lock file if the installation succeeds (\n#7498\n).\nDo not write the unused package category into the lock file (\n#7637\n).\nFixed\nFix an issue where Poetry's internal pyproject.toml continually grows larger with empty lines (\n#7705\n).\nFix an issue where Poetry crashes due to corrupt cache files (\n#7453\n).\nFix an issue where the\nRetry-After\nin HTTP responses was not respected and retries were handled inconsistently (\n#7072\n).\nFix an issue where Poetry silently ignored invalid groups (\n#7529\n).\nFix an issue where Poetry does not find a compatible Python version if not given explicitly (\n#7771\n).\nFix an issue where the\ndirect_url.json\nof an editable install from a git dependency was invalid (\n#7473\n).\nFix an issue where error messages from build backends were not decoded correctly (\n#7781\n).\nFix an infinite loop when adding certain dependencies (\n#7405\n).\nFix an issue where pre-commit hooks skip pyproject.toml files in subdirectories (\n#7239\n).\nFix an issue where pre-commit hooks do not use the expected Python version (\n#6989\n).\nFix an issue where an unclear error message is printed if the project name is the same as one of its dependencies (\n#7757\n).\nFix an issue where\npoetry install\nreturns a zero exit status even though the build script failed (\n#7812\n).\nFix an issue where an existing\n.venv\nwas not used if\nin-project\nwas not set (\n#7792\n).\nFix an issue where multiple extras passed to\npoetry add\nwere not parsed correctly (\n#7836\n).\nFix an issue where\npoetry shell\ndid not send a newline to\nfish\n(\n#7884\n).\nFix an issue where\npoetry update --lock\nprinted operations that were not executed (\n#7915\n).\nFix an issue where\npoetry add --lock\ndid perform a full update of all dependencies (\n#7920\n).\nFix an issue where\npoetry shell\ndid not work with\nnushell\n(\n#7919\n).\nFix an issue where subprocess calls failed on Python 3.7 (\n#7932\n).\nFix an issue where keyring was called even though the password was stored in an environment variable (\n#7928\n).\nDocs\nAdd information about what to use instead of\n--dev\n(\n#7647\n).\nPromote semantic versioning less aggressively (\n#7517\n).\nExplain Poetry's own versioning scheme in the FAQ (\n#7517\n).\nUpdate documentation for configuration with environment variables (\n#6711\n).\nAdd details how to disable the virtualenv prompt (\n#7874\n).\nImprove documentation on whether to commit\npoetry.lock\n(\n#7506\n).\nImprove documentation of\nvirtualenv.create\n(\n#7608\n).\npoetry-core (\n1.6.0\n)\nImprove error message for invalid markers (\n#569\n).\nIncrease robustness when deleting temporary directories on Windows (\n#460\n).\nReplace\ntomlkit\nwith\ntomli\n, which changes the interface of some\ninternal\nclasses (\n#483\n).\nDeprecate\nPackage.category\n(\n#561\n).\nFix a performance regression in marker handling (\n#568\n).\nFix an issue where wildcard version constraints were not handled correctly (\n#402\n).\nFix an issue where\npoetry build\ncreated duplicate Python classifiers if they were specified manually (\n#578\n).\nFix an issue where local versions where not handled correctly (\n#579\n).",
    "crawl_status": "success"
  },
  {
    "library_name": "Poetry",
    "url": "https://github.com/python-poetry/poetry/releases/tag/1.8.0",
    "version": "1.8.0",
    "title": "Release 1.8.0 路 python-poetry/poetry 路 GitHub",
    "release_date": "2024-02-25T12:18:41Z",
    "content": "Added\nAdd a\nnon-package\nmode for use cases where Poetry is only used for dependency management\n(\n#8650\n).\nAdd support for PEP 658 to fetch metadata without having to download wheels\n(\n#5509\n).\nAdd a\nlazy-wheel\nconfig option (default:\ntrue\n) to reduce wheel downloads during dependency resolution\n(\n#8815\n,\n#8941\n).\nImprove performance of dependency resolution by using shallow copies instead of deep copies (\n#8671\n).\npoetry check\nvalidates that no unknown sources are referenced in dependencies (\n#8709\n).\nAdd archive validation during installation for further hash algorithms (\n#8851\n).\nAdd a\nto\nkey in\ntool.poetry.packages\nto allow custom subpackage names (\n#8791\n).\nAdd a config option to disable\nkeyring\n(\n#8910\n).\nAdd a\n--sync\noption to\npoetry update\n(\n#8931\n).\nAdd an\n--output\noption to\npoetry build\n(\n#8828\n).\nAdd a\n--dist-dir\noption to\npoetry publish\n(\n#8828\n).\nChanged\nThe implicit PyPI source is disabled if at least one primary source is configured\n(\n#8771\n).\nDeprecate source priority\ndefault\n(\n#8771\n).\nUpgrade the warning about an inconsistent lockfile to an error\n(\n#8737\n).\nDeprecate setting\ninstaller.modern-installation\nto\nfalse\n(\n#8988\n).\nDrop support for\npip<19\n(\n#8894\n).\nRequire\nrequests-toolbelt>=1\n(\n#8680\n).\nAllow\nplatformdirs\n4.x (\n#8668\n).\nAllow and require\nxattr\n1.x on macOS (\n#8801\n).\nImprove venv shell activation in\nfish\n(\n#8804\n).\nRename\nsystem\nto\nbase\nin output of\npoetry env info\n(\n#8832\n).\nUse pretty name in output of\npoetry version\n(\n#8849\n).\nImprove error handling for invalid entries in\ntool.poetry.scripts\n(\n#8898\n).\nImprove verbose output for dependencies with extras during dependency resolution (\n#8834\n).\nImprove message about an outdated lockfile (\n#8962\n).\nFixed\nFix an issue where\npoetry shell\nfailed when Python has been installed with MSYS2 (\n#8644\n).\nFix an issue where Poetry commands failed in a terminal with a non-UTF-8 encoding (\n#8608\n).\nFix an issue where a missing project name caused an incomprehensible error message (\n#8691\n).\nFix an issue where Poetry failed to install an\nsdist\npath dependency (\n#8682\n).\nFix an issue where\npoetry install\nfailed because an unused extra was not available (\n#8548\n).\nFix an issue where\npoetry install --sync\ndid not remove an unrequested extra (\n#8621\n).\nFix an issue where\npoetry init\ndid not allow specific characters in the author field (\n#8779\n).\nFix an issue where Poetry could not download\nsdists\nfrom misconfigured servers (\n#8701\n).\nFix an issue where metadata of sdists that call CLI tools of their build requirements could not be determined (\n#8827\n).\nFix an issue where Poetry failed to use the currently activated environment (\n#8831\n).\nFix an issue where\npoetry shell\nfailed in\nzsh\nif a space was in the venv path (\n#7245\n).\nFix an issue where scripts with extras could not be installed (\n#8900\n).\nFix an issue where explicit sources where not propagated correctly (\n#8835\n).\nFix an issue where debug prints where swallowed when using a build script (\n#8760\n).\nFix an issue where explicit sources of locked dependencies where not propagated correctly (\n#8948\n).\nFix an issue where Poetry's own environment was falsely identified as system environment (\n#8970\n).\nFix an issue where dependencies from a\nsetup.py\nwere ignored silently (\n#9000\n).\nFix an issue where environment variables for\nvirtualenv.options\nwere ignored (\n#9015\n).\nFix an issue where\nvirtualenvs.options.no-pip\nand\nvirtualenvs.options.no-setuptools\nwere not normalized (\n#9015\n).\nDocs\nReplace deprecated\n--no-dev\nwith\n--without dev\nin the FAQ (\n#8659\n).\nRecommend\npoetry-check\ninstead of the deprecated\npoetry-lock\npre-commit hook (\n#8675\n).\nClarify the names of the environment variables to provide credentials for repositories (\n#8782\n).\nAdd note how to install several version of Poetry in parallel (\n#8814\n).\nImprove description of\npoetry show --why\n(\n#8817\n).\nImprove documentation of\npoetry update\n(\n#8706\n).\nAdd a warning about passing variables that may start with a hyphen via command line (\n#8850\n).\nMention that the virtual environment in which Poetry itself is installed should not be activated (\n#8833\n).\nAdd note about\npoetry run\nand externally managed environments (\n#8748\n).\nUpdate FAQ entry about\ntox\nfor\ntox\n4.x (\n#8658\n).\nFix documentation for default\nformat\noption for\ninclude\nand\nexclude\nvalue (\n#8852\n).\nAdd note about\ntox\nand configured credentials (\n#8888\n).\nAdd note and link how to install\npipx\n(\n#8878\n).\nFix examples for\npoetry add\nwith git dependencies over ssh (\n#8911\n).\nRemove reference to deprecated scripts extras feature (\n#8903\n).\nChange examples to prefer\n--only main\ninstead of\n--without dev\n(\n#8921\n).\nMention that the\ndevelop\nattribute is a Poetry-specific feature and not propagated to other tools (\n#8971\n).\nFix examples for adding supplemental and secondary sources (\n#8953\n).\nAdd PyTorch example for explicit sources (\n#9006\n).\npoetry-core (\n1.9.0\n)\nDeprecate scripts that depend on extras\n(\n#690\n).\nAdd support for path dependencies that do not define a build system (\n#675\n).\nUpdate list of supported licenses (\n#659\n,\n#669\n,\n#678\n,\n#694\n).\nRework list of files included in build artifacts (\n#666\n).\nFix an issue where insignificant errors were printed if the working directory is not inside a git repository (\n#684\n).\nFix an issue where the project's directory was not recognized as git repository on Windows due to an encoding issue (\n#685\n).",
    "crawl_status": "success"
  },
  {
    "library_name": "Watchdog",
    "url": "https://github.com/gorakhargosh/watchdog/releases/tag/v3.0.0",
    "version": "v3.0.0",
    "title": "Release 3.0.0 路 gorakhargosh/watchdog 路 GitHub",
    "release_date": "2023-03-20T09:22:33Z",
    "content": "Breaking Changes\nDrop support for Python 3.6.\nOther Changes\nwatchdog\nis now PEP 561 compatible, and tested with\nmypy\nFix missing\n>\nin\nFileSystemEvent.__repr__()\n(\n#980\n)\n[ci] Lots of improvements\n[inotify] Return from\nInotifyEmitter.queue_events()\nif not launched when thread is inactive (\n#963\n)\n[tests] Stability improvements\n[utils] Remove handling of\nthreading.Event.isSet\nspelling (\n#962\n)\n[watchmedo] Fixed tricks YAML generation (\n#965\n)\n  Thanks to our beloved contributors:\n@kurtmckee\n,\n@altendky\n,\n@agroszer\n,\n@BoboTiG",
    "crawl_status": "success"
  },
  {
    "library_name": "Watchdog",
    "url": "https://github.com/gorakhargosh/watchdog/releases/tag/v4.0.0",
    "version": "v4.0.0",
    "title": "Release 4.0.0 路 gorakhargosh/watchdog 路 GitHub",
    "release_date": "2024-02-06T22:07:43Z",
    "content": "Breaking Changes\nDrop support for Python 3.7.\n[events]\nFileSystemEvent\n, and subclasses, are now\ndataclass\nes, and their\nrepr()\nhas changed\n[windows]\nWinAPINativeEvent\nis now a\ndataclass\n, and its\nrepr()\nhas changed\n[windows] The\nobservers.read_directory_changes.WATCHDOG_TRAVERSE_MOVED_DIR_DELAY\nhack was removed. The constant will be kept to prevent breaking other softwares.\nOther Changes\nAdd support for Python 3.12.\n[snapshot] Add typing to\ndirsnapshot\n(\n#1012\n)\n[snapshot] Added\nDirectorySnapshotDiff.ContextManager\n(\n#1011\n)\n[events] Log\nFileOpenedEvent\n, and\nFileClosedEvent\n, events in\nLoggingEventHandler\n[tests] Improve\nFileSystemEvent\ncoverage\n[watchmedo] Log all events in\nLoggerTrick\n Thanks to our beloved contributors:\n@BoboTiG\n,\n@msabramo",
    "crawl_status": "success"
  },
  {
    "library_name": "Watchdog",
    "url": "https://github.com/gorakhargosh/watchdog/releases/tag/v6.0.0",
    "version": "v6.0.0",
    "title": "Release 6.0.0 路 gorakhargosh/watchdog 路 GitHub",
    "release_date": "2024-11-01T14:09:55Z",
    "content": "Breaking Changes\n[inotify] Use of\nselect.poll()\ninstead of deprecated\nselect.select()\n, if available. (\n#1078\n)\n[utils] Removed the unused\necho_class()\nfunction from the\necho\nmodule.\n[utils] Removed the unused\necho_instancemethod()\nfunction from the\necho\nmodule.\n[utils] Removed the unused\necho_module()\nfunction from the\necho\nmodule.\n[utils] Removed the unused\nis_class_private_name()\nfunction from the\necho\nmodule.\n[utils] Removed the unused\nis_classmethod()\nfunction from the\necho\nmodule.\n[utils] Removed the unused\nis_method(met()\nfunction from the\necho\nmodule.\n[utils] Removed the unused\nmethod_name()\nfunction from the\necho\nmodule.\n[utils] Removed the unused\nname()\nfunction from the\necho\nmodule.\n[watchmedo] Removed the\n--trace\nCLI argument from the\nwatchmedo log\ncommand, useless since events are logged by default at the\nLoggerTrick\nclass level.\nOther Changes\nPin test dependecies.\n[docs] Add typing info to quick start. (\n#1082\n)\n[inotify] Fix reading inotify file descriptor after closing it. (\n#1081\n)\n[utils] The\nstop_signal\nkeyword-argument type of the\nAutoRestartTrick\nclass can now be either a\nsignal.Signals\nor an\nint\n.\n[utils] Added the\n__repr__()\nmethod to the\nTrick\nclass.\n[watchmedo] Fixed Mypy issues.\n[watchmedo] Added the\n__repr__()\nmethod to the\nHelpFormatter\nclass.\n[windows] Fixed Mypy issues.\n Thanks to our beloved contributors:\n@g-pichler\n,\n@ethan-vanderheijden\n,\n@nhairs\n,\n@BoboTiG",
    "crawl_status": "success"
  },
  {
    "library_name": "Tortoise-ORM",
    "url": "https://github.com/tortoise/tortoise-orm/releases/tag/0.21.0",
    "version": "0.21.0",
    "title": "Release 0.21.0 路 tortoise/tortoise-orm 路 GitHub",
    "release_date": "2024-05-23T20:38:22Z",
    "content": "Added\nEnhancement for FastAPI lifespan support (\n#1371\n)\nAdd\n__eq__\nmethod to\nQ\nto more easily test dynamically-built queries (\n#1506\n)\nAdded PlainToTsQuery function for postgres (\n#1347\n)\nAllow field's default keyword to be async function (\n#1498\n)\nAdd support for queryset slicing. (\n#1341\n)\nFixed\nFix\nDatetimeField\nuse '__year' report\n'int' object has no attribute 'utcoffset'\n. (\n#1575\n)\nFix\nbulk_update\nwhen using custom fields. (\n#1564\n)\nFix\noptional\nparameter in\npydantic_model_creator\ndoes not work for pydantic v2. (\n#1551\n)\nFix\nget_annotations\nnow evaluates annotations in the default scope instead of the app namespace. (\n#1552\n)\nFix\nget_or_create\nmethod. (\n#1404\n)\nUse\nindex_name\ninstead of\nBaseSchemaGenerator._generate_index_name\nto generate index name.\nUse subquery for count() and exists() in\nQuerySet\nto match count result to\nQuerySet\nresult. (\n#1607\n)\nChanged\nChange\nutils.chunk\nfrom function to return iterables lazily.\nRemoved lower bound of id keys in generated pydantic models. (\n#1602\n)\nRename Field initial arguments\npk\n/\nindex\nto\nprimary_key\n/\ndb_index\n. (\n#1621\n)\nRenamed\nModel.check\nmethod to\nModel._check\nto avoid naming collision issues  (\n#1559\n) (\n#1550\n)\nBreaking Changes\nbulk_create\nnow does not return anything. (\n#1614\n)",
    "crawl_status": "success"
  },
  {
    "library_name": "Tortoise-ORM",
    "url": "https://github.com/tortoise/tortoise-orm/releases/tag/0.25.0",
    "version": "0.25.0",
    "title": "Release 0.25.0 路 tortoise/tortoise-orm 路 GitHub",
    "release_date": "2025-04-14T11:41:57Z",
    "content": "Fixed\nFix\npydantic_model_creator\nincompatibility with Pydantic 2.11 (\n#1925\n)\nChanged\nSkip database selection if the router is not configured to improve performance (\n#1915\n)\n.values()\n,\n.values_list()\nand\n.only()\ncannot be used together (\n#1923\n)\nAdded\n.only\nsupports selecting related fields, e.g.\n.only(\"related__field\")\n(\n#1923\n)",
    "crawl_status": "success"
  },
  {
    "library_name": "Tortoise-ORM",
    "url": "https://github.com/tortoise/tortoise-orm/releases/tag/0.20.0",
    "version": "0.20.0",
    "title": "Release 0.20.0 路 tortoise/tortoise-orm 路 GitHub",
    "release_date": "2023-08-11T03:42:54Z",
    "content": "Added\nAllow ForeignKeyField(on_delete=NO_ACTION) (\n#1393\n)\nSupport\npydantic\n2.0. (\n#1433\n)\nFixed\nFix foreign key constraint not generated on MSSQL Server. (\n#1400\n)\nFix testcase error with python3.11 (\n#1308\n)\nBreaking Changes\nDrop support for\npydantic\n1.x.\nDrop support for\npython\n3.7.\nParam\nconfig_class\nof\npydantic_model_creator\nis renamed to\nmodel_config\n.\nAttr\nconfig_class\nof\nPydanticMeta\nis renamed to\nmodel_config\n.",
    "crawl_status": "success"
  },
  {
    "library_name": "Locust",
    "url": "https://github.com/locustio/locust/releases/tag/2.16.0",
    "version": "2.16.0",
    "title": "Release 2.16.0 路 locustio/locust 路 GitHub",
    "release_date": "2023-08-04T11:33:09Z",
    "content": "What's Changed\nFix: show host url by\n@zifter\nin\n#2324\nRename link text on README.md by\n@JE-Chen\nin\n#2334\nRemove codecov from build by\n@cyberw\nin\n#2337\nPut dependencies/project information in pyproject.toml instead of setup.cfg (PEP621) by\n@JE-Chen\nin\n#2336\nAdd worker_connect event by\n@cyberw\nin\n#2344\nDuplicated titles by\n@Daemo00\nin\n#2346\nUpdate rest.py by\n@BhattcharyaCodes\nin\n#2352\nFixed the users dispatching when it got infinite loop (fixes\n#2345\n) by\n@EzR1d3r\nin\n#2350\nClarify documentation string for\ntotal_content_length\nby\n@johenning\nin\n#2354\nAllow selecting user classes using LOCUST_USER_CLASSES env var by\n@ibarbech\nin\n#2355\nFix passing host to user class when debugging by\n@LKajan\nin\n#2365\nWeb UI dropdown for custom args with choices by\n@ktrnka\nin\n#2372\nupdate links to requests homepage by\n@evgeni\nin\n#2373\nFix\n#1910\nKeyboardInterrupt with load shapes by\n@JevonCowell\nin\n#2375\nNew Contributors\n@JE-Chen\nmade their first contribution in\n#2334\n@Daemo00\nmade their first contribution in\n#2346\n@BhattcharyaCodes\nmade their first contribution in\n#2352\n@johenning\nmade their first contribution in\n#2354\n@ibarbech\nmade their first contribution in\n#2355\n@LKajan\nmade their first contribution in\n#2365\n@ktrnka\nmade their first contribution in\n#2372\n@evgeni\nmade their first contribution in\n#2373\n@JevonCowell\nmade their first contribution in\n#2375\nFull Changelog\n:\n2.15.1...2.16.0",
    "crawl_status": "success"
  },
  {
    "library_name": "Locust",
    "url": "https://github.com/locustio/locust/releases/tag/2.42.6",
    "version": "2.42.6",
    "title": "Release 2.42.6 路 locustio/locust 路 GitHub",
    "release_date": "2025-11-29T17:31:00Z",
    "content": "What's Changed\nGH Actions: Bump actions/checkout from 5 to 6 in the all_dependencies group by\n@dependabot\n[bot] in\n#3287\nFix Toml Parser Being Called on Conf Files by\n@andrewbaldwin44\nin\n#3293\nOnly log \"OpenTelemetry enabled\" message when success by\n@amadeuppereira\nin\n#3294\nAdd otel unit tests by\n@amadeuppereira\nin\n#3295\nLog duplicate client_ready messages as debug instead of info level by\n@cyberw\nin\n#3296\nImprove tests by\n@amadeuppereira\nin\n#3297\nAdd OTel documentation by\n@amadeuppereira\nin\n#3298\nUpdate OTel setup by\n@amadeuppereira\nin\n#3300\nUse match-case instead of gigantic if-elif statement when handling zmq messages in master-worker communication by\n@cyberw\nin\n#3299\nrefactor case statements and update to use 3.10 set syntax by\n@cyberw\nin\n#3301\nDon't import pytest unless it is really needed, to speed up startup by\n@cyberw\nin\n#3302\nFull Changelog\n:\n2.42.5...2.42.6",
    "crawl_status": "success"
  },
  {
    "library_name": "Locust",
    "url": "https://github.com/locustio/locust/releases/tag/2.29.0",
    "version": "2.29.0",
    "title": "Release 2.29.0 路 locustio/locust 路 GitHub",
    "release_date": "2024-06-07T18:53:11Z",
    "content": "What's Changed\nShow Reset Button when Test is Stopped by\n@andrewbaldwin44\nin\n#2726\nEnsure spawning_complete only happens once on workers by\n@cyberw\nin\n#2728\nImprove confusing log messages if someone accidentally accesses the Web UI over HTTPS by\n@cyberw\nin\n#2727\nThe time of the downloaded HTML report is not correct by\n@andrewbaldwin44\nin\n#2729\nUse requests 2.32.2 or higher for Python 3.12 by\n@cyberw\nin\n#2730\nDocs: Upgrade Sphinx to latest version (7.3.7) by\n@plaindocs\nin\n#2732\nDocs: Fix theme by\n@plaindocs\nin\n#2735\nDocs: Fix sphinx and theme upgrade by\n@plaindocs\nin\n#2736\nAdd date and zoom to charts in web UI by\n@andrewbaldwin44\nin\n#2731\nDocs: Fix API TOC by\n@plaindocs\nin\n#2737\nModify timestamp generation to remove deprecation warning by\n@JavierUhagon\nin\n#2738\nAdd Logging to download_locustfile_from_master by\n@andrewbaldwin44\nin\n#2749\nMention installing Locust in Building the Docs by\n@plaindocs\nin\n#2733\nDocs: Import wiki to docs by\n@plaindocs\nin\n#2734\nSend logs from workers to master and improve log viewer tab in the Web UI by\n@andrewbaldwin44\nin\n#2750\nNew Contributors\n@plaindocs\nmade their first contribution in\n#2732\nFull Changelog\n:\n2.28.0...2.29.0",
    "crawl_status": "success"
  },
  {
    "library_name": "NetworkX",
    "url": "https://github.com/networkx/networkx/releases/tag/networkx-3.5",
    "version": "networkx-3.5",
    "title": "Release NetworkX 3.5 路 networkx/networkx 路 GitHub",
    "release_date": "2025-05-29T11:58:31Z",
    "content": "networkx 3.5\nWe're happy to announce the release of networkx 3.5!\nAPI Changes\nSave Layouts on Graphs (\n#7571\n).\nExpire d_separated and minimum_d_separator functions (\n#7830\n).\nExpire all_triplets deprecation (\n#7828\n).\nExpire random_triad deprecation (\n#7829\n).\nDEP: Raise an exception for k_core functions with multigraphs (\n#7831\n).\nDeprecate graph_could_be_isomorphic (\n#7826\n).\nExpire total_spanning_tree_weight deprecation (\n#7843\n).\nExpire deprecation of create kwarg in nonisomorphic_trees (\n#7847\n).\nNew draw API (\n#7589\n).\nEnhancements\nperf: optimise\nrandom_k_out_graph\n(\n#7702\n).\nClausets local community detection algorithm (\n#7691\n).\nfind_asteroidal_triple\nimprovement (\n#7736\n).\nAdd\nweight\nto harmonic_diameter (\n#7636\n).\nDensest Subgraph Problem: Greedy Peeling and Greedy++ Implementations (\n#7731\n).\nsingle_source_all_shortest_paths: don't loop over all nodes (\n#7762\n).\nError message improvement for nbunch_iter ( NetworkXError raised with specific message on TypeError with \"iter\" in msg ) (\n#7790\n).\nFaster computation of energy in Laplacian centrality (\n#7793\n).\nMake\nforceatlas2_layout\ndispatchable (\n#7794\n).\nUpdate dispatchable for\nforceatlas2_layout\n(\n#7798\n).\nEnable backend-only functions where NetworkX is just an API (\n#7690\n).\nSteinertree kou enhancement in response to issue 5889 type:Enhancements (\n#7767\n).\nAdd Leiden as a backend-only algorithm (\n#7743\n).\nBipartite layout nodes optional (\n#7756\n).\nDensest Subgraph Problem: FISTA based algorithm + Large scale tests (\n#7770\n).\nDispatch\nget_node_attributes\nand a few more from\nnx.classes.function\n(\n#7824\n).\nFaster\ncould_be_isomorphic\nand\nnumber_of_cliques\n(\n#7855\n).\nAdd square_clustering to algorithm benchmarks (\n#7857\n).\nFaster Implementation of Structural Holes (\n#7249\n).\nImprove runtime of number_of_nonisomorphic_trees() (\n#7917\n).\nFix write_gexf timeformat for dynamic Graphs (\n#7914\n).\nConsolidate could_be_isomorphic (\n#7852\n).\nImproving rooted_tree_isomorphism for deep trees (\n#7945\n).\nFixing nx.diameter inconsistent results with usebounds=True (\n#7954\n).\nFaster\nsquare_clustering\n(\n#7810\n).\nAvoid repeated cache conversion failures for backends (\n#7768\n).\nImprove _sparse_fruchterman_reingold with L-BFGS (\n#7889\n).\nImprove Performance of Tree Isomorphism and Center Calculation (\n#7946\n).\nAdd option for\nbiadjacency_matrix\nto be returned as a dense NumPy array (\n#7973\n).\nAdd Functions for Finding Connected Dominating Sets (\n#7774\n).\nAdd feature to make storing node contraction data optional (\n#7902\n).\nAdded \"initial_node\" param to generate_random_paths() to allow a starting node to be specified for generated walks (\n#8002\n).\nFix behavior for iterable\nsources\nargument in\nbfs_layers\n(\n#8013\n).\nSpeed up\nconnected_components\nand\nweakly_connected_components\n(\n#7971\n).\nBiRank Algorithm Implementation (\n#7978\n).\nEnforce correct graph types for graph matchers (\n#8043\n).\nBug Fixes\nUpdate\n_raise_on_directed\nto work with\ncreate_using\npos arg (\n#7695\n).\ntrophic_levels now checks for paths from each node to a basal node (\n#7453\n).\nFix TSP weight parameter issues (\n#7721\n).\nFix for filtered MultiGraph views from\nedge_subgraph\n(\n#7724\n) (\n#7729\n).\nBUG: fixed the\nif\ncondition in\nasadpour_atsp\n(\n#7753\n).\nImplement Bar ConnectionStyle for labels (\n#7739\n).\nFixed a divide by zero error in forceatlas2 (\n#7791\n).\nFix for issue\n#7645\n: Do not preserve 'cw' and 'ccw' attributes in PlanarEmbedding.to_undirected() (\n#7750\n).\nfix typo in ramanujan branch (\n#7804\n).\nFix\nwith nx.config(backend_priority=backends):\n(\n#7814\n).\nFix handling of faux_infinite values in network_simplex (\n#7796\n).\nFixed the return type from an empty dict to an empty set (\n#7910\n).\nAdd\nedge_attrs=\"weight\"\nto\nforceatlas2_layout\ndispatch decorator (\n#7918\n).\nFix graph_hash iteration counts and DiGraph handling (\n#7834\n).\nRefactored the working of chordless_cycles to handle self loops (\n#7901\n).\nFix bc scale with k endpoints (\n#7908\n).\nFix BC scaling for source nodes with k and endpoints=False (\n#7949\n).\nBUG: graph6 format invariant to trailing newline (\n#7941\n).\nFix\nrandom_degree_sequence_graph\nwhen input is an iterator (\n#7979\n).\nImprove special cases in dispatch testing (paying off tech debt) (\n#7982\n).\nFix bug when assigning list to\nnx.config.backend_priority\n(\n#8034\n).\nA minimal fix for\nis_aperiodic\n(\n#8029\n).\nfix bug of _sparse_fruchterman_reingold and remove try/except idiom (\n#8041\n).\nFix edge case in ISMAGS symmetry detection (\n#8055\n).\nDocumentation\nset nx-arangodb link to github (\n#7694\n).\nRe-submission of\ngh-7087\nwith better file provenance (\n#7681\n).\nFix code formatting of some examples (\n#7730\n).\nAdd examples for custom graph in the doc of\nsoft_random_geometric_graph\nand\nthresholded_random_geometric_graph\n(\n#7749\n).\nGallery example: bipartite a/b-core motif (\n#7757\n).\nAdd blurb about pytest-mpl dependency to contributing guide (\n#7741\n).\nMinor updates to\nsingle_source_shortest_path_length\ndocstring (\n#7637\n).\nAdded a note to the contributor guideline to avoid numpy scalars as a (\n#7773\n).\nCorrecting the example given under subgraph_is_monomorphic.py (\n#7779\n).\n[easy] Add to Contributor List (\n#7801\n).\ndoc: mention the second major update (\n#7782\n).\nDOC: Add details about more grants (\n#7823\n).\nRefactor: Moving backend docs from\nbackends.py\nto\nbackends.rst\n(\n#7776\n).\nUpdate readwrite docstrings for the\npath\nparameter (\n#7835\n).\nFix docstring example of\nnx.generate_random_paths(index_map=...)\n(\n#7832\n).\nAdds NVIDIA Corporation to list of supporters (\n#7846\n).\nFix use of triple backticks in docstrings (\n#7845\n).\nAdd paragraph about university classes to mentored projects (\n#7838\n).\nFix pygraphviz_layout example (\n#7849\n).\nAdd test-extras to optional dependencies (\n#7854\n).\ndoc: hash size are in bytes (\n#7866\n).\nDOC: Clean up mentored projects page: move visualization project to completed section (\n#7881\n).\nadded 2 projects for GSoC 2025 (\n#7880\n).\nAdd missing usebounds param descr to distance docstrings (\n#7703\n).\nAdd examples to graph_atlas_g docstring (\n#7900\n).\nAdd missing\nweight\nand\ngravity\nattribute to\nforceatlas2_layout\ndocstring (\n#7915\n).\nDOC: Update first docstring example and add a serialization example (\n#7928\n).\nDOC: Remove myself from the mentor list for projects (\n#7943\n).\nFix typo in forceatlas2_layout (\n#7966\n).\nAdd\ntournament_matrix\nto docs (\n#7968\n).\nAdd function descriptions in the threshold.py file (\n#7906\n).\nbugfix: use supergraph to compute superpos in plot_clusters example (\n#7997\n).\nMore\nrandom_paths\ndocstring improvements (\n#7841\n).\nAdd nx-guides link to navbar without dropdown (\n#8015\n).\nClarifying backend graph class interface is_directed+is_multigraph (\n#8032\n).\nFix all sphinx build warnings (\n#8047\n).\nAdd a new gallery spring layout (\n#8042\n).\nAdd note about cycles in\nmaximum_flow()\n(\n#8058\n).\nClarify subgraph node/edge order is not preserved (\n#8069\n).\nFix typo in\nmin_edge_cover\ndocstring (\n#8075\n).\nMaintenance\nMAINT: wrapping\npartial\nwith\nstaticmethod()\nin\ntest_link_prediction.py\n(\n#7673\n).\nUpdating\npip install\ns in benchmarking workflow (\n#7647\n).\nMv changelist to release deps (\n#7708\n).\nDrop support for Python 3.10 (\n#7668\n).\nUpdate minimum dependencies (SPEC 0) (\n#7711\n).\nRemove print statements and comments from test suite (\n#7715\n).\nRefactor closeness centrality tests (\n#7712\n).\nAdd Python fallback to random_k_out_graph + document dependencies (\n#7718\n).\nFix sphinx warnings from numpydoc parsing (\n#7742\n).\nMAINT: Updating geospatial example to be compatible with\nosmnx=2.0.0\n(\n#7746\n).\nAdd more tests for\nnx.lowest_common_ancestor\n(\n#7726\n).\nUpdate\nshortest_path\nand\nsingle_target_shortest_path_length\nfor 3.5 (\n#7754\n).\nParametrize edge_subgraph multigraph test (\n#7737\n).\nAdd filters for LOBPCG convergence warnings (\n#7778\n).\nMAINT: Close mpl figures in tests to clear up test env (\n#7783\n).\nUpdate pre-commit linting (\n#7797\n).\nSmall dispatching refactor: simple\n__call__\nwhen no backends (\n#7761\n).\nBenchmarking: graph atlas (\n#7766\n).\nImprove square clustering test derived from Zhang paper (reference 2) (\n#7811\n).\nFix exception for backend-only functions (\n#7812\n).\nAdd a subplot fixture to automate test cleanup (\n#7799\n).\nMAINT: use nx.layout instead of importing layouts (\n#7819\n).\nMAINT: Move stub func in the correct scope for pickle test (\n#7818\n).\nEnsure standard import conventions are used (\n#7821\n).\nClean up pygrep pre-commit for import convention checks (\n#7822\n).\nAdd a few more square clustering test cases (\n#7825\n).\nDon't use\nassert\nwhen using\npytest.raises\n(\n#7833\n).\nUpdate doc requirements (\n#7837\n).\nUpdate developer requirements (\n#7839\n).\nMAINT: Minus not underscore in the dep package name (\n#7840\n).\nUpdate readwrite docstrings for the\npath\nparameter (\n#7835\n).\nFix docstring example of\nnx.generate_random_paths(index_map=...)\n(\n#7832\n).\nFix use of triple backticks in docstrings (\n#7845\n).\nAdd .mailmap file to consilidate contributors (\n#7853\n).\nTST: Refactor example test case generation functions (\n#7844\n).\nRefactor network_simplex test of faux_infinity (\n#7858\n).\nChange CRLF format of two files (\n#7861\n).\nFix some typos (\n#7863\n).\nPre commit hooks to check line endings and trailing whitespace (\n#7862\n).\nMAINT: replace the SHAs for blame and move the changes within pre-commit (\n#7869\n).\nRm stray instances of sparse matrices from test suite (\n#7860\n).\nRemove unused imports (\n#7864\n).\nRemove unnecessary\ndict(...)\nfor SSSP algos that return dicts (\n#7878\n).\nChange function calls to address pandas linting (\n#7885\n).\nActivate pycodestyle in linting pre-commit (\n#7859\n).\nCorrect sphinx warnings from doc build (\n#7888\n).\neffective_size\nof nodes with only self-loop edges is undefined (\n#7347\n).\nDOC: docstring changes to\nto_dict_of_dicts\nand\nattr_matrix\nand input name change in\nmin_fill_in_heuristic\n(\n#7883\n).\nUpdate layout.py (\n#7939\n).\nTree isomorphism input validation (\n#7920\n).\nTweaks and notes from a dive into backends.py (\n#7884\n).\nMAINT: Follow-up to 7945 - rm helper function (\n#7952\n).\nSome light refactoring to make the tree isomorphism tests more readable (\n#7924\n).\nnew try at will_call_mutate_inputs (\n#7959\n).\nMAINT: rm debug print from similarity module (\n#7937\n).\nImprove special cases in dispatch testing (paying off tech debt) (\n#7982\n).\nRemove unused import in convert_matrix.py (networkx.utils.not_implemented_for) (\n#7983\n).\nUse\n-n auto\nfrom pytest-xdist for dispatch and coverage CI jobs (\n#7987\n).\nMake test file names unique to be threadsafe (\n#7998\n).\nUpdate pre-commit repos (\n#8017\n).\nMinor follow-up to\ngh-8002\ntests (\n#8016\n).\nAdd linting for line length in docstrings and comments (\n#7938\n).\nAdd sg_execution_times.rst to gitignore (\n#8025\n).\nSupport both pydot v3 and pydot v4 (\n#8027\n).\nUpdate copyright license years (\n#8038\n).\nFix all sphinx build warnings (\n#8047\n).\nFix intermittent test failures in expander graph generator tests (\n#8048\n).\nRefactor tree_isomorphism to improve code reuse and readability (\n#7929\n).\nSTY: Rm local variable remapping of heappush and heappop (\n#8051\n).\nTST: Minor improvements to layout test suite (\n#8049\n).\nMinor refactor to cleanup/improve matching test suite (\n#8068\n).\nContributors\n56 authors added to this release (alphabetically):\n@Bigstool\n@Celelibi\n@Frankwii\n@lmeNaN\n@nelsonaloysio\n@Schwarf\n@vtrifonov-altos\n@vttrifonov\n@xavieronassis\nAditi Juneja (\n@Schefflera-Arboricola\n)\nakshita  (\n@akshitasure12\n)\nAlejandro Candioti (\n@amcandio\n)\nAndrew Knyazev, Professor Emeritus (\n@lobpcg\n)\nAnthony Labarre (\n@alabarre\n)\nAnthony Mahanna (\n@aMahanna\n)\nChristian Clauss (\n@cclauss\n)\nColman Bouton (\n@LorentzFactor\n)\nDan Schult (\n@dschult\n)\ndgpb (\n@dg-pb\n)\nElfarouk Harb (\n@FaroukY\n)\nErik Welch (\n@eriknw\n)\nFei Pan (\n@fei0319\n)\nFernando P茅rez (\n@fperez\n)\nGilles Peiffer (\n@Peiffap\n)\ngmichaeli (\n@GalMichaeli\n)\nHesam Sheikh (\n@hesamsheikh\n)\nHiroki Hamaguchi (\n@HirokiHamaguchi\n)\nJarrod Millman (\n@jarrodmillman\n)\nJason Mitchell (\n@oestej\n)\nJuanita Gomez (\n@juanis2112\n)\nKeith Hughitt (\n@khughitt\n)\nMatt Schwennesen (\n@mjschwenne\n)\nMatt Thorne (\n@MattThorne\n)\nMaverick18 (\n@Aditya-Shandilya1182\n)\nMichael Weinold (\n@michaelweinold\n)\nMorteza24 (\n@Morteza-24\n)\nMridul Seth (\n@MridulS\n)\nNikolaos Chatzikonstantinou (\n@createyourpersonalaccount\n)\nPeter C Kroon (\n@pckroon\n)\nPo-Lin Cho (\n@berlincho\n)\nQian Zhang (\n@QianZhang19\n)\nRaj Pawar (\n@Raj3110\n)\nRalph Liu (\n@nv-rliu\n)\nRatan Kulshreshtha (\n@RatanShreshtha\n)\nRicardo Bittencourt (\n@ricbit\n)\nRick Ratzel (\n@rlratzel\n)\nRoss Barnowski (\n@rossbar\n)\nShiyun(Arthur) Hu (\n@Shiyun-Hu\n)\nShunyang Li (\n@ShunyangLi\n)\nThomas Louf (\n@TLouf\n)\nTh茅o Cavignac (\n@Lattay\n)\nTL Vromen (\n@ThijsVromen\n)\nWoojin Jung (\n@WoojinJung-04\n)\nXiao Yuan (\n@yuanx749\n)\nZhige Xin (\n@xinzhige\n)\n澶х藉 (\n@dawangbaixiaofu\n)\n32 reviewers added to this release (alphabetically):\n@Celelibi\n@Schwarf\n@vttrifonov\nAditi Juneja (\n@Schefflera-Arboricola\n)\nAlejandro Candioti (\n@amcandio\n)\nAnthony Mahanna (\n@aMahanna\n)\nChuck Hastings (\n@ChuckHastings\n)\nColman Bouton (\n@LorentzFactor\n)\nDan Schult (\n@dschult\n)\nElfarouk Harb (\n@FaroukY\n)\nErik Welch (\n@eriknw\n)\nFei Pan (\n@fei0319\n)\nGilles Peiffer (\n@Peiffap\n)\ngmichaeli (\n@GalMichaeli\n)\nHiroki Hamaguchi (\n@HirokiHamaguchi\n)\nJarrod Millman (\n@jarrodmillman\n)\nKeith Hughitt (\n@khughitt\n)\nMatt Schwennesen (\n@mjschwenne\n)\nMatt Thorne (\n@MattThorne\n)\nMichael Martini (\n@MichaelMartini-Celonis\n)\nMridul Seth (\n@MridulS\n)\nQian Zhang (\n@QianZhang19\n)\nRaj Pawar (\n@Raj3110\n)\nRicardo Bittencourt (\n@ricbit\n)\nRick Ratzel (\n@rlratzel\n)\nRoss Barnowski (\n@rossbar\n)\nRuida Zeng (\n@ruidazeng\n)\nShiyun(Arthur) Hu (\n@Shiyun-Hu\n)\nThomas Louf (\n@TLouf\n)\nTL Vromen (\n@ThijsVromen\n)\nWoojin Jung (\n@WoojinJung-04\n)\nXiao Yuan (\n@yuanx749\n)\nThese lists are automatically generated, and may not be complete or may contain duplicates.",
    "crawl_status": "success"
  },
  {
    "library_name": "NetworkX",
    "url": "https://github.com/networkx/networkx/releases/tag/networkx-3.1rc0",
    "version": "networkx-3.1rc0",
    "title": "Release networkx-3.1rc0 路 networkx/networkx 路 GitHub",
    "release_date": "2023-03-30T21:39:25Z",
    "content": "What's Changed\nFix link in isomorphvf2.py by\n@paulitapb\nin\n#6347\nUpdate precommit hooks by\n@jarrodmillman\nin\n#6348\nAdd clique examples and deprecate helper funtions by\n@rossbar\nin\n#6186\nLaplace centrality for issue 4973 by\n@gaborberei\nin\n#5399\ndoc:improve doc of possible values of nodes and expected behaviour by\n@tinaoberoi\nin\n#6333\nadd OrderedGraph removal as an API change in release_3.0.rst by\n@dschult\nin\n#6354\nUpdate release_3.0 authors (add Jim and Erik) by\n@eriknw\nin\n#6356\nFix broken link nx guide by\n@paulitapb\nin\n#6361\nAdd nx-guide link in the tutorial by\n@paulitapb\nin\n#6353\nDOC: Minor formatting fixups to get rid of doc build warnings. by\n@rossbar\nin\n#6363\nFix ecuation in clustering documentation by\n@paulitapb\nin\n#6369\nAdd reference to paper in vf2pp by\n@paulitapb\nin\n#6373\nprovide tikz with degrees, not radians by\n@dimpase\nin\n#6360\nImprove handling of create_using to allow Mixins of type Protocol by\n@dschult\nin\n#6244\nRemove an instance of random.sample from a set (deprecated in Python 3.9) by\n@eriknw\nin\n#6380\nDOC: Add banner for user survey annoucement by\n@MridulS\nin\n#6375\nbump pre-commit hooks (and fix CI) by\n@danieleades\nin\n#6396\nAdd generate / write \"network text\" (formerly graph_str) by\n@Erotemic\nin\n#5602\nImprove doc regular graphs by\n@paulitapb\nin\n#6397\nFix link vonoroi by\n@paulitapb\nin\n#6398\nDocument PageRank algo convergence condition  by\n@Qudirah\nin\n#6212\nFix pre-commit on Python 3.10 by\n@rossbar\nin\n#6407\nDOC: list pred method for MultiDiGraphs by\n@MridulS\nin\n#6409\nDelete warning in approximation documentation by\n@paulitapb\nin\n#6221\nComment out unused unlayered dict construction. by\n@rossbar\nin\n#6411\nUpdate installation test instructions by\n@EricPostMaster\nin\n#6303\nAdded new tests in test_clique.py by\n@paulitapb\nin\n#6142\nAdded test in project. Coverage up to 100. by\n@Mjh9122\nin\n#6196\nAdd dispatching to more shortest path algorithms by\n@eriknw\nin\n#6415\nAdd Plausible Analytics to our docs by\n@MridulS\nin\n#6413\nFix docstring heading title. by\n@rossbar\nin\n#6424\nAdded tests to test_directed.py. by\n@Mjh9122\nin\n#6208\nGallery example for Maximum Independent Set by\n@stanyas\nin\n#5563\nspectral bisection for graphs using fiedler vector by\n@MridulS\nin\n#6404\nUpdate developer requirements by\n@jarrodmillman\nin\n#6429\nFix reference in line.py-inverse_line_graph by\n@Blueclaus13\nin\n#6434\nAdd project desc for visualization and ISMAGs by\n@dschult\nin\n#6432\nLint using Ruff by\n@danieleades\nin\n#6371\nadd ruff commit to git-blame-ignore by\n@MridulS\nin\n#6440\nNXEP 0 and NXEP 1 - change status to Accepted by\n@MridulS\nin\n#5343\nBump gh-pages deploy bot version. by\n@rossbar\nin\n#6446\nStart using ruff for pyupgrade and isort by\n@MridulS\nin\n#6441\nAdd documentation building to contributor guide by\n@rossbar\nin\n#6437\nReset deploy-action param names for latest version. by\n@rossbar\nin\n#6451\nDoc upgrade paley graph by\n@paulitapb\nin\n#6399\nAdded two tests for convert_numpy by\n@Mjh9122\nin\n#6455\nClean up similarity.py and use dataclasses for storing state by\n@MridulS\nin\n#5831\nRemove pdf latex builds of docs by\n@MridulS\nin\n#5572\nAdd docstring for dorogovtsev_goltsev_mendes generator by\n@rossbar\nin\n#6450\ntweak _dispatch to allow G keyword. Add test. by\n@dschult\nin\n#6471\nFix negative edge cycle function raising exception for empty graph and added test function by\n@PurviChaurasia\nin\n#6473\nDispatch more BFS-based algorithms by\n@eriknw\nin\n#6467\nIgnore weakrefs when testing for memory leak by\n@eriknw\nin\n#6466\nFix reference formatting in generator docstring. by\n@rossbar\nin\n#6493\ntweak\ntest_override_dispatch\nto allow G keyword by\n@eriknw\nin\n#6499\nImprove test coverage for astar.py by\n@navyagarwal\nin\n#6504\nAdd docstring example to weighted.py by\n@navyagarwal\nin\n#6497\nFix len operation of UnionAtlas by\n@dschult\nin\n#6478\nImprove test coverage for edgelist.py by\n@navyagarwal\nin\n#6507\nImprove test coverage for mst.py and bug fix in prim_mst_edges() by\n@navyagarwal\nin\n#6486\nAdd examples clarifying ambiguity of nbunch by\n@navyagarwal\nin\n#6513\nUpdating removing explicit import for communities by\n@Lukong123\nin\n#6459\nUse generator to limit memory footprint of read_graph6. by\n@rossbar\nin\n#6519\nUpdate docstring of paley graph  by\n@paulitapb\nin\n#6529\nFixed bug k_truss doesn't raise exception for self loops by\n@PurviChaurasia\nin\n#6521\nUpdate pre-commit by\n@jarrodmillman\nin\n#6545\nUpdate sphinx by\n@jarrodmillman\nin\n#6544\nAdd docstring examples to dag.py by\n@navyagarwal\nin\n#6491\nAdd example script for mst by\n@PurviChaurasia\nin\n#6525\nAdd docstring examples to boundary.py by\n@navyagarwal\nin\n#6487\nimprove test coverage for branchings.py by\n@Qudirah\nin\n#6523\nImprove test coverage for redundancy.py by\n@navyagarwal\nin\n#6551\nFixed return type inconsistencies in shortest path methods documentation by\n@navyagarwal\nin\n#6528\nOptimize _single_shortest_path_length function by\n@Tortar\nin\n#6299\nDeprecate shortest_path functions to have consistent return values in v3.3 by\n@dschult\nin\n#6567\nAdd community detection example to Gallery by\n@navyagarwal\nin\n#6526\nadd simple cycle enumerator for undirected class by\n@boothby\nin\n#6461\nFix survey URL by @Infiniticity in\n#6548\nTest dispatching via nx-loopback backend by\n@jim22k\nin\n#6536\nFixed return type inconsistencies in weighted.py by\n@navyagarwal\nin\n#6568\nUpdate team galleries by\n@jarrodmillman\nin\n#6569\nAdded Docstring Example for Bidirectional Shortest Path by\n@vanshika230\nin\n#6570\nUpdate release requirements by\n@jarrodmillman\nin\n#6587\nNew Contributors\n@gaborberei\nmade their first contribution in\n#5399\n@stanyas\nmade their first contribution in\n#5563\n@Blueclaus13\nmade their first contribution in\n#6434\n@PurviChaurasia\nmade their first contribution in\n#6473\n@navyagarwal\nmade their first contribution in\n#6504\n@Tortar\nmade their first contribution in\n#6299\n@jim22k\nmade their first contribution in\n#6536\n@vanshika230\nmade their first contribution in\n#6570\nFull Changelog\n:\nnetworkx-3.0...networkx-3.1rc0",
    "crawl_status": "success"
  },
  {
    "library_name": "NetworkX",
    "url": "https://github.com/networkx/networkx/releases/tag/networkx-3.3",
    "version": "networkx-3.3",
    "title": "Release NetworkX 3.3 路 networkx/networkx 路 GitHub",
    "release_date": "2024-04-06T13:09:07Z",
    "content": "networkx 3.3\nWe're happy to announce the release of networkx 3.3!\nAPI Changes\nDisallow negative number of nodes in\ncomplete_multipartite_graph\n(\n#7057\n).\nDEP: Deprecate the all_triplets one-liner (\n#7060\n).\n[A-star] Added expansion pruning via cutoff if cutoff is provided (\n#7073\n).\nMake HITS raise exceptions consistent with power iterations (\n#7084\n).\nDEP: Deprecate random_triad (\n#7061\n).\nAdded feature modular graph product (\n#7227\n).\nENH: Speed up common/non_neighbors by using _adj dict operations (\n#7244\n).\nDeprecate the\ncreate\nargument of\nnonisomorphic_trees\n(\n#7316\n).\nImprove total_spanning_tree_weight (\n#7100\n).\nUpdate\ninit\n.py (\n#7320\n).\nadd **kwargs to traveling_salesman_problem (\n#7371\n).\nEnhancements\nAdd Tadpole graph (\n#6999\n).\n[A-star] Added expansion pruning via cutoff if cutoff is provided (\n#7073\n).\nImplementation of\n$S^1$\nmodel (\n#6858\n).\n[Feat] Random expanders utilities (\n#6761\n).\nCompare graphs for generator functions when running tests with backend (\n#7066\n).\nAdd Kirchhoff index / Effective graph resistance (\n#6926\n).\nChanged return types of shortest path methods to improve consistency (\n#6584\n).\nNew PR for Fixes minimal d-separator function failing to handle cases where no d-separators exist (\n#7019\n).\nENH : Provide non-normalized and normalized directed laplacian matrix calculation (\n#7199\n).\nfeat: drop the use of node attribute \"first_nbr\" in PlanarEmbedding (\n#7202\n).\nAdd functions to compute Schultz and Gutman Index (\n#3709\n).\nDivisive community algorithms (\n#5830\n).\nAdded feature modular graph product (\n#7227\n).\nENH : added\nsort_neighbors\nto all functions in\ndepth_first_search.py\n(\n#7196\n).\nNew graph generator for the Kneser graph (\n#7146\n).\nDraw MultiDiGraph edges and labels qa7008 (\n#7010\n).\nUse github actions to run a comparison benchmark (\n#7268\n).\nBFS layout implementation (\n#5179\n).\nAdd\nmax_level=\nargument to\nlouvain_communities\nto limit macro-iterations (\n#6909\n).\nReview and update\n@nx._dispatchable\nusage since 3.2.1 (\n#7302\n).\nTransmogrify\n_dispatchable\nobjects into functions (\n#7298\n).\nfix: make\nPlanarEmbedding.copy()\nuse\nadd_edges_from()\nfrom parent (closes\n#7223\n) (\n#7224\n).\nAllow seed of np.random instance to exactly produce arbitrarily large integers (\n#6869\n).\nImprove total_spanning_tree_weight (\n#7100\n).\nadd seed to\nnx.generate_random_paths\n(\n#7332\n).\nAllow backends to implement\nshould_run\n(\n#7257\n).\nAdding tree broadcasting algorithm in a new module (\n#6928\n).\nOption to include initial labels in\nweisfeiler_lehman_subgraph_hashes\n(\n#6601\n).\nAdd better error message when trying to get edge that is not present (\n#7245\n).\nMake\nis_negatively_weighted\ndispatchable (\n#7352\n).\nAdd option to hide or show tick labels (\n#6018\n).\nENH: Cache graphs objects when converting to a backend (\n#7345\n).\nBug Fixes\nFix listing of release notes on Releases page (\n#7030\n).\nFix syntax warning from bad escape sequence (\n#7034\n).\nFix triangles to avoid using\nis\nto compare nodes (\n#7041\n).\nFix error message for\nnx.mycielski_graph(0)\n(\n#7056\n).\nDisallow negative number of nodes in\ncomplete_multipartite_graph\n(\n#7057\n).\nHandle edge cases for greedy_modularity_communities (\n#6973\n).\nFIX: Match the doc description while copying over data (\n#7092\n).\nfix: Include singleton/trivial paths in all_simple_paths & other functions (\n#6694\n).\nDinitz correction (\n#6968\n).\nModify GML test to fix invalid octal character warning (\n#7159\n).\nFix random_spanning_tree() for single node and empty graphs (\n#7211\n).\nPlanarEmbedding.remove_edge() now updates removed edge's neighbors (\n#6798\n).\nadd seed to graph creation (\n#7241\n).\nadd seed to tests of fast_label_propatation_communities (\n#7242\n).\nFix rich_club_coefficient() for single node and empty graphs (\n#7212\n).\nFix minimum_spanning_arborescence regression (\n#7280\n).\nMove arrowstyle input munging after intput validation (\n#7293\n).\nFix empty GraphML attribute is not parsed (\n#7319\n).\nAdd new test result to\ntest_asadpour_tsp\nand change\nlinprog\nmethod (\n#7335\n).\nFix custom weight attribute for Mehlhorn (\n#6681\n).\nDocumentation\nUpdate release process (\n#7029\n).\nUpdate convert_matrix.py (\n#7018\n).\nfix extendability function name in bipartite.rst (\n#7042\n).\nMinor doc cleanups to remove doc build warnings (\n#7048\n).\nDOC: Add example to generic_bfs_edges to demonstrate the\nneighbors\nparam (\n#7072\n).\nHierarchical clustering layout gallery example (\n#7058\n).\nFixed an error in the documentation of the katz centrality (\n#6294\n).\nCreate 3d_rotation_anime.py (\n#7025\n).\nDOC: Add docstrings to filter view functions (\n#7086\n).\nDOC: Add docstrings to Filter mapping views (\n#7075\n).\nDOCS: Fix internal links to other functions in isomorphvf2 (\n#6706\n).\nadded note for the triangle inequality case in TSP (\n#6995\n).\nAdd note about importance of testing to contributor guide (\n#7103\n).\nProposal to add centrality overview to mentored projects (\n#7104\n).\nImprove documentation of Component Algorithms (\n#5473\n).\nAdd dot io to readwrite (\n#5061\n).\nAdd Python versions to release notes (\n#7113\n).\nDOC: Turn on inline plots in graph generators docstrings (\n#6401\n).\nFix duplicate numbering in contributor guide (\n#7116\n).\nDOC: remove unnecessary 'or' in planted_partition_graph (\n#7115\n).\nDOC: Link methods in functions to base Graph methods/properties (\n#7125\n).\nConnect docs to doc_string for total_spanning_tree_weight (\n#7098\n).\nImage (3D RGB data) segmentation by spectral clustering with 3D illustrations (\n#7040\n).\nupdate triadic_census documentation for undirected graphs - issue 4386 (\n#7141\n).\nadded 3d and animation to plot_greedy_coloring.py (\n#7090\n).\nDOC: fix URL econded links and doc references (\n#7152\n).\nDOC: add reference to fast_label_propagation_communities (\n#7167\n).\nupdated See also sec of argmap class (\n#7163\n).\nDOC : updated examples in mincost.py (\n#7169\n).\nDocument the walk_type argument default in directed_laplacian and similar functions (\n#7171\n).\nDOC: Add plots to classic graph generators docs (\n#7114\n).\nFix a tiny typo in\nstructuralholes.py::local_constraint\ndocstring (\n#7198\n).\nAdded\nsubgraph_is_monomorphic\nand\nsubgraph_monomorphisms_iter\nin docs (\n#7197\n).\nFix online docs for\n_dispatch\n(\n#7194\n).\nDOC : Updated docs for panther_similarity (\n#7175\n).\nFix warnings when building docs (\n#7195\n).\nImprove docs for optimal_edit_paths (\n#7130\n).\nDOC: build with nx-parallel extra documentation information (\n#7220\n).\nFixed typo in tensor product documentation (Fixes\n#7228\n) (\n#7229\n).\nAdd example for cycle detection (\n#6560\n).\nUpdate general_k_edge_subgraphs docstring (\n#7254\n).\nUpdate docstring of nonisomorphic_trees (\n#7255\n).\nadding self loops related docs and tests for functions in\ncluster.py\n(\n#7261\n).\nAdd minimum_cycle_basis to cycle_basis See Also (\n#7274\n).\nUpdate CONTRIBUTING.rst (\n#7270\n).\nFix all sphinx warnings during doc build (\n#7289\n).\nDoc infrastructure: replace\nnb2plot\nwith\nmyst-nb\n(\n#7237\n).\nAdd explicit targets of missing modules for intersphinx (\n#7313\n).\nDOC: add doc suggestions for arbitrarily large random integers tools (\n#7322\n).\nTry/except intermittently failing basemaps in geospatial examples (\n#7324\n).\nUpdate docstring example with future-proof pandas assignment (\n#7323\n).\nRemove animation from spectral clustering example to improve performance (\n#7328\n).\nDoc Improvements for Approximations Files (\n#7338\n).\nUpdate\nLCF_graph\ndocstring (\n#7262\n).\nOption to include initial labels in\nweisfeiler_lehman_subgraph_hashes\n(\n#6601\n).\nAdd eriknw as contributor (\n#7343\n).\n[DOC, DISPATCH] : updated and added\nbackend.py\n's docs (\n#7305\n).\nadd **kwargs to traveling_salesman_problem (\n#7371\n).\nMove the backend docs and connect the config docs. Both in a single sidebar entry (\n#7389\n).\nMaintenance\nDrop Python 3.9 support (\n#7028\n).\nfix: Explicitly check for None/False in edge_attr during import from np (\n#6825\n).\nAdd favicon (\n#7043\n).\nRemove unused code resistance_distance (\n#7053\n).\nFix names of small graphs (\n#7055\n).\nImprove error messages for misconfigured backend treatment (\n#7062\n).\nMAINT: Fixup union exception message (\n#7071\n).\nMAINT: Minor touchups to tadpole and lollipop graph (\n#7049\n).\nAdd\n@not_implemented_for(\"directed\")\nto\nnumber_connected_components\n(\n#7074\n).\nremove unused code (\n#7076\n).\nMinor touchups to the beamsearch module (\n#7059\n).\nFix annoying split strings on same line (\n#7079\n).\nUpdate dispatch decorator for\nhits\nto use\n\"weight\"\nedge weight (\n#7081\n).\nRemove nbconvert upper pin (revert\n#6984\n) (\n#7083\n).\nAdd a step to CI to check for warnings at import time (\n#7077\n).\nAdded few tests for /generators/duplication.py and /generators/geomet (\n#6976\n).\nTest on Python 3.13-dev (\n#7096\n).\nChanged arguments list of GraphMLWriterLxml.dump() (\n#6261\n).\nwrite_graphml\n: Small fix for object type description on\nTypeError\nexception (\n#7109\n).\nupdated functions in\ncore.py\n(\n#7027\n).\nlabel check on push and change check name (\n#7111\n).\nDEP : adding\nnot_implemented_for(\"multigraph)\nto\nk_core\n,\nk_shell\n,\nk_crust\nand\nk_corona\n(\n#7121\n).\nAdd label check when pull request is edited instead of push (\n#7134\n).\nAdd label workflow pull_request type synchronize and echo message (\n#7135\n).\nadding test coverage for isomorphism when using digraphs (\n#6417\n).\nRemove usage of\n__networkx_plugin__\n(use\n__networkx_backend__\ninstead) (\n#7157\n).\nDOC: consistent spelling of neighbor and rename vars (\n#7162\n).\nMAINT: use ruff format instead of black (\n#7160\n).\nEnsure warnings related to changes in shortest_path returns are visible to users (\n#7161\n).\nSync up behavior of is_{type} for empty graphs (\n#5849\n).\nAdded\nNodeNotFound\nexceptions to\n_apply_prediction\nand\nsimrank\n, and ignored isolated nodes in\npanther_similarity\n(\n#7110\n).\nFix not_implemented_for decorator for is_regular and related functions (\n#7182\n).\nFix all_node_cuts output for complete graphs (\n#6558\n).\nRemove\n\"networkx.plugins\"\nand\n\"networkx.plugin_info\"\nentry-points (\n#7192\n).\nBump actions/setup-python from 4 to 5 (\n#7201\n).\nUpdate test suite for Pytest v8 (\n#7203\n).\nUndeprecate\nnx_pydot\nnow that pydot is actively maintained again (\n#7204\n).\nFuture-proofing and improve tests (\n#7209\n).\nDrop old dependencies per SPEC 0 (\n#7217\n).\nUpdate pygraphviz (\n#7216\n).\nRefactor geometric_soft_configuration_model tests for performance (\n#7210\n).\nRename\n_dispatch\nto\n_dispatchable\n(\n#7193\n).\nReplace tempfile with tmp_path fixture in test suite (\n#7221\n).\nupdated test_directed_edge_swap\n#5814\n(\n#6426\n).\nBump copyright year for 2024 (\n#7232\n).\nImproving test coverage for Small.py (\n#7260\n).\nTest for symmetric edge flow betweenness partition (\n#7251\n).\nMAINT : added\nseed\nto\ngnm_random_graph\nin\ncommunity/tests/test_label_propagation.py\n(\n#7264\n).\nBump scientific-python/upload-nightly-action from 0.2.0 to 0.3.0 (\n#7266\n).\nadding self loops related docs and tests for functions in\ncluster.py\n(\n#7261\n).\nImproving test coverage for Mycielsky.py (\n#7271\n).\nUse ruff's docstring formatting (\n#7276\n).\nAdd docstring formatting change to blame-ignore-revs (\n#7281\n).\nImprove test coverage for random_clustered and update function names (\n#7273\n).\nDoc infrastructure: replace\nnb2plot\nwith\nmyst-nb\n(\n#7237\n).\nTemporarily rm geospatial examples to fix CI (\n#7299\n).\nImprove test coverage for bipartite extendability (\n#7306\n).\nCI: Update scientific-python/upload-nightly-action from 0.3.0 to 0.4.0 (\n#7309\n).\nCI: Group dependabot updates (\n#7308\n).\nCI: update upload-nightly-action to 0.5.0 (\n#7311\n).\nrenaming backend\nfunc_info\ndictionary's keys (\n#7219\n).\nAdd\nmutates_input=\nand\nreturns_graph=\nto\n_dispatchable\n(\n#7191\n).\nAvoid creating results with numpy scalars (re: NEP 51) (\n#7282\n).\nBump changelist from 0.4 to 0.5 (\n#7325\n).\nImprove test coverage for bipartite matrix.py (\n#7312\n).\nUn-dispatch coloring strategies (\n#7329\n).\nUndo change in return type of\nsingle_target_shortest_path_length\n(\n#7327\n).\nRemove animation from spectral clustering example to improve performance (\n#7328\n).\nExpire steinertree mehlhorn futurewarning (\n#7337\n).\nUpdate louvain test modularity comparison to leq (\n#7336\n).\nAdd aaronzo as contributor (\n#7342\n).\nFix\n#7339\n.\nshortest_path\ninconsisitent with warning (\n#7341\n).\nAdd\nnx.config\ndict for configuring dispatching and backends (\n#7225\n).\nImprove test coverage for Steiner Tree & Docs (\n#7348\n).\nadded\nseed\nto\ntest_richclub_normalized\n(\n#7355\n).\nAdd tests to link_prediction.py (\n#7357\n).\nFix pydot tests when testing backends (\n#7356\n).\nFuture proof xml parsing in graphml (\n#7360\n).\nmake doc_string examples order-independent by removing np.set_printoptions (\n#7361\n).\nClose figures on test cleanup (\n#7373\n).\nMore numpy scalars cleanup for numpy 2.0 (\n#7374\n).\nUpdate numpydoc (\n#7364\n).\nFix pygraphviz tests causing segmentation faults in backend test (\n#7380\n).\nAdd dispatching to broadcasting.py (\n#7386\n).\nUpdate test suite to handle when scipy is not installed (\n#7388\n).\nRm deprecated np.row_stack in favor of vstack (\n#7390\n).\nFix exception for\ndel config[key]\n(\n#7391\n).\nBump the GH actions with 3 updates (\n#7310\n).\nContributors\n54 authors added to this release (alphabetically):\n@BucketHeadP65\n@dependabot[bot]\n@nelsonaloysio\n@YVWX\nAaron Z. (\n@aaronzo\n)\nAditi Juneja (\n@Schefflera-Arboricola\n)\nAKSHAYA MADHURI (\n@akshayamadhuri\n)\nAlex Markham (\n@Alex-Markham\n)\nAnders Rydbirk (\n@anders-rydbirk\n)\nAndrew Knyazev (\n@lobpcg\n)\nAyooluwa (\n@Ay-slim\n)\nBaldo (\n@BrunoBaldissera\n)\nBenjamin Edwards (\n@bjedwards\n)\nChiranjeevi Karthik Kuruganti (\n@karthikchiru12\n)\nChris Pryer (\n@cnpryer\n)\nd.grigonis (\n@dgrigonis\n)\nDan Schult (\n@dschult\n)\nDaniel V. Egdal (\n@DanielEgdal\n)\nDilara Tekinoglu (\n@dtekinoglu\n)\nDishie Vinchhi (\n@Dishie2498\n)\nErik Welch (\n@eriknw\n)\nFr茅d茅ric Crozatier (\n@fcrozatier\n)\nHenrik Finsberg (\n@finsberg\n)\nJangwon Yie (\n@jangwon-yie\n)\nJaron Lee (\n@jaron-lee\n)\nJarrod Millman (\n@jarrodmillman\n)\nJon Crall (\n@Erotemic\n)\nJonas Otto (\n@ottojo\n)\nJordan Matelsky (\n@j6k4m8\n)\nKoen van den Berk (\n@kalkoen\n)\nLuigi Sciarretta (\n@LuigiSciar\n)\nLuigi Sciarretta (\n@LuigiSciarretta\n)\nMatt Schwennesen (\n@mjschwenne\n)\nMatthew Feickert (\n@matthewfeickert\n)\nMatthieu Gouel (\n@matthieugouel\n)\nMauricio Souza de Alencar (\n@mdealencar\n)\nMaximilian Seeliger (\n@max-seeli\n)\nMridul Seth (\n@MridulS\n)\nNavya Agarwal (\n@navyagarwal\n)\nNeil Botelho (\n@NeilBotelho\n)\nNihal John George (\n@nihalgeorge01\n)\nPaolo Lammens (\n@plammens\n)\nPatrick Nicodemus (\n@patrick-nicodemus\n)\nPaula P茅rez Bianchi (\n@paulitapb\n)\nPurvi Chaurasia (\n@PurviChaurasia\n)\nRobert (\n@ImHereForTheCookies\n)\nRobert Jankowski (\n@robertjankowski\n)\nRoss Barnowski (\n@rossbar\n)\nSadra Barikbin (\n@sadra-barikbin\n)\nSalim BELHADDAD (\n@salym\n)\nTill Hoffmann (\n@tillahoffmann\n)\nVanshika Mishra (\n@vanshika230\n)\nWilliam Black (\n@smokestacklightnin\n)\nWilliam Zijie Zhang (\n@Transurgeon\n)\n29 reviewers added to this release (alphabetically):\n@YVWX\nAaron Z. (\n@aaronzo\n)\nAditi Juneja (\n@Schefflera-Arboricola\n)\nAKSHAYA MADHURI (\n@akshayamadhuri\n)\nAndrew Knyazev (\n@lobpcg\n)\nAyooluwa (\n@Ay-slim\n)\nChiranjeevi Karthik Kuruganti (\n@karthikchiru12\n)\nChris Pryer (\n@cnpryer\n)\nd.grigonis (\n@dgrigonis\n)\nDan Schult (\n@dschult\n)\nErik Welch (\n@eriknw\n)\nFr茅d茅ric Crozatier (\n@fcrozatier\n)\nHenrik Finsberg (\n@finsberg\n)\nJarrod Millman (\n@jarrodmillman\n)\nKyle Sunden (\n@ksunden\n)\nMatt Schwennesen (\n@mjschwenne\n)\nMauricio Souza de Alencar (\n@mdealencar\n)\nMaximilian Seeliger (\n@max-seeli\n)\nMridul Seth (\n@MridulS\n)\nNihal John George (\n@nihalgeorge01\n)\nPaolo Lammens (\n@plammens\n)\nPaula P茅rez Bianchi (\n@paulitapb\n)\nRick Ratzel (\n@rlratzel\n)\nRobert Jankowski (\n@robertjankowski\n)\nRoss Barnowski (\n@rossbar\n)\nStefan van der Walt (\n@stefanv\n)\nVanshika Mishra (\n@vanshika230\n)\nWilliam Black (\n@smokestacklightnin\n)\nWilliam Zijie Zhang (\n@Transurgeon\n)\nThese lists are automatically generated, and may not be complete or may contain duplicates.",
    "crawl_status": "success"
  },
  {
    "library_name": "Pre-commit",
    "url": "https://github.com/pre-commit/pre-commit/releases/tag/v4.0.0",
    "version": "v4.0.0",
    "title": "Release pre-commit v4.0.0 路 pre-commit/pre-commit 路 GitHub",
    "release_date": "2024-10-05T19:19:45Z",
    "content": "Features\nImprove\npre-commit migrate-config\nto handle more yaml formats.\n#3301\nPR by\n@asottile\n.\nHandle\nstages\ndeprecation in\npre-commit migrate-config\n.\n#3302\nPR by\n@asottile\n.\n#2732\nissue by\n@asottile\n.\nUpgrade\nruby-build\n.\n#3199\nPR by\n@ThisGuyCodes\n.\nAdd \"sensible regex\" warnings to\nrepo: meta\n.\n#3311\nPR by\n@asottile\n.\nAdd warnings for deprecated\nstages\n(\ncommit\n->\npre-commit\n,\npush\n->\npre-push\n,\nmerge-commit\n->\npre-merge-commit\n).\n#3312\nPR by\n@asottile\n.\n#3313\nPR by\n@asottile\n.\n#3315\nPR by\n@asottile\n.\n#2732\nissue by\n@asottile\n.\nMigrating\nlanguage: python_venv\nhas been removed -- use\nlanguage: python\ninstead.\n#3320\nPR by\n@asottile\n.\n#2734\nissue by\n@asottile\n.",
    "crawl_status": "success"
  },
  {
    "library_name": "Pre-commit",
    "url": "https://github.com/pre-commit/pre-commit/releases/tag/v3.1.0",
    "version": "v3.1.0",
    "title": "Release pre-commit v3.1.0 路 pre-commit/pre-commit 路 GitHub",
    "release_date": "2023-02-23T01:56:32Z",
    "content": "Fixes\nFix\ndotnet\nfor\n.sln\n-based hooks for dotnet>=7.0.200.\n#2763\nPR by\n@m-rsha\n.\nPrevent stashing when\ndiff\nfails to execute.\n#2774\nPR by\n@asottile\n.\n#2773\nissue by\n@strubbly\n.\nDependencies are no longer sorted in repository key.\n#2776\nPR by\n@asottile\n.\nUpdating\nDeprecate\nlanguage: python_venv\n.  Use\nlanguage: python\ninstead.\n#2746\nPR by\n@asottile\n.\n#2734\nissue by\n@asottile\n.",
    "crawl_status": "success"
  },
  {
    "library_name": "Pre-commit",
    "url": "https://github.com/pre-commit/pre-commit/releases/tag/v4.4.0",
    "version": "v4.4.0",
    "title": "Release pre-commit v4.4.0 路 pre-commit/pre-commit 路 GitHub",
    "release_date": "2025-11-08T21:48:28Z",
    "content": "Features\nAdd\n--fail-fast\noption to\npre-commit run\n.\n#3528\nPR by\n@JulianMaurin\n.\nUpgrade\nruby-build\n/\nrbenv\n.\n#3566\nPR by\n@asottile\n.\n#3565\nissue by\n@MRigal\n.\nAdd\nlanguage: unsupported\n/\nlanguage: unsupported_script\nas aliases for\nlanguage: system\n/\nlanguage: script\n(which will eventually be deprecated).\n#3577\nPR by\n@asottile\n.\nAdd support docker-in-docker detection for cgroups v2.\n#3535\nPR by\n@br-rhrbacek\n.\n#3360\nissue by\n@JasonAlt\n.\nFixes\nHandle when docker gives\nSecurityOptions: null\n.\n#3537\nPR by\n@asottile\n.\n#3514\nissue by\n@jenstroeger\n.\nFix error context for invalid\nstages\nin\n.pre-commit-config.yaml\n.\n#3576\nPR by\n@asottile\n.",
    "crawl_status": "success"
  },
  {
    "library_name": "Xlwings",
    "url": "https://docs.xlwings.org/en/latest/whatsnew.html#v0-32-0-aug-13-2024",
    "version": "v0.32.0",
    "title": "Changelog - xlwings Documentation",
    "release_date": "Unknown release date",
    "content": "v0.32.0 (Aug 13, 2024)\n露\nThis release introduces support for type hints in UDFs/custom functions. Type hints can be used alone or alongside decorators to specify data conversion between Excel and Python:\nfrom\nxlwings\nimport\nfunc\n# or: from xlwings.server import func\nimport\npandas\nas\npd\n@func\ndef\nmyfunction\n(\ndf\n:\npd\n.\nDataFrame\n)\n->\npd\n.\nDataFrame\n:\n# df is a DataFrame, do something with it\nreturn\ndf\nIn this example, the return type (\n->\npd.DataFrame\n) is optional, as xlwings automatically checks the type of the returned object.\nIf you need to provide additional conversion arguments, you can either provide them via an annotated type hint or via a decorator. Note that when you use type hints and decorators together, decorators override type hints for conversion.\nTo set\nindex=False\nfor both the argument and the return value, you can annotate the type hint like this:\nfrom\ntyping\nimport\nAnnotated\nfrom\nxlwings\nimport\nfunc\n# or: from xlwings.server import func\nimport\npandas\nas\npd\n@func\ndef\nmyfunction\n(\ndf\n:\nAnnotated\n[\npd\n.\nDataFrame\n,\n{\n\"index\"\n:\nFalse\n}]\n)\n->\nAnnotated\n[\npd\n.\nDataFrame\n,\n{\n\"index\"\n:\nFalse\n}]:\n# df is a DataFrame, do something with it\nreturn\ndf\nAs this might be a little harder to read, you can extract the type definition, which also allows you to reuse it like so:\nfrom\ntyping\nimport\nAnnotated\nfrom\nxlwings\nimport\nfunc\n# or: from xlwings.server import func\nimport\npandas\nas\npd\nDf\n=\nAnnotated\n[\npd\n.\nDataFrame\n,\n{\n\"index\"\n:\nFalse\n}]\n@func\ndef\nmyfunction\n(\ndf\n:\nDf\n)\n->\nDf\n:\n# df is a DataFrame, do something with it\nreturn\ndf\nAlternatively, you could also combine type hints with decorators:\nfrom\ntyping\nimport\nAnnotated\nfrom\nxlwings\nimport\nfunc\n,\narg\n,\nret\n# or: from xlwings.server import func, arg, ret\nimport\npandas\nas\npd\n@func\n@arg\n(\n\"df\"\n,\nindex\n=\nFalse\n)\n@ret\n(\nindex\n=\nFalse\n)\ndef\nmyfunction\n(\ndf\n:\npd\n.\nDataFrame\n)\n->\npd\n.\nDataFrame\n:\n# df is a DataFrame, do something with it\nreturn\ndf\nOther changes include:\nBreaking Change\nDropped Python 3.8 support (\nGH 2497\n).\nBug Fix\nv0.31.4 introduced a change that would set the Matplotlib backend to\nagg\nglobally. This has been reverted (\nGH 2484\n).\nEnhancement\nPRO\nxlwings Reports: when using Markdown functionality,\nmistune\nis now required as dependency (\nGH 2498\n).\nBug Fix\nPRO\nFixed a bug with streaming functions (\nGH 2491\n).",
    "crawl_status": "success"
  },
  {
    "library_name": "Xlwings",
    "url": "https://docs.xlwings.org/en/latest/whatsnew.html#v0-30-7-may-18-2023",
    "version": "v0.30.7",
    "title": "Changelog - xlwings Documentation",
    "release_date": "Unknown release date",
    "content": "v0.30.7 (May 18, 2023)\n露\nEnhancement\nPRO\nxlwings Server: added named range support for Office Scripts, Office.js, and Google Apps Script clients in addition to the VBA client (\nGH 2257\n).\nEnhancement\nPRO\nxlwings Server: the documentation has been improved to point out that the\nbook\nobject has to be closed at the end of a request in oder to prevent a memory leak. This can be done via\nmybook.close()\nor by using\nBook\nas a context manager (\nwith\nxw.Book(json=data)\nas\nbook:`\n). Note that your framework may offer better means to automatically close the book at the end of a request via middleware or similar mechanism. As an example, for FastAPI, you can use dependency injection. See\npro/server/server:Introduction\n(\nGH 2260\n).",
    "crawl_status": "success"
  },
  {
    "library_name": "Xlwings",
    "url": "https://docs.xlwings.org/en/latest/whatsnew.html#v0-33-17-dec-6-2025",
    "version": "v0.33.17",
    "title": "Changelog - xlwings Documentation",
    "release_date": "Unknown release date",
    "content": "v0.33.17 (Dec 6, 2025)\n露\nEnhancement\nAdded a new\ntuple\nconverter to turn values into tuple of tuples instead of list of lists (\nGH 2648\n).\nEnhancement\nBetter support for non-default locations of Conda envs (\nGH 2656\n).\nBreaking Change\nThe\n@sub\ndecorator is now called\n@script\nto be in line with xlwings Lite.\n@sub\nis deprecated (\nGH 2646\n).",
    "crawl_status": "success"
  },
  {
    "library_name": "Fire",
    "url": "https://github.com/google/python-fire/releases/tag/v0.5.0",
    "version": "v0.5.0",
    "title": "Release Python Fire v0.5.0 路 google/python-fire 路 GitHub",
    "release_date": "2022-12-12T20:36:55Z",
    "content": "Changelist\nSupport for custom serializers with fire.Fire(serializer=your_serializer)\n#345\nAuto-generated help text now shows short arguments (e.g. -a) when appropriate\n#318\nDocumentation improvements (\n#334\n,\n#399\n,\n#372\n,\n#383\n,\n#387\n)\nDefault values are now shown in help for kwonly arguments\n#414\nCompletion script fix where previously completions might not show at all\n#336\nHighlighted change:\nfire.Fire(serialize=custom_serialize_fn)\n#345\nYou can now pass a custom serialization function to fire to control how the output is serialized.\nYour serialize function should accept an object as input, and may return a string as output. If it returns a string, Fire will display that string. If it returns None, Fire will display nothing. If it returns something else, Fire will use the default serialization method to convert it to text.\nThe default serialization remains unchanged from previous versions. Primitives and collections of primitives are serialized one item per line. Objects that define a custom\n__str__\nfunction are serialized using that. Complex objects that don't define\n__str__\ntrigger their help screen rather than being serialized and displayed.",
    "crawl_status": "success"
  },
  {
    "library_name": "Fire",
    "url": "https://github.com/google/python-fire/releases/tag/v0.6.0",
    "version": "v0.6.0",
    "title": "Release Python Fire v0.6.0 路 google/python-fire 路 GitHub",
    "release_date": "2024-03-11T19:52:24Z",
    "content": "This is the last release supporting Python 2. Subsequent releases will be Python 3 only. The automatically generated release notes follow.\nWhat's Changed\nUse literal dict to satisfy linter by\n@dbieber\nin\n#430\nfreeze CI requirements by\n@Borda\nin\n#431\nFix path to requirements.txt by\n@hugovk\nin\n#433\nFix deprecation warning: LICENSE is autodetected by\n@hugovk\nin\n#434\nadding python 3.10 [tag & CI] by\n@Borda\nin\n#428\ndocs: fix brand name\nGithub\n->\nGitHub\nby\n@jbampton\nin\n#425\nFix typos in console and tests by\n@yarikoptic\nin\n#436\nSplit too long line, fixing lint by\n@dbieber\nin\n#437\nAdd missing argument description by\n@sp1thas\nin\n#462\nFix missing\n$\nsign in bash completion by\n@maximehk\nin\n#472\nremove asyncio.coroutine by\n@cocolato\nin\n#440\nUpdate build.yml dropping Python 2.7 by\n@dbieber\nin\n#479\nUpdate formatting_windows.py by\n@excript\nin\n#477\nAdd Python 3.11 and Python 3.12 to build workflow by\n@dbieber\nin\n#485\nNew Contributors\n@Borda\nmade their first contribution in\n#431\n@hugovk\nmade their first contribution in\n#433\n@jbampton\nmade their first contribution in\n#425\n@yarikoptic\nmade their first contribution in\n#436\n@sp1thas\nmade their first contribution in\n#462\n@maximehk\nmade their first contribution in\n#472\n@cocolato\nmade their first contribution in\n#440\n@excript\nmade their first contribution in\n#477\nFull Changelog\n:\nv0.5.0...v0.6.0",
    "crawl_status": "success"
  },
  {
    "library_name": "Fire",
    "url": "https://github.com/google/python-fire/releases/tag/v0.7.1",
    "version": "v0.7.1",
    "title": "Release Python Fire v0.7.1 路 google/python-fire 路 GitHub",
    "release_date": "2025-08-16T20:25:34Z",
    "content": "What's Changed\nUse Neutral theme for IPython Inspector, supporting newer IPython versions in\n#588\nCall inspectutils.GetClassAttrsDict on component, not None in\n#606\nMove to pyproject.toml, adding wheel support in pypi\nUse ty in place of pytype\nUpdate requirements\n@dependabot\n[bot]\nFull Changelog\n:\nv0.7.0...v0.7.1",
    "crawl_status": "success"
  },
  {
    "library_name": "Uvicorn",
    "url": "https://github.com/encode/uvicorn/releases/tag/0.35.0",
    "version": "0.35.0",
    "title": "Release Version 0.35.0 路 Kludex/uvicorn 路 GitHub",
    "release_date": "2025-06-28T16:14:55Z",
    "content": "Added\nAdd\nWebSocketsSansIOProtocol\nby\n@Kludex\nin\n#2540\nChanged\nRefine help message for option\n--proxy-headers\nby\n@zhangyoufu\nin\n#2653\nNew Contributors\n@zhangyoufu\nmade their first contribution in\n#2653\nFull Changelog\n:\n0.34.3...0.35.0",
    "crawl_status": "success"
  },
  {
    "library_name": "Uvicorn",
    "url": "https://github.com/encode/uvicorn/releases/tag/0.30.0",
    "version": "0.30.0",
    "title": "Release Version 0.30.0 路 Kludex/uvicorn 路 GitHub",
    "release_date": "2024-05-28T07:19:41Z",
    "content": "Added\nNew multiprocess manager (\n#2183\n)\nAllow\nConfigParser\nor a\nio.IO[Any]\non\nlog_config\n(\n#1976\n)\nFixed\nSuppress side effects of signal propagation (\n#2317\n)\nSend\ncontent-length\nheader on 5xx (\n#2304\n)\nDeprecated\nDeprecate the\nuvicorn.workers\nmodule (\n#2302\n)\nFull Changelog\n:\n0.29.0...0.30.0",
    "crawl_status": "success"
  },
  {
    "library_name": "Uvicorn",
    "url": "https://github.com/encode/uvicorn/releases/tag/0.23.0",
    "version": "0.23.0",
    "title": "Release Version 0.23.0 路 Kludex/uvicorn 路 GitHub",
    "release_date": "2023-07-15T06:26:23Z",
    "content": "Added\nAdd\n--ws-max-queue\nparameter WebSockets (\n#2033\n) 10/07/23\nRemoved\nDrop support for Python 3.7 (\n#1996\n) 19/06/23\nRemove\nasgiref\nas typing dependency (\n#1999\n) 08/06/23\nFixed\nSet\nscope[\"scheme\"]\nto\nws\nor\nwss\ninstead of\nhttp\nor\nhttps\non\nProxyHeadersMiddleware\nfor WebSockets (\n#2043\n) 12/07/23\nChanged\nRaise\nImportError\non circular import (\n#2040\n) 09/07/23\nUse\nlogger.getEffectiveLevel()\ninstead of\nlogger.level\nto check if log level is\nTRACE\n(\n#1966\n) 01/06/23\nFull Changelog\n:\n0.22.0...0.23.0",
    "crawl_status": "success"
  },
  {
    "library_name": "Textual",
    "url": "https://github.com/Textualize/textual/releases/tag/v5.0.0",
    "version": "v5.0.0",
    "title": "Release The Tabled release. 路 Textualize/textual 路 GitHub",
    "release_date": "2025-07-25T07:50:48Z",
    "content": "This is quite a large release! Fueled in part by my work on\nToad\nMarkdown rendering has been improved, with full text selection, prettier code blocks and tables. Plus streaming support.\nPlenty of other fixes and additions. Thats to everyone who contributed code and issues!\nThere are two breaking changes (see below). These are unlikely to affect anyone, but\nSemver\nrequires bumping the major version number.\n[5.0.0] - 2025-07-25\nAdded\nAdded get_minimal_width to Visual protocol\n#5962\nAdded\nexpand\nand\nshrink\nattributes to GridLayout\n#5962\nAdded\nMarkdown.get_stream\n#5966\nAdded\ntextual.highlight\nmodule for syntax highlighting\n#5966\nAdded\nMessagePump.wait_for_refresh\nmethod\n#5966\nAdded\nWidget.container_scroll_offset\ne84600c\nAdded\nMarkdown.source\nattribute to MarkdownBlocks\ne84600c\nAdded extension mechanism to Markdown\ne84600c\nAdded\nindex\nto\nListView.Selected\nevent\n#5973\nAdded\nlayout\nswitch to Static.update\n#5973\nFixed\nFixed\nTextArea\nissue with the\ncss\ntheme, where the background color was stuck from the previous theme\n#5964\nChanged\nImproved rendering of Markdown tables (replace Rich table with grid) which allows text selection\n#5962\nChange look of command palette, to drop accented borders\n#5966\nSome style tweaks to Markdown\ne84600c\nContent markup can now accept component classes when preceded by a dot, e.g. \"Hello [.my_custo_style]World[/]!\"\n#5981\nBreaking change:\nVisual.render_strips\nhas a new signature. If you aren't explicitly building Visuals then this won't effect you.\n#5981\nBreaking change: The component classes on Markdown have been moved to MarkdownBlock. This won't affect you unless you have customize the Markdown CSS\n#5981\nThe textual-speedups library will now be imported automatically if it is installed. Set\nTEXTUAL_SPEEDUPS=0\nto disable.",
    "crawl_status": "success"
  },
  {
    "library_name": "Textual",
    "url": "https://github.com/Textualize/textual/releases/tag/v0.31.0",
    "version": "v0.31.0",
    "title": "Release Worker update and more 路 Textualize/textual 路 GitHub",
    "release_date": "2023-08-01T10:10:32Z",
    "content": "Fixes and updates. Also a few breaking changes, see below for details...\n[0.31.0] - 2023-08-01\nAdded\nAdded App.begin_capture_print, App.end_capture_print, Widget.begin_capture_print, Widget.end_capture_print\n#2952\nAdded the ability to run async methods as thread workers\n#2938\nAdded\nApp.stop_animation\n#2786\nAdded\nWidget.stop_animation\n#2786\nChanged\nBreaking change: Creating a thread worker now requires that a\nthread=True\nkeyword argument is passed\n#2938\nBreaking change:\nMarkdown.load\nno longer captures all errors and returns a\nbool\n, errors now propagate\n#2956\nBreaking change: the default style of a\nDataTable\nnow has\nmax-height: 100%\n#2959\nFixed\nFixed a crash when a\nSelectionList\nhad a prompt wider than itself\n#2900\nFixed a bug where\nClick\nevents were bubbling up from\nSwitch\nwidgets\n#2366\nFixed a crash when using empty CSS variables\n#1849\nFixed issue with tabs in TextLog\n#3007\nFixed a bug with\nDataTable\nhover highlighting\n#2909",
    "crawl_status": "success"
  },
  {
    "library_name": "Textual",
    "url": "https://github.com/Textualize/textual/releases/tag/v0.77.0",
    "version": "v0.77.0",
    "title": "Release The lucky number 77 release 路 Textualize/textual 路 GitHub",
    "release_date": "2024-08-22T14:18:02Z",
    "content": "This is quite a large release!\nWe've done a lot of work on the\ncommand palette\nto make it easier to work with and use.\nWe've also added a \"help panel\" which you can summon from the command palette. This will give you context sensitive help, and a summary of all the key bindings. Here it is in action:\nScreen.Recording.2024-08-22.at.15.13.22.mov\nAlso in the command palette is a \"save screenshot\" command, which will save a screenshot of the current screen. Very handy for adding to documentation.\nThere are a number of other smaller changes, fixes, and a few breaking changes. See the detailed release notes below:\n[0.77.0] - 2024-08-22\nAdded\nAdded\ntooltip\nto Binding\n#4859\nAdded a link to the command palette to the Footer (set\nshow_command_palette=False\nto disable)\n#4867\nAdded\nTOOLTIP_DELAY\nto App to customize time until a tooltip is displayed\nAdded \"Show keys\" option to system commands to show a summary of key bindings.\n#4876\nAdded \"split\" CSS style, currently undocumented, and may change.\n#4876\nAdded\nRegion.get_spacing_between\n#4876\nAdded\nApp.COMMAND_PALETTE_KEY\nto change default command palette key binding\n#4867\nAdded\nApp.get_key_display\n#4890\nAdded\nDOMNode.BINDING_GROUP\n#4906\nAdded\nDOMNode.HELP\nclassvar which contains Markdown help to be shown in the help panel\n#4915\nAdded\nApp.get_system_commands\n#4920\nAdded \"Save Screenshot\" system command\n#4922\nChanged\nRemoved caps_lock and num_lock modifiers\n#4861\nKeys such as escape and space are now displayed in lower case in footer\n#4876\nChanged default command palette binding to\nctrl+p\n#4867\nRemoved\nctrl_to_caret\nand\nupper_case_keys\nfrom Footer. These can be implemented in\nApp.get_key_display\n.\nRenamed\nSystemCommands\nto\nSystemCommandsProvider\n#4920\nBreaking change: Removed\nClassicFooter\nwidget (please use new\nFooter\nwidget)\n#4921\nDisallowed\nScreen\ninstances in\nApp.SCREENS\nand\nApp.MODES\nFixed\nFix crash when\nvalidate_on\nvalue isn't a set\n#4868\nFix\nInput.cursor_blink\nhaving no effect on the blink cycle after mounting\n#4869\nFixed scrolling by page not taking scrollbar in to account\n#4916\nFixed\nApp.MODES\nbeing the same for all instances -- per-instance modes now exist internally",
    "crawl_status": "success"
  },
  {
    "library_name": "Alembic",
    "url": "https://github.com/sqlalchemy/alembic/releases/tag/rel_1_12_0",
    "version": "rel_1_12_0",
    "title": "Release 1.12.0 路 sqlalchemy/alembic 路 GitHub",
    "release_date": "2023-08-31T17:27:27Z",
    "content": "1.12.0\nReleased: August 31, 2023\nfeature\n[feature] [autogenerate]\nAdded new feature to the \"code formatter\" function which allows standalone\nexecutable tools to be run against code, without going through the Python\ninterpreter.  Known as the\nexec\nrunner, it complements the existing\nconsole_scripts\nrunner by allowing non-Python tools such as\nruff\nto\nbe used.   Pull request courtesy Mihail Milushev.\nReferences:\n#1275\nusecase\n[usecase] [autogenerate]\nChange the default value of\nEnvironmentContext.configure.compare_type\nto\nTrue\n.\nAs Alembic's autogenerate for types was dramatically improved in\nversion 1.4 released in 2020, the type comparison feature is now much\nmore reliable so is now enabled by default.\nReferences:\n#1248\nbug\n[bug] [operations]\nAdded support for\nop.drop_constraint()\nto support PostrgreSQL\nExcludeConstraint\nobjects, as well as other constraint-like objects\nthat may be present in third party dialects, by resolving the\ntype_\nparameter to be\nNone\nfor this case.   Autogenerate has also been\nenhanced to exclude the\ntype_\nparameter from rendering within this\ncommand when\ntype_\nis\nNone\n.  Pull request courtesy David Hills.\nReferences:\n#1300\n[bug] [commmands]\nFixed issue where the\nrevision_environment\ndirective in\nalembic.ini\nwas ignored by the\nalembic merge\ncommand, leading to issues when other\nconfigurational elements depend upon\nenv.py\nbeing invoked within the\ncommand.\nReferences:\n#1299\n[bug] [autogenerate]\nFixed issue where the\nForeignKeyConstraint.match\nparameter would not be\nrendered in autogenerated migrations.  Pull request courtesy Asib\nKamalsada.\nReferences:\n#1302",
    "crawl_status": "success"
  },
  {
    "library_name": "Alembic",
    "url": "https://github.com/sqlalchemy/alembic/releases/tag/rel_1_16_3",
    "version": "rel_1_16_3",
    "title": "Release 1.16.3 路 sqlalchemy/alembic 路 GitHub",
    "release_date": "2025-07-08T18:57:56Z",
    "content": "1.16.3\nReleased: July 8, 2025\nusecase\n[usecase] [commands]\nAdded new\npyproject_async\ntemplate, combining the new\npyproject\ntemplate with the\nasync\ntemplate.  Pull request courtesy Alc-Alc.\nReferences:\n#1683\n[usecase] [autogenerate]\nAdd \"module\" post-write hook. This hook type is almost identical to the\nconsole_scripts hook, except it's running\npython -m black\ninstead of\nusing black's\nconsole_script\n. It is mainly useful for tools without\nconsole scripts (e.g. ruff), but has semantics closer to the\nconsole_scripts hook in that it finds the ruff module available to the\nrunning interpreter instead of finding an executable by path. Pull request\ncourtesy Frazer McLean.\nReferences:\n#1686\nbug\n[bug] [autogenerate]\nFixed the rendering of\nserver_default=FetchedValue()\nto ensure it is\npreceded by the\nsa.\nprefix in the migration script. Pull request\ncourtesy david-fed.\nReferences:\n#1633\n[bug] [autogenerate]\nFixed autogenerate rendering bug which failed to render foreign key\nconstraints local to a\nCreateTableOp\nobject if it did not refer\nto a\nMetaData\ncollection via a private constructor argument that would\nnot ordinarily be passed in user-defined rewriter recipes, including ones\nin the Alembic cookbook section of the docs.\nReferences:\n#1692",
    "crawl_status": "success"
  },
  {
    "library_name": "Alembic",
    "url": "https://github.com/sqlalchemy/alembic/releases/tag/rel_1_13_3",
    "version": "rel_1_13_3",
    "title": "Release 1.13.3 路 sqlalchemy/alembic 路 GitHub",
    "release_date": "2024-09-23T14:52:24Z",
    "content": "1.13.3\nReleased: September 23, 2024\nusecase\n[usecase] [autogenerate]\nRender\nif_exists\nand\nif_not_exists\nparameters in\nCreateTableOp\n,\nCreateIndexOp\n,\nDropTableOp\nand\nDropIndexOp\nin an autogenerate context.  While Alembic does not\nset these parameters during an autogenerate run, they can be enabled using\na custom\nRewriter\nin the\nenv.py\nfile, where they will now be\npart of the rendered Python code in revision files.  Pull request courtesy\nof Louis-Amaury Chaib (\n@lachaib\n).\n[usecase] [environment]\nEnhance\nversion_locations\nparsing to handle paths containing newlines.\nReferences:\n#1509\n[usecase] [operations]\nAdded support for\nOperations.create_table.if_not_exists\nand\nOperations.drop_table.if_exists\n, adding similar functionality\nto render IF [NOT] EXISTS for table operations in a similar way as with\nindexes. Pull request courtesy Aaron Griffin.\nReferences:\n#1520\nmisc\n[change] [general]\nThe pin for\nsetuptools<69.3\nin\npyproject.toml\nhas been removed.\nThis pin was to prevent a sudden change to\nPEP 625\nin setuptools from\ntaking place which changes the file name of SQLAlchemy's source\ndistribution on pypi to be an all lower case name, and the change was\nextended to all SQLAlchemy projects to prevent any further surprises.\nHowever, the presence of this pin is now holding back environments that\notherwise want to use a newer setuptools, so we've decided to move forward\nwith this change, with the assumption that build environments will have\nlargely accommodated the setuptools change by now.",
    "crawl_status": "success"
  },
  {
    "library_name": "Pandas",
    "url": "https://pandas.pydata.org/pandas-docs/version/2.3.0/whatsnew/v2.3.0.html",
    "version": "v2.3.0.html",
    "title": "What芒s new in 2.3.0 (June 4, 2025)  pandas 2.3.0 documentation",
    "release_date": "Unknown release date",
    "content": "Release notes\nWhat芒s new...\nWhat芒s new in 2.3.0 (June 4, 2025)\n#\nThese are the changes in pandas 2.3.0. See\nRelease notes\nfor a full changelog\nincluding other versions of pandas.\nEnhancements\n#\nOther enhancements\n#\nThe semantics for the\ncopy\nkeyword in\n__array__\nmethods (i.e. called\nwhen using\nnp.array()\nor\nnp.asarray()\non pandas objects) has been\nupdated to work correctly with NumPy >= 2 (\nGH 57739\n)\nSeries.str.decode()\nresult now has\nStringDtype\nwhen\nfuture.infer_string\nis True (\nGH 60709\n)\nto_hdf()\nand\nto_hdf()\nnow round-trip with\nStringDtype\n(\nGH 60663\n)\nImproved\nrepr\nof\nNumpyExtensionArray\nto account for NEP51 (\nGH 61085\n)\nThe\nSeries.str.decode()\nhas gained the argument\ndtype\nto control the dtype of the result (\nGH 60940\n)\nThe\ncumsum()\n,\ncummin()\n, and\ncummax()\nreductions are now implemented for\nStringDtype\ncolumns (\nGH 60633\n)\nThe\nsum()\nreduction is now implemented for\nStringDtype\ncolumns (\nGH 59853\n)\nNotable bug fixes\n#\nThese are bug fixes that might have notable behavior changes.\nnotable_bug_fix1\n#\nIn previous versions, comparing\nSeries\nof different string dtypes (e.g.\npd.StringDtype(\"pyarrow\",\nna_value=pd.NA)\nagainst\npd.StringDtype(\"python\",\nna_value=np.nan)\n) would result in inconsistent resulting dtype or incorrectly raise. pandas will now use the hierarchy\nIncreased minimum version for Python\n#\nin determining the result dtype when there are different string dtypes compared. Some examples:\nWhen\npd.StringDtype(\"pyarrow\",\nna_value=pd.NA)\nis compared against any other string dtype, the result will always be\nboolean[pyarrow]\n.\nWhen\npd.StringDtype(\"python\",\nna_value=pd.NA)\nis compared against\npd.StringDtype(\"pyarrow\",\nna_value=np.nan)\n, the result will be\nboolean\n, the NumPy-backed nullable extension array.\nWhen\npd.StringDtype(\"python\",\nna_value=pd.NA)\nis compared against\npd.StringDtype(\"python\",\nna_value=np.nan)\n, the result will be\nboolean\n, the NumPy-backed nullable extension array.\nAPI changes\n#\nWhen enabling the\nfuture.infer_string\noption,\nIndex\nset operations (like\nunion or intersection) will now ignore the dtype of an empty\nRangeIndex\nor\nempty\nIndex\nwith\nobject\ndtype when determining the dtype of the resulting\nIndex (\nGH 60797\n)\nDeprecations\n#\nDeprecated allowing non-\nbool\nvalues for\nna\nin\nstr.contains()\n,\nstr.startswith()\n, and\nstr.endswith()\nfor dtypes that do not already disallow these (\nGH 59615\n)\nDeprecated the\n\"pyarrow_numpy\"\nstorage option for\nStringDtype\n(\nGH 60152\n)\nThe deprecation of setting the argument\ninclude_groups\nto\nTrue\nin\nDataFrameGroupBy.apply()\nhas been promoted from a\nDeprecationWarning\nto\nFutureWarning\n; only\nFalse\nwill be allowed (\nGH 7155\n)\nBug fixes\n#\nNumeric\n#\nBug in\nSeries.mode()\nand\nDataFrame.mode()\nwith\ndropna=False\nwhere not all dtypes would sort in the presence of\nNA\nvalues (\nGH 60702\n)\nBug in\nSeries.round()\nwhere a\nTypeError\nwould always raise with\nobject\ndtype (\nGH 61206\n)\nStrings\n#\nBug in\nDataFrameGroupBy.min()\n,\nDataFrameGroupBy.max()\n,\nResampler.min()\n,\nResampler.max()\nwhere all NA values of string dtype would return float instead of string dtype (\nGH 60810\n)\nBug in\nDataFrame.sum()\nwith\naxis=1\n,\nDataFrameGroupBy.sum()\nor\nSeriesGroupBy.sum()\nwith\nskipna=True\n, and\nResampler.sum()\nwith all NA values of\nStringDtype\nresulted in\n0\ninstead of the empty string\n\"\"\n(\nGH 60229\n)\nBug in\nSeries.__pos__()\nand\nDataFrame.__pos__()\nwhere an\nException\nwas not raised for\nStringDtype\nwith\nstorage=\"pyarrow\"\n(\nGH 60710\n)\nBug in\nSeries.rank()\nfor\nStringDtype\nwith\nstorage=\"pyarrow\"\nthat incorrectly returned integer results with\nmethod=\"average\"\nand raised an error if it would truncate results (\nGH 59768\n)\nBug in\nSeries.replace()\nwith\nStringDtype\nwhen replacing with a non-string value was not upcasting to\nobject\ndtype (\nGH 60282\n)\nBug in\nSeries.str.center()\nwith\nStringDtype\nwith\nstorage=\"pyarrow\"\nnot matching the python behavior in corner cases with an odd number of fill characters (\nGH 54792\n)\nBug in\nSeries.str.replace()\nwhen\nn\n<\n0\nfor\nStringDtype\nwith\nstorage=\"pyarrow\"\n(\nGH 59628\n)\nBug in\nSeries.str.slice()\nwith negative\nstep\nwith\nArrowDtype\nand\nStringDtype\nwith\nstorage=\"pyarrow\"\ngiving incorrect results (\nGH 59710\n)\nIndexing\n#\nBug in\nIndex.get_indexer()\nround-tripping through string dtype when\ninfer_string\nis enabled (\nGH 55834\n)\nI/O\n#\nBug in\nDataFrame.to_excel()\nwhich stored decimals as strings instead of numbers (\nGH 49598\n)\nOther\n#\nFixed usage of\ninspect\nwhen the optional dependencies\npyarrow\nor\njinja2\nare not installed (\nGH 60196\n)\nContributors\n#\nA total of 24 people contributed patches to this release.  People with a\n芒+芒 by their names contributed a patch for the first time.\nChiLin Chiu +\nIrv Lustig\nIsuru Fernando +\nJake Thomas Trevallion +\nJoris Van den Bossche\nKevin Amparado +\nLOCHAN PAUDEL +\nLumberbot (aka Jack)\nMarc Mueller +\nMarco Edward Gorelli\nMatthew Roeschke\nPandas Development Team\nPatrick Hoefler\nRichard Shadrach\nSALCAN +\nSebastian Berg\nSimon Hawkins\nThomas Li\nWill Ayd\nWilliam Andrea\nWilliam Ayd\ndependabot[bot]\njbrockmendel\ntasfia8 +\nprevious\nRelease notes\nnext\nWhat芒s new in 2.2.3 (September 20, 2024)\nOn this page\nEnhancements\nOther enhancements\nNotable bug fixes\nnotable_bug_fix1\nIncreased minimum version for Python\nAPI changes\nDeprecations\nBug fixes\nNumeric\nStrings\nIndexing\nI/O\nOther\nContributors\nShow Source",
    "crawl_status": "success"
  },
  {
    "library_name": "Pandas",
    "url": "https://pandas.pydata.org/pandas-docs/version/2.2.0/whatsnew/v2.2.0.html",
    "version": "v2.2.0.html",
    "title": "What芒s new in 2.2.0 (January 19, 2024)  pandas 2.2.0 documentation",
    "release_date": "Unknown release date",
    "content": "Release notes\nWhat芒s new...\nWhat芒s new in 2.2.0 (January 19, 2024)\n#\nThese are the changes in pandas 2.2.0. See\nRelease notes\nfor a full changelog\nincluding other versions of pandas.\nUpcoming changes in pandas 3.0\n#\npandas 3.0 will bring two bigger changes to the default behavior of pandas.\nCopy-on-Write\n#\nThe currently optional mode Copy-on-Write will be enabled by default in pandas 3.0. There\nwon芒t be an option to keep the current behavior enabled. The new behavioral semantics are\nexplained in the\nuser guide about Copy-on-Write\n.\nThe new behavior can be enabled since pandas 2.0 with the following option:\npd\n.\noptions\n.\nmode\n.\ncopy_on_write\n=\nTrue\nThis change brings different changes in behavior in how pandas operates with respect to\ncopies and views. Some of these changes allow a clear deprecation, like the changes in\nchained assignment. Other changes are more subtle and thus, the warnings are hidden behind\nan option that can be enabled in pandas 2.2.\npd\n.\noptions\n.\nmode\n.\ncopy_on_write\n=\n\"warn\"\nThis mode will warn in many different scenarios that aren芒t actually relevant to\nmost queries. We recommend exploring this mode, but it is not necessary to get rid\nof all of these warnings. The\nmigration guide\nexplains the upgrade process in more detail.\nDedicated string data type (backed by Arrow) by default\n#\nHistorically, pandas represented string columns with NumPy object data type. This\nrepresentation has numerous problems, including slow performance and a large memory\nfootprint. This will change in pandas 3.0. pandas will start inferring string columns\nas a new\nstring\ndata type, backed by Arrow, which represents strings contiguous in memory. This brings\na huge performance and memory improvement.\nOld behavior:\nIn [1]:\nser\n=\npd\n.\nSeries\n([\n\"a\"\n,\n\"b\"\n])\nOut[1]:\n0    a\n1    b\ndtype: object\nNew behavior:\nIn [1]:\nser\n=\npd\n.\nSeries\n([\n\"a\"\n,\n\"b\"\n])\nOut[1]:\n0    a\n1    b\ndtype: string\nThe string data type that is used in these scenarios will mostly behave as NumPy\nobject would, including missing value semantics and general operations on these\ncolumns.\nThis change includes a few additional changes across the API:\nCurrently, specifying\ndtype=\"string\"\ncreates a dtype that is backed by Python strings\nwhich are stored in a NumPy array. This will change in pandas 3.0, this dtype\nwill create an Arrow backed string column.\nThe column names and the Index will also be backed by Arrow strings.\nPyArrow will become a required dependency with pandas 3.0 to accommodate this change.\nThis future dtype inference logic can be enabled with:\npd\n.\noptions\n.\nfuture\n.\ninfer_string\n=\nTrue\nEnhancements\n#\nADBC Driver support in to_sql and read_sql\n#\nread_sql()\nand\nto_sql()\nnow work with\nApache Arrow ADBC\ndrivers. Compared to\ntraditional drivers used via SQLAlchemy, ADBC drivers should provide\nsignificant performance improvements, better type support and cleaner\nnullability handling.\nimport\nadbc_driver_postgresql.dbapi\nas\npg_dbapi\ndf\n=\npd\n.\nDataFrame\n(\n[\n[\n1\n,\n2\n,\n3\n],\n[\n4\n,\n5\n,\n6\n],\n],\ncolumns\n=\n[\n'a'\n,\n'b'\n,\n'c'\n]\n)\nuri\n=\n\"postgresql://postgres:postgres@localhost/postgres\"\nwith\npg_dbapi\n.\nconnect\n(\nuri\n)\nas\nconn\n:\ndf\n.\nto_sql\n(\n\"pandas_table\"\n,\nconn\n,\nindex\n=\nFalse\n)\n# for round-tripping\nwith\npg_dbapi\n.\nconnect\n(\nuri\n)\nas\nconn\n:\ndf2\n=\npd\n.\nread_sql\n(\n\"pandas_table\"\n,\nconn\n)\nThe Arrow type system offers a wider array of types that can more closely match\nwhat databases like PostgreSQL can offer. To illustrate, note this (non-exhaustive)\nlisting of types available in different databases and pandas backends:\nnumpy/pandas\narrow\npostgres\nsqlite\nint16/Int16\nint16\nSMALLINT\nINTEGER\nint32/Int32\nint32\nINTEGER\nINTEGER\nint64/Int64\nint64\nBIGINT\nINTEGER\nfloat32\nfloat32\nREAL\nREAL\nfloat64\nfloat64\nDOUBLE PRECISION\nREAL\nobject\nstring\nTEXT\nTEXT\nbool\nbool_\nBOOLEAN\ndatetime64[ns]\ntimestamp(us)\nTIMESTAMP\ndatetime64[ns,tz]\ntimestamp(us,tz)\nTIMESTAMPTZ\ndate32\nDATE\nmonth_day_nano_interval\nINTERVAL\nbinary\nBINARY\nBLOB\ndecimal128\nDECIMAL\n[\n1\n]\nlist\nARRAY\n[\n1\n]\nstruct\nCOMPOSITE TYPE\n[\n1\n]\nFootnotes\n[\n1\n]\n(\n1\n,\n2\n,\n3\n)\nNot implemented as of writing, but theoretically possible\nIf you are interested in preserving database types as best as possible\nthroughout the lifecycle of your DataFrame, users are encouraged to\nleverage the\ndtype_backend=\"pyarrow\"\nargument of\nread_sql()\n# for round-tripping\nwith\npg_dbapi\n.\nconnect\n(\nuri\n)\nas\nconn\n:\ndf2\n=\npd\n.\nread_sql\n(\n\"pandas_table\"\n,\nconn\n,\ndtype_backend\n=\n\"pyarrow\"\n)\nThis will prevent your data from being converted to the traditional pandas/NumPy\ntype system, which often converts SQL types in ways that make them impossible to\nround-trip.\nFor a full list of ADBC drivers and their development status, see the\nADBC Driver\nImplementation Status\ndocumentation.\nCreate a pandas Series based on one or more conditions\n#\nThe\nSeries.case_when()\nfunction has been added to create a Series object based on one or more conditions. (\nGH 39154\n)\nIn [1]:\nimport\npandas\nas\npd\nIn [2]:\ndf\n=\npd\n.\nDataFrame\n(\ndict\n(\na\n=\n[\n1\n,\n2\n,\n3\n],\nb\n=\n[\n4\n,\n5\n,\n6\n]))\nIn [3]:\ndefault\n=\npd\n.\nSeries\n(\n'default'\n,\nindex\n=\ndf\n.\nindex\n)\nIn [4]:\ndefault\n.\ncase_when\n(\n...:\ncaselist\n=\n[\n...:\n(\ndf\n.\na\n==\n1\n,\n'first'\n),\n# condition, replacement\n...:\n(\ndf\n.\na\n.\ngt\n(\n1\n)\n&\ndf\n.\nb\n.\neq\n(\n5\n),\n'second'\n),\n# condition, replacement\n...:\n],\n...:\n)\n...:\nOut[4]:\n0      first\n1     second\n2    default\ndtype: object\nto_numpy\nfor NumPy nullable and Arrow types converts to suitable NumPy dtype\n#\nto_numpy\nfor NumPy nullable and Arrow types will now convert to a\nsuitable NumPy dtype instead of\nobject\ndtype for nullable and PyArrow backed extension dtypes.\nOld behavior:\nIn [1]:\nser\n=\npd\n.\nSeries\n([\n1\n,\n2\n,\n3\n],\ndtype\n=\n\"Int64\"\n)\nIn [2]:\nser\n.\nto_numpy\n()\nOut[2]:\narray([1, 2, 3], dtype=object)\nNew behavior:\nIn [5]:\nser\n=\npd\n.\nSeries\n([\n1\n,\n2\n,\n3\n],\ndtype\n=\n\"Int64\"\n)\nIn [6]:\nser\n.\nto_numpy\n()\nOut[6]:\narray([1, 2, 3])\nIn [7]:\nser\n=\npd\n.\nSeries\n([\n1\n,\n2\n,\n3\n],\ndtype\n=\n\"timestamp[ns][pyarrow]\"\n)\nIn [8]:\nser\n.\nto_numpy\n()\nOut[8]:\narray(['1970-01-01T00:00:00.000000001', '1970-01-01T00:00:00.000000002',\n'1970-01-01T00:00:00.000000003'], dtype='datetime64[ns]')\nThe default NumPy dtype (without any arguments) is determined as follows:\nfloat dtypes are cast to NumPy floats\ninteger dtypes without missing values are cast to NumPy integer dtypes\ninteger dtypes with missing values are cast to NumPy float dtypes and\nNaN\nis used as missing value indicator\nboolean dtypes without missing values are cast to NumPy bool dtype\nboolean dtypes with missing values keep object dtype\ndatetime and timedelta types are cast to Numpy datetime64 and timedelta64 types respectively and\nNaT\nis used as missing value indicator\nSeries.struct accessor for PyArrow structured data\n#\nThe\nSeries.struct\naccessor provides attributes and methods for processing\ndata with\nstruct[pyarrow]\ndtype Series. For example,\nSeries.struct.explode()\nconverts PyArrow structured data to a pandas\nDataFrame. (\nGH 54938\n)\nIn [9]:\nimport\npyarrow\nas\npa\nIn [10]:\nseries\n=\npd\n.\nSeries\n(\n....:\n[\n....:\n{\n\"project\"\n:\n\"pandas\"\n,\n\"version\"\n:\n\"2.2.0\"\n},\n....:\n{\n\"project\"\n:\n\"numpy\"\n,\n\"version\"\n:\n\"1.25.2\"\n},\n....:\n{\n\"project\"\n:\n\"pyarrow\"\n,\n\"version\"\n:\n\"13.0.0\"\n},\n....:\n],\n....:\ndtype\n=\npd\n.\nArrowDtype\n(\n....:\npa\n.\nstruct\n([\n....:\n(\n\"project\"\n,\npa\n.\nstring\n()),\n....:\n(\n\"version\"\n,\npa\n.\nstring\n()),\n....:\n])\n....:\n),\n....:\n)\n....:\nIn [11]:\nseries\n.\nstruct\n.\nexplode\n()\nOut[11]:\nproject version\n0   pandas   2.2.0\n1    numpy  1.25.2\n2  pyarrow  13.0.0\nUse\nSeries.struct.field()\nto index into a (possible nested)\nstruct field.\nIn [12]:\nseries\n.\nstruct\n.\nfield\n(\n\"project\"\n)\nOut[12]:\n0     pandas\n1      numpy\n2    pyarrow\nName: project, dtype: string[pyarrow]\nSeries.list accessor for PyArrow list data\n#\nThe\nSeries.list\naccessor provides attributes and methods for processing\ndata with\nlist[pyarrow]\ndtype Series. For example,\nSeries.list.__getitem__()\nallows indexing pyarrow lists in\na Series. (\nGH 55323\n)\nIn [13]:\nimport\npyarrow\nas\npa\nIn [14]:\nseries\n=\npd\n.\nSeries\n(\n....:\n[\n....:\n[\n1\n,\n2\n,\n3\n],\n....:\n[\n4\n,\n5\n],\n....:\n[\n6\n],\n....:\n],\n....:\ndtype\n=\npd\n.\nArrowDtype\n(\n....:\npa\n.\nlist_\n(\npa\n.\nint64\n())\n....:\n),\n....:\n)\n....:\nIn [15]:\nseries\n.\nlist\n[\n0\n]\nOut[15]:\n0    1\n1    4\n2    6\ndtype: int64[pyarrow]\nCalamine engine for\nread_excel()\n#\nThe\ncalamine\nengine was added to\nread_excel()\n.\nIt uses\npython-calamine\n, which provides Python bindings for the Rust library\ncalamine\n.\nThis engine supports Excel files (\n.xlsx\n,\n.xlsm\n,\n.xls\n,\n.xlsb\n) and OpenDocument spreadsheets (\n.ods\n) (\nGH 50395\n).\nThere are two advantages of this engine:\nCalamine is often faster than other engines, some benchmarks show results up to 5x faster than 芒openpyxl芒, 20x - 芒odf芒, 4x - 芒pyxlsb芒, and 1.5x - 芒xlrd芒.\nBut, 芒openpyxl芒 and 芒pyxlsb芒 are faster in reading a few rows from large files because of lazy iteration over rows.\nCalamine supports the recognition of datetime in\n.xlsb\nfiles, unlike 芒pyxlsb芒 which is the only other engine in pandas that can read\n.xlsb\nfiles.\npd\n.\nread_excel\n(\n\"path_to_file.xlsb\"\n,\nengine\n=\n\"calamine\"\n)\nFor more, see\nCalamine (Excel and ODS files)\nin the user guide on IO tools.\nOther enhancements\n#\nto_sql()\nwith method parameter set to\nmulti\nworks with Oracle on the backend\nSeries.attrs\n/\nDataFrame.attrs\nnow uses a deepcopy for propagating\nattrs\n(\nGH 54134\n).\nget_dummies()\nnow returning  extension dtypes\nboolean\nor\nbool[pyarrow]\nthat are compatible with the input dtype (\nGH 56273\n)\nread_csv()\nnow supports\non_bad_lines\nparameter with\nengine=\"pyarrow\"\n(\nGH 54480\n)\nread_sas()\nreturns\ndatetime64\ndtypes with resolutions better matching those stored natively in SAS, and avoids returning object-dtype in cases that cannot be stored with\ndatetime64[ns]\ndtype (\nGH 56127\n)\nread_spss()\nnow returns a\nDataFrame\nthat stores the metadata in\nDataFrame.attrs\n(\nGH 54264\n)\ntseries.api.guess_datetime_format()\nis now part of the public API (\nGH 54727\n)\nDataFrame.apply()\nnow allows the usage of numba (via\nengine=\"numba\"\n) to JIT compile the passed function, allowing for potential speedups (\nGH 54666\n)\nExtensionArray._explode()\ninterface method added to allow extension type implementations of the\nexplode\nmethod (\nGH 54833\n)\nExtensionArray.duplicated()\nadded to allow extension type implementations of the\nduplicated\nmethod (\nGH 55255\n)\nSeries.ffill()\n,\nSeries.bfill()\n,\nDataFrame.ffill()\n, and\nDataFrame.bfill()\nhave gained the argument\nlimit_area\n; 3rd party\nExtensionArray\nauthors need to add this argument to the method\n_pad_or_backfill\n(\nGH 56492\n)\nAllow passing\nread_only\n,\ndata_only\nand\nkeep_links\narguments to openpyxl using\nengine_kwargs\nof\nread_excel()\n(\nGH 55027\n)\nImplement\nSeries.interpolate()\nand\nDataFrame.interpolate()\nfor\nArrowDtype\nand masked dtypes (\nGH 56267\n)\nImplement masked algorithms for\nSeries.value_counts()\n(\nGH 54984\n)\nImplemented\nSeries.dt()\nmethods and attributes for\nArrowDtype\nwith\npyarrow.duration\ntype (\nGH 52284\n)\nImplemented\nSeries.str.extract()\nfor\nArrowDtype\n(\nGH 56268\n)\nImproved error message that appears in\nDatetimeIndex.to_period()\nwith frequencies which are not supported as period frequencies, such as\n\"BMS\"\n(\nGH 56243\n)\nImproved error message when constructing\nPeriod\nwith invalid offsets such as\n\"QS\"\n(\nGH 55785\n)\nThe dtypes\nstring[pyarrow]\nand\nstring[pyarrow_numpy]\nnow both utilize the\nlarge_string\ntype from PyArrow to avoid overflow for long columns (\nGH 56259\n)\nNotable bug fixes\n#\nThese are bug fixes that might have notable behavior changes.\nmerge()\nand\nDataFrame.join()\nnow consistently follow documented sort behavior\n#\nIn previous versions of pandas,\nmerge()\nand\nDataFrame.join()\ndid not\nalways return a result that followed the documented sort behavior. pandas now\nfollows the documented sort behavior in merge and join operations (\nGH 54611\n,\nGH 56426\n,\nGH 56443\n).\nAs documented,\nsort=True\nsorts the join keys lexicographically in the resulting\nDataFrame\n. With\nsort=False\n, the order of the join keys depends on the\njoin type (\nhow\nkeyword):\nhow=\"left\"\n: preserve the order of the left keys\nhow=\"right\"\n: preserve the order of the right keys\nhow=\"inner\"\n: preserve the order of the left keys\nhow=\"outer\"\n: sort keys lexicographically\nOne example with changing behavior is inner joins with non-unique left join keys\nand\nsort=False\n:\nIn [16]:\nleft\n=\npd\n.\nDataFrame\n({\n\"a\"\n:\n[\n1\n,\n2\n,\n1\n]})\nIn [17]:\nright\n=\npd\n.\nDataFrame\n({\n\"a\"\n:\n[\n1\n,\n2\n]})\nIn [18]:\nresult\n=\npd\n.\nmerge\n(\nleft\n,\nright\n,\nhow\n=\n\"inner\"\n,\non\n=\n\"a\"\n,\nsort\n=\nFalse\n)\nOld Behavior\nIn [5]:\nresult\nOut[5]:\na\n0  1\n1  1\n2  2\nNew Behavior\nIn [19]:\nresult\nOut[19]:\na\n0  1\n1  2\n2  1\nmerge()\nand\nDataFrame.join()\nno longer reorder levels when levels differ\n#\nIn previous versions of pandas,\nmerge()\nand\nDataFrame.join()\nwould reorder\nindex levels when joining on two indexes with different levels (\nGH 34133\n).\nIn [20]:\nleft\n=\npd\n.\nDataFrame\n({\n\"left\"\n:\n1\n},\nindex\n=\npd\n.\nMultiIndex\n.\nfrom_tuples\n([(\n\"x\"\n,\n1\n),\n(\n\"x\"\n,\n2\n)],\nnames\n=\n[\n\"A\"\n,\n\"B\"\n]))\nIn [21]:\nright\n=\npd\n.\nDataFrame\n({\n\"right\"\n:\n2\n},\nindex\n=\npd\n.\nMultiIndex\n.\nfrom_tuples\n([(\n1\n,\n1\n),\n(\n2\n,\n2\n)],\nnames\n=\n[\n\"B\"\n,\n\"C\"\n]))\nIn [22]:\nleft\nOut[22]:\nleft\nA B\nx 1     1\n2     1\nIn [23]:\nright\nOut[23]:\nright\nB C\n1 1      2\n2 2      2\nIn [24]:\nresult\n=\nleft\n.\njoin\n(\nright\n)\nOld Behavior\nIn [5]:\nresult\nOut[5]:\nleft  right\nB A C\n1 x 1     1      2\n2 x 2     1      2\nNew Behavior\nIn [25]:\nresult\nOut[25]:\nleft  right\nA B C\nx 1 1     1      2\n2 2     1      2\nIncreased minimum versions for dependencies\n#\nFor\noptional dependencies\nthe general recommendation is to use the latest version.\nOptional dependencies below the lowest tested version may still work but are not considered supported.\nThe following table lists the optional dependencies that have had their minimum tested version increased.\nPackage\nNew Minimum Version\nbeautifulsoup4\n4.11.2\nblosc\n1.21.3\nbottleneck\n1.3.6\nfastparquet\n2022.12.0\nfsspec\n2022.11.0\ngcsfs\n2022.11.0\nlxml\n4.9.2\nmatplotlib\n3.6.3\nnumba\n0.56.4\nnumexpr\n2.8.4\nqtpy\n2.3.0\nopenpyxl\n3.1.0\npsycopg2\n2.9.6\npyreadstat\n1.2.0\npytables\n3.8.0\npyxlsb\n1.0.10\ns3fs\n2022.11.0\nscipy\n1.10.0\nsqlalchemy\n2.0.0\ntabulate\n0.9.0\nxarray\n2022.12.0\nxlsxwriter\n3.0.5\nzstandard\n0.19.0\npyqt5\n5.15.8\ntzdata\n2022.7\nSee\nDependencies\nand\nOptional dependencies\nfor more.\nOther API changes\n#\nThe hash values of nullable extension dtypes changed to improve the performance of the hashing operation (\nGH 56507\n)\ncheck_exact\nnow only takes effect for floating-point dtypes in\ntesting.assert_frame_equal()\nand\ntesting.assert_series_equal()\n. In particular, integer dtypes are always checked exactly (\nGH 55882\n)\nDeprecations\n#\nChained assignment\n#\nIn preparation of larger upcoming changes to the copy / view behaviour in pandas 3.0\n(\nCopy-on-Write (CoW)\n, PDEP-7), we started deprecating\nchained assignment\n.\nChained assignment occurs when you try to update a pandas DataFrame or Series through\ntwo subsequent indexing operations. Depending on the type and order of those operations\nthis currently does or does not work.\nA typical example is as follows:\ndf\n=\npd\n.\nDataFrame\n({\n\"foo\"\n:\n[\n1\n,\n2\n,\n3\n],\n\"bar\"\n:\n[\n4\n,\n5\n,\n6\n]})\n# first selecting rows with a mask, then assigning values to a column\n# -> this has never worked and raises a SettingWithCopyWarning\ndf\n[\ndf\n[\n\"bar\"\n]\n>\n5\n][\n\"foo\"\n]\n=\n100\n# first selecting the column, and then assigning to a subset of that column\n# -> this currently works\ndf\n[\n\"foo\"\n][\ndf\n[\n\"bar\"\n]\n>\n5\n]\n=\n100\nThis second example of chained assignment currently works to update the original\ndf\n.\nThis will no longer work in pandas 3.0, and therefore we started deprecating this:\n>>>\ndf\n[\n\"foo\"\n][\ndf\n[\n\"bar\"\n]\n>\n5\n]\n=\n100\nFutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\nYou are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\nA typical example is when you are setting values in a column of a DataFrame, like:\ndf[\"col\"][row_indexer] = value\nUse `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\nYou can fix this warning and ensure your code is ready for pandas 3.0 by removing\nthe usage of chained assignment. Typically, this can be done by doing the assignment\nin a single step using for example\n.loc\n. For the example above, we can do:\ndf\n.\nloc\n[\ndf\n[\n\"bar\"\n]\n>\n5\n,\n\"foo\"\n]\n=\n100\nThe same deprecation applies to inplace methods that are done in a chained manner, such as:\n>>>\ndf\n[\n\"foo\"\n]\n.\nfillna\n(\n0\n,\ninplace\n=\nTrue\n)\nFutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\nWhen the goal is to update the column in the DataFrame\ndf\n, the alternative here is\nto call the method on\ndf\nitself, such as\ndf.fillna({\"foo\":\n0},\ninplace=True)\n.\nSee more details in the\nmigration guide\n.\nDeprecate aliases\nM\n,\nQ\n,\nY\n, etc. in favour of\nME\n,\nQE\n,\nYE\n, etc. for offsets\n#\nDeprecated the following frequency aliases (\nGH 9586\n):\noffsets\ndeprecated aliases\nnew aliases\nMonthEnd\nM\nME\nBusinessMonthEnd\nBM\nBME\nSemiMonthEnd\nSM\nSME\nCustomBusinessMonthEnd\nCBM\nCBME\nQuarterEnd\nQ\nQE\nBQuarterEnd\nBQ\nBQE\nYearEnd\nY\nYE\nBYearEnd\nBY\nBYE\nFor example:\nPrevious behavior\n:\nIn [8]:\npd\n.\ndate_range\n(\n'2020-01-01'\n,\nperiods\n=\n3\n,\nfreq\n=\n'Q-NOV'\n)\nOut[8]:\nDatetimeIndex(['2020-02-29', '2020-05-31', '2020-08-31'],\ndtype='datetime64[ns]', freq='Q-NOV')\nFuture behavior\n:\nIn [26]:\npd\n.\ndate_range\n(\n'2020-01-01'\n,\nperiods\n=\n3\n,\nfreq\n=\n'QE-NOV'\n)\nOut[26]:\nDatetimeIndex(['2020-02-29', '2020-05-31', '2020-08-31'], dtype='datetime64[ns]', freq='QE-NOV')\nDeprecated automatic downcasting\n#\nDeprecated the automatic downcasting of object dtype results in a number of\nmethods. These would silently change the dtype in a hard to predict manner since the\nbehavior was value dependent. Additionally, pandas is moving away from silent dtype\nchanges (\nGH 54710\n,\nGH 54261\n).\nThese methods are:\nSeries.replace()\nand\nDataFrame.replace()\nDataFrame.fillna()\n,\nSeries.fillna()\nDataFrame.ffill()\n,\nSeries.ffill()\nDataFrame.bfill()\n,\nSeries.bfill()\nDataFrame.mask()\n,\nSeries.mask()\nDataFrame.where()\n,\nSeries.where()\nDataFrame.clip()\n,\nSeries.clip()\nExplicitly call\nDataFrame.infer_objects()\nto replicate the current behavior in the future.\nresult\n=\nresult\n.\ninfer_objects\n(\ncopy\n=\nFalse\n)\nOr explicitly cast all-round floats to ints using\nastype\n.\nSet the following option to opt into the future behavior:\nIn [9]:\npd\n.\nset_option\n(\n\"future.no_silent_downcasting\"\n,\nTrue\n)\nOther Deprecations\n#\nChanged\nTimedelta.resolution_string()\nto return\nh\n,\nmin\n,\ns\n,\nms\n,\nus\n, and\nns\ninstead of\nH\n,\nT\n,\nS\n,\nL\n,\nU\n, and\nN\n, for compatibility with respective deprecations in frequency aliases (\nGH 52536\n)\nDeprecated\noffsets.Day.delta\n,\noffsets.Hour.delta\n,\noffsets.Minute.delta\n,\noffsets.Second.delta\n,\noffsets.Milli.delta\n,\noffsets.Micro.delta\n,\noffsets.Nano.delta\n, use\npd.Timedelta(obj)\ninstead (\nGH 55498\n)\nDeprecated\npandas.api.types.is_interval()\nand\npandas.api.types.is_period()\n, use\nisinstance(obj,\npd.Interval)\nand\nisinstance(obj,\npd.Period)\ninstead (\nGH 55264\n)\nDeprecated\nread_gbq()\nand\nDataFrame.to_gbq()\n. Use\npandas_gbq.read_gbq\nand\npandas_gbq.to_gbq\ninstead\nhttps://pandas-gbq.readthedocs.io/en/latest/api.html\n(\nGH 55525\n)\nDeprecated\nDataFrameGroupBy.fillna()\nand\nSeriesGroupBy.fillna()\n; use\nDataFrameGroupBy.ffill()\n,\nDataFrameGroupBy.bfill()\nfor forward and backward filling or\nDataFrame.fillna()\nto fill with a single value (or the Series equivalents) (\nGH 55718\n)\nDeprecated\nDateOffset.is_anchored()\n, use\nobj.n\n==\n1\nfor non-Tick subclasses (for Tick this was always False) (\nGH 55388\n)\nDeprecated\nDatetimeArray.__init__()\nand\nTimedeltaArray.__init__()\n, use\narray()\ninstead (\nGH 55623\n)\nDeprecated\nIndex.format()\n, use\nindex.astype(str)\nor\nindex.map(formatter)\ninstead (\nGH 55413\n)\nDeprecated\nSeries.ravel()\n, the underlying array is already 1D, so ravel is not necessary (\nGH 52511\n)\nDeprecated\nSeries.resample()\nand\nDataFrame.resample()\nwith a\nPeriodIndex\n(and the 芒convention芒 keyword), convert to\nDatetimeIndex\n(with\n.to_timestamp()\n) before resampling instead (\nGH 53481\n)\nDeprecated\nSeries.view()\n, use\nSeries.astype()\ninstead to change the dtype (\nGH 20251\n)\nDeprecated\noffsets.Tick.is_anchored()\n, use\nFalse\ninstead (\nGH 55388\n)\nDeprecated\ncore.internals\nmembers\nBlock\n,\nExtensionBlock\n, and\nDatetimeTZBlock\n, use public APIs instead (\nGH 55139\n)\nDeprecated\nyear\n,\nmonth\n,\nquarter\n,\nday\n,\nhour\n,\nminute\n, and\nsecond\nkeywords in the\nPeriodIndex\nconstructor, use\nPeriodIndex.from_fields()\ninstead (\nGH 55960\n)\nDeprecated accepting a type as an argument in\nIndex.view()\n, call without any arguments instead (\nGH 55709\n)\nDeprecated allowing non-integer\nperiods\nargument in\ndate_range()\n,\ntimedelta_range()\n,\nperiod_range()\n, and\ninterval_range()\n(\nGH 56036\n)\nDeprecated allowing non-keyword arguments in\nDataFrame.to_clipboard()\n(\nGH 54229\n)\nDeprecated allowing non-keyword arguments in\nDataFrame.to_csv()\nexcept\npath_or_buf\n(\nGH 54229\n)\nDeprecated allowing non-keyword arguments in\nDataFrame.to_dict()\n(\nGH 54229\n)\nDeprecated allowing non-keyword arguments in\nDataFrame.to_excel()\nexcept\nexcel_writer\n(\nGH 54229\n)\nDeprecated allowing non-keyword arguments in\nDataFrame.to_gbq()\nexcept\ndestination_table\n(\nGH 54229\n)\nDeprecated allowing non-keyword arguments in\nDataFrame.to_hdf()\nexcept\npath_or_buf\n(\nGH 54229\n)\nDeprecated allowing non-keyword arguments in\nDataFrame.to_html()\nexcept\nbuf\n(\nGH 54229\n)\nDeprecated allowing non-keyword arguments in\nDataFrame.to_json()\nexcept\npath_or_buf\n(\nGH 54229\n)\nDeprecated allowing non-keyword arguments in\nDataFrame.to_latex()\nexcept\nbuf\n(\nGH 54229\n)\nDeprecated allowing non-keyword arguments in\nDataFrame.to_markdown()\nexcept\nbuf\n(\nGH 54229\n)\nDeprecated allowing non-keyword arguments in\nDataFrame.to_parquet()\nexcept\npath\n(\nGH 54229\n)\nDeprecated allowing non-keyword arguments in\nDataFrame.to_pickle()\nexcept\npath\n(\nGH 54229\n)\nDeprecated allowing non-keyword arguments in\nDataFrame.to_string()\nexcept\nbuf\n(\nGH 54229\n)\nDeprecated allowing non-keyword arguments in\nDataFrame.to_xml()\nexcept\npath_or_buffer\n(\nGH 54229\n)\nDeprecated allowing passing\nBlockManager\nobjects to\nDataFrame\nor\nSingleBlockManager\nobjects to\nSeries\n(\nGH 52419\n)\nDeprecated behavior of\nIndex.insert()\nwith an object-dtype index silently performing type inference on the result, explicitly call\nresult.infer_objects(copy=False)\nfor the old behavior instead (\nGH 51363\n)\nDeprecated casting non-datetimelike values (mainly strings) in\nSeries.isin()\nand\nIndex.isin()\nwith\ndatetime64\n,\ntimedelta64\n, and\nPeriodDtype\ndtypes (\nGH 53111\n)\nDeprecated dtype inference in\nIndex\n,\nSeries\nand\nDataFrame\nconstructors when giving a pandas input, call\n.infer_objects\non the input to keep the current behavior (\nGH 56012\n)\nDeprecated dtype inference when setting a\nIndex\ninto a\nDataFrame\n, cast explicitly instead (\nGH 56102\n)\nDeprecated including the groups in computations when using\nDataFrameGroupBy.apply()\nand\nDataFrameGroupBy.resample()\n; pass\ninclude_groups=False\nto exclude the groups (\nGH 7155\n)\nDeprecated indexing an\nIndex\nwith a boolean indexer of length zero (\nGH 55820\n)\nDeprecated not passing a tuple to\nDataFrameGroupBy.get_group\nor\nSeriesGroupBy.get_group\nwhen grouping by a length-1 list-like (\nGH 25971\n)\nDeprecated string\nAS\ndenoting frequency in\nYearBegin\nand strings\nAS-DEC\n,\nAS-JAN\n, etc. denoting annual frequencies with various fiscal year starts (\nGH 54275\n)\nDeprecated string\nA\ndenoting frequency in\nYearEnd\nand strings\nA-DEC\n,\nA-JAN\n, etc. denoting annual frequencies with various fiscal year ends (\nGH 54275\n)\nDeprecated string\nBAS\ndenoting frequency in\nBYearBegin\nand strings\nBAS-DEC\n,\nBAS-JAN\n, etc. denoting annual frequencies with various fiscal year starts (\nGH 54275\n)\nDeprecated string\nBA\ndenoting frequency in\nBYearEnd\nand strings\nBA-DEC\n,\nBA-JAN\n, etc. denoting annual frequencies with various fiscal year ends (\nGH 54275\n)\nDeprecated strings\nH\n,\nBH\n, and\nCBH\ndenoting frequencies in\nHour\n,\nBusinessHour\n,\nCustomBusinessHour\n(\nGH 52536\n)\nDeprecated strings\nH\n,\nS\n,\nU\n, and\nN\ndenoting units in\nto_timedelta()\n(\nGH 52536\n)\nDeprecated strings\nH\n,\nT\n,\nS\n,\nL\n,\nU\n, and\nN\ndenoting units in\nTimedelta\n(\nGH 52536\n)\nDeprecated strings\nT\n,\nS\n,\nL\n,\nU\n, and\nN\ndenoting frequencies in\nMinute\n,\nSecond\n,\nMilli\n,\nMicro\n,\nNano\n(\nGH 52536\n)\nDeprecated support for combining parsed datetime columns in\nread_csv()\nalong with the\nkeep_date_col\nkeyword (\nGH 55569\n)\nDeprecated the\nDataFrameGroupBy.grouper\nand\nSeriesGroupBy.grouper\n; these attributes will be removed in a future version of pandas (\nGH 56521\n)\nDeprecated the\nGrouping\nattributes\ngroup_index\n,\nresult_index\n, and\ngroup_arraylike\n; these will be removed in a future version of pandas (\nGH 56148\n)\nDeprecated the\ndelim_whitespace\nkeyword in\nread_csv()\nand\nread_table()\n, use\nsep=\"\\\\s+\"\ninstead (\nGH 55569\n)\nDeprecated the\nerrors=\"ignore\"\noption in\nto_datetime()\n,\nto_timedelta()\n, and\nto_numeric()\n; explicitly catch exceptions instead (\nGH 54467\n)\nDeprecated the\nfastpath\nkeyword in the\nSeries\nconstructor (\nGH 20110\n)\nDeprecated the\nkind\nkeyword in\nSeries.resample()\nand\nDataFrame.resample()\n, explicitly cast the object芒s\nindex\ninstead (\nGH 55895\n)\nDeprecated the\nordinal\nkeyword in\nPeriodIndex\n, use\nPeriodIndex.from_ordinals()\ninstead (\nGH 55960\n)\nDeprecated the\nunit\nkeyword in\nTimedeltaIndex\nconstruction, use\nto_timedelta()\ninstead (\nGH 55499\n)\nDeprecated the\nverbose\nkeyword in\nread_csv()\nand\nread_table()\n(\nGH 55569\n)\nDeprecated the behavior of\nDataFrame.replace()\nand\nSeries.replace()\nwith\nCategoricalDtype\n; in a future version replace will change the values while preserving the categories. To change the categories, use\nser.cat.rename_categories\ninstead (\nGH 55147\n)\nDeprecated the behavior of\nSeries.value_counts()\nand\nIndex.value_counts()\nwith object dtype; in a future version these will not perform dtype inference on the resulting\nIndex\n, do\nresult.index\n=\nresult.index.infer_objects()\nto retain the old behavior (\nGH 56161\n)\nDeprecated the default of\nobserved=False\nin\nDataFrame.pivot_table()\n; will be\nTrue\nin a future version (\nGH 56236\n)\nDeprecated the extension test classes\nBaseNoReduceTests\n,\nBaseBooleanReduceTests\n, and\nBaseNumericReduceTests\n, use\nBaseReduceTests\ninstead (\nGH 54663\n)\nDeprecated the option\nmode.data_manager\nand the\nArrayManager\n; only the\nBlockManager\nwill be available in future versions (\nGH 55043\n)\nDeprecated the previous implementation of\nDataFrame.stack\n; specify\nfuture_stack=True\nto adopt the future version (\nGH 53515\n)\nPerformance improvements\n#\nPerformance improvement in\ntesting.assert_frame_equal()\nand\ntesting.assert_series_equal()\n(\nGH 55949\n,\nGH 55971\n)\nPerformance improvement in\nconcat()\nwith\naxis=1\nand objects with unaligned indexes (\nGH 55084\n)\nPerformance improvement in\nget_dummies()\n(\nGH 56089\n)\nPerformance improvement in\nmerge()\nand\nmerge_ordered()\nwhen joining on sorted ascending keys (\nGH 56115\n)\nPerformance improvement in\nmerge_asof()\nwhen\nby\nis not\nNone\n(\nGH 55580\n,\nGH 55678\n)\nPerformance improvement in\nread_stata()\nfor files with many variables (\nGH 55515\n)\nPerformance improvement in\nDataFrame.groupby()\nwhen aggregating pyarrow timestamp and duration dtypes (\nGH 55031\n)\nPerformance improvement in\nDataFrame.join()\nwhen joining on unordered categorical indexes (\nGH 56345\n)\nPerformance improvement in\nDataFrame.loc()\nand\nSeries.loc()\nwhen indexing with a\nMultiIndex\n(\nGH 56062\n)\nPerformance improvement in\nDataFrame.sort_index()\nand\nSeries.sort_index()\nwhen indexed by a\nMultiIndex\n(\nGH 54835\n)\nPerformance improvement in\nDataFrame.to_dict()\non converting DataFrame to dictionary (\nGH 50990\n)\nPerformance improvement in\nIndex.difference()\n(\nGH 55108\n)\nPerformance improvement in\nIndex.sort_values()\nwhen index is already sorted (\nGH 56128\n)\nPerformance improvement in\nMultiIndex.get_indexer()\nwhen\nmethod\nis not\nNone\n(\nGH 55839\n)\nPerformance improvement in\nSeries.duplicated()\nfor pyarrow dtypes (\nGH 55255\n)\nPerformance improvement in\nSeries.str.get_dummies()\nwhen dtype is\n\"string[pyarrow]\"\nor\n\"string[pyarrow_numpy]\"\n(\nGH 56110\n)\nPerformance improvement in\nSeries.str()\nmethods (\nGH 55736\n)\nPerformance improvement in\nSeries.value_counts()\nand\nSeries.mode()\nfor masked dtypes (\nGH 54984\n,\nGH 55340\n)\nPerformance improvement in\nDataFrameGroupBy.nunique()\nand\nSeriesGroupBy.nunique()\n(\nGH 55972\n)\nPerformance improvement in\nSeriesGroupBy.idxmax()\n,\nSeriesGroupBy.idxmin()\n,\nDataFrameGroupBy.idxmax()\n,\nDataFrameGroupBy.idxmin()\n(\nGH 54234\n)\nPerformance improvement when hashing a nullable extension array (\nGH 56507\n)\nPerformance improvement when indexing into a non-unique index (\nGH 55816\n)\nPerformance improvement when indexing with more than 4 keys (\nGH 54550\n)\nPerformance improvement when localizing time to UTC (\nGH 55241\n)\nBug fixes\n#\nCategorical\n#\nCategorical.isin()\nraising\nInvalidIndexError\nfor categorical containing overlapping\nInterval\nvalues (\nGH 34974\n)\nBug in\nCategoricalDtype.__eq__()\nreturning\nFalse\nfor unordered categorical data with mixed types (\nGH 55468\n)\nBug when casting\npa.dictionary\nto\nCategoricalDtype\nusing a\npa.DictionaryArray\nas categories (\nGH 56672\n)\nDatetimelike\n#\nBug in\nDatetimeIndex\nconstruction when passing both a\ntz\nand either\ndayfirst\nor\nyearfirst\nignoring dayfirst/yearfirst (\nGH 55813\n)\nBug in\nDatetimeIndex\nwhen passing an object-dtype ndarray of float objects and a\ntz\nincorrectly localizing the result (\nGH 55780\n)\nBug in\nSeries.isin()\nwith\nDatetimeTZDtype\ndtype and comparison values that are all\nNaT\nincorrectly returning all-\nFalse\neven if the series contains\nNaT\nentries (\nGH 56427\n)\nBug in\nconcat()\nraising\nAttributeError\nwhen concatenating all-NA DataFrame with\nDatetimeTZDtype\ndtype DataFrame (\nGH 52093\n)\nBug in\ntesting.assert_extension_array_equal()\nthat could use the wrong unit when comparing resolutions (\nGH 55730\n)\nBug in\nto_datetime()\nand\nDatetimeIndex\nwhen passing a list of mixed-string-and-numeric types incorrectly raising (\nGH 55780\n)\nBug in\nto_datetime()\nand\nDatetimeIndex\nwhen passing mixed-type objects with a mix of timezones or mix of timezone-awareness failing to raise\nValueError\n(\nGH 55693\n)\nBug in\nTick.delta()\nwith very large ticks raising\nOverflowError\ninstead of\nOutOfBoundsTimedelta\n(\nGH 55503\n)\nBug in\nDatetimeIndex.shift()\nwith non-nanosecond resolution incorrectly returning with nanosecond resolution (\nGH 56117\n)\nBug in\nDatetimeIndex.union()\nreturning object dtype for tz-aware indexes with the same timezone but different units (\nGH 55238\n)\nBug in\nIndex.is_monotonic_increasing()\nand\nIndex.is_monotonic_decreasing()\nalways caching\nIndex.is_unique()\nas\nTrue\nwhen first value in index is\nNaT\n(\nGH 55755\n)\nBug in\nIndex.view()\nto a datetime64 dtype with non-supported resolution incorrectly raising (\nGH 55710\n)\nBug in\nSeries.dt.round()\nwith non-nanosecond resolution and\nNaT\nentries incorrectly raising\nOverflowError\n(\nGH 56158\n)\nBug in\nSeries.fillna()\nwith non-nanosecond resolution dtypes and higher-resolution vector values returning incorrect (internally-corrupted) results (\nGH 56410\n)\nBug in\nTimestamp.unit()\nbeing inferred incorrectly from an ISO8601 format string with minute or hour resolution and a timezone offset (\nGH 56208\n)\nBug in\n.astype\nconverting from a higher-resolution\ndatetime64\ndtype to a lower-resolution\ndatetime64\ndtype (e.g.\ndatetime64[us]->datetime64[ms]\n) silently overflowing with values near the lower implementation bound (\nGH 55979\n)\nBug in adding or subtracting a\nWeek\noffset to a\ndatetime64\nSeries\n,\nIndex\n, or\nDataFrame\ncolumn with non-nanosecond resolution returning incorrect results (\nGH 55583\n)\nBug in addition or subtraction of\nBusinessDay\noffset with\noffset\nattribute to non-nanosecond\nIndex\n,\nSeries\n, or\nDataFrame\ncolumn giving incorrect results (\nGH 55608\n)\nBug in addition or subtraction of\nDateOffset\nobjects with microsecond components to\ndatetime64\nIndex\n,\nSeries\n, or\nDataFrame\ncolumns with non-nanosecond resolution (\nGH 55595\n)\nBug in addition or subtraction of very large\nTick\nobjects with\nTimestamp\nor\nTimedelta\nobjects raising\nOverflowError\ninstead of\nOutOfBoundsTimedelta\n(\nGH 55503\n)\nBug in creating a\nIndex\n,\nSeries\n, or\nDataFrame\nwith a non-nanosecond\nDatetimeTZDtype\nand inputs that would be out of bounds with nanosecond resolution incorrectly raising\nOutOfBoundsDatetime\n(\nGH 54620\n)\nBug in creating a\nIndex\n,\nSeries\n, or\nDataFrame\nwith a non-nanosecond\ndatetime64\n(or\nDatetimeTZDtype\n) from mixed-numeric inputs treating those as nanoseconds instead of as multiples of the dtype芒s unit (which would happen with non-mixed numeric inputs) (\nGH 56004\n)\nBug in creating a\nIndex\n,\nSeries\n, or\nDataFrame\nwith a non-nanosecond\ndatetime64\ndtype and inputs that would be out of bounds for a\ndatetime64[ns]\nincorrectly raising\nOutOfBoundsDatetime\n(\nGH 55756\n)\nBug in parsing datetime strings with nanosecond resolution with non-ISO8601 formats incorrectly truncating sub-microsecond components (\nGH 56051\n)\nBug in parsing datetime strings with sub-second resolution and trailing zeros incorrectly inferring second or millisecond resolution (\nGH 55737\n)\nBug in the results of\nto_datetime()\nwith an floating-dtype argument with\nunit\nnot matching the pointwise results of\nTimestamp\n(\nGH 56037\n)\nFixed regression where\nconcat()\nwould raise an error when concatenating\ndatetime64\ncolumns with differing resolutions (\nGH 53641\n)\nTimedelta\n#\nBug in\nTimedelta\nconstruction raising\nOverflowError\ninstead of\nOutOfBoundsTimedelta\n(\nGH 55503\n)\nBug in rendering (\n__repr__\n) of\nTimedeltaIndex\nand\nSeries\nwith timedelta64 values with non-nanosecond resolution entries that are all multiples of 24 hours failing to use the compact representation used in the nanosecond cases (\nGH 55405\n)\nTimezones\n#\nBug in\nAbstractHolidayCalendar\nwhere timezone data was not propagated when computing holiday observances (\nGH 54580\n)\nBug in\nTimestamp\nconstruction with an ambiguous value and a\npytz\ntimezone failing to raise\npytz.AmbiguousTimeError\n(\nGH 55657\n)\nBug in\nTimestamp.tz_localize()\nwith\nnonexistent=\"shift_forward\naround UTC+0 during DST (\nGH 51501\n)\nNumeric\n#\nBug in\nread_csv()\nwith\nengine=\"pyarrow\"\ncausing rounding errors for large integers (\nGH 52505\n)\nBug in\nSeries.__floordiv__()\nand\nSeries.__truediv__()\nfor\nArrowDtype\nwith integral dtypes raising for large divisors (\nGH 56706\n)\nBug in\nSeries.__floordiv__()\nfor\nArrowDtype\nwith integral dtypes raising for large values (\nGH 56645\n)\nBug in\nSeries.pow()\nnot filling missing values correctly (\nGH 55512\n)\nBug in\nSeries.replace()\nand\nDataFrame.replace()\nmatching float\n0.0\nwith\nFalse\nand vice versa (\nGH 55398\n)\nBug in\nSeries.round()\nraising for nullable boolean dtype (\nGH 55936\n)\nConversion\n#\nBug in\nDataFrame.astype()\nwhen called with\nstr\non unpickled array - the array might change in-place (\nGH 54654\n)\nBug in\nDataFrame.astype()\nwhere\nerrors=\"ignore\"\nhad no effect for extension types (\nGH 54654\n)\nBug in\nSeries.convert_dtypes()\nnot converting all NA column to\nnull[pyarrow]\n(\nGH 55346\n)\nBug in :meth:\nDataFrame.loc\nwas not throwing 芒incompatible dtype warning芒 (see\nPDEP6\n) when assigning a\nSeries\nwith a different dtype using a full column setter (e.g.\ndf.loc[:,\n'a']\n=\nincompatible_value\n) (\nGH 39584\n)\nStrings\n#\nBug in\npandas.api.types.is_string_dtype()\nwhile checking object array with no elements is of the string dtype (\nGH 54661\n)\nBug in\nDataFrame.apply()\nfailing when\nengine=\"numba\"\nand columns or index have\nStringDtype\n(\nGH 56189\n)\nBug in\nDataFrame.reindex()\nnot matching\nIndex\nwith\nstring[pyarrow_numpy]\ndtype (\nGH 56106\n)\nBug in\nIndex.str.cat()\nalways casting result to object dtype (\nGH 56157\n)\nBug in\nSeries.__mul__()\nfor\nArrowDtype\nwith\npyarrow.string\ndtype and\nstring[pyarrow]\nfor the pyarrow backend (\nGH 51970\n)\nBug in\nSeries.str.find()\nwhen\nstart\n<\n0\nfor\nArrowDtype\nwith\npyarrow.string\n(\nGH 56411\n)\nBug in\nSeries.str.fullmatch()\nwhen\ndtype=pandas.ArrowDtype(pyarrow.string()))\nallows partial matches when regex ends in literal //$ (\nGH 56652\n)\nBug in\nSeries.str.replace()\nwhen\nn\n<\n0\nfor\nArrowDtype\nwith\npyarrow.string\n(\nGH 56404\n)\nBug in\nSeries.str.startswith()\nand\nSeries.str.endswith()\nwith arguments of type\ntuple[str,\n...]\nfor\nArrowDtype\nwith\npyarrow.string\ndtype (\nGH 56579\n)\nBug in\nSeries.str.startswith()\nand\nSeries.str.endswith()\nwith arguments of type\ntuple[str,\n...]\nfor\nstring[pyarrow]\n(\nGH 54942\n)\nBug in comparison operations for\ndtype=\"string[pyarrow_numpy]\"\nraising if dtypes can芒t be compared (\nGH 56008\n)\nInterval\n#\nBug in\nInterval\n__repr__\nnot displaying UTC offsets for\nTimestamp\nbounds. Additionally the hour, minute and second components will now be shown (\nGH 55015\n)\nBug in\nIntervalIndex.factorize()\nand\nSeries.factorize()\nwith\nIntervalDtype\nwith datetime64 or timedelta64 intervals not preserving non-nanosecond units (\nGH 56099\n)\nBug in\nIntervalIndex.from_arrays()\nwhen passed\ndatetime64\nor\ntimedelta64\narrays with mismatched resolutions constructing an invalid\nIntervalArray\nobject (\nGH 55714\n)\nBug in\nIntervalIndex.from_tuples()\nraising if subtype is a nullable extension dtype (\nGH 56765\n)\nBug in\nIntervalIndex.get_indexer()\nwith datetime or timedelta intervals incorrectly matching on integer targets (\nGH 47772\n)\nBug in\nIntervalIndex.get_indexer()\nwith timezone-aware datetime intervals incorrectly matching on a sequence of timezone-naive targets (\nGH 47772\n)\nBug in setting values on a\nSeries\nwith an\nIntervalIndex\nusing a slice incorrectly raising (\nGH 54722\n)\nIndexing\n#\nBug in\nDataFrame.loc()\nmutating a boolean indexer when\nDataFrame\nhas a\nMultiIndex\n(\nGH 56635\n)\nBug in\nDataFrame.loc()\nwhen setting\nSeries\nwith extension dtype into NumPy dtype (\nGH 55604\n)\nBug in\nIndex.difference()\nnot returning a unique set of values when\nother\nis empty or\nother\nis considered non-comparable (\nGH 55113\n)\nBug in setting\nCategorical\nvalues into a\nDataFrame\nwith numpy dtypes raising\nRecursionError\n(\nGH 52927\n)\nFixed bug when creating new column with missing values when setting a single string value (\nGH 56204\n)\nMissing\n#\nBug in\nDataFrame.update()\nwasn芒t updating in-place for tz-aware datetime64 dtypes (\nGH 56227\n)\nMultiIndex\n#\nBug in\nMultiIndex.get_indexer()\nnot raising\nValueError\nwhen\nmethod\nprovided and index is non-monotonic (\nGH 53452\n)\nI/O\n#\nBug in\nread_csv()\nwhere\nengine=\"python\"\ndid not respect\nchunksize\narg when\nskiprows\nwas specified (\nGH 56323\n)\nBug in\nread_csv()\nwhere\nengine=\"python\"\nwas causing a\nTypeError\nwhen a callable\nskiprows\nand a chunk size was specified (\nGH 55677\n)\nBug in\nread_csv()\nwhere\non_bad_lines=\"warn\"\nwould write to\nstderr\ninstead of raising a Python warning; this now yields a\nerrors.ParserWarning\n(\nGH 54296\n)\nBug in\nread_csv()\nwith\nengine=\"pyarrow\"\nwhere\nquotechar\nwas ignored (\nGH 52266\n)\nBug in\nread_csv()\nwith\nengine=\"pyarrow\"\nwhere\nusecols\nwasn芒t working with a CSV with no headers (\nGH 54459\n)\nBug in\nread_excel()\n, with\nengine=\"xlrd\"\n(\nxls\nfiles) erroring when the file contains\nNaN\nor\nInf\n(\nGH 54564\n)\nBug in\nread_json()\nnot handling dtype conversion properly if\ninfer_string\nis set (\nGH 56195\n)\nBug in\nDataFrame.to_excel()\n, with\nOdsWriter\n(\nods\nfiles) writing Boolean/string value (\nGH 54994\n)\nBug in\nDataFrame.to_hdf()\nand\nread_hdf()\nwith\ndatetime64\ndtypes with non-nanosecond resolution failing to round-trip correctly (\nGH 55622\n)\nBug in\nDataFrame.to_stata()\nraising for extension dtypes (\nGH 54671\n)\nBug in\nread_excel()\nwith\nengine=\"odf\"\n(\nods\nfiles) when a string cell contains an annotation (\nGH 55200\n)\nBug in\nread_excel()\nwith an ODS file without cached formatted cell for float values (\nGH 55219\n)\nBug where\nDataFrame.to_json()\nwould raise an\nOverflowError\ninstead of a\nTypeError\nwith unsupported NumPy types (\nGH 55403\n)\nPeriod\n#\nBug in\nPeriodIndex\nconstruction when more than one of\ndata\n,\nordinal\nand\n**fields\nare passed failing to raise\nValueError\n(\nGH 55961\n)\nBug in\nPeriod\naddition silently wrapping around instead of raising\nOverflowError\n(\nGH 55503\n)\nBug in casting from\nPeriodDtype\nwith\nastype\nto\ndatetime64\nor\nDatetimeTZDtype\nwith non-nanosecond unit incorrectly returning with nanosecond unit (\nGH 55958\n)\nPlotting\n#\nBug in\nDataFrame.plot.box()\nwith\nvert=False\nand a Matplotlib\nAxes\ncreated with\nsharey=True\n(\nGH 54941\n)\nBug in\nDataFrame.plot.scatter()\ndiscarding string columns (\nGH 56142\n)\nBug in\nSeries.plot()\nwhen reusing an\nax\nobject failing to raise when a\nhow\nkeyword is passed (\nGH 55953\n)\nGroupby/resample/rolling\n#\nBug in\nDataFrameGroupBy.idxmin()\n,\nDataFrameGroupBy.idxmax()\n,\nSeriesGroupBy.idxmin()\n, and\nSeriesGroupBy.idxmax()\nwould not retain\nCategorical\ndtype when the index was a\nCategoricalIndex\nthat contained NA values (\nGH 54234\n)\nBug in\nDataFrameGroupBy.transform()\nand\nSeriesGroupBy.transform()\nwhen\nobserved=False\nand\nf=\"idxmin\"\nor\nf=\"idxmax\"\nwould incorrectly raise on unobserved categories (\nGH 54234\n)\nBug in\nDataFrameGroupBy.value_counts()\nand\nSeriesGroupBy.value_counts()\ncould result in incorrect sorting if the columns of the DataFrame or name of the Series are integers (\nGH 55951\n)\nBug in\nDataFrameGroupBy.value_counts()\nand\nSeriesGroupBy.value_counts()\nwould not respect\nsort=False\nin\nDataFrame.groupby()\nand\nSeries.groupby()\n(\nGH 55951\n)\nBug in\nDataFrameGroupBy.value_counts()\nand\nSeriesGroupBy.value_counts()\nwould sort by proportions rather than frequencies when\nsort=True\nand\nnormalize=True\n(\nGH 55951\n)\nBug in\nDataFrame.asfreq()\nand\nSeries.asfreq()\nwith a\nDatetimeIndex\nwith non-nanosecond resolution incorrectly converting to nanosecond resolution (\nGH 55958\n)\nBug in\nDataFrame.ewm()\nwhen passed\ntimes\nwith non-nanosecond\ndatetime64\nor\nDatetimeTZDtype\ndtype (\nGH 56262\n)\nBug in\nDataFrame.groupby()\nand\nSeries.groupby()\nwhere grouping by a combination of\nDecimal\nand NA values would fail when\nsort=True\n(\nGH 54847\n)\nBug in\nDataFrame.groupby()\nfor DataFrame subclasses when selecting a subset of columns to apply the function to (\nGH 56761\n)\nBug in\nDataFrame.resample()\nnot respecting\nclosed\nand\nlabel\narguments for\nBusinessDay\n(\nGH 55282\n)\nBug in\nDataFrame.resample()\nwhen resampling on a\nArrowDtype\nof\npyarrow.timestamp\nor\npyarrow.duration\ntype (\nGH 55989\n)\nBug in\nDataFrame.resample()\nwhere bin edges were not correct for\nBusinessDay\n(\nGH 55281\n)\nBug in\nDataFrame.resample()\nwhere bin edges were not correct for\nMonthBegin\n(\nGH 55271\n)\nBug in\nDataFrame.rolling()\nand\nSeries.rolling()\nwhere duplicate datetimelike indexes are treated as consecutive rather than equal with\nclosed='left'\nand\nclosed='neither'\n(\nGH 20712\n)\nBug in\nDataFrame.rolling()\nand\nSeries.rolling()\nwhere either the\nindex\nor\non\ncolumn was\nArrowDtype\nwith\npyarrow.timestamp\ntype (\nGH 55849\n)\nReshaping\n#\nBug in\nconcat()\nignoring\nsort\nparameter when passed\nDatetimeIndex\nindexes (\nGH 54769\n)\nBug in\nconcat()\nrenaming\nSeries\nwhen\nignore_index=False\n(\nGH 15047\n)\nBug in\nmerge_asof()\nraising\nTypeError\nwhen\nby\ndtype is not\nobject\n,\nint64\n, or\nuint64\n(\nGH 22794\n)\nBug in\nmerge_asof()\nraising incorrect error for string dtype (\nGH 56444\n)\nBug in\nmerge_asof()\nwhen using a\nTimedelta\ntolerance on a\nArrowDtype\ncolumn (\nGH 56486\n)\nBug in\nmerge()\nnot raising when merging datetime columns with timedelta columns (\nGH 56455\n)\nBug in\nmerge()\nnot raising when merging string columns with numeric columns (\nGH 56441\n)\nBug in\nmerge()\nnot sorting for new string dtype (\nGH 56442\n)\nBug in\nmerge()\nreturning columns in incorrect order when left and/or right is empty (\nGH 51929\n)\nBug in\nDataFrame.melt()\nwhere an exception was raised if\nvar_name\nwas not a string (\nGH 55948\n)\nBug in\nDataFrame.melt()\nwhere it would not preserve the datetime (\nGH 55254\n)\nBug in\nDataFrame.pivot_table()\nwhere the row margin is incorrect when the columns have numeric names (\nGH 26568\n)\nBug in\nDataFrame.pivot()\nwith numeric columns and extension dtype for data (\nGH 56528\n)\nBug in\nDataFrame.stack()\nwith\nfuture_stack=True\nwould not preserve NA values in the index (\nGH 56573\n)\nSparse\n#\nBug in\narrays.SparseArray.take()\nwhen using a different fill value than the array芒s fill value (\nGH 55181\n)\nOther\n#\nDataFrame.__dataframe__()\ndid not support pyarrow large strings (\nGH 56702\n)\nBug in\nDataFrame.describe()\nwhen formatting percentiles in the resulting percentile 99.999% is rounded to 100% (\nGH 55765\n)\nBug in\napi.interchange.from_dataframe()\nwhere it raised\nNotImplementedError\nwhen handling empty string columns (\nGH 56703\n)\nBug in\ncut()\nand\nqcut()\nwith\ndatetime64\ndtype values with non-nanosecond units incorrectly returning nanosecond-unit bins (\nGH 56101\n)\nBug in\ncut()\nincorrectly allowing cutting of timezone-aware datetimes with timezone-naive bins (\nGH 54964\n)\nBug in\ninfer_freq()\nand\nDatetimeIndex.inferred_freq()\nwith weekly frequencies and non-nanosecond resolutions (\nGH 55609\n)\nBug in\nDataFrame.apply()\nwhere passing\nraw=True\nignored\nargs\npassed to the applied function (\nGH 55009\n)\nBug in\nDataFrame.from_dict()\nwhich would always sort the rows of the created\nDataFrame\n.  (\nGH 55683\n)\nBug in\nDataFrame.sort_index()\nwhen passing\naxis=\"columns\"\nand\nignore_index=True\nraising a\nValueError\n(\nGH 56478\n)\nBug in rendering\ninf\nvalues inside a\nDataFrame\nwith the\nuse_inf_as_na\noption enabled (\nGH 55483\n)\nBug in rendering a\nSeries\nwith a\nMultiIndex\nwhen one of the index level芒s names is 0 not having that name displayed (\nGH 55415\n)\nBug in the error message when assigning an empty\nDataFrame\nto a column (\nGH 55956\n)\nBug when time-like strings were being cast to\nArrowDtype\nwith\npyarrow.time64\ntype (\nGH 56463\n)\nFixed a spurious deprecation warning from\nnumba\n>= 0.58.0 when passing a numpy ufunc in\ncore.window.Rolling.apply\nwith\nengine=\"numba\"\n(\nGH 55247\n)\nContributors\n#\nA total of 162 people contributed patches to this release.  People with a\n芒+芒 by their names contributed a patch for the first time.\nAG\nAaron Rahman +\nAbdullah Ihsan Secer +\nAbhijit Deo +\nAdrian D芒Alessandro\nAhmad Mustafa Anis +\nAmanda Bizzinotto\nAmith KK +\nAniket Patil +\nAntonio Fonseca +\nArtur Barseghyan\nBen Greiner\nBill Blum +\nBoyd Kane\nDamian Kula\nDan King +\nDaniel Weindl +\nDaniele Nicolodi\nDavid Poznik\nDavid Toneian +\nDea Mar颅a L漏on\nDeepak George +\nDmitriy +\nDominique Garmier +\nDonald Thevalingam +\nDoug Davis +\nDukastlik +\nElahe Sharifi +\nEric Han +\nFangchen Li\nFrancisco Alfaro +\nGadea Autric +\nGuillaume Lemaitre\nHadi Abdi Khojasteh\nHedeer El Showk +\nHuanghz2001 +\nIsaac Virshup\nIssam +\nItay Azolay +\nItayazolay +\nJaca +\nJack McIvor +\nJackCollins91 +\nJames Spencer +\nJay\nJessica Greene\nJirka Borovec +\nJohannaTrost +\nJohn C +\nJoris Van den Bossche\nJos漏 Lucas Mayer +\nJos漏 Lucas Silva Mayer +\nJo拢o Andrade +\nKai M录hlbauer\nKatharina Tielking, MD +\nKazuto Haruguchi +\nKevin\nLawrence Mitchell\nLinus +\nLinus Sommer +\nLouis-mile Robitaille +\nLuke Manley\nLumberbot (aka Jack)\nMaggie Liu +\nMainHanzo +\nMarc Garcia\nMarco Edward Gorelli\nMarcoGorelli\nMartin 颅cho +\nMateusz Sok鲁\nMatheus Felipe +\nMatthew Roeschke\nMatthias Bussonnier\nMaxwell Bileschi +\nMichael Tiemann\nMicha G鲁rny\nMolly Bowers +\nMoritz Schubert +\nNNLNR +\nNatalia Mokeeva\nNils M录ller-Wendt +\nOmar Elbaz\nPandas Development Team\nParas Gupta +\nParthi\nPatrick Hoefler\nPaul Pellissier +\nPaul Uhlenbruck +\nPhilip Meier\nPhilippe THOMY +\nQuang Nguy谩禄n\nRaghav\nRajat Subhra Mukherjee\nRalf Gommers\nRandolf Scholz +\nRichard Shadrach\nRob +\nRohan Jain +\nRyan Gibson +\nSai-Suraj-27 +\nSamuel Oranyeli +\nSara Bonati +\nSebastian Berg\nSergey Zakharov +\nShyamala Venkatakrishnan +\nStEmGeo +\nStefanie Molin\nStijn de Gooijer +\nThiago Gariani +\nThomas A Caswell\nThomas Baumann +\nThomas Guillet +\nThomas Lazarus +\nThomas Li\nTim Hoffmann\nTim Swast\nTom Augspurger\nToro +\nTorsten W露rtwein\nVille Aikas +\nVinita Parasrampuria +\nVyas Ramasubramani +\nWilliam Andrea\nWilliam Ayd\nWillian Wang +\nXiao Yuan\nYao Xiao\nYves Delley\nZemux1613 +\nZiad Kermadi +\naaron-robeson-8451 +\naram-cinnamon +\ncaneff +\nccccjone +\nchris-caballero +\ncobalt\ncolor455nm +\ndenisrei +\ndependabot[bot]\njbrockmendel\njfadia +\njohanna.trost +\nkgmuzungu +\nmecopur +\nmhb143 +\nmorotti +\nmvirts +\nomar-elbaz\npaulreece\npre-commit-ci[bot]\nraj-thapa\nrebecca-palmer\nrmhowe425\nrohanjain101\nshiersansi +\nsmij720\nsrkds +\ntaytzehao\ntorext\nvboxuser +\nxzmeng +\nyashb +\nprevious\nRelease notes\nnext\nWhat芒s new in 2.1.4 (December 8, 2023)\nOn this page\nUpcoming changes in pandas 3.0\nCopy-on-Write\nDedicated string data type (backed by Arrow) by default\nEnhancements\nADBC Driver support in to_sql and read_sql\nCreate a pandas Series based on one or more conditions\nto_numpy\nfor NumPy nullable and Arrow types converts to suitable NumPy dtype\nSeries.struct accessor for PyArrow structured data\nSeries.list accessor for PyArrow list data\nCalamine engine for\nread_excel()\nOther enhancements\nNotable bug fixes\nmerge()\nand\nDataFrame.join()\nnow consistently follow documented sort behavior\nmerge()\nand\nDataFrame.join()\nno longer reorder levels when levels differ\nIncreased minimum versions for dependencies\nOther API changes\nDeprecations\nChained assignment\nDeprecate aliases\nM\n,\nQ\n,\nY\n, etc. in favour of\nME\n,\nQE\n,\nYE\n, etc. for offsets\nDeprecated automatic downcasting\nOther Deprecations\nPerformance improvements\nBug fixes\nCategorical\nDatetimelike\nTimedelta\nTimezones\nNumeric\nConversion\nStrings\nInterval\nIndexing\nMissing\nMultiIndex\nI/O\nPeriod\nPlotting\nGroupby/resample/rolling\nReshaping\nSparse\nOther\nContributors\nShow Source",
    "crawl_status": "success"
  },
  {
    "library_name": "Pandas",
    "url": "https://pandas.pydata.org/pandas-docs/version/2.0/whatsnew/v2.0.0.html",
    "version": "v2.0.0.html",
    "title": "What芒s new in 2.0.0 (April 3, 2023)  pandas 2.0.3 documentation",
    "release_date": "Unknown release date",
    "content": "What芒s new in 2.0.0 (April 3, 2023)\n#\nThese are the changes in pandas 2.0.0. See\nRelease notes\nfor a full changelog\nincluding other versions of pandas.\nEnhancements\n#\nInstalling optional dependencies with pip extras\n#\nWhen installing pandas using pip, sets of optional dependencies can also be installed by specifying extras.\npip\ninstall\n\"pandas[performance, aws]>=2.0.0\"\nThe available extras, found in the\ninstallation guide\n, are\n[all,\nperformance,\ncomputation,\nfss,\naws,\ngcp,\nexcel,\nparquet,\nfeather,\nhdf5,\nspss,\npostgresql,\nmysql,\nsql-other,\nhtml,\nxml,\nplot,\noutput_formatting,\nclipboard,\ncompression,\ntest]\n(\nGH39164\n).\nIndex\ncan now hold numpy numeric dtypes\n#\nIt is now possible to use any numpy numeric dtype in a\nIndex\n(\nGH42717\n).\nPreviously it was only possible to use\nint64\n,\nuint64\n&\nfloat64\ndtypes:\nIn [1]:\npd\n.\nIndex\n([\n1\n,\n2\n,\n3\n],\ndtype\n=\nnp\n.\nint8\n)\nOut[1]:\nInt64Index([1, 2, 3], dtype=\"int64\")\nIn [2]:\npd\n.\nIndex\n([\n1\n,\n2\n,\n3\n],\ndtype\n=\nnp\n.\nuint16\n)\nOut[2]:\nUInt64Index([1, 2, 3], dtype=\"uint64\")\nIn [3]:\npd\n.\nIndex\n([\n1\n,\n2\n,\n3\n],\ndtype\n=\nnp\n.\nfloat32\n)\nOut[3]:\nFloat64Index([1.0, 2.0, 3.0], dtype=\"float64\")\nInt64Index\n,\nUInt64Index\n&\nFloat64Index\nwere deprecated in pandas\nversion 1.4 and have now been removed. Instead\nIndex\nshould be used directly, and\ncan it now take all numpy numeric dtypes, i.e.\nint8\n/\nint16\n/\nint32\n/\nint64\n/\nuint8\n/\nuint16\n/\nuint32\n/\nuint64\n/\nfloat32\n/\nfloat64\ndtypes:\nIn [1]:\npd\n.\nIndex\n([\n1\n,\n2\n,\n3\n],\ndtype\n=\nnp\n.\nint8\n)\nOut[1]:\nIndex([1, 2, 3], dtype='int8')\nIn [2]:\npd\n.\nIndex\n([\n1\n,\n2\n,\n3\n],\ndtype\n=\nnp\n.\nuint16\n)\nOut[2]:\nIndex([1, 2, 3], dtype='uint16')\nIn [3]:\npd\n.\nIndex\n([\n1\n,\n2\n,\n3\n],\ndtype\n=\nnp\n.\nfloat32\n)\nOut[3]:\nIndex([1.0, 2.0, 3.0], dtype='float32')\nThe ability for\nIndex\nto hold the numpy numeric dtypes has meant some changes in Pandas\nfunctionality. In particular, operations that previously were forced to create 64-bit indexes,\ncan now create indexes with lower bit sizes, e.g. 32-bit indexes.\nBelow is a possibly non-exhaustive list of changes:\nInstantiating using a numpy numeric array now follows the dtype of the numpy array.\nPreviously, all indexes created from numpy numeric arrays were forced to 64-bit. Now,\nfor example,\nIndex(np.array([1,\n2,\n3]))\nwill be\nint32\non 32-bit systems, where\nit previously would have been\nint64\neven on 32-bit systems.\nInstantiating\nIndex\nusing a list of numbers will still return 64bit dtypes,\ne.g.\nIndex([1,\n2,\n3])\nwill have a\nint64\ndtype, which is the same as previously.\nThe various numeric datetime attributes of\nDatetimeIndex\n(\nday\n,\nmonth\n,\nyear\netc.) were previously in of\ndtype\nint64\n, while they were\nint32\nfor\narrays.DatetimeArray\n. They are now\nint32\non\nDatetimeIndex\nalso:\nIn [4]:\nidx\n=\npd\n.\ndate_range\n(\nstart\n=\n'1/1/2018'\n,\nperiods\n=\n3\n,\nfreq\n=\n'M'\n)\nIn [5]:\nidx\n.\narray\n.\nyear\nOut[5]:\narray([2018, 2018, 2018], dtype=int32)\nIn [6]:\nidx\n.\nyear\nOut[6]:\nIndex([2018, 2018, 2018], dtype='int32')\nLevel dtypes on Indexes from\nSeries.sparse.from_coo()\nare now of dtype\nint32\n,\nthe same as they are on the\nrows\n/\ncols\non a scipy sparse matrix. Previously they\nwere of dtype\nint64\n.\nIn [7]:\nfrom\nscipy\nimport\nsparse\nIn [8]:\nA\n=\nsparse\n.\ncoo_matrix\n(\n...:\n([\n3.0\n,\n1.0\n,\n2.0\n],\n([\n1\n,\n0\n,\n0\n],\n[\n0\n,\n2\n,\n3\n])),\nshape\n=\n(\n3\n,\n4\n)\n...:\n)\n...:\nIn [9]:\nser\n=\npd\n.\nSeries\n.\nsparse\n.\nfrom_coo\n(\nA\n)\nIn [10]:\nser\n.\nindex\n.\ndtypes\nOut[10]:\nlevel_0    int32\nlevel_1    int32\ndtype: object\nIndex\ncannot be instantiated using a float16 dtype. Previously instantiating\nan\nIndex\nusing dtype\nfloat16\nresulted in a\nFloat64Index\nwith a\nfloat64\ndtype. It now raises a\nNotImplementedError\n:\nIn [11]:\npd\n.\nIndex\n([\n1\n,\n2\n,\n3\n],\ndtype\n=\nnp\n.\nfloat16\n)\n---------------------------------------------------------------------------\nNotImplementedError\nTraceback (most recent call last)\nCell\nIn\n[\n11\n],\nline\n1\n---->\n1\npd\n.\nIndex\n([\n1\n,\n2\n,\n3\n],\ndtype\n=\nnp\n.\nfloat16\n)\nFile ~/work/pandas/pandas/pandas/core/indexes/base.py:562,\nin\nIndex.__new__\n(cls, data, dtype, copy, name, tupleize_cols)\n558\narr\n=\nensure_wrapped_if_datetimelike\n(\narr\n)\n560\nklass\n=\ncls\n.\n_dtype_to_subclass\n(\narr\n.\ndtype\n)\n-->\n562\narr\n=\nklass\n.\n_ensure_array\n(\narr\n,\narr\n.\ndtype\n,\ncopy\n=\nFalse\n)\n563\nreturn\nklass\n.\n_simple_new\n(\narr\n,\nname\n,\nrefs\n=\nrefs\n)\nFile ~/work/pandas/pandas/pandas/core/indexes/base.py:575,\nin\nIndex._ensure_array\n(cls, data, dtype, copy)\n572\nraise\nValueError\n(\n\"Index data must be 1-dimensional\"\n)\n573\nelif\ndtype\n==\nnp\n.\nfloat16\n:\n574\n# float16 not supported (no indexing engine)\n-->\n575\nraise\nNotImplementedError\n(\n\"float16 indexes are not supported\"\n)\n577\nif\ncopy\n:\n578\n# asarray_tuplesafe does not always copy underlying data,\n579\n#  so need to make sure that this happens\n580\ndata\n=\ndata\n.\ncopy\n()\nNotImplementedError\n: float16 indexes are not supported\nArgument\ndtype_backend\n, to return pyarrow-backed or numpy-backed nullable dtypes\n#\nThe following functions gained a new keyword\ndtype_backend\n(\nGH36712\n)\nread_csv()\nread_clipboard()\nread_fwf()\nread_excel()\nread_html()\nread_xml()\nread_json()\nread_sql()\nread_sql_query()\nread_sql_table()\nread_parquet()\nread_orc()\nread_feather()\nread_spss()\nto_numeric()\nDataFrame.convert_dtypes()\nSeries.convert_dtypes()\nWhen this option is set to\n\"numpy_nullable\"\nit will return a\nDataFrame\nthat is\nbacked by nullable dtypes.\nWhen this keyword is set to\n\"pyarrow\"\n, then these functions will return pyarrow-backed nullable\nArrowDtype\nDataFrames (\nGH48957\n,\nGH49997\n):\nread_csv()\nread_clipboard()\nread_fwf()\nread_excel()\nread_html()\nread_xml()\nread_json()\nread_sql()\nread_sql_query()\nread_sql_table()\nread_parquet()\nread_orc()\nread_feather()\nread_spss()\nto_numeric()\nDataFrame.convert_dtypes()\nSeries.convert_dtypes()\nIn [12]:\nimport\nio\nIn [13]:\ndata\n=\nio\n.\nStringIO\n(\n\"\"\"a,b,c,d,e,f,g,h,i\n....:\n1,2.5,True,a,,,,,\n....:\n3,4.5,False,b,6,7.5,True,a,\n....:\n\"\"\"\n)\n....:\nIn [14]:\ndf\n=\npd\n.\nread_csv\n(\ndata\n,\ndtype_backend\n=\n\"pyarrow\"\n)\nIn [15]:\ndf\n.\ndtypes\nOut[15]:\na     int64[pyarrow]\nb    double[pyarrow]\nc      bool[pyarrow]\nd    string[pyarrow]\ne     int64[pyarrow]\nf    double[pyarrow]\ng      bool[pyarrow]\nh    string[pyarrow]\ni      null[pyarrow]\ndtype: object\nIn [16]:\ndata\n.\nseek\n(\n0\n)\nOut[16]:\n0\nIn [17]:\ndf_pyarrow\n=\npd\n.\nread_csv\n(\ndata\n,\ndtype_backend\n=\n\"pyarrow\"\n,\nengine\n=\n\"pyarrow\"\n)\nIn [18]:\ndf_pyarrow\n.\ndtypes\nOut[18]:\na     int64[pyarrow]\nb    double[pyarrow]\nc      bool[pyarrow]\nd    string[pyarrow]\ne     int64[pyarrow]\nf    double[pyarrow]\ng      bool[pyarrow]\nh    string[pyarrow]\ni      null[pyarrow]\ndtype: object\nCopy-on-Write improvements\n#\nA new lazy copy mechanism that defers the copy until the object in question is modified\nwas added to the methods listed in\nCopy-on-Write optimizations\n.\nThese methods return views when Copy-on-Write is enabled, which provides a significant\nperformance improvement compared to the regular execution (\nGH49473\n).\nAccessing a single column of a DataFrame as a Series (e.g.\ndf[\"col\"]\n) now always\nreturns a new object every time it is constructed when Copy-on-Write is enabled (not\nreturning multiple times an identical, cached Series object). This ensures that those\nSeries objects correctly follow the Copy-on-Write rules (\nGH49450\n)\nThe\nSeries\nconstructor will now create a lazy copy (deferring the copy until\na modification to the data happens) when constructing a Series from an existing\nSeries with the default of\ncopy=False\n(\nGH50471\n)\nThe\nDataFrame\nconstructor will now create a lazy copy (deferring the copy until\na modification to the data happens) when constructing from an existing\nDataFrame\nwith the default of\ncopy=False\n(\nGH51239\n)\nThe\nDataFrame\nconstructor, when constructing a DataFrame from a dictionary\nof Series objects and specifying\ncopy=False\n, will now use a lazy copy\nof those Series objects for the columns of the DataFrame (\nGH50777\n)\nThe\nDataFrame\nconstructor, when constructing a DataFrame from a\nSeries\nor\nIndex\nand specifying\ncopy=False\n, will\nnow respect Copy-on-Write.\nThe\nDataFrame\nand\nSeries\nconstructors, when constructing from\na NumPy array, will now copy the array by default to avoid mutating\nthe\nDataFrame\n/\nSeries\nwhen mutating the array. Specify\ncopy=False\nto get the old behavior.\nWhen setting\ncopy=False\npandas does not guarantee correct Copy-on-Write\nbehavior when the NumPy array is modified after creation of the\nDataFrame\n/\nSeries\n.\nThe\nDataFrame.from_records()\nwill now respect Copy-on-Write when called\nwith a\nDataFrame\n.\nTrying to set values using chained assignment (for example,\ndf[\"a\"][1:3]\n=\n0\n)\nwill now always raise a warning when Copy-on-Write is enabled. In this mode,\nchained assignment can never work because we are always setting into a temporary\nobject that is the result of an indexing operation (getitem), which under\nCopy-on-Write always behaves as a copy. Thus, assigning through a chain\ncan never update the original Series or DataFrame. Therefore, an informative\nwarning is raised to the user to avoid silently doing nothing (\nGH49467\n)\nDataFrame.replace()\nwill now respect the Copy-on-Write mechanism\nwhen\ninplace=True\n.\nDataFrame.transpose()\nwill now respect the Copy-on-Write mechanism.\nArithmetic operations that can be inplace, e.g.\nser\n*=\n2\nwill now respect the\nCopy-on-Write mechanism.\nDataFrame.__getitem__()\nwill now respect the Copy-on-Write mechanism when the\nDataFrame\nhas\nMultiIndex\ncolumns.\nSeries.__getitem__()\nwill now respect the Copy-on-Write mechanism when the\nSeries\nhas a\nMultiIndex\n.\nSeries.view()\nwill now respect the Copy-on-Write mechanism.\nCopy-on-Write can be enabled through one of\npd\n.\nset_option\n(\n\"mode.copy_on_write\"\n,\nTrue\n)\npd\n.\noptions\n.\nmode\n.\ncopy_on_write\n=\nTrue\nAlternatively, copy on write can be enabled locally through:\nwith\npd\n.\noption_context\n(\n\"mode.copy_on_write\"\n,\nTrue\n):\n...\nOther enhancements\n#\nAdded support for\nstr\naccessor methods when using\nArrowDtype\nwith a\npyarrow.string\ntype (\nGH50325\n)\nAdded support for\ndt\naccessor methods when using\nArrowDtype\nwith a\npyarrow.timestamp\ntype (\nGH50954\n)\nread_sas()\nnow supports using\nencoding='infer'\nto correctly read and use the encoding specified by the sas file. (\nGH48048\n)\nDataFrameGroupBy.quantile()\n,\nSeriesGroupBy.quantile()\nand\nDataFrameGroupBy.std()\nnow preserve nullable dtypes instead of casting to numpy dtypes (\nGH37493\n)\nDataFrameGroupBy.std()\n,\nSeriesGroupBy.std()\nnow support datetime64, timedelta64, and\nDatetimeTZDtype\ndtypes (\nGH48481\n)\nSeries.add_suffix()\n,\nDataFrame.add_suffix()\n,\nSeries.add_prefix()\nand\nDataFrame.add_prefix()\nsupport an\naxis\nargument. If\naxis\nis set, the default behaviour of which axis to consider can be overwritten (\nGH47819\n)\ntesting.assert_frame_equal()\nnow shows the first element where the DataFrames differ, analogously to\npytest\n芒s output (\nGH47910\n)\nAdded\nindex\nparameter to\nDataFrame.to_dict()\n(\nGH46398\n)\nAdded support for extension array dtypes in\nmerge()\n(\nGH44240\n)\nAdded metadata propagation for binary operators on\nDataFrame\n(\nGH28283\n)\nAdded\ncumsum\n,\ncumprod\n,\ncummin\nand\ncummax\nto the\nExtensionArray\ninterface via\n_accumulate\n(\nGH28385\n)\nCategoricalConversionWarning\n,\nInvalidComparison\n,\nInvalidVersion\n,\nLossySetitemError\n, and\nNoBufferPresent\nare now exposed in\npandas.errors\n(\nGH27656\n)\nFix\ntest\noptional_extra by adding missing test package\npytest-asyncio\n(\nGH48361\n)\nDataFrame.astype()\nexception message thrown improved to include column name when type conversion is not possible. (\nGH47571\n)\ndate_range()\nnow supports a\nunit\nkeyword (芒s芒, 芒ms芒, 芒us芒, or 芒ns芒) to specify the desired resolution of the output index (\nGH49106\n)\ntimedelta_range()\nnow supports a\nunit\nkeyword (芒s芒, 芒ms芒, 芒us芒, or 芒ns芒) to specify the desired resolution of the output index (\nGH49824\n)\nDataFrame.to_json()\nnow supports a\nmode\nkeyword with supported inputs 芒w芒 and 芒a芒. Defaulting to 芒w芒, 芒a芒 can be used when lines=True and orient=芒records芒 to append record oriented json lines to an existing json file. (\nGH35849\n)\nAdded\nname\nparameter to\nIntervalIndex.from_breaks()\n,\nIntervalIndex.from_arrays()\nand\nIntervalIndex.from_tuples()\n(\nGH48911\n)\nImprove exception message when using\ntesting.assert_frame_equal()\non a\nDataFrame\nto include the column that is compared (\nGH50323\n)\nImproved error message for\nmerge_asof()\nwhen join-columns were duplicated (\nGH50102\n)\nAdded support for extension array dtypes to\nget_dummies()\n(\nGH32430\n)\nAdded\nIndex.infer_objects()\nanalogous to\nSeries.infer_objects()\n(\nGH50034\n)\nAdded\ncopy\nparameter to\nSeries.infer_objects()\nand\nDataFrame.infer_objects()\n, passing\nFalse\nwill avoid making copies for series or columns that are already non-object or where no better dtype can be inferred (\nGH50096\n)\nDataFrame.plot.hist()\nnow recognizes\nxlabel\nand\nylabel\narguments (\nGH49793\n)\nSeries.drop_duplicates()\nhas gained\nignore_index\nkeyword to reset index (\nGH48304\n)\nSeries.dropna()\nand\nDataFrame.dropna()\nhas gained\nignore_index\nkeyword to reset index (\nGH31725\n)\nImproved error message in\nto_datetime()\nfor non-ISO8601 formats, informing users about the position of the first error (\nGH50361\n)\nImproved error message when trying to align\nDataFrame\nobjects (for example, in\nDataFrame.compare()\n) to clarify that 芒identically labelled芒 refers to both index and columns (\nGH50083\n)\nAdded support for\nIndex.min()\nand\nIndex.max()\nfor pyarrow string dtypes (\nGH51397\n)\nAdded\nDatetimeIndex.as_unit()\nand\nTimedeltaIndex.as_unit()\nto convert to different resolutions; supported resolutions are 芒s芒, 芒ms芒, 芒us芒, and 芒ns芒 (\nGH50616\n)\nAdded\nSeries.dt.unit()\nand\nSeries.dt.as_unit()\nto convert to different resolutions; supported resolutions are 芒s芒, 芒ms芒, 芒us芒, and 芒ns芒 (\nGH51223\n)\nAdded new argument\ndtype\nto\nread_sql()\nto be consistent with\nread_sql_query()\n(\nGH50797\n)\nread_csv()\n,\nread_table()\n,\nread_fwf()\nand\nread_excel()\nnow accept\ndate_format\n(\nGH50601\n)\nto_datetime()\nnow accepts\n\"ISO8601\"\nas an argument to\nformat\n, which will match any ISO8601 string (but possibly not identically-formatted) (\nGH50411\n)\nto_datetime()\nnow accepts\n\"mixed\"\nas an argument to\nformat\n, which will infer the format for each element individually (\nGH50972\n)\nAdded new argument\nengine\nto\nread_json()\nto support parsing JSON with pyarrow by specifying\nengine=\"pyarrow\"\n(\nGH48893\n)\nAdded support for SQLAlchemy 2.0 (\nGH40686\n)\nAdded support for\ndecimal\nparameter when\nengine=\"pyarrow\"\nin\nread_csv()\n(\nGH51302\n)\nIndex\nset operations\nIndex.union()\n,\nIndex.intersection()\n,\nIndex.difference()\n, and\nIndex.symmetric_difference()\nnow support\nsort=True\n, which will always return a sorted result, unlike the default\nsort=None\nwhich does not sort in some cases (\nGH25151\n)\nNotable bug fixes\n#\nThese are bug fixes that might have notable behavior changes.\nDataFrameGroupBy.cumsum()\nand\nDataFrameGroupBy.cumprod()\noverflow instead of lossy casting to float\n#\nIn previous versions we cast to float when applying\ncumsum\nand\ncumprod\nwhich\nlead to incorrect results even if the result could be hold by\nint64\ndtype.\nAdditionally, the aggregation overflows consistent with numpy and the regular\nDataFrame.cumprod()\nand\nDataFrame.cumsum()\nmethods when the limit of\nint64\nis reached (\nGH37493\n).\nOld Behavior\nIn [1]:\ndf\n=\npd\n.\nDataFrame\n({\n\"key\"\n:\n[\n\"b\"\n]\n*\n7\n,\n\"value\"\n:\n625\n})\nIn [2]:\ndf\n.\ngroupby\n(\n\"key\"\n)[\n\"value\"\n]\n.\ncumprod\n()[\n5\n]\nOut[2]:\n5.960464477539062e+16\nWe return incorrect results with the 6th value.\nNew Behavior\nIn [19]:\ndf\n=\npd\n.\nDataFrame\n({\n\"key\"\n:\n[\n\"b\"\n]\n*\n7\n,\n\"value\"\n:\n625\n})\nIn [20]:\ndf\n.\ngroupby\n(\n\"key\"\n)[\n\"value\"\n]\n.\ncumprod\n()\nOut[20]:\n0                   625\n1                390625\n2             244140625\n3          152587890625\n4        95367431640625\n5     59604644775390625\n6    359414837200037393\nName: value, dtype: int64\nWe overflow with the 7th value, but the 6th value is still correct.\nDataFrameGroupBy.nth()\nand\nSeriesGroupBy.nth()\nnow behave as filtrations\n#\nIn previous versions of pandas,\nDataFrameGroupBy.nth()\nand\nSeriesGroupBy.nth()\nacted as if they were aggregations. However, for most\ninputs\nn\n, they may return either zero or multiple rows per group. This means\nthat they are filtrations, similar to e.g.\nDataFrameGroupBy.head()\n. pandas\nnow treats them as filtrations (\nGH13666\n).\nIn [21]:\ndf\n=\npd\n.\nDataFrame\n({\n\"a\"\n:\n[\n1\n,\n1\n,\n2\n,\n1\n,\n2\n],\n\"b\"\n:\n[\nnp\n.\nnan\n,\n2.0\n,\n3.0\n,\n4.0\n,\n5.0\n]})\nIn [22]:\ngb\n=\ndf\n.\ngroupby\n(\n\"a\"\n)\nOld Behavior\nIn [5]:\ngb\n.\nnth\n(\nn\n=\n1\n)\nOut[5]:\nA    B\n1  1  2.0\n4  2  5.0\nNew Behavior\nIn [23]:\ngb\n.\nnth\n(\nn\n=\n1\n)\nOut[23]:\na    b\n1  1  2.0\n4  2  5.0\nIn particular, the index of the result is derived from the input by selecting\nthe appropriate rows. Also, when\nn\nis larger than the group, no rows instead of\nNaN\nis returned.\nOld Behavior\nIn [5]:\ngb\n.\nnth\n(\nn\n=\n3\n,\ndropna\n=\n\"any\"\n)\nOut[5]:\nB\nA\n1 NaN\n2 NaN\nNew Behavior\nIn [24]:\ngb\n.\nnth\n(\nn\n=\n3\n,\ndropna\n=\n\"any\"\n)\nOut[24]:\nEmpty DataFrame\nColumns: [a, b]\nIndex: []\nBackwards incompatible API changes\n#\nConstruction with datetime64 or timedelta64 dtype with unsupported resolution\n#\nIn past versions, when constructing a\nSeries\nor\nDataFrame\nand\npassing a 芒datetime64芒 or 芒timedelta64芒 dtype with unsupported resolution\n(i.e. anything other than 芒ns芒), pandas would silently replace the given dtype\nwith its nanosecond analogue:\nPrevious behavior\n:\nIn [5]:\npd\n.\nSeries\n([\n\"2016-01-01\"\n],\ndtype\n=\n\"datetime64[s]\"\n)\nOut[5]:\n0   2016-01-01\ndtype: datetime64[ns]\nIn [6] pd.Series([\"2016-01-01\"], dtype=\"datetime64[D]\")\nOut[6]:\n0   2016-01-01\ndtype: datetime64[ns]\nIn pandas 2.0 we support resolutions 芒s芒, 芒ms芒, 芒us芒, and 芒ns芒. When passing\na supported dtype (e.g. 芒datetime64[s]芒), the result now has exactly\nthe requested dtype:\nNew behavior\n:\nIn [25]:\npd\n.\nSeries\n([\n\"2016-01-01\"\n],\ndtype\n=\n\"datetime64[s]\"\n)\nOut[25]:\n0   2016-01-01\ndtype: datetime64[s]\nWith an un-supported dtype, pandas now raises instead of silently swapping in\na supported dtype:\nNew behavior\n:\nIn [26]:\npd\n.\nSeries\n([\n\"2016-01-01\"\n],\ndtype\n=\n\"datetime64[D]\"\n)\n---------------------------------------------------------------------------\nTypeError\nTraceback (most recent call last)\nCell\nIn\n[\n26\n],\nline\n1\n---->\n1\npd\n.\nSeries\n([\n\"2016-01-01\"\n],\ndtype\n=\n\"datetime64[D]\"\n)\nFile ~/work/pandas/pandas/pandas/core/series.py:509,\nin\nSeries.__init__\n(self, data, index, dtype, name, copy, fastpath)\n507\ndata\n=\ndata\n.\ncopy\n()\n508\nelse\n:\n-->\n509\ndata\n=\nsanitize_array\n(\ndata\n,\nindex\n,\ndtype\n,\ncopy\n)\n511\nmanager\n=\nget_option\n(\n\"mode.data_manager\"\n)\n512\nif\nmanager\n==\n\"block\"\n:\nFile ~/work/pandas/pandas/pandas/core/construction.py:599,\nin\nsanitize_array\n(data, index, dtype, copy, allow_2d)\n596\nsubarr\n=\nnp\n.\narray\n([],\ndtype\n=\nnp\n.\nfloat64\n)\n598\nelif\ndtype\nis\nnot\nNone\n:\n-->\n599\nsubarr\n=\n_try_cast\n(\ndata\n,\ndtype\n,\ncopy\n)\n601\nelse\n:\n602\nsubarr\n=\nmaybe_convert_platform\n(\ndata\n)\nFile ~/work/pandas/pandas/pandas/core/construction.py:756,\nin\n_try_cast\n(arr, dtype, copy)\n751\nreturn\nlib\n.\nensure_string_array\n(\narr\n,\nconvert_na_value\n=\nFalse\n,\ncopy\n=\ncopy\n)\n.\nreshape\n(\n752\nshape\n753\n)\n755\nelif\ndtype\n.\nkind\nin\n[\n\"m\"\n,\n\"M\"\n]:\n-->\n756\nreturn\nmaybe_cast_to_datetime\n(\narr\n,\ndtype\n)\n758\n# GH#15832: Check if we are requesting a numeric dtype and\n759\n# that we can convert the data to the requested dtype.\n760\nelif\nis_integer_dtype\n(\ndtype\n):\n761\n# this will raise if we have e.g. floats\nFile ~/work/pandas/pandas/pandas/core/dtypes/cast.py:1236,\nin\nmaybe_cast_to_datetime\n(value, dtype)\n1232\nraise\nTypeError\n(\n\"value must be listlike\"\n)\n1234\n# TODO: _from_sequence would raise ValueError in cases where\n1235\n#  _ensure_nanosecond_dtype raises TypeError\n->\n1236\n_ensure_nanosecond_dtype\n(\ndtype\n)\n1238\nif\nis_timedelta64_dtype\n(\ndtype\n):\n1239\nres\n=\nTimedeltaArray\n.\n_from_sequence\n(\nvalue\n,\ndtype\n=\ndtype\n)\nFile ~/work/pandas/pandas/pandas/core/dtypes/cast.py:1294,\nin\n_ensure_nanosecond_dtype\n(dtype)\n1291\nraise\nValueError\n(\nmsg\n)\n1292\n# TODO: ValueError or TypeError? existing test\n1293\n#  test_constructor_generic_timestamp_bad_frequency expects TypeError\n->\n1294\nraise\nTypeError\n(\n1295\nf\n\"dtype=\n{\ndtype\n}\nis not supported. Supported resolutions are 's', \"\n1296\n\"'ms', 'us', and 'ns'\"\n1297\n)\nTypeError\n: dtype=datetime64[D] is not supported. Supported resolutions are 's', 'ms', 'us', and 'ns'\nValue counts sets the resulting name to\ncount\n#\nIn past versions, when running\nSeries.value_counts()\n, the result would inherit\nthe original object芒s name, and the result index would be nameless. This would cause\nconfusion when resetting the index, and the column names would not correspond with the\ncolumn values.\nNow, the result name will be\n'count'\n(or\n'proportion'\nif\nnormalize=True\nwas passed),\nand the index will be named after the original object (\nGH49497\n).\nPrevious behavior\n:\nIn [8]:\npd\n.\nSeries\n([\n'quetzal'\n,\n'quetzal'\n,\n'elk'\n],\nname\n=\n'animal'\n)\n.\nvalue_counts\n()\nOut[2]:\nquetzal    2\nelk        1\nName: animal, dtype: int64\nNew behavior\n:\nIn [27]:\npd\n.\nSeries\n([\n'quetzal'\n,\n'quetzal'\n,\n'elk'\n],\nname\n=\n'animal'\n)\n.\nvalue_counts\n()\nOut[27]:\nanimal\nquetzal    2\nelk        1\nName: count, dtype: int64\nLikewise for other\nvalue_counts\nmethods (for example,\nDataFrame.value_counts()\n).\nDisallow astype conversion to non-supported datetime64/timedelta64 dtypes\n#\nIn previous versions, converting a\nSeries\nor\nDataFrame\nfrom\ndatetime64[ns]\nto a different\ndatetime64[X]\ndtype would return\nwith\ndatetime64[ns]\ndtype instead of the requested dtype. In pandas 2.0,\nsupport is added for 芒datetime64[s]芒, 芒datetime64[ms]芒, and 芒datetime64[us]芒 dtypes,\nso converting to those dtypes gives exactly the requested dtype:\nPrevious behavior\n:\nIn [28]:\nidx\n=\npd\n.\ndate_range\n(\n\"2016-01-01\"\n,\nperiods\n=\n3\n)\nIn [29]:\nser\n=\npd\n.\nSeries\n(\nidx\n)\nPrevious behavior\n:\nIn [4]:\nser\n.\nastype\n(\n\"datetime64[s]\"\n)\nOut[4]:\n0   2016-01-01\n1   2016-01-02\n2   2016-01-03\ndtype: datetime64[ns]\nWith the new behavior, we get exactly the requested dtype:\nNew behavior\n:\nIn [30]:\nser\n.\nastype\n(\n\"datetime64[s]\"\n)\nOut[30]:\n0   2016-01-01\n1   2016-01-02\n2   2016-01-03\ndtype: datetime64[s]\nFor non-supported resolutions e.g. 芒datetime64[D]芒, we raise instead of silently\nignoring the requested dtype:\nNew behavior\n:\nIn [31]:\nser\n.\nastype\n(\n\"datetime64[D]\"\n)\n---------------------------------------------------------------------------\nTypeError\nTraceback (most recent call last)\nCell\nIn\n[\n31\n],\nline\n1\n---->\n1\nser\n.\nastype\n(\n\"datetime64[D]\"\n)\nFile ~/work/pandas/pandas/pandas/core/generic.py:6324,\nin\nNDFrame.astype\n(self, dtype, copy, errors)\n6317\nresults\n=\n[\n6318\nself\n.\niloc\n[:,\ni\n]\n.\nastype\n(\ndtype\n,\ncopy\n=\ncopy\n)\n6319         for i\nin\nrange(len\n(self.columns))\n6320\n]\n6322\nelse\n:\n6323\n# else, only a single dtype is given\n->\n6324\nnew_data\n=\nself\n.\n_mgr\n.\nastype\n(\ndtype\n=\ndtype\n,\ncopy\n=\ncopy\n,\nerrors\n=\nerrors\n)\n6325\nreturn\nself\n.\n_constructor\n(\nnew_data\n)\n.\n__finalize__\n(\nself\n,\nmethod\n=\n\"astype\"\n)\n6327\n# GH 33113: handle empty frame or series\nFile ~/work/pandas/pandas/pandas/core/internals/managers.py:451,\nin\nBaseBlockManager.astype\n(self, dtype, copy, errors)\n448\nelif\nusing_copy_on_write\n():\n449\ncopy\n=\nFalse\n-->\n451\nreturn\nself\n.\napply\n(\n452\n\"astype\"\n,\n453\ndtype\n=\ndtype\n,\n454\ncopy\n=\ncopy\n,\n455\nerrors\n=\nerrors\n,\n456\nusing_cow\n=\nusing_copy_on_write\n(),\n457\n)\nFile ~/work/pandas/pandas/pandas/core/internals/managers.py:352,\nin\nBaseBlockManager.apply\n(self, f, align_keys, **kwargs)\n350\napplied\n=\nb\n.\napply\n(\nf\n,\n**\nkwargs\n)\n351\nelse\n:\n-->\n352\napplied\n=\ngetattr\n(\nb\n,\nf\n)(\n**\nkwargs\n)\n353\nresult_blocks\n=\nextend_blocks\n(\napplied\n,\nresult_blocks\n)\n355\nout\n=\ntype\n(\nself\n)\n.\nfrom_blocks\n(\nresult_blocks\n,\nself\n.\naxes\n)\nFile ~/work/pandas/pandas/pandas/core/internals/blocks.py:511,\nin\nBlock.astype\n(self, dtype, copy, errors, using_cow)\n491\n\"\"\"\n492\nCoerce to the new dtype.\n493\n(...)\n507\nBlock\n508\n\"\"\"\n509\nvalues\n=\nself\n.\nvalues\n-->\n511\nnew_values\n=\nastype_array_safe\n(\nvalues\n,\ndtype\n,\ncopy\n=\ncopy\n,\nerrors\n=\nerrors\n)\n513\nnew_values\n=\nmaybe_coerce_values\n(\nnew_values\n)\n515\nrefs\n=\nNone\nFile ~/work/pandas/pandas/pandas/core/dtypes/astype.py:242,\nin\nastype_array_safe\n(values, dtype, copy, errors)\n239\ndtype\n=\ndtype\n.\nnumpy_dtype\n241\ntry\n:\n-->\n242\nnew_values\n=\nastype_array\n(\nvalues\n,\ndtype\n,\ncopy\n=\ncopy\n)\n243\nexcept\n(\nValueError\n,\nTypeError\n):\n244\n# e.g. _astype_nansafe can fail on object-dtype of strings\n245\n#  trying to convert to float\n246\nif\nerrors\n==\n\"ignore\"\n:\nFile ~/work/pandas/pandas/pandas/core/dtypes/astype.py:184,\nin\nastype_array\n(values, dtype, copy)\n180\nreturn\nvalues\n182\nif\nnot\nisinstance\n(\nvalues\n,\nnp\n.\nndarray\n):\n183\n# i.e. ExtensionArray\n-->\n184\nvalues\n=\nvalues\n.\nastype\n(\ndtype\n,\ncopy\n=\ncopy\n)\n186\nelse\n:\n187\nvalues\n=\n_astype_nansafe\n(\nvalues\n,\ndtype\n,\ncopy\n=\ncopy\n)\nFile ~/work/pandas/pandas/pandas/core/arrays/datetimes.py:701,\nin\nDatetimeArray.astype\n(self, dtype, copy)\n699\nelif\nis_period_dtype\n(\ndtype\n):\n700\nreturn\nself\n.\nto_period\n(\nfreq\n=\ndtype\n.\nfreq\n)\n-->\n701\nreturn\ndtl\n.\nDatetimeLikeArrayMixin\n.\nastype\n(\nself\n,\ndtype\n,\ncopy\n)\nFile ~/work/pandas/pandas/pandas/core/arrays/datetimelike.py:487,\nin\nDatetimeLikeArrayMixin.astype\n(self, dtype, copy)\n480\nelif\n(\n481\nis_datetime_or_timedelta_dtype\n(\ndtype\n)\n482\nand\nnot\nis_dtype_equal\n(\nself\n.\ndtype\n,\ndtype\n)\n483\n)\nor\nis_float_dtype\n(\ndtype\n):\n484\n# disallow conversion between datetime/timedelta,\n485\n# and conversions for any datetimelike to float\n486\nmsg\n=\nf\n\"Cannot cast\n{\ntype\n(\nself\n)\n.\n__name__\n}\nto dtype\n{\ndtype\n}\n\"\n-->\n487\nraise\nTypeError\n(\nmsg\n)\n488\nelse\n:\n489\nreturn\nnp\n.\nasarray\n(\nself\n,\ndtype\n=\ndtype\n)\nTypeError\n: Cannot cast DatetimeArray to dtype datetime64[D]\nFor conversion from\ntimedelta64[ns]\ndtypes, the old behavior converted\nto a floating point format.\nPrevious behavior\n:\nIn [32]:\nidx\n=\npd\n.\ntimedelta_range\n(\n\"1 Day\"\n,\nperiods\n=\n3\n)\nIn [33]:\nser\n=\npd\n.\nSeries\n(\nidx\n)\nPrevious behavior\n:\nIn [7]:\nser\n.\nastype\n(\n\"timedelta64[s]\"\n)\nOut[7]:\n0     86400.0\n1    172800.0\n2    259200.0\ndtype: float64\nIn [8]:\nser\n.\nastype\n(\n\"timedelta64[D]\"\n)\nOut[8]:\n0    1.0\n1    2.0\n2    3.0\ndtype: float64\nThe new behavior, as for datetime64, either gives exactly the requested dtype or raises:\nNew behavior\n:\nIn [34]:\nser\n.\nastype\n(\n\"timedelta64[s]\"\n)\nOut[34]:\n0   1 days 00:00:00\n1   2 days 00:00:00\n2   3 days 00:00:00\ndtype: timedelta64[s]\nIn [35]:\nser\n.\nastype\n(\n\"timedelta64[D]\"\n)\n---------------------------------------------------------------------------\nValueError\nTraceback (most recent call last)\nCell\nIn\n[\n35\n],\nline\n1\n---->\n1\nser\n.\nastype\n(\n\"timedelta64[D]\"\n)\nFile ~/work/pandas/pandas/pandas/core/generic.py:6324,\nin\nNDFrame.astype\n(self, dtype, copy, errors)\n6317\nresults\n=\n[\n6318\nself\n.\niloc\n[:,\ni\n]\n.\nastype\n(\ndtype\n,\ncopy\n=\ncopy\n)\n6319         for i\nin\nrange(len\n(self.columns))\n6320\n]\n6322\nelse\n:\n6323\n# else, only a single dtype is given\n->\n6324\nnew_data\n=\nself\n.\n_mgr\n.\nastype\n(\ndtype\n=\ndtype\n,\ncopy\n=\ncopy\n,\nerrors\n=\nerrors\n)\n6325\nreturn\nself\n.\n_constructor\n(\nnew_data\n)\n.\n__finalize__\n(\nself\n,\nmethod\n=\n\"astype\"\n)\n6327\n# GH 33113: handle empty frame or series\nFile ~/work/pandas/pandas/pandas/core/internals/managers.py:451,\nin\nBaseBlockManager.astype\n(self, dtype, copy, errors)\n448\nelif\nusing_copy_on_write\n():\n449\ncopy\n=\nFalse\n-->\n451\nreturn\nself\n.\napply\n(\n452\n\"astype\"\n,\n453\ndtype\n=\ndtype\n,\n454\ncopy\n=\ncopy\n,\n455\nerrors\n=\nerrors\n,\n456\nusing_cow\n=\nusing_copy_on_write\n(),\n457\n)\nFile ~/work/pandas/pandas/pandas/core/internals/managers.py:352,\nin\nBaseBlockManager.apply\n(self, f, align_keys, **kwargs)\n350\napplied\n=\nb\n.\napply\n(\nf\n,\n**\nkwargs\n)\n351\nelse\n:\n-->\n352\napplied\n=\ngetattr\n(\nb\n,\nf\n)(\n**\nkwargs\n)\n353\nresult_blocks\n=\nextend_blocks\n(\napplied\n,\nresult_blocks\n)\n355\nout\n=\ntype\n(\nself\n)\n.\nfrom_blocks\n(\nresult_blocks\n,\nself\n.\naxes\n)\nFile ~/work/pandas/pandas/pandas/core/internals/blocks.py:511,\nin\nBlock.astype\n(self, dtype, copy, errors, using_cow)\n491\n\"\"\"\n492\nCoerce to the new dtype.\n493\n(...)\n507\nBlock\n508\n\"\"\"\n509\nvalues\n=\nself\n.\nvalues\n-->\n511\nnew_values\n=\nastype_array_safe\n(\nvalues\n,\ndtype\n,\ncopy\n=\ncopy\n,\nerrors\n=\nerrors\n)\n513\nnew_values\n=\nmaybe_coerce_values\n(\nnew_values\n)\n515\nrefs\n=\nNone\nFile ~/work/pandas/pandas/pandas/core/dtypes/astype.py:242,\nin\nastype_array_safe\n(values, dtype, copy, errors)\n239\ndtype\n=\ndtype\n.\nnumpy_dtype\n241\ntry\n:\n-->\n242\nnew_values\n=\nastype_array\n(\nvalues\n,\ndtype\n,\ncopy\n=\ncopy\n)\n243\nexcept\n(\nValueError\n,\nTypeError\n):\n244\n# e.g. _astype_nansafe can fail on object-dtype of strings\n245\n#  trying to convert to float\n246\nif\nerrors\n==\n\"ignore\"\n:\nFile ~/work/pandas/pandas/pandas/core/dtypes/astype.py:184,\nin\nastype_array\n(values, dtype, copy)\n180\nreturn\nvalues\n182\nif\nnot\nisinstance\n(\nvalues\n,\nnp\n.\nndarray\n):\n183\n# i.e. ExtensionArray\n-->\n184\nvalues\n=\nvalues\n.\nastype\n(\ndtype\n,\ncopy\n=\ncopy\n)\n186\nelse\n:\n187\nvalues\n=\n_astype_nansafe\n(\nvalues\n,\ndtype\n,\ncopy\n=\ncopy\n)\nFile ~/work/pandas/pandas/pandas/core/arrays/timedeltas.py:363,\nin\nTimedeltaArray.astype\n(self, dtype, copy)\n359\nreturn\ntype\n(\nself\n)\n.\n_simple_new\n(\n360\nres_values\n,\ndtype\n=\nres_values\n.\ndtype\n,\nfreq\n=\nself\n.\nfreq\n361\n)\n362\nelse\n:\n-->\n363\nraise\nValueError\n(\n364\nf\n\"Cannot convert from\n{\nself\n.\ndtype\n}\nto\n{\ndtype\n}\n. \"\n365\n\"Supported resolutions are 's', 'ms', 'us', 'ns'\"\n366\n)\n368\nreturn\ndtl\n.\nDatetimeLikeArrayMixin\n.\nastype\n(\nself\n,\ndtype\n,\ncopy\n=\ncopy\n)\nValueError\n: Cannot convert from timedelta64[ns] to timedelta64[D]. Supported resolutions are 's', 'ms', 'us', 'ns'\nUTC and fixed-offset timezones default to standard-library tzinfo objects\n#\nIn previous versions, the default\ntzinfo\nobject used to represent UTC\nwas\npytz.UTC\n. In pandas 2.0, we default to\ndatetime.timezone.utc\ninstead.\nSimilarly, for timezones represent fixed UTC offsets, we use\ndatetime.timezone\nobjects instead of\npytz.FixedOffset\nobjects. See (\nGH34916\n)\nPrevious behavior\n:\nIn [2]:\nts\n=\npd\n.\nTimestamp\n(\n\"2016-01-01\"\n,\ntz\n=\n\"UTC\"\n)\nIn [3]:\ntype\n(\nts\n.\ntzinfo\n)\nOut[3]:\npytz.UTC\nIn [4]:\nts2\n=\npd\n.\nTimestamp\n(\n\"2016-01-01 04:05:06-07:00\"\n)\nIn [3]:\ntype\n(\nts2\n.\ntzinfo\n)\nOut[5]:\npytz._FixedOffset\nNew behavior\n:\nIn [36]:\nts\n=\npd\n.\nTimestamp\n(\n\"2016-01-01\"\n,\ntz\n=\n\"UTC\"\n)\nIn [37]:\ntype\n(\nts\n.\ntzinfo\n)\nOut[37]:\ndatetime.timezone\nIn [38]:\nts2\n=\npd\n.\nTimestamp\n(\n\"2016-01-01 04:05:06-07:00\"\n)\nIn [39]:\ntype\n(\nts2\n.\ntzinfo\n)\nOut[39]:\ndatetime.timezone\nFor timezones that are neither UTC nor fixed offsets, e.g. 芒US/Pacific芒, we\ncontinue to default to\npytz\nobjects.\nEmpty DataFrames/Series will now default to have a\nRangeIndex\n#\nBefore, constructing an empty (where\ndata\nis\nNone\nor an empty list-like argument)\nSeries\nor\nDataFrame\nwithout\nspecifying the axes (\nindex=None\n,\ncolumns=None\n) would return the axes as empty\nIndex\nwith object dtype.\nNow, the axes return an empty\nRangeIndex\n(\nGH49572\n).\nPrevious behavior\n:\nIn [8]:\npd\n.\nSeries\n()\n.\nindex\nOut[8]:\nIndex([], dtype='object')\nIn [9] pd.DataFrame().axes\nOut[9]:\n[Index([], dtype='object'), Index([], dtype='object')]\nNew behavior\n:\nIn [40]:\npd\n.\nSeries\n()\n.\nindex\nOut[40]:\nRangeIndex(start=0, stop=0, step=1)\nIn [41]:\npd\n.\nDataFrame\n()\n.\naxes\nOut[41]:\n[RangeIndex(start=0, stop=0, step=1), RangeIndex(start=0, stop=0, step=1)]\nDataFrame to LaTeX has a new render engine\n#\nThe existing\nDataFrame.to_latex()\nhas been restructured to utilise the\nextended implementation previously available under\nStyler.to_latex()\n.\nThe arguments signature is similar, albeit\ncol_space\nhas been removed since\nit is ignored by LaTeX engines. This render engine also requires\njinja2\nas a\ndependency which needs to be installed, since rendering is based upon jinja2 templates.\nThe pandas latex options below are no longer used and have been removed. The generic\nmax rows and columns arguments remain but for this functionality should be replaced\nby the Styler equivalents.\nThe alternative options giving similar functionality are indicated below:\ndisplay.latex.escape\n: replaced with\nstyler.format.escape\n,\ndisplay.latex.longtable\n: replaced with\nstyler.latex.environment\n,\ndisplay.latex.multicolumn\n,\ndisplay.latex.multicolumn_format\nand\ndisplay.latex.multirow\n: replaced with\nstyler.sparse.rows\n,\nstyler.sparse.columns\n,\nstyler.latex.multirow_align\nand\nstyler.latex.multicol_align\n,\ndisplay.latex.repr\n: replaced with\nstyler.render.repr\n,\ndisplay.max_rows\nand\ndisplay.max_columns\n: replace with\nstyler.render.max_rows\n,\nstyler.render.max_columns\nand\nstyler.render.max_elements\n.\nNote that due to this change some defaults have also changed:\nmultirow\nnow defaults to\nTrue\n.\nmultirow_align\ndefaults to\n芒r芒\ninstead of\n芒l芒\n.\nmulticol_align\ndefaults to\n芒r芒\ninstead of\n芒l芒\n.\nescape\nnow defaults to\nFalse\n.\nNote that the behaviour of\n_repr_latex_\nis also changed. Previously\nsetting\ndisplay.latex.repr\nwould generate LaTeX only when using nbconvert for a\nJupyterNotebook, and not when the user is running the notebook. Now the\nstyler.render.repr\noption allows control of the specific output\nwithin JupyterNotebooks for operations (not just on nbconvert). See\nGH39911\n.\nIncreased minimum versions for dependencies\n#\nSome minimum supported versions of dependencies were updated.\nIf installed, we now require:\nPackage\nMinimum Version\nRequired\nChanged\nmypy (dev)\n1.0\nX\npytest (dev)\n7.0.0\nX\npytest-xdist (dev)\n2.2.0\nX\nhypothesis (dev)\n6.34.2\nX\npython-dateutil\n2.8.2\nX\nX\ntzdata\n2022.1\nX\nX\nFor\noptional libraries\nthe general recommendation is to use the latest version.\nThe following table lists the lowest version per library that is currently being tested throughout the development of pandas.\nOptional libraries below the lowest tested version may still work, but are not considered supported.\nPackage\nMinimum Version\nChanged\npyarrow\n7.0.0\nX\nmatplotlib\n3.6.1\nX\nfastparquet\n0.6.3\nX\nxarray\n0.21.0\nX\nSee\nDependencies\nand\nOptional dependencies\nfor more.\nDatetimes are now parsed with a consistent format\n#\nIn the past,\nto_datetime()\nguessed the format for each element independently. This was appropriate for some cases where elements had mixed date formats - however, it would regularly cause problems when users expected a consistent format but the function would switch formats between elements. As of version 2.0.0, parsing will use a consistent format, determined by the first non-NA value (unless the user specifies a format, in which case that is used).\nOld behavior\n:\nIn [1]:\nser\n=\npd\n.\nSeries\n([\n'13-01-2000'\n,\n'12-01-2000'\n])\nIn [2]:\npd\n.\nto_datetime\n(\nser\n)\nOut[2]:\n0   2000-01-13\n1   2000-12-01\ndtype: datetime64[ns]\nNew behavior\n:\nIn [42]:\nser\n=\npd\n.\nSeries\n([\n'13-01-2000'\n,\n'12-01-2000'\n])\nIn [43]:\npd\n.\nto_datetime\n(\nser\n)\nOut[43]:\n0   2000-01-13\n1   2000-01-12\ndtype: datetime64[ns]\nNote that this affects\nread_csv()\nas well.\nIf you still need to parse dates with inconsistent formats, you can use\nformat='mixed'\n(possibly alongside\ndayfirst\n)\nser\n=\npd\n.\nSeries\n([\n'13-01-2000'\n,\n'12 January 2000'\n])\npd\n.\nto_datetime\n(\nser\n,\nformat\n=\n'mixed'\n,\ndayfirst\n=\nTrue\n)\nor, if your formats are all ISO8601 (but possibly not identically-formatted)\nser\n=\npd\n.\nSeries\n([\n'2020-01-01'\n,\n'2020-01-01 03:00'\n])\npd\n.\nto_datetime\n(\nser\n,\nformat\n=\n'ISO8601'\n)\nOther API changes\n#\nThe\nfreq\n,\ntz\n,\nnanosecond\n, and\nunit\nkeywords in the\nTimestamp\nconstructor are now keyword-only (\nGH45307\n,\nGH32526\n)\nPassing\nnanoseconds\ngreater than 999 or less than 0 in\nTimestamp\nnow raises a\nValueError\n(\nGH48538\n,\nGH48255\n)\nread_csv()\n: specifying an incorrect number of columns with\nindex_col\nof now raises\nParserError\ninstead of\nIndexError\nwhen using the c parser.\nDefault value of\ndtype\nin\nget_dummies()\nis changed to\nbool\nfrom\nuint8\n(\nGH45848\n)\nDataFrame.astype()\n,\nSeries.astype()\n, and\nDatetimeIndex.astype()\ncasting datetime64 data to any of 芒datetime64[s]芒, 芒datetime64[ms]芒, 芒datetime64[us]芒 will return an object with the given resolution instead of coercing back to 芒datetime64[ns]芒 (\nGH48928\n)\nDataFrame.astype()\n,\nSeries.astype()\n, and\nDatetimeIndex.astype()\ncasting timedelta64 data to any of 芒timedelta64[s]芒, 芒timedelta64[ms]芒, 芒timedelta64[us]芒 will return an object with the given resolution instead of coercing to 芒float64芒 dtype (\nGH48963\n)\nDatetimeIndex.astype()\n,\nTimedeltaIndex.astype()\n,\nPeriodIndex.astype()\nSeries.astype()\n,\nDataFrame.astype()\nwith\ndatetime64\n,\ntimedelta64\nor\nPeriodDtype\ndtypes no longer allow converting to integer dtypes other than 芒int64芒, do\nobj.astype('int64',\ncopy=False).astype(dtype)\ninstead (\nGH49715\n)\nIndex.astype()\nnow allows casting from\nfloat64\ndtype to datetime-like dtypes, matching\nSeries\nbehavior (\nGH49660\n)\nPassing data with dtype of 芒timedelta64[s]芒, 芒timedelta64[ms]芒, or 芒timedelta64[us]芒 to\nTimedeltaIndex\n,\nSeries\n, or\nDataFrame\nconstructors will now retain that dtype instead of casting to 芒timedelta64[ns]芒; timedelta64 data with lower resolution will be cast to the lowest supported resolution 芒timedelta64[s]芒 (\nGH49014\n)\nPassing\ndtype\nof 芒timedelta64[s]芒, 芒timedelta64[ms]芒, or 芒timedelta64[us]芒 to\nTimedeltaIndex\n,\nSeries\n, or\nDataFrame\nconstructors will now retain that dtype instead of casting to 芒timedelta64[ns]芒; passing a dtype with lower resolution for\nSeries\nor\nDataFrame\nwill be cast to the lowest supported resolution 芒timedelta64[s]芒 (\nGH49014\n)\nPassing a\nnp.datetime64\nobject with non-nanosecond resolution to\nTimestamp\nwill retain the input resolution if it is 芒s芒, 芒ms芒, 芒us芒, or 芒ns芒; otherwise it will be cast to the closest supported resolution (\nGH49008\n)\nPassing\ndatetime64\nvalues with resolution other than nanosecond to\nto_datetime()\nwill retain the input resolution if it is 芒s芒, 芒ms芒, 芒us芒, or 芒ns芒; otherwise it will be cast to the closest supported resolution (\nGH50369\n)\nPassing integer values and a non-nanosecond datetime64 dtype (e.g. 芒datetime64[s]芒)\nDataFrame\n,\nSeries\n, or\nIndex\nwill treat the values as multiples of the dtype芒s unit, matching the behavior of e.g.\nSeries(np.array(values,\ndtype=\"M8[s]\"))\n(\nGH51092\n)\nPassing a string in ISO-8601 format to\nTimestamp\nwill retain the resolution of the parsed input if it is 芒s芒, 芒ms芒, 芒us芒, or 芒ns芒; otherwise it will be cast to the closest supported resolution (\nGH49737\n)\nThe\nother\nargument in\nDataFrame.mask()\nand\nSeries.mask()\nnow defaults to\nno_default\ninstead of\nnp.nan\nconsistent with\nDataFrame.where()\nand\nSeries.where()\n. Entries will be filled with the corresponding NULL value (\nnp.nan\nfor numpy dtypes,\npd.NA\nfor extension dtypes). (\nGH49111\n)\nChanged behavior of\nSeries.quantile()\nand\nDataFrame.quantile()\nwith\nSparseDtype\nto retain sparse dtype (\nGH49583\n)\nWhen creating a\nSeries\nwith a object-dtype\nIndex\nof datetime objects, pandas no longer silently converts the index to a\nDatetimeIndex\n(\nGH39307\n,\nGH23598\n)\npandas.testing.assert_index_equal()\nwith parameter\nexact=\"equiv\"\nnow considers two indexes equal when both are either a\nRangeIndex\nor\nIndex\nwith an\nint64\ndtype. Previously it meant either a\nRangeIndex\nor a\nInt64Index\n(\nGH51098\n)\nSeries.unique()\nwith dtype 芒timedelta64[ns]芒 or 芒datetime64[ns]芒 now returns\nTimedeltaArray\nor\nDatetimeArray\ninstead of\nnumpy.ndarray\n(\nGH49176\n)\nto_datetime()\nand\nDatetimeIndex\nnow allow sequences containing both\ndatetime\nobjects and numeric entries, matching\nSeries\nbehavior (\nGH49037\n,\nGH50453\n)\npandas.api.types.is_string_dtype()\nnow only returns\nTrue\nfor array-likes with\ndtype=object\nwhen the elements are inferred to be strings (\nGH15585\n)\nPassing a sequence containing\ndatetime\nobjects and\ndate\nobjects to\nSeries\nconstructor will return with\nobject\ndtype instead of\ndatetime64[ns]\ndtype, consistent with\nIndex\nbehavior (\nGH49341\n)\nPassing strings that cannot be parsed as datetimes to\nSeries\nor\nDataFrame\nwith\ndtype=\"datetime64[ns]\"\nwill raise instead of silently ignoring the keyword and returning\nobject\ndtype (\nGH24435\n)\nPassing a sequence containing a type that cannot be converted to\nTimedelta\nto\nto_timedelta()\nor to the\nSeries\nor\nDataFrame\nconstructor with\ndtype=\"timedelta64[ns]\"\nor to\nTimedeltaIndex\nnow raises\nTypeError\ninstead of\nValueError\n(\nGH49525\n)\nChanged behavior of\nIndex\nconstructor with sequence containing at least one\nNaT\nand everything else either\nNone\nor\nNaN\nto infer\ndatetime64[ns]\ndtype instead of\nobject\n, matching\nSeries\nbehavior (\nGH49340\n)\nread_stata()\nwith parameter\nindex_col\nset to\nNone\n(the default) will now set the index on the returned\nDataFrame\nto a\nRangeIndex\ninstead of a\nInt64Index\n(\nGH49745\n)\nChanged behavior of\nIndex\n,\nSeries\n, and\nDataFrame\narithmetic methods when working with object-dtypes, the results no longer do type inference on the result of the array operations, use\nresult.infer_objects(copy=False)\nto do type inference on the result (\nGH49999\n,\nGH49714\n)\nChanged behavior of\nIndex\nconstructor with an object-dtype\nnumpy.ndarray\ncontaining all-\nbool\nvalues or all-complex values, this will now retain object dtype, consistent with the\nSeries\nbehavior (\nGH49594\n)\nChanged behavior of\nSeries.astype()\nfrom object-dtype containing\nbytes\nobjects to string dtypes; this now does\nval.decode()\non bytes objects instead of\nstr(val)\n, matching\nIndex.astype()\nbehavior (\nGH45326\n)\nAdded\n\"None\"\nto default\nna_values\nin\nread_csv()\n(\nGH50286\n)\nChanged behavior of\nSeries\nand\nDataFrame\nconstructors when given an integer dtype and floating-point data that is not round numbers, this now raises\nValueError\ninstead of silently retaining the float dtype; do\nSeries(data)\nor\nDataFrame(data)\nto get the old behavior, and\nSeries(data).astype(dtype)\nor\nDataFrame(data).astype(dtype)\nto get the specified dtype (\nGH49599\n)\nChanged behavior of\nDataFrame.shift()\nwith\naxis=1\n, an integer\nfill_value\n, and homogeneous datetime-like dtype, this now fills new columns with integer dtypes instead of casting to datetimelike (\nGH49842\n)\nFiles are now closed when encountering an exception in\nread_json()\n(\nGH49921\n)\nChanged behavior of\nread_csv()\n,\nread_json()\n&\nread_fwf()\n, where the index will now always be a\nRangeIndex\n, when no index is specified. Previously the index would be a\nIndex\nwith dtype\nobject\nif the new DataFrame/Series has length 0 (\nGH49572\n)\nDataFrame.values()\n,\nDataFrame.to_numpy()\n,\nDataFrame.xs()\n,\nDataFrame.reindex()\n,\nDataFrame.fillna()\n, and\nDataFrame.replace()\nno longer silently consolidate the underlying arrays; do\ndf\n=\ndf.copy()\nto ensure consolidation (\nGH49356\n)\nCreating a new DataFrame using a full slice on both axes with\nloc\nor\niloc\n(thus,\ndf.loc[:,\n:]\nor\ndf.iloc[:,\n:]\n) now returns a\nnew DataFrame (shallow copy) instead of the original DataFrame, consistent with other\nmethods to get a full slice (for example\ndf.loc[:]\nor\ndf[:]\n) (\nGH49469\n)\nThe\nSeries\nand\nDataFrame\nconstructors will now return a shallow copy\n(i.e. share data, but not attributes) when passed a Series and DataFrame,\nrespectively, and with the default of\ncopy=False\n(and if no other keyword triggers\na copy). Previously, the new Series or DataFrame would share the index attribute (e.g.\ndf.index\n=\n...\nwould also update the index of the parent or child) (\nGH49523\n)\nDisallow computing\ncumprod\nfor\nTimedelta\nobject; previously this returned incorrect values (\nGH50246\n)\nDataFrame\nobjects read from a\nHDFStore\nfile without an index now have a\nRangeIndex\ninstead of an\nint64\nindex (\nGH51076\n)\nInstantiating an\nIndex\nwith an numeric numpy dtype with data containing\nNA\nand/or\nNaT\nnow raises a\nValueError\n. Previously a\nTypeError\nwas raised (\nGH51050\n)\nLoading a JSON file with duplicate columns using\nread_json(orient='split')\nrenames columns to avoid duplicates, as\nread_csv()\nand the other readers do (\nGH50370\n)\nThe levels of the index of the\nSeries\nreturned from\nSeries.sparse.from_coo\nnow always have dtype\nint32\n. Previously they had dtype\nint64\n(\nGH50926\n)\nto_datetime()\nwith\nunit\nof either 芒Y芒 or 芒M芒 will now raise if a sequence contains a non-round\nfloat\nvalue, matching the\nTimestamp\nbehavior (\nGH50301\n)\nThe methods\nSeries.round()\n,\nDataFrame.__invert__()\n,\nSeries.__invert__()\n,\nDataFrame.swapaxes()\n,\nDataFrame.first()\n,\nDataFrame.last()\n,\nSeries.first()\n,\nSeries.last()\nand\nDataFrame.align()\nwill now always return new objects (\nGH51032\n)\nDataFrame\nand\nDataFrameGroupBy\naggregations (e.g. 芒sum芒) with object-dtype columns no longer infer non-object dtypes for their results, explicitly call\nresult.infer_objects(copy=False)\non the result to obtain the old behavior (\nGH51205\n,\nGH49603\n)\nDivision by zero with\nArrowDtype\ndtypes returns\n-inf\n,\nnan\n, or\ninf\ndepending on the numerator, instead of raising (\nGH51541\n)\nAdded\npandas.api.types.is_any_real_numeric_dtype()\nto check for real numeric dtypes (\nGH51152\n)\nvalue_counts()\nnow returns data with\nArrowDtype\nwith\npyarrow.int64\ntype instead of\n\"Int64\"\ntype (\nGH51462\n)\nArrowExtensionArray\ncomparison methods now return data with\nArrowDtype\nwith\npyarrow.bool_\ntype instead of\n\"boolean\"\ndtype (\nGH51643\n)\nfactorize()\nand\nunique()\npreserve the original dtype when passed numpy timedelta64 or datetime64 with non-nanosecond resolution (\nGH48670\n)\nNote\nA current PDEP proposes the deprecation and removal of the keywords\ninplace\nand\ncopy\nfor all but a small subset of methods from the pandas API. The current discussion takes place\nat\nhere\n. The keywords won芒t be necessary\nanymore in the context of Copy-on-Write. If this proposal is accepted, both\nkeywords would be deprecated in the next release of pandas and removed in pandas 3.0.\nDeprecations\n#\nDeprecated parsing datetime strings with system-local timezone to\ntzlocal\n, pass a\ntz\nkeyword or explicitly call\ntz_localize\ninstead (\nGH50791\n)\nDeprecated argument\ninfer_datetime_format\nin\nto_datetime()\nand\nread_csv()\n, as a strict version of it is now the default (\nGH48621\n)\nDeprecated behavior of\nto_datetime()\nwith\nunit\nwhen parsing strings, in a future version these will be parsed as datetimes (matching unit-less behavior) instead of cast to floats. To retain the old behavior, cast strings to numeric types before calling\nto_datetime()\n(\nGH50735\n)\nDeprecated\npandas.io.sql.execute()\n(\nGH50185\n)\nIndex.is_boolean()\nhas been deprecated. Use\npandas.api.types.is_bool_dtype()\ninstead (\nGH50042\n)\nIndex.is_integer()\nhas been deprecated. Use\npandas.api.types.is_integer_dtype()\ninstead (\nGH50042\n)\nIndex.is_floating()\nhas been deprecated. Use\npandas.api.types.is_float_dtype()\ninstead (\nGH50042\n)\nIndex.holds_integer()\nhas been deprecated. Use\npandas.api.types.infer_dtype()\ninstead (\nGH50243\n)\nIndex.is_numeric()\nhas been deprecated. Use\npandas.api.types.is_any_real_numeric_dtype()\ninstead (\nGH50042\n,:issue:\n51152\n)\nIndex.is_categorical()\nhas been deprecated. Use\npandas.api.types.is_categorical_dtype()\ninstead (\nGH50042\n)\nIndex.is_object()\nhas been deprecated. Use\npandas.api.types.is_object_dtype()\ninstead (\nGH50042\n)\nIndex.is_interval()\nhas been deprecated. Use\npandas.api.types.is_interval_dtype()\ninstead (\nGH50042\n)\nDeprecated argument\ndate_parser\nin\nread_csv()\n,\nread_table()\n,\nread_fwf()\n, and\nread_excel()\nin favour of\ndate_format\n(\nGH50601\n)\nDeprecated\nall\nand\nany\nreductions with\ndatetime64\nand\nDatetimeTZDtype\ndtypes, use e.g.\n(obj\n!=\npd.Timestamp(0),\ntz=obj.tz).all()\ninstead (\nGH34479\n)\nDeprecated unused arguments\n*args\nand\n**kwargs\nin\nResampler\n(\nGH50977\n)\nDeprecated calling\nfloat\nor\nint\non a single element\nSeries\nto return a\nfloat\nor\nint\nrespectively. Extract the element before calling\nfloat\nor\nint\ninstead (\nGH51101\n)\nDeprecated\nGrouper.groups()\n, use\nGroupby.groups()\ninstead (\nGH51182\n)\nDeprecated\nGrouper.grouper()\n, use\nGroupby.grouper()\ninstead (\nGH51182\n)\nDeprecated\nGrouper.obj()\n, use\nGroupby.obj()\ninstead (\nGH51206\n)\nDeprecated\nGrouper.indexer()\n, use\nResampler.indexer()\ninstead (\nGH51206\n)\nDeprecated\nGrouper.ax()\n, use\nResampler.ax()\ninstead (\nGH51206\n)\nDeprecated keyword\nuse_nullable_dtypes\nin\nread_parquet()\n, use\ndtype_backend\ninstead (\nGH51853\n)\nDeprecated\nSeries.pad()\nin favor of\nSeries.ffill()\n(\nGH33396\n)\nDeprecated\nSeries.backfill()\nin favor of\nSeries.bfill()\n(\nGH33396\n)\nDeprecated\nDataFrame.pad()\nin favor of\nDataFrame.ffill()\n(\nGH33396\n)\nDeprecated\nDataFrame.backfill()\nin favor of\nDataFrame.bfill()\n(\nGH33396\n)\nDeprecated\nclose()\n. Use\nStataReader\nas a context manager instead (\nGH49228\n)\nRemoval of prior version deprecations/changes\n#\nRemoved\nInt64Index\n,\nUInt64Index\nand\nFloat64Index\n. See also\nhere\nfor more information (\nGH42717\n)\nRemoved deprecated\nTimestamp.freq\n,\nTimestamp.freqstr\nand argument\nfreq\nfrom the\nTimestamp\nconstructor and\nTimestamp.fromordinal()\n(\nGH14146\n)\nRemoved deprecated\nCategoricalBlock\n,\nBlock.is_categorical()\n, require datetime64 and timedelta64 values to be wrapped in\nDatetimeArray\nor\nTimedeltaArray\nbefore passing to\nBlock.make_block_same_class()\n, require\nDatetimeTZBlock.values\nto have the correct ndim when passing to the\nBlockManager\nconstructor, and removed the 芒fastpath芒 keyword from the\nSingleBlockManager\nconstructor (\nGH40226\n,\nGH40571\n)\nRemoved deprecated global option\nuse_inf_as_null\nin favor of\nuse_inf_as_na\n(\nGH17126\n)\nRemoved deprecated module\npandas.core.index\n(\nGH30193\n)\nRemoved deprecated alias\npandas.core.tools.datetimes.to_time\n, import the function directly from\npandas.core.tools.times\ninstead (\nGH34145\n)\nRemoved deprecated alias\npandas.io.json.json_normalize\n, import the function directly from\npandas.json_normalize\ninstead (\nGH27615\n)\nRemoved deprecated\nCategorical.to_dense()\n, use\nnp.asarray(cat)\ninstead (\nGH32639\n)\nRemoved deprecated\nCategorical.take_nd()\n(\nGH27745\n)\nRemoved deprecated\nCategorical.mode()\n, use\nSeries(cat).mode()\ninstead (\nGH45033\n)\nRemoved deprecated\nCategorical.is_dtype_equal()\nand\nCategoricalIndex.is_dtype_equal()\n(\nGH37545\n)\nRemoved deprecated\nCategoricalIndex.take_nd()\n(\nGH30702\n)\nRemoved deprecated\nIndex.is_type_compatible()\n(\nGH42113\n)\nRemoved deprecated\nIndex.is_mixed()\n, check\nindex.inferred_type\ndirectly instead (\nGH32922\n)\nRemoved deprecated\npandas.api.types.is_categorical()\n; use\npandas.api.types.is_categorical_dtype()\ninstead  (\nGH33385\n)\nRemoved deprecated\nIndex.asi8()\n(\nGH37877\n)\nEnforced deprecation changing behavior when passing\ndatetime64[ns]\ndtype data and timezone-aware dtype to\nSeries\n, interpreting the values as wall-times instead of UTC times, matching\nDatetimeIndex\nbehavior (\nGH41662\n)\nEnforced deprecation changing behavior when applying a numpy ufunc on multiple non-aligned (on the index or columns)\nDataFrame\nthat will now align the inputs first (\nGH39239\n)\nRemoved deprecated\nDataFrame._AXIS_NUMBERS()\n,\nDataFrame._AXIS_NAMES()\n,\nSeries._AXIS_NUMBERS()\n,\nSeries._AXIS_NAMES()\n(\nGH33637\n)\nRemoved deprecated\nIndex.to_native_types()\n, use\nobj.astype(str)\ninstead (\nGH36418\n)\nRemoved deprecated\nSeries.iteritems()\n,\nDataFrame.iteritems()\n, use\nobj.items\ninstead (\nGH45321\n)\nRemoved deprecated\nDataFrame.lookup()\n(\nGH35224\n)\nRemoved deprecated\nSeries.append()\n,\nDataFrame.append()\n, use\nconcat()\ninstead (\nGH35407\n)\nRemoved deprecated\nSeries.iteritems()\n,\nDataFrame.iteritems()\nand\nHDFStore.iteritems()\nuse\nobj.items\ninstead (\nGH45321\n)\nRemoved deprecated\nDatetimeIndex.union_many()\n(\nGH45018\n)\nRemoved deprecated\nweekofyear\nand\nweek\nattributes of\nDatetimeArray\n,\nDatetimeIndex\nand\ndt\naccessor in favor of\nisocalendar().week\n(\nGH33595\n)\nRemoved deprecated\nRangeIndex._start()\n,\nRangeIndex._stop()\n,\nRangeIndex._step()\n, use\nstart\n,\nstop\n,\nstep\ninstead (\nGH30482\n)\nRemoved deprecated\nDatetimeIndex.to_perioddelta()\n, Use\ndtindex\n-\ndtindex.to_period(freq).to_timestamp()\ninstead (\nGH34853\n)\nRemoved deprecated\nStyler.hide_index()\nand\nStyler.hide_columns()\n(\nGH49397\n)\nRemoved deprecated\nStyler.set_na_rep()\nand\nStyler.set_precision()\n(\nGH49397\n)\nRemoved deprecated\nStyler.where()\n(\nGH49397\n)\nRemoved deprecated\nStyler.render()\n(\nGH49397\n)\nRemoved deprecated argument\ncol_space\nin\nDataFrame.to_latex()\n(\nGH47970\n)\nRemoved deprecated argument\nnull_color\nin\nStyler.highlight_null()\n(\nGH49397\n)\nRemoved deprecated argument\ncheck_less_precise\nin\ntesting.assert_frame_equal()\n,\ntesting.assert_extension_array_equal()\n,\ntesting.assert_series_equal()\n,\ntesting.assert_index_equal()\n(\nGH30562\n)\nRemoved deprecated\nnull_counts\nargument in\nDataFrame.info()\n. Use\nshow_counts\ninstead (\nGH37999\n)\nRemoved deprecated\nIndex.is_monotonic()\n, and\nSeries.is_monotonic()\n; use\nobj.is_monotonic_increasing\ninstead (\nGH45422\n)\nRemoved deprecated\nIndex.is_all_dates()\n(\nGH36697\n)\nEnforced deprecation disallowing passing a timezone-aware\nTimestamp\nand\ndtype=\"datetime64[ns]\"\nto\nSeries\nor\nDataFrame\nconstructors (\nGH41555\n)\nEnforced deprecation disallowing passing a sequence of timezone-aware values and\ndtype=\"datetime64[ns]\"\nto to\nSeries\nor\nDataFrame\nconstructors (\nGH41555\n)\nEnforced deprecation disallowing\nnumpy.ma.mrecords.MaskedRecords\nin the\nDataFrame\nconstructor; pass\n\"{name:\ndata[name]\nfor\nname\nin\ndata.dtype.names}\ninstead (\nGH40363\n)\nEnforced deprecation disallowing unit-less 芒datetime64芒 dtype in\nSeries.astype()\nand\nDataFrame.astype()\n(\nGH47844\n)\nEnforced deprecation disallowing using\n.astype\nto convert a\ndatetime64[ns]\nSeries\n,\nDataFrame\n, or\nDatetimeIndex\nto timezone-aware dtype, use\nobj.tz_localize\nor\nser.dt.tz_localize\ninstead (\nGH39258\n)\nEnforced deprecation disallowing using\n.astype\nto convert a timezone-aware\nSeries\n,\nDataFrame\n, or\nDatetimeIndex\nto timezone-naive\ndatetime64[ns]\ndtype, use\nobj.tz_localize(None)\nor\nobj.tz_convert(\"UTC\").tz_localize(None)\ninstead (\nGH39258\n)\nEnforced deprecation disallowing passing non boolean argument to sort in\nconcat()\n(\nGH44629\n)\nRemoved Date parser functions\nparse_date_time()\n,\nparse_date_fields()\n,\nparse_all_fields()\nand\ngeneric_parser()\n(\nGH24518\n)\nRemoved argument\nindex\nfrom the\ncore.arrays.SparseArray\nconstructor (\nGH43523\n)\nRemove argument\nsqueeze\nfrom\nDataFrame.groupby()\nand\nSeries.groupby()\n(\nGH32380\n)\nRemoved deprecated\napply\n,\napply_index\n,\n__call__\n,\nonOffset\n, and\nisAnchored\nattributes from\nDateOffset\n(\nGH34171\n)\nRemoved\nkeep_tz\nargument in\nDatetimeIndex.to_series()\n(\nGH29731\n)\nRemove arguments\nnames\nand\ndtype\nfrom\nIndex.copy()\nand\nlevels\nand\ncodes\nfrom\nMultiIndex.copy()\n(\nGH35853\n,\nGH36685\n)\nRemove argument\ninplace\nfrom\nMultiIndex.set_levels()\nand\nMultiIndex.set_codes()\n(\nGH35626\n)\nRemoved arguments\nverbose\nand\nencoding\nfrom\nDataFrame.to_excel()\nand\nSeries.to_excel()\n(\nGH47912\n)\nRemoved argument\nline_terminator\nfrom\nDataFrame.to_csv()\nand\nSeries.to_csv()\n, use\nlineterminator\ninstead (\nGH45302\n)\nRemoved argument\ninplace\nfrom\nDataFrame.set_axis()\nand\nSeries.set_axis()\n, use\nobj\n=\nobj.set_axis(...,\ncopy=False)\ninstead (\nGH48130\n)\nDisallow passing positional arguments to\nMultiIndex.set_levels()\nand\nMultiIndex.set_codes()\n(\nGH41485\n)\nDisallow parsing to Timedelta strings with components with units 芒Y芒, 芒y芒, or 芒M芒, as these do not represent unambiguous durations (\nGH36838\n)\nRemoved\nMultiIndex.is_lexsorted()\nand\nMultiIndex.lexsort_depth()\n(\nGH38701\n)\nRemoved argument\nhow\nfrom\nPeriodIndex.astype()\n, use\nPeriodIndex.to_timestamp()\ninstead (\nGH37982\n)\nRemoved argument\ntry_cast\nfrom\nDataFrame.mask()\n,\nDataFrame.where()\n,\nSeries.mask()\nand\nSeries.where()\n(\nGH38836\n)\nRemoved argument\ntz\nfrom\nPeriod.to_timestamp()\n, use\nobj.to_timestamp(...).tz_localize(tz)\ninstead (\nGH34522\n)\nRemoved argument\nsort_columns\nin\nDataFrame.plot()\nand\nSeries.plot()\n(\nGH47563\n)\nRemoved argument\nis_copy\nfrom\nDataFrame.take()\nand\nSeries.take()\n(\nGH30615\n)\nRemoved argument\nkind\nfrom\nIndex.get_slice_bound()\n,\nIndex.slice_indexer()\nand\nIndex.slice_locs()\n(\nGH41378\n)\nRemoved arguments\nprefix\n,\nsqueeze\n,\nerror_bad_lines\nand\nwarn_bad_lines\nfrom\nread_csv()\n(\nGH40413\n,\nGH43427\n)\nRemoved arguments\nsqueeze\nfrom\nread_excel()\n(\nGH43427\n)\nRemoved argument\ndatetime_is_numeric\nfrom\nDataFrame.describe()\nand\nSeries.describe()\nas datetime data will always be summarized as numeric data (\nGH34798\n)\nDisallow passing list\nkey\nto\nSeries.xs()\nand\nDataFrame.xs()\n, pass a tuple instead (\nGH41789\n)\nDisallow subclass-specific keywords (e.g. 芒freq芒, 芒tz芒, 芒names芒, 芒closed芒) in the\nIndex\nconstructor (\nGH38597\n)\nRemoved argument\ninplace\nfrom\nCategorical.remove_unused_categories()\n(\nGH37918\n)\nDisallow passing non-round floats to\nTimestamp\nwith\nunit=\"M\"\nor\nunit=\"Y\"\n(\nGH47266\n)\nRemove keywords\nconvert_float\nand\nmangle_dupe_cols\nfrom\nread_excel()\n(\nGH41176\n)\nRemove keyword\nmangle_dupe_cols\nfrom\nread_csv()\nand\nread_table()\n(\nGH48137\n)\nRemoved\nerrors\nkeyword from\nDataFrame.where()\n,\nSeries.where()\n,\nDataFrame.mask()\nand\nSeries.mask()\n(\nGH47728\n)\nDisallow passing non-keyword arguments to\nread_excel()\nexcept\nio\nand\nsheet_name\n(\nGH34418\n)\nDisallow passing non-keyword arguments to\nDataFrame.drop()\nand\nSeries.drop()\nexcept\nlabels\n(\nGH41486\n)\nDisallow passing non-keyword arguments to\nDataFrame.fillna()\nand\nSeries.fillna()\nexcept\nvalue\n(\nGH41485\n)\nDisallow passing non-keyword arguments to\nStringMethods.split()\nand\nStringMethods.rsplit()\nexcept for\npat\n(\nGH47448\n)\nDisallow passing non-keyword arguments to\nDataFrame.set_index()\nexcept\nkeys\n(\nGH41495\n)\nDisallow passing non-keyword arguments to\nResampler.interpolate()\nexcept\nmethod\n(\nGH41699\n)\nDisallow passing non-keyword arguments to\nDataFrame.reset_index()\nand\nSeries.reset_index()\nexcept\nlevel\n(\nGH41496\n)\nDisallow passing non-keyword arguments to\nDataFrame.dropna()\nand\nSeries.dropna()\n(\nGH41504\n)\nDisallow passing non-keyword arguments to\nExtensionArray.argsort()\n(\nGH46134\n)\nDisallow passing non-keyword arguments to\nCategorical.sort_values()\n(\nGH47618\n)\nDisallow passing non-keyword arguments to\nIndex.drop_duplicates()\nand\nSeries.drop_duplicates()\n(\nGH41485\n)\nDisallow passing non-keyword arguments to\nDataFrame.drop_duplicates()\nexcept for\nsubset\n(\nGH41485\n)\nDisallow passing non-keyword arguments to\nDataFrame.sort_index()\nand\nSeries.sort_index()\n(\nGH41506\n)\nDisallow passing non-keyword arguments to\nDataFrame.interpolate()\nand\nSeries.interpolate()\nexcept for\nmethod\n(\nGH41510\n)\nDisallow passing non-keyword arguments to\nDataFrame.any()\nand\nSeries.any()\n(\nGH44896\n)\nDisallow passing non-keyword arguments to\nIndex.set_names()\nexcept for\nnames\n(\nGH41551\n)\nDisallow passing non-keyword arguments to\nIndex.join()\nexcept for\nother\n(\nGH46518\n)\nDisallow passing non-keyword arguments to\nconcat()\nexcept for\nobjs\n(\nGH41485\n)\nDisallow passing non-keyword arguments to\npivot()\nexcept for\ndata\n(\nGH48301\n)\nDisallow passing non-keyword arguments to\nDataFrame.pivot()\n(\nGH48301\n)\nDisallow passing non-keyword arguments to\nread_html()\nexcept for\nio\n(\nGH27573\n)\nDisallow passing non-keyword arguments to\nread_json()\nexcept for\npath_or_buf\n(\nGH27573\n)\nDisallow passing non-keyword arguments to\nread_sas()\nexcept for\nfilepath_or_buffer\n(\nGH47154\n)\nDisallow passing non-keyword arguments to\nread_stata()\nexcept for\nfilepath_or_buffer\n(\nGH48128\n)\nDisallow passing non-keyword arguments to\nread_csv()\nexcept\nfilepath_or_buffer\n(\nGH41485\n)\nDisallow passing non-keyword arguments to\nread_table()\nexcept\nfilepath_or_buffer\n(\nGH41485\n)\nDisallow passing non-keyword arguments to\nread_fwf()\nexcept\nfilepath_or_buffer\n(\nGH44710\n)\nDisallow passing non-keyword arguments to\nread_xml()\nexcept for\npath_or_buffer\n(\nGH45133\n)\nDisallow passing non-keyword arguments to\nSeries.mask()\nand\nDataFrame.mask()\nexcept\ncond\nand\nother\n(\nGH41580\n)\nDisallow passing non-keyword arguments to\nDataFrame.to_stata()\nexcept for\npath\n(\nGH48128\n)\nDisallow passing non-keyword arguments to\nDataFrame.where()\nand\nSeries.where()\nexcept for\ncond\nand\nother\n(\nGH41523\n)\nDisallow passing non-keyword arguments to\nSeries.set_axis()\nand\nDataFrame.set_axis()\nexcept for\nlabels\n(\nGH41491\n)\nDisallow passing non-keyword arguments to\nSeries.rename_axis()\nand\nDataFrame.rename_axis()\nexcept for\nmapper\n(\nGH47587\n)\nDisallow passing non-keyword arguments to\nSeries.clip()\nand\nDataFrame.clip()\nexcept\nlower\nand\nupper\n(\nGH41511\n)\nDisallow passing non-keyword arguments to\nSeries.bfill()\n,\nSeries.ffill()\n,\nDataFrame.bfill()\nand\nDataFrame.ffill()\n(\nGH41508\n)\nDisallow passing non-keyword arguments to\nDataFrame.replace()\n,\nSeries.replace()\nexcept for\nto_replace\nand\nvalue\n(\nGH47587\n)\nDisallow passing non-keyword arguments to\nDataFrame.sort_values()\nexcept for\nby\n(\nGH41505\n)\nDisallow passing non-keyword arguments to\nSeries.sort_values()\n(\nGH41505\n)\nDisallow passing non-keyword arguments to\nDataFrame.reindex()\nexcept for\nlabels\n(\nGH17966\n)\nDisallow\nIndex.reindex()\nwith non-unique\nIndex\nobjects (\nGH42568\n)\nDisallowed constructing\nCategorical\nwith scalar\ndata\n(\nGH38433\n)\nDisallowed constructing\nCategoricalIndex\nwithout passing\ndata\n(\nGH38944\n)\nRemoved\nRolling.validate()\n,\nExpanding.validate()\n, and\nExponentialMovingWindow.validate()\n(\nGH43665\n)\nRemoved\nRolling.win_type\nreturning\n\"freq\"\n(\nGH38963\n)\nRemoved\nRolling.is_datetimelike\n(\nGH38963\n)\nRemoved the\nlevel\nkeyword in\nDataFrame\nand\nSeries\naggregations; use\ngroupby\ninstead (\nGH39983\n)\nRemoved deprecated\nTimedelta.delta()\n,\nTimedelta.is_populated()\n, and\nTimedelta.freq\n(\nGH46430\n,\nGH46476\n)\nRemoved deprecated\nNaT.freq\n(\nGH45071\n)\nRemoved deprecated\nCategorical.replace()\n, use\nSeries.replace()\ninstead (\nGH44929\n)\nRemoved the\nnumeric_only\nkeyword from\nCategorical.min()\nand\nCategorical.max()\nin favor of\nskipna\n(\nGH48821\n)\nChanged behavior of\nDataFrame.median()\nand\nDataFrame.mean()\nwith\nnumeric_only=None\nto not exclude datetime-like columns THIS NOTE WILL BE IRRELEVANT ONCE\nnumeric_only=None\nDEPRECATION IS ENFORCED (\nGH29941\n)\nRemoved\nis_extension_type()\nin favor of\nis_extension_array_dtype()\n(\nGH29457\n)\nRemoved\n.ExponentialMovingWindow.vol\n(\nGH39220\n)\nRemoved\nIndex.get_value()\nand\nIndex.set_value()\n(\nGH33907\n,\nGH28621\n)\nRemoved\nSeries.slice_shift()\nand\nDataFrame.slice_shift()\n(\nGH37601\n)\nRemove\nDataFrameGroupBy.pad()\nand\nDataFrameGroupBy.backfill()\n(\nGH45076\n)\nRemove\nnumpy\nargument from\nread_json()\n(\nGH30636\n)\nDisallow passing abbreviations for\norient\nin\nDataFrame.to_dict()\n(\nGH32516\n)\nDisallow partial slicing on an non-monotonic\nDatetimeIndex\nwith keys which are not in Index. This now raises a\nKeyError\n(\nGH18531\n)\nRemoved\nget_offset\nin favor of\nto_offset()\n(\nGH30340\n)\nRemoved the\nwarn\nkeyword in\ninfer_freq()\n(\nGH45947\n)\nRemoved the\ninclude_start\nand\ninclude_end\narguments in\nDataFrame.between_time()\nin favor of\ninclusive\n(\nGH43248\n)\nRemoved the\nclosed\nargument in\ndate_range()\nand\nbdate_range()\nin favor of\ninclusive\nargument (\nGH40245\n)\nRemoved the\ncenter\nkeyword in\nDataFrame.expanding()\n(\nGH20647\n)\nRemoved the\ntruediv\nkeyword from\neval()\n(\nGH29812\n)\nRemoved the\nmethod\nand\ntolerance\narguments in\nIndex.get_loc()\n. Use\nindex.get_indexer([label],\nmethod=...,\ntolerance=...)\ninstead (\nGH42269\n)\nRemoved the\npandas.datetime\nsubmodule (\nGH30489\n)\nRemoved the\npandas.np\nsubmodule (\nGH30296\n)\nRemoved\npandas.util.testing\nin favor of\npandas.testing\n(\nGH30745\n)\nRemoved\nSeries.str.__iter__()\n(\nGH28277\n)\nRemoved\npandas.SparseArray\nin favor of\narrays.SparseArray\n(\nGH30642\n)\nRemoved\npandas.SparseSeries\nand\npandas.SparseDataFrame\n, including pickle support. (\nGH30642\n)\nEnforced disallowing passing an integer\nfill_value\nto\nDataFrame.shift()\nand\nSeries.shift`()\nwith datetime64, timedelta64, or period dtypes (\nGH32591\n)\nEnforced disallowing a string column label into\ntimes\nin\nDataFrame.ewm()\n(\nGH43265\n)\nEnforced disallowing passing\nTrue\nand\nFalse\ninto\ninclusive\nin\nSeries.between()\nin favor of\n\"both\"\nand\n\"neither\"\nrespectively (\nGH40628\n)\nEnforced disallowing using\nusecols\nwith out of bounds indices for\nread_csv\nwith\nengine=\"c\"\n(\nGH25623\n)\nEnforced disallowing the use of\n**kwargs\nin\nExcelWriter\n; use the keyword argument\nengine_kwargs\ninstead (\nGH40430\n)\nEnforced disallowing a tuple of column labels into\nDataFrameGroupBy.__getitem__()\n(\nGH30546\n)\nEnforced disallowing missing labels when indexing with a sequence of labels on a level of a\nMultiIndex\n. This now raises a\nKeyError\n(\nGH42351\n)\nEnforced disallowing setting values with\n.loc\nusing a positional slice. Use\n.loc\nwith labels or\n.iloc\nwith positions instead (\nGH31840\n)\nEnforced disallowing positional indexing with a\nfloat\nkey even if that key is a round number, manually cast to integer instead (\nGH34193\n)\nEnforced disallowing using a\nDataFrame\nindexer with\n.iloc\n, use\n.loc\ninstead for automatic alignment (\nGH39022\n)\nEnforced disallowing\nset\nor\ndict\nindexers in\n__getitem__\nand\n__setitem__\nmethods (\nGH42825\n)\nEnforced disallowing indexing on a\nIndex\nor positional indexing on a\nSeries\nproducing multi-dimensional objects e.g.\nobj[:,\nNone]\n, convert to numpy before indexing instead (\nGH35141\n)\nEnforced disallowing\ndict\nor\nset\nobjects in\nsuffixes\nin\nmerge()\n(\nGH34810\n)\nEnforced disallowing\nmerge()\nto produce duplicated columns through the\nsuffixes\nkeyword and already existing columns (\nGH22818\n)\nEnforced disallowing using\nmerge()\nor\njoin()\non a different number of levels (\nGH34862\n)\nEnforced disallowing\nvalue_name\nargument in\nDataFrame.melt()\nto match an element in the\nDataFrame\ncolumns (\nGH35003\n)\nEnforced disallowing passing\nshowindex\ninto\n**kwargs\nin\nDataFrame.to_markdown()\nand\nSeries.to_markdown()\nin favor of\nindex\n(\nGH33091\n)\nRemoved setting Categorical._codes directly (\nGH41429\n)\nRemoved setting Categorical.categories directly (\nGH47834\n)\nRemoved argument\ninplace\nfrom\nCategorical.add_categories()\n,\nCategorical.remove_categories()\n,\nCategorical.set_categories()\n,\nCategorical.rename_categories()\n,\nCategorical.reorder_categories()\n,\nCategorical.set_ordered()\n,\nCategorical.as_ordered()\n,\nCategorical.as_unordered()\n(\nGH37981\n,\nGH41118\n,\nGH41133\n,\nGH47834\n)\nEnforced\nRolling.count()\nwith\nmin_periods=None\nto default to the size of the window (\nGH31302\n)\nRenamed\nfname\nto\npath\nin\nDataFrame.to_parquet()\n,\nDataFrame.to_stata()\nand\nDataFrame.to_feather()\n(\nGH30338\n)\nEnforced disallowing indexing a\nSeries\nwith a single item list with a slice (e.g.\nser[[slice(0,\n2)]]\n). Either convert the list to tuple, or pass the slice directly instead (\nGH31333\n)\nChanged behavior indexing on a\nDataFrame\nwith a\nDatetimeIndex\nindex using a string indexer, previously this operated as a slice on rows, now it operates like any other column key; use\nframe.loc[key]\nfor the old behavior (\nGH36179\n)\nEnforced the\ndisplay.max_colwidth\noption to not accept negative integers (\nGH31569\n)\nRemoved the\ndisplay.column_space\noption in favor of\ndf.to_string(col_space=...)\n(\nGH47280\n)\nRemoved the deprecated method\nmad\nfrom pandas classes (\nGH11787\n)\nRemoved the deprecated method\ntshift\nfrom pandas classes (\nGH11631\n)\nChanged behavior of empty data passed into\nSeries\n; the default dtype will be\nobject\ninstead of\nfloat64\n(\nGH29405\n)\nChanged the behavior of\nDatetimeIndex.union()\n,\nDatetimeIndex.intersection()\n, and\nDatetimeIndex.symmetric_difference()\nwith mismatched timezones to convert to UTC instead of casting to object dtype (\nGH39328\n)\nChanged the behavior of\nto_datetime()\nwith argument 芒now芒 with\nutc=False\nto match\nTimestamp(\"now\")\n(\nGH18705\n)\nChanged the behavior of indexing on a timezone-aware\nDatetimeIndex\nwith a timezone-naive\ndatetime\nobject or vice-versa; these now behave like any other non-comparable type by raising\nKeyError\n(\nGH36148\n)\nChanged the behavior of\nIndex.reindex()\n,\nSeries.reindex()\n, and\nDataFrame.reindex()\nwith a\ndatetime64\ndtype and a\ndatetime.date\nobject for\nfill_value\n; these are no longer considered equivalent to\ndatetime.datetime\nobjects so the reindex casts to object dtype (\nGH39767\n)\nChanged behavior of\nSparseArray.astype()\nwhen given a dtype that is not explicitly\nSparseDtype\n, cast to the exact requested dtype rather than silently using a\nSparseDtype\ninstead (\nGH34457\n)\nChanged behavior of\nIndex.ravel()\nto return a view on the original\nIndex\ninstead of a\nnp.ndarray\n(\nGH36900\n)\nChanged behavior of\nSeries.to_frame()\nand\nIndex.to_frame()\nwith explicit\nname=None\nto use\nNone\nfor the column name instead of the index芒s name or default\n0\n(\nGH45523\n)\nChanged behavior of\nconcat()\nwith one array of\nbool\n-dtype and another of integer dtype, this now returns\nobject\ndtype instead of integer dtype; explicitly cast the bool object to integer before concatenating to get the old behavior (\nGH45101\n)\nChanged behavior of\nDataFrame\nconstructor given floating-point\ndata\nand an integer\ndtype\n, when the data cannot be cast losslessly, the floating point dtype is retained, matching\nSeries\nbehavior (\nGH41170\n)\nChanged behavior of\nIndex\nconstructor when given a\nnp.ndarray\nwith object-dtype containing numeric entries; this now retains object dtype rather than inferring a numeric dtype, consistent with\nSeries\nbehavior (\nGH42870\n)\nChanged behavior of\nIndex.__and__()\n,\nIndex.__or__()\nand\nIndex.__xor__()\nto behave as logical operations (matching\nSeries\nbehavior) instead of aliases for set operations (\nGH37374\n)\nChanged behavior of\nDataFrame\nconstructor when passed a list whose first element is a\nCategorical\n, this now treats the elements as rows casting to\nobject\ndtype, consistent with behavior for other types (\nGH38845\n)\nChanged behavior of\nDataFrame\nconstructor when passed a\ndtype\n(other than int) that the data cannot be cast to; it now raises instead of silently ignoring the dtype (\nGH41733\n)\nChanged the behavior of\nSeries\nconstructor, it will no longer infer a datetime64 or timedelta64 dtype from string entries (\nGH41731\n)\nChanged behavior of\nTimestamp\nconstructor with a\nnp.datetime64\nobject and a\ntz\npassed to interpret the input as a wall-time as opposed to a UTC time (\nGH42288\n)\nChanged behavior of\nTimestamp.utcfromtimestamp()\nto return a timezone-aware object satisfying\nTimestamp.utcfromtimestamp(val).timestamp()\n==\nval\n(\nGH45083\n)\nChanged behavior of\nIndex\nconstructor when passed a\nSparseArray\nor\nSparseDtype\nto retain that dtype instead of casting to\nnumpy.ndarray\n(\nGH43930\n)\nChanged behavior of setitem-like operations (\n__setitem__\n,\nfillna\n,\nwhere\n,\nmask\n,\nreplace\n,\ninsert\n, fill_value for\nshift\n) on an object with\nDatetimeTZDtype\nwhen using a value with a non-matching timezone, the value will be cast to the object芒s timezone instead of casting both to object-dtype (\nGH44243\n)\nChanged behavior of\nIndex\n,\nSeries\n,\nDataFrame\nconstructors with floating-dtype data and a\nDatetimeTZDtype\n, the data are now interpreted as UTC-times instead of wall-times, consistent with how integer-dtype data are treated (\nGH45573\n)\nChanged behavior of\nSeries\nand\nDataFrame\nconstructors with integer dtype and floating-point data containing\nNaN\n, this now raises\nIntCastingNaNError\n(\nGH40110\n)\nChanged behavior of\nSeries\nand\nDataFrame\nconstructors with an integer\ndtype\nand values that are too large to losslessly cast to this dtype, this now raises\nValueError\n(\nGH41734\n)\nChanged behavior of\nSeries\nand\nDataFrame\nconstructors with an integer\ndtype\nand values having either\ndatetime64\nor\ntimedelta64\ndtypes, this now raises\nTypeError\n, use\nvalues.view(\"int64\")\ninstead (\nGH41770\n)\nRemoved the deprecated\nbase\nand\nloffset\narguments from\npandas.DataFrame.resample()\n,\npandas.Series.resample()\nand\npandas.Grouper\n. Use\noffset\nor\norigin\ninstead (\nGH31809\n)\nChanged behavior of\nSeries.fillna()\nand\nDataFrame.fillna()\nwith\ntimedelta64[ns]\ndtype and an incompatible\nfill_value\n; this now casts to\nobject\ndtype instead of raising, consistent with the behavior with other dtypes (\nGH45746\n)\nChange the default argument of\nregex\nfor\nSeries.str.replace()\nfrom\nTrue\nto\nFalse\n. Additionally, a single character\npat\nwith\nregex=True\nis now treated as a regular expression instead of a string literal. (\nGH36695\n,\nGH24804\n)\nChanged behavior of\nDataFrame.any()\nand\nDataFrame.all()\nwith\nbool_only=True\n; object-dtype columns with all-bool values will no longer be included, manually cast to\nbool\ndtype first (\nGH46188\n)\nChanged behavior of\nDataFrame.max()\n,\nDataFrame.min\n,\nDataFrame.mean\n,\nDataFrame.median\n,\nDataFrame.skew\n,\nDataFrame.kurt\nwith\naxis=None\nto return a scalar applying the aggregation across both axes (\nGH45072\n)\nChanged behavior of comparison of a\nTimestamp\nwith a\ndatetime.date\nobject; these now compare as un-equal and raise on inequality comparisons, matching the\ndatetime.datetime\nbehavior (\nGH36131\n)\nChanged behavior of comparison of\nNaT\nwith a\ndatetime.date\nobject; these now raise on inequality comparisons (\nGH39196\n)\nEnforced deprecation of silently dropping columns that raised a\nTypeError\nin\nSeries.transform\nand\nDataFrame.transform\nwhen used with a list or dictionary (\nGH43740\n)\nChanged behavior of\nDataFrame.apply()\nwith list-like so that any partial failure will raise an error (\nGH43740\n)\nChanged behaviour of\nDataFrame.to_latex()\nto now use the Styler implementation via\nStyler.to_latex()\n(\nGH47970\n)\nChanged behavior of\nSeries.__setitem__()\nwith an integer key and a\nFloat64Index\nwhen the key is not present in the index; previously we treated the key as positional (behaving like\nseries.iloc[key]\n=\nval\n), now we treat it is a label (behaving like\nseries.loc[key]\n=\nval\n), consistent with\nSeries.__getitem__`()\nbehavior (\nGH33469\n)\nRemoved\nna_sentinel\nargument from\nfactorize()\n,\nIndex.factorize()\n, and\nExtensionArray.factorize()\n(\nGH47157\n)\nChanged behavior of\nSeries.diff()\nand\nDataFrame.diff()\nwith\nExtensionDtype\ndtypes whose arrays do not implement\ndiff\n, these now raise\nTypeError\nrather than casting to numpy (\nGH31025\n)\nEnforced deprecation of calling numpy 芒ufunc芒s on\nDataFrame\nwith\nmethod=\"outer\"\n; this now raises\nNotImplementedError\n(\nGH36955\n)\nEnforced deprecation disallowing passing\nnumeric_only=True\nto\nSeries\nreductions (\nrank\n,\nany\n,\nall\n, 芒娄) with non-numeric dtype (\nGH47500\n)\nChanged behavior of\nDataFrameGroupBy.apply()\nand\nSeriesGroupBy.apply()\nso that\ngroup_keys\nis respected even if a transformer is detected (\nGH34998\n)\nComparisons between a\nDataFrame\nand a\nSeries\nwhere the frame芒s columns do not match the series芒s index raise\nValueError\ninstead of automatically aligning, do\nleft,\nright\n=\nleft.align(right,\naxis=1,\ncopy=False)\nbefore comparing (\nGH36795\n)\nEnforced deprecation\nnumeric_only=None\n(the default) in DataFrame reductions that would silently drop columns that raised;\nnumeric_only\nnow defaults to\nFalse\n(\nGH41480\n)\nChanged default of\nnumeric_only\nto\nFalse\nin all DataFrame methods with that argument (\nGH46096\n,\nGH46906\n)\nChanged default of\nnumeric_only\nto\nFalse\nin\nSeries.rank()\n(\nGH47561\n)\nEnforced deprecation of silently dropping nuisance columns in groupby and resample operations when\nnumeric_only=False\n(\nGH41475\n)\nEnforced deprecation of silently dropping nuisance columns in\nRolling\n,\nExpanding\n, and\nExponentialMovingWindow\nops. This will now raise a\nerrors.DataError\n(\nGH42834\n)\nChanged behavior in setting values with\ndf.loc[:,\nfoo]\n=\nbar\nor\ndf.iloc[:,\nfoo]\n=\nbar\n, these now always attempt to set values inplace before falling back to casting (\nGH45333\n)\nChanged default of\nnumeric_only\nin various\nDataFrameGroupBy\nmethods; all methods now default to\nnumeric_only=False\n(\nGH46072\n)\nChanged default of\nnumeric_only\nto\nFalse\nin\nResampler\nmethods (\nGH47177\n)\nUsing the method\nDataFrameGroupBy.transform()\nwith a callable that returns DataFrames will align to the input芒s index (\nGH47244\n)\nWhen providing a list of columns of length one to\nDataFrame.groupby()\n, the keys that are returned by iterating over the resulting\nDataFrameGroupBy\nobject will now be tuples of length one (\nGH47761\n)\nRemoved deprecated methods\nExcelWriter.write_cells()\n,\nExcelWriter.save()\n,\nExcelWriter.cur_sheet()\n,\nExcelWriter.handles()\n,\nExcelWriter.path()\n(\nGH45795\n)\nThe\nExcelWriter\nattribute\nbook\ncan no longer be set; it is still available to be accessed and mutated (\nGH48943\n)\nRemoved unused\n*args\nand\n**kwargs\nin\nRolling\n,\nExpanding\n, and\nExponentialMovingWindow\nops (\nGH47851\n)\nRemoved the deprecated argument\nline_terminator\nfrom\nDataFrame.to_csv()\n(\nGH45302\n)\nRemoved the deprecated argument\nlabel\nfrom\nlreshape()\n(\nGH30219\n)\nArguments after\nexpr\nin\nDataFrame.eval()\nand\nDataFrame.query()\nare keyword-only (\nGH47587\n)\nRemoved\nIndex._get_attributes_dict()\n(\nGH50648\n)\nRemoved\nSeries.__array_wrap__()\n(\nGH50648\n)\nChanged behavior of\nDataFrame.value_counts()\nto return a\nSeries\nwith\nMultiIndex\nfor any list-like(one element or not) but an\nIndex\nfor a single label (\nGH50829\n)\nPerformance improvements\n#\nPerformance improvement in\nDataFrameGroupBy.median()\nand\nSeriesGroupBy.median()\nand\nDataFrameGroupBy.cumprod()\nfor nullable dtypes (\nGH37493\n)\nPerformance improvement in\nDataFrameGroupBy.all()\n,\nDataFrameGroupBy.any()\n,\nSeriesGroupBy.all()\n, and\nSeriesGroupBy.any()\nfor object dtype (\nGH50623\n)\nPerformance improvement in\nMultiIndex.argsort()\nand\nMultiIndex.sort_values()\n(\nGH48406\n)\nPerformance improvement in\nMultiIndex.size()\n(\nGH48723\n)\nPerformance improvement in\nMultiIndex.union()\nwithout missing values and without duplicates (\nGH48505\n,\nGH48752\n)\nPerformance improvement in\nMultiIndex.difference()\n(\nGH48606\n)\nPerformance improvement in\nMultiIndex\nset operations with sort=None (\nGH49010\n)\nPerformance improvement in\nDataFrameGroupBy.mean()\n,\nSeriesGroupBy.mean()\n,\nDataFrameGroupBy.var()\n, and\nSeriesGroupBy.var()\nfor extension array dtypes (\nGH37493\n)\nPerformance improvement in\nMultiIndex.isin()\nwhen\nlevel=None\n(\nGH48622\n,\nGH49577\n)\nPerformance improvement in\nMultiIndex.putmask()\n(\nGH49830\n)\nPerformance improvement in\nIndex.union()\nand\nMultiIndex.union()\nwhen index contains duplicates (\nGH48900\n)\nPerformance improvement in\nSeries.rank()\nfor pyarrow-backed dtypes (\nGH50264\n)\nPerformance improvement in\nSeries.searchsorted()\nfor pyarrow-backed dtypes (\nGH50447\n)\nPerformance improvement in\nSeries.fillna()\nfor extension array dtypes (\nGH49722\n,\nGH50078\n)\nPerformance improvement in\nIndex.join()\n,\nIndex.intersection()\nand\nIndex.union()\nfor masked and arrow dtypes when\nIndex\nis monotonic (\nGH50310\n,\nGH51365\n)\nPerformance improvement for\nSeries.value_counts()\nwith nullable dtype (\nGH48338\n)\nPerformance improvement for\nSeries\nconstructor passing integer numpy array with nullable dtype (\nGH48338\n)\nPerformance improvement for\nDatetimeIndex\nconstructor passing a list (\nGH48609\n)\nPerformance improvement in\nmerge()\nand\nDataFrame.join()\nwhen joining on a sorted\nMultiIndex\n(\nGH48504\n)\nPerformance improvement in\nto_datetime()\nwhen parsing strings with timezone offsets (\nGH50107\n)\nPerformance improvement in\nDataFrame.loc()\nand\nSeries.loc()\nfor tuple-based indexing of a\nMultiIndex\n(\nGH48384\n)\nPerformance improvement for\nSeries.replace()\nwith categorical dtype (\nGH49404\n)\nPerformance improvement for\nMultiIndex.unique()\n(\nGH48335\n)\nPerformance improvement for indexing operations with nullable and arrow dtypes (\nGH49420\n,\nGH51316\n)\nPerformance improvement for\nconcat()\nwith extension array backed indexes (\nGH49128\n,\nGH49178\n)\nPerformance improvement for\napi.types.infer_dtype()\n(\nGH51054\n)\nReduce memory usage of\nDataFrame.to_pickle()\n/\nSeries.to_pickle()\nwhen using BZ2 or LZMA (\nGH49068\n)\nPerformance improvement for\nStringArray\nconstructor passing a numpy array with type\nnp.str_\n(\nGH49109\n)\nPerformance improvement in\nfrom_tuples()\n(\nGH50620\n)\nPerformance improvement in\nfactorize()\n(\nGH49177\n)\nPerformance improvement in\n__setitem__()\n(\nGH50248\n,\nGH50632\n)\nPerformance improvement in\nArrowExtensionArray\ncomparison methods when array contains NA (\nGH50524\n)\nPerformance improvement in\nto_numpy()\n(\nGH49973\n,\nGH51227\n)\nPerformance improvement when parsing strings to\nBooleanDtype\n(\nGH50613\n)\nPerformance improvement in\nDataFrame.join()\nwhen joining on a subset of a\nMultiIndex\n(\nGH48611\n)\nPerformance improvement for\nMultiIndex.intersection()\n(\nGH48604\n)\nPerformance improvement in\nDataFrame.__setitem__()\n(\nGH46267\n)\nPerformance improvement in\nvar\nand\nstd\nfor nullable dtypes (\nGH48379\n).\nPerformance improvement when iterating over pyarrow and nullable dtypes (\nGH49825\n,\nGH49851\n)\nPerformance improvements to\nread_sas()\n(\nGH47403\n,\nGH47405\n,\nGH47656\n,\nGH48502\n)\nMemory improvement in\nRangeIndex.sort_values()\n(\nGH48801\n)\nPerformance improvement in\nSeries.to_numpy()\nif\ncopy=True\nby avoiding copying twice (\nGH24345\n)\nPerformance improvement in\nSeries.rename()\nwith\nMultiIndex\n(\nGH21055\n)\nPerformance improvement in\nDataFrameGroupBy\nand\nSeriesGroupBy\nwhen\nby\nis a categorical type and\nsort=False\n(\nGH48976\n)\nPerformance improvement in\nDataFrameGroupBy\nand\nSeriesGroupBy\nwhen\nby\nis a categorical type and\nobserved=False\n(\nGH49596\n)\nPerformance improvement in\nread_stata()\nwith parameter\nindex_col\nset to\nNone\n(the default). Now the index will be a\nRangeIndex\ninstead of\nInt64Index\n(\nGH49745\n)\nPerformance improvement in\nmerge()\nwhen not merging on the index - the new index will now be\nRangeIndex\ninstead of\nInt64Index\n(\nGH49478\n)\nPerformance improvement in\nDataFrame.to_dict()\nand\nSeries.to_dict()\nwhen using any non-object dtypes (\nGH46470\n)\nPerformance improvement in\nread_html()\nwhen there are multiple tables (\nGH49929\n)\nPerformance improvement in\nPeriod\nconstructor when constructing from a string or integer (\nGH38312\n)\nPerformance improvement in\nto_datetime()\nwhen using\n'%Y%m%d'\nformat (\nGH17410\n)\nPerformance improvement in\nto_datetime()\nwhen format is given or can be inferred (\nGH50465\n)\nPerformance improvement in\nSeries.median()\nfor nullable dtypes (\nGH50838\n)\nPerformance improvement in\nread_csv()\nwhen passing\nto_datetime()\nlambda-function to\ndate_parser\nand inputs have mixed timezone offsetes (\nGH35296\n)\nPerformance improvement in\nisna()\nand\nisnull()\n(\nGH50658\n)\nPerformance improvement in\nSeriesGroupBy.value_counts()\nwith categorical dtype (\nGH46202\n)\nFixed a reference leak in\nread_hdf()\n(\nGH37441\n)\nFixed a memory leak in\nDataFrame.to_json()\nand\nSeries.to_json()\nwhen serializing datetimes and timedeltas (\nGH40443\n)\nDecreased memory usage in many\nDataFrameGroupBy\nmethods (\nGH51090\n)\nPerformance improvement in\nDataFrame.round()\nfor an integer\ndecimal\nparameter (\nGH17254\n)\nPerformance improvement in\nDataFrame.replace()\nand\nSeries.replace()\nwhen using a large dict for\nto_replace\n(\nGH6697\n)\nMemory improvement in\nStataReader\nwhen reading seekable files (\nGH48922\n)\nBug fixes\n#\nCategorical\n#\nBug in\nCategorical.set_categories()\nlosing dtype information (\nGH48812\n)\nBug in\nSeries.replace()\nwith categorical dtype when\nto_replace\nvalues overlap with new values (\nGH49404\n)\nBug in\nSeries.replace()\nwith categorical dtype losing nullable dtypes of underlying categories (\nGH49404\n)\nBug in\nDataFrame.groupby()\nand\nSeries.groupby()\nwould reorder categories when used as a grouper (\nGH48749\n)\nBug in\nCategorical\nconstructor when constructing from a\nCategorical\nobject and\ndtype=\"category\"\nlosing ordered-ness (\nGH49309\n)\nBug in\nSeriesGroupBy.min()\n,\nSeriesGroupBy.max()\n,\nDataFrameGroupBy.min()\n, and\nDataFrameGroupBy.max()\nwith unordered\nCategoricalDtype\nwith no groups failing to raise\nTypeError\n(\nGH51034\n)\nDatetimelike\n#\nBug in\npandas.infer_freq()\n, raising\nTypeError\nwhen inferred on\nRangeIndex\n(\nGH47084\n)\nBug in\nto_datetime()\nincorrectly raising\nOverflowError\nwith string arguments corresponding to large integers (\nGH50533\n)\nBug in\nto_datetime()\nwas raising on invalid offsets with\nerrors='coerce'\nand\ninfer_datetime_format=True\n(\nGH48633\n)\nBug in\nDatetimeIndex\nconstructor failing to raise when\ntz=None\nis explicitly specified in conjunction with timezone-aware\ndtype\nor data (\nGH48659\n)\nBug in subtracting a\ndatetime\nscalar from\nDatetimeIndex\nfailing to retain the original\nfreq\nattribute (\nGH48818\n)\nBug in\npandas.tseries.holiday.Holiday\nwhere a half-open date interval causes inconsistent return types from\nUSFederalHolidayCalendar.holidays()\n(\nGH49075\n)\nBug in rendering\nDatetimeIndex\nand\nSeries\nand\nDataFrame\nwith timezone-aware dtypes with\ndateutil\nor\nzoneinfo\ntimezones near daylight-savings transitions (\nGH49684\n)\nBug in\nto_datetime()\nwas raising\nValueError\nwhen parsing\nTimestamp\n,\ndatetime.datetime\n,\ndatetime.date\n, or\nnp.datetime64\nobjects when non-ISO8601\nformat\nwas passed (\nGH49298\n,\nGH50036\n)\nBug in\nto_datetime()\nwas raising\nValueError\nwhen parsing empty string and non-ISO8601 format was passed. Now, empty strings will be parsed as\nNaT\n, for compatibility with how is done for ISO8601 formats (\nGH50251\n)\nBug in\nTimestamp\nwas showing\nUserWarning\n, which was not actionable by users, when parsing non-ISO8601 delimited date strings (\nGH50232\n)\nBug in\nto_datetime()\nwas showing misleading\nValueError\nwhen parsing dates with format containing ISO week directive and ISO weekday directive (\nGH50308\n)\nBug in\nTimestamp.round()\nwhen the\nfreq\nargument has zero-duration (e.g. 芒0ns芒) returning incorrect results instead of raising (\nGH49737\n)\nBug in\nto_datetime()\nwas not raising\nValueError\nwhen invalid format was passed and\nerrors\nwas\n'ignore'\nor\n'coerce'\n(\nGH50266\n)\nBug in\nDateOffset\nwas throwing\nTypeError\nwhen constructing with milliseconds and another super-daily argument (\nGH49897\n)\nBug in\nto_datetime()\nwas not raising\nValueError\nwhen parsing string with decimal date with format\n'%Y%m%d'\n(\nGH50051\n)\nBug in\nto_datetime()\nwas not converting\nNone\nto\nNaT\nwhen parsing mixed-offset date strings with ISO8601 format (\nGH50071\n)\nBug in\nto_datetime()\nwas not returning input when parsing out-of-bounds date string with\nerrors='ignore'\nand\nformat='%Y%m%d'\n(\nGH14487\n)\nBug in\nto_datetime()\nwas converting timezone-naive\ndatetime.datetime\nto timezone-aware when parsing with timezone-aware strings, ISO8601 format, and\nutc=False\n(\nGH50254\n)\nBug in\nto_datetime()\nwas throwing\nValueError\nwhen parsing dates with ISO8601 format where some values were not zero-padded (\nGH21422\n)\nBug in\nto_datetime()\nwas giving incorrect results when using\nformat='%Y%m%d'\nand\nerrors='ignore'\n(\nGH26493\n)\nBug in\nto_datetime()\nwas failing to parse date strings\n'today'\nand\n'now'\nif\nformat\nwas not ISO8601 (\nGH50359\n)\nBug in\nTimestamp.utctimetuple()\nraising a\nTypeError\n(\nGH32174\n)\nBug in\nto_datetime()\nwas raising\nValueError\nwhen parsing mixed-offset\nTimestamp\nwith\nerrors='ignore'\n(\nGH50585\n)\nBug in\nto_datetime()\nwas incorrectly handling floating-point inputs within 1\nunit\nof the overflow boundaries (\nGH50183\n)\nBug in\nto_datetime()\nwith unit of 芒Y芒 or 芒M芒 giving incorrect results, not matching pointwise\nTimestamp\nresults (\nGH50870\n)\nBug in\nSeries.interpolate()\nand\nDataFrame.interpolate()\nwith datetime or timedelta dtypes incorrectly raising\nValueError\n(\nGH11312\n)\nBug in\nto_datetime()\nwas not returning input with\nerrors='ignore'\nwhen input was out-of-bounds (\nGH50587\n)\nBug in\nDataFrame.from_records()\nwhen given a\nDataFrame\ninput with timezone-aware datetime64 columns incorrectly dropping the timezone-awareness (\nGH51162\n)\nBug in\nto_datetime()\nwas raising\ndecimal.InvalidOperation\nwhen parsing date strings with\nerrors='coerce'\n(\nGH51084\n)\nBug in\nto_datetime()\nwith both\nunit\nand\norigin\nspecified returning incorrect results (\nGH42624\n)\nBug in\nSeries.astype()\nand\nDataFrame.astype()\nwhen converting an object-dtype object containing timezone-aware datetimes or strings to\ndatetime64[ns]\nincorrectly localizing as UTC instead of raising\nTypeError\n(\nGH50140\n)\nBug in\nDataFrameGroupBy.quantile()\nand\nSeriesGroupBy.quantile()\nwith datetime or timedelta dtypes giving incorrect results for groups containing\nNaT\n(\nGH51373\n)\nBug in\nDataFrameGroupBy.quantile()\nand\nSeriesGroupBy.quantile()\nincorrectly raising with\nPeriodDtype\nor\nDatetimeTZDtype\n(\nGH51373\n)\nTimedelta\n#\nBug in\nto_timedelta()\nraising error when input has nullable dtype\nFloat64\n(\nGH48796\n)\nBug in\nTimedelta\nconstructor incorrectly raising instead of returning\nNaT\nwhen given a\nnp.timedelta64(\"nat\")\n(\nGH48898\n)\nBug in\nTimedelta\nconstructor failing to raise when passed both a\nTimedelta\nobject and keywords (e.g. days, seconds) (\nGH48898\n)\nBug in\nTimedelta\ncomparisons with very large\ndatetime.timedelta\nobjects incorrect raising\nOutOfBoundsTimedelta\n(\nGH49021\n)\nTimezones\n#\nBug in\nSeries.astype()\nand\nDataFrame.astype()\nwith object-dtype containing multiple timezone-aware\ndatetime\nobjects with heterogeneous timezones to a\nDatetimeTZDtype\nincorrectly raising (\nGH32581\n)\nBug in\nto_datetime()\nwas failing to parse date strings with timezone name when\nformat\nwas specified with\n%Z\n(\nGH49748\n)\nBetter error message when passing invalid values to\nambiguous\nparameter in\nTimestamp.tz_localize()\n(\nGH49565\n)\nBug in string parsing incorrectly allowing a\nTimestamp\nto be constructed with an invalid timezone, which would raise when trying to print (\nGH50668\n)\nNumeric\n#\nBug in\nDataFrame.add()\ncannot apply ufunc when inputs contain mixed DataFrame type and Series type (\nGH39853\n)\nBug in arithmetic operations on\nSeries\nnot propagating mask when combining masked dtypes and numpy dtypes (\nGH45810\n,\nGH42630\n)\nBug in\nDataFrame.sem()\nand\nSeries.sem()\nwhere an erroneous\nTypeError\nwould always raise when using data backed by an\nArrowDtype\n(\nGH49759\n)\nBug in\nSeries.__add__()\ncasting to object for list and masked\nSeries\n(\nGH22962\n)\nBug in\nmode()\nwhere\ndropna=False\nwas not respected when there was\nNA\nvalues (\nGH50982\n)\nBug in\nDataFrame.query()\nwith\nengine=\"numexpr\"\nand column names are\nmin\nor\nmax\nwould raise a\nTypeError\n(\nGH50937\n)\nBug in\nDataFrame.min()\nand\nDataFrame.max()\nwith tz-aware data containing\npd.NaT\nand\naxis=1\nwould return incorrect results (\nGH51242\n)\nConversion\n#\nBug in constructing\nSeries\nwith\nint64\ndtype from a string list raising instead of casting (\nGH44923\n)\nBug in constructing\nSeries\nwith masked dtype and boolean values with\nNA\nraising (\nGH42137\n)\nBug in\nDataFrame.eval()\nincorrectly raising an\nAttributeError\nwhen there are negative values in function call (\nGH46471\n)\nBug in\nSeries.convert_dtypes()\nnot converting dtype to nullable dtype when\nSeries\ncontains\nNA\nand has dtype\nobject\n(\nGH48791\n)\nBug where any\nExtensionDtype\nsubclass with\nkind=\"M\"\nwould be interpreted as a timezone type (\nGH34986\n)\nBug in\narrays.ArrowExtensionArray\nthat would raise\nNotImplementedError\nwhen passed a sequence of strings or binary (\nGH49172\n)\nBug in\nSeries.astype()\nraising\npyarrow.ArrowInvalid\nwhen converting from a non-pyarrow string dtype to a pyarrow numeric type (\nGH50430\n)\nBug in\nDataFrame.astype()\nmodifying input array inplace when converting to\nstring\nand\ncopy=False\n(\nGH51073\n)\nBug in\nSeries.to_numpy()\nconverting to NumPy array before applying\nna_value\n(\nGH48951\n)\nBug in\nDataFrame.astype()\nnot copying data when converting to pyarrow dtype (\nGH50984\n)\nBug in\nto_datetime()\nwas not respecting\nexact\nargument when\nformat\nwas an ISO8601 format (\nGH12649\n)\nBug in\nTimedeltaArray.astype()\nraising\nTypeError\nwhen converting to a pyarrow duration type (\nGH49795\n)\nBug in\nDataFrame.eval()\nand\nDataFrame.query()\nraising for extension array dtypes (\nGH29618\n,\nGH50261\n,\nGH31913\n)\nBug in\nSeries()\nnot copying data when created from\nIndex\nand\ndtype\nis equal to\ndtype\nfrom\nIndex\n(\nGH52008\n)\nStrings\n#\nBug in\npandas.api.types.is_string_dtype()\nthat would not return\nTrue\nfor\nStringDtype\nor\nArrowDtype\nwith\npyarrow.string()\n(\nGH15585\n)\nBug in converting string dtypes to 芒datetime64[ns]芒 or 芒timedelta64[ns]芒 incorrectly raising\nTypeError\n(\nGH36153\n)\nBug in setting values in a string-dtype column with an array, mutating the array as side effect when it contains missing values (\nGH51299\n)\nInterval\n#\nBug in\nIntervalIndex.is_overlapping()\nincorrect output if interval has duplicate left boundaries (\nGH49581\n)\nBug in\nSeries.infer_objects()\nfailing to infer\nIntervalDtype\nfor an object series of\nInterval\nobjects (\nGH50090\n)\nBug in\nSeries.shift()\nwith\nIntervalDtype\nand invalid null\nfill_value\nfailing to raise\nTypeError\n(\nGH51258\n)\nIndexing\n#\nBug in\nDataFrame.__setitem__()\nraising when indexer is a\nDataFrame\nwith\nboolean\ndtype (\nGH47125\n)\nBug in\nDataFrame.reindex()\nfilling with wrong values when indexing columns and index for\nuint\ndtypes (\nGH48184\n)\nBug in\nDataFrame.loc()\nwhen setting\nDataFrame\nwith different dtypes coercing values to single dtype (\nGH50467\n)\nBug in\nDataFrame.sort_values()\nwhere\nNone\nwas not returned when\nby\nis empty list and\ninplace=True\n(\nGH50643\n)\nBug in\nDataFrame.loc()\ncoercing dtypes when setting values with a list indexer (\nGH49159\n)\nBug in\nSeries.loc()\nraising error for out of bounds end of slice indexer (\nGH50161\n)\nBug in\nDataFrame.loc()\nraising\nValueError\nwith all\nFalse\nbool\nindexer and empty object (\nGH51450\n)\nBug in\nDataFrame.loc()\nraising\nValueError\nwith\nbool\nindexer and\nMultiIndex\n(\nGH47687\n)\nBug in\nDataFrame.loc()\nraising\nIndexError\nwhen setting values for a pyarrow-backed column with a non-scalar indexer (\nGH50085\n)\nBug in\nDataFrame.__getitem__()\n,\nSeries.__getitem__()\n,\nDataFrame.__setitem__()\nand\nSeries.__setitem__()\nwhen indexing on indexes with extension float dtypes (\nFloat64\n&\nFloat64\n) or complex dtypes using integers (\nGH51053\n)\nBug in\nDataFrame.loc()\nmodifying object when setting incompatible value with an empty indexer (\nGH45981\n)\nBug in\nDataFrame.__setitem__()\nraising\nValueError\nwhen right hand side is\nDataFrame\nwith\nMultiIndex\ncolumns (\nGH49121\n)\nBug in\nDataFrame.reindex()\ncasting dtype to\nobject\nwhen\nDataFrame\nhas single extension array column when re-indexing\ncolumns\nand\nindex\n(\nGH48190\n)\nBug in\nDataFrame.iloc()\nraising\nIndexError\nwhen indexer is a\nSeries\nwith numeric extension array dtype (\nGH49521\n)\nBug in\ndescribe()\nwhen formatting percentiles in the resulting index showed more decimals than needed (\nGH46362\n)\nBug in\nDataFrame.compare()\ndoes not recognize differences when comparing\nNA\nwith value in nullable dtypes (\nGH48939\n)\nBug in\nSeries.rename()\nwith\nMultiIndex\nlosing extension array dtypes (\nGH21055\n)\nBug in\nDataFrame.isetitem()\ncoercing extension array dtypes in\nDataFrame\nto object (\nGH49922\n)\nBug in\nSeries.__getitem__()\nreturning corrupt object when selecting from an empty pyarrow backed object (\nGH51734\n)\nBug in\nBusinessHour\nwould cause creation of\nDatetimeIndex\nto fail when no opening hour was included in the index (\nGH49835\n)\nMissing\n#\nBug in\nIndex.equals()\nraising\nTypeError\nwhen\nIndex\nconsists of tuples that contain\nNA\n(\nGH48446\n)\nBug in\nSeries.map()\ncaused incorrect result when data has NaNs and defaultdict mapping was used (\nGH48813\n)\nBug in\nNA\nraising a\nTypeError\ninstead of return\nNA\nwhen performing a binary operation with a\nbytes\nobject (\nGH49108\n)\nBug in\nDataFrame.update()\nwith\noverwrite=False\nraising\nTypeError\nwhen\nself\nhas column with\nNaT\nvalues and column not present in\nother\n(\nGH16713\n)\nBug in\nSeries.replace()\nraising\nRecursionError\nwhen replacing value in object-dtype\nSeries\ncontaining\nNA\n(\nGH47480\n)\nBug in\nSeries.replace()\nraising\nRecursionError\nwhen replacing value in numeric\nSeries\nwith\nNA\n(\nGH50758\n)\nMultiIndex\n#\nBug in\nMultiIndex.get_indexer()\nnot matching\nNaN\nvalues (\nGH29252\n,\nGH37222\n,\nGH38623\n,\nGH42883\n,\nGH43222\n,\nGH46173\n,\nGH48905\n)\nBug in\nMultiIndex.argsort()\nraising\nTypeError\nwhen index contains\nNA\n(\nGH48495\n)\nBug in\nMultiIndex.difference()\nlosing extension array dtype (\nGH48606\n)\nBug in\nMultiIndex.set_levels\nraising\nIndexError\nwhen setting empty level (\nGH48636\n)\nBug in\nMultiIndex.unique()\nlosing extension array dtype (\nGH48335\n)\nBug in\nMultiIndex.intersection()\nlosing extension array (\nGH48604\n)\nBug in\nMultiIndex.union()\nlosing extension array (\nGH48498\n,\nGH48505\n,\nGH48900\n)\nBug in\nMultiIndex.union()\nnot sorting when sort=None and index contains missing values (\nGH49010\n)\nBug in\nMultiIndex.append()\nnot checking names for equality (\nGH48288\n)\nBug in\nMultiIndex.symmetric_difference()\nlosing extension array (\nGH48607\n)\nBug in\nMultiIndex.join()\nlosing dtypes when\nMultiIndex\nhas duplicates (\nGH49830\n)\nBug in\nMultiIndex.putmask()\nlosing extension array (\nGH49830\n)\nBug in\nMultiIndex.value_counts()\nreturning a\nSeries\nindexed by flat index of tuples instead of a\nMultiIndex\n(\nGH49558\n)\nI/O\n#\nBug in\nread_sas()\ncaused fragmentation of\nDataFrame\nand raised\nerrors.PerformanceWarning\n(\nGH48595\n)\nImproved error message in\nread_excel()\nby including the offending sheet name when an exception is raised while reading a file (\nGH48706\n)\nBug when a pickling a subset PyArrow-backed data that would serialize the entire data instead of the subset (\nGH42600\n)\nBug in\nread_sql_query()\nignoring\ndtype\nargument when\nchunksize\nis specified and result is empty (\nGH50245\n)\nBug in\nread_csv()\nfor a single-line csv with fewer columns than\nnames\nraised\nerrors.ParserError\nwith\nengine=\"c\"\n(\nGH47566\n)\nBug in\nread_json()\nraising with\norient=\"table\"\nand\nNA\nvalue (\nGH40255\n)\nBug in displaying\nstring\ndtypes not showing storage option (\nGH50099\n)\nBug in\nDataFrame.to_string()\nwith\nheader=False\nthat printed the index name on the same line as the first row of the data (\nGH49230\n)\nBug in\nDataFrame.to_string()\nignoring float formatter for extension arrays (\nGH39336\n)\nFixed memory leak which stemmed from the initialization of the internal JSON module (\nGH49222\n)\nFixed issue where\njson_normalize()\nwould incorrectly remove leading characters from column names that matched the\nsep\nargument (\nGH49861\n)\nBug in\nread_csv()\nunnecessarily overflowing for extension array dtype when containing\nNA\n(\nGH32134\n)\nBug in\nDataFrame.to_dict()\nnot converting\nNA\nto\nNone\n(\nGH50795\n)\nBug in\nDataFrame.to_json()\nwhere it would segfault when failing to encode a string (\nGH50307\n)\nBug in\nDataFrame.to_html()\nwith\nna_rep\nset when the\nDataFrame\ncontains non-scalar data (\nGH47103\n)\nBug in\nread_xml()\nwhere file-like objects failed when iterparse is used (\nGH50641\n)\nBug in\nread_csv()\nwhen\nengine=\"pyarrow\"\nwhere\nencoding\nparameter was not handled correctly (\nGH51302\n)\nBug in\nread_xml()\nignored repeated elements when iterparse is used (\nGH51183\n)\nBug in\nExcelWriter\nleaving file handles open if an exception occurred during instantiation (\nGH51443\n)\nBug in\nDataFrame.to_parquet()\nwhere non-string index or columns were raising a\nValueError\nwhen\nengine=\"pyarrow\"\n(\nGH52036\n)\nPeriod\n#\nBug in\nPeriod.strftime()\nand\nPeriodIndex.strftime()\n, raising\nUnicodeDecodeError\nwhen a locale-specific directive was passed (\nGH46319\n)\nBug in adding a\nPeriod\nobject to an array of\nDateOffset\nobjects incorrectly raising\nTypeError\n(\nGH50162\n)\nBug in\nPeriod\nwhere passing a string with finer resolution than nanosecond would result in a\nKeyError\ninstead of dropping the extra precision (\nGH50417\n)\nBug in parsing strings representing Week-periods e.g. 芒2017-01-23/2017-01-29芒 as minute-frequency instead of week-frequency (\nGH50803\n)\nBug in\nDataFrameGroupBy.sum()\n,\nDataFrameGroupByGroupBy.cumsum()\n,\nDataFrameGroupByGroupBy.prod()\n,\nDataFrameGroupByGroupBy.cumprod()\nwith\nPeriodDtype\nfailing to raise\nTypeError\n(\nGH51040\n)\nBug in parsing empty string with\nPeriod\nincorrectly raising\nValueError\ninstead of returning\nNaT\n(\nGH51349\n)\nPlotting\n#\nBug in\nDataFrame.plot.hist()\n, not dropping elements of\nweights\ncorresponding to\nNaN\nvalues in\ndata\n(\nGH48884\n)\nax.set_xlim\nwas sometimes raising\nUserWarning\nwhich users couldn芒t address due to\nset_xlim\nnot accepting parsing arguments - the converter now uses\nTimestamp()\ninstead (\nGH49148\n)\nGroupby/resample/rolling\n#\nBug in\nExponentialMovingWindow\nwith\nonline\nnot raising a\nNotImplementedError\nfor unsupported operations (\nGH48834\n)\nBug in\nDataFrameGroupBy.sample()\nraises\nValueError\nwhen the object is empty (\nGH48459\n)\nBug in\nSeries.groupby()\nraises\nValueError\nwhen an entry of the index is equal to the name of the index (\nGH48567\n)\nBug in\nDataFrameGroupBy.resample()\nproduces inconsistent results when passing empty DataFrame (\nGH47705\n)\nBug in\nDataFrameGroupBy\nand\nSeriesGroupBy\nwould not include unobserved categories in result when grouping by categorical indexes (\nGH49354\n)\nBug in\nDataFrameGroupBy\nand\nSeriesGroupBy\nwould change result order depending on the input index when grouping by categoricals (\nGH49223\n)\nBug in\nDataFrameGroupBy\nand\nSeriesGroupBy\nwhen grouping on categorical data would sort result values even when used with\nsort=False\n(\nGH42482\n)\nBug in\nDataFrameGroupBy.apply()\nand\nSeriesGroupBy.apply\nwith\nas_index=False\nwould not attempt the computation without using the grouping keys when using them failed with a\nTypeError\n(\nGH49256\n)\nBug in\nDataFrameGroupBy.describe()\nwould describe the group keys (\nGH49256\n)\nBug in\nSeriesGroupBy.describe()\nwith\nas_index=False\nwould have the incorrect shape (\nGH49256\n)\nBug in\nDataFrameGroupBy\nand\nSeriesGroupBy\nwith\ndropna=False\nwould drop NA values when the grouper was categorical (\nGH36327\n)\nBug in\nSeriesGroupBy.nunique()\nwould incorrectly raise when the grouper was an empty categorical and\nobserved=True\n(\nGH21334\n)\nBug in\nSeriesGroupBy.nth()\nwould raise when grouper contained NA values after subsetting from a\nDataFrameGroupBy\n(\nGH26454\n)\nBug in\nDataFrame.groupby()\nwould not include a\nGrouper\nspecified by\nkey\nin the result when\nas_index=False\n(\nGH50413\n)\nBug in\nDataFrameGroupBy.value_counts()\nwould raise when used with a\nTimeGrouper\n(\nGH50486\n)\nBug in\nResampler.size()\ncaused a wide\nDataFrame\nto be returned instead of a\nSeries\nwith\nMultiIndex\n(\nGH46826\n)\nBug in\nDataFrameGroupBy.transform()\nand\nSeriesGroupBy.transform()\nwould raise incorrectly when grouper had\naxis=1\nfor\n\"idxmin\"\nand\n\"idxmax\"\narguments (\nGH45986\n)\nBug in\nDataFrameGroupBy\nwould raise when used with an empty DataFrame, categorical grouper, and\ndropna=False\n(\nGH50634\n)\nBug in\nSeriesGroupBy.value_counts()\ndid not respect\nsort=False\n(\nGH50482\n)\nBug in\nDataFrameGroupBy.resample()\nraises\nKeyError\nwhen getting the result from a key list when resampling on time index (\nGH50840\n)\nBug in\nDataFrameGroupBy.transform()\nand\nSeriesGroupBy.transform()\nwould raise incorrectly when grouper had\naxis=1\nfor\n\"ngroup\"\nargument (\nGH45986\n)\nBug in\nDataFrameGroupBy.describe()\nproduced incorrect results when data had duplicate columns (\nGH50806\n)\nBug in\nDataFrameGroupBy.agg()\nwith\nengine=\"numba\"\nfailing to respect\nas_index=False\n(\nGH51228\n)\nBug in\nDataFrameGroupBy.agg()\n,\nSeriesGroupBy.agg()\n, and\nResampler.agg()\nwould ignore arguments when passed a list of functions (\nGH50863\n)\nBug in\nDataFrameGroupBy.ohlc()\nignoring\nas_index=False\n(\nGH51413\n)\nReshaping\n#\nBug in\nDataFrame.pivot_table()\nraising\nTypeError\nfor nullable dtype and\nmargins=True\n(\nGH48681\n)\nBug in\nDataFrame.unstack()\nand\nSeries.unstack()\nunstacking wrong level of\nMultiIndex\nwhen\nMultiIndex\nhas mixed names (\nGH48763\n)\nBug in\nDataFrame.melt()\nlosing extension array dtype (\nGH41570\n)\nBug in\nDataFrame.pivot()\nnot respecting\nNone\nas column name (\nGH48293\n)\nBug in\nDataFrame.join()\nwhen\nleft_on\nor\nright_on\nis or includes a\nCategoricalIndex\nincorrectly raising\nAttributeError\n(\nGH48464\n)\nBug in\nDataFrame.pivot_table()\nraising\nValueError\nwith parameter\nmargins=True\nwhen result is an empty\nDataFrame\n(\nGH49240\n)\nClarified error message in\nmerge()\nwhen passing invalid\nvalidate\noption (\nGH49417\n)\nBug in\nDataFrame.explode()\nraising\nValueError\non multiple columns with\nNaN\nvalues or empty lists (\nGH46084\n)\nBug in\nDataFrame.transpose()\nwith\nIntervalDtype\ncolumn with\ntimedelta64[ns]\nendpoints (\nGH44917\n)\nBug in\nDataFrame.agg()\nand\nSeries.agg()\nwould ignore arguments when passed a list of functions (\nGH50863\n)\nSparse\n#\nBug in\nSeries.astype()\nwhen converting a\nSparseDtype\nwith\ndatetime64[ns]\nsubtype to\nint64\ndtype raising, inconsistent with the non-sparse behavior (\nGH49631\n,:issue:\n50087\n)\nBug in\nSeries.astype()\nwhen converting a from\ndatetime64[ns]\nto\nSparse[datetime64[ns]]\nincorrectly raising (\nGH50082\n)\nBug in\nSeries.sparse.to_coo()\nraising\nSystemError\nwhen\nMultiIndex\ncontains a\nExtensionArray\n(\nGH50996\n)\nExtensionArray\n#\nBug in\nSeries.mean()\noverflowing unnecessarily with nullable integers (\nGH48378\n)\nBug in\nSeries.tolist()\nfor nullable dtypes returning numpy scalars instead of python scalars (\nGH49890\n)\nBug in\nSeries.round()\nfor pyarrow-backed dtypes raising\nAttributeError\n(\nGH50437\n)\nBug when concatenating an empty DataFrame with an ExtensionDtype to another DataFrame with the same ExtensionDtype, the resulting dtype turned into object (\nGH48510\n)\nBug in\narray.PandasArray.to_numpy()\nraising with\nNA\nvalue when\nna_value\nis specified (\nGH40638\n)\nBug in\napi.types.is_numeric_dtype()\nwhere a custom\nExtensionDtype\nwould not return\nTrue\nif\n_is_numeric\nreturned\nTrue\n(\nGH50563\n)\nBug in\napi.types.is_integer_dtype()\n,\napi.types.is_unsigned_integer_dtype()\n,\napi.types.is_signed_integer_dtype()\n,\napi.types.is_float_dtype()\nwhere a custom\nExtensionDtype\nwould not return\nTrue\nif\nkind\nreturned the corresponding NumPy type (\nGH50667\n)\nBug in\nSeries\nconstructor unnecessarily overflowing for nullable unsigned integer dtypes (\nGH38798\n,\nGH25880\n)\nBug in setting non-string value into\nStringArray\nraising\nValueError\ninstead of\nTypeError\n(\nGH49632\n)\nBug in\nDataFrame.reindex()\nnot honoring the default\ncopy=True\nkeyword in case of columns with ExtensionDtype (and as a result also selecting multiple columns with getitem (\n[]\n) didn芒t correctly result in a copy) (\nGH51197\n)\nBug in\nSeries.any()\nand\nSeries.all()\nreturning\nNA\nfor empty or all null pyarrow-backed data when\nskipna=True\n(\nGH51624\n)\nBug in\nArrowExtensionArray\nlogical operations\n&\nand\n|\nraising\nKeyError\n(\nGH51688\n)\nStyler\n#\nFix\nbackground_gradient()\nfor nullable dtype\nSeries\nwith\nNA\nvalues (\nGH50712\n)\nMetadata\n#\nFixed metadata propagation in\nDataFrame.corr()\nand\nDataFrame.cov()\n(\nGH28283\n)\nOther\n#\nBug in incorrectly accepting dtype strings containing 芒[pyarrow]芒 more than once (\nGH51548\n)\nBug in\nSeries.searchsorted()\ninconsistent behavior when accepting\nDataFrame\nas parameter\nvalue\n(\nGH49620\n)\nBug in\narray()\nfailing to raise on\nDataFrame\ninputs (\nGH51167\n)\nContributors\n#\nA total of 260 people contributed patches to this release.  People with a\n芒+芒 by their names contributed a patch for the first time.\n5j9 +\nABCPAN-rank +\nAarni Koskela +\nAashish KC +\nAbubeker Mohammed +\nAdam Mr鲁z +\nAdam Ormondroyd +\nAditya Anulekh +\nAhmed Ibrahim\nAkshay Babbar +\nAleksa Radojicic +\nAlex +\nAlex Buzenet +\nAlex Kirko\nAllison Kwan +\nAmay Patel +\nAmbuj Pawar +\nAmotz +\nAndreas Schwab +\nAndrew Chen +\nAnton Shevtsov\nAntonio Ossa Guerra +\nAntonio Ossa-Guerra +\nAnushka Bishnoi +\nArda Kosar\nArmin Berres\nAsadullah Naeem +\nAsish Mahapatra\nBailey Lissington +\nBarkotBeyene\nBen Beasley\nBhavesh Rajendra Patil +\nBibek Jha +\nBill +\nBishwas +\nCarlosGDCJ +\nCarlotta Fabian +\nChris Roth +\nChuck Cadman +\nCorralien +\nDG +\nDan Hendry +\nDaniel Isaac\nDavid Kleindienst +\nDavid Poznik +\nDavid Rudel +\nDavidKleindienst +\nDea Mar颅a L漏on +\nDeepak Sirohiwal +\nDennis Chukwunta\nDouglas Lohmann +\nDries Schaumont\nDustin K +\nEdoardo Abati +\nEduardo Chaves +\nEge zg录rolu +\nEkaterina Borovikova +\nEli Schwartz +\nElvis Lim +\nEmily Taylor +\nEmma Carballal Haire +\nErik Welch +\nFangchen Li\nFlorian Hofstetter +\nFlynn Owen +\nFredrik Erlandsson +\nGaurav Sheni\nGeoreth Chow +\nGeorge Munyoro +\nGuilherme Beltramini\nGulnur Baimukhambetova +\nH L +\nHans\nHatim Zahid +\nHighYoda +\nHiki +\nHimanshu Wagh +\nHugo van Kemenade +\nIdil Ismiguzel +\nIrv Lustig\nIsaac Chung\nIsaac Virshup\nJHM Darbyshire\nJHM Darbyshire (iMac)\nJMBurley\nJaime Di Cristina\nJan Koch\nJanVHII +\nJanosh Riebesell\nJasmandeepKaur +\nJeremy Tuloup\nJessica M +\nJonas Haag\nJoris Van den Bossche\nJo拢o Meirelles +\nJulia Aoun +\nJustus Magin +\nKang Su Min +\nKevin Sheppard\nKhor Chean Wei\nKian Eliasi\nKostya Farber +\nKotlinIsland +\nLakmal Pinnaduwage +\nLakshya A Agrawal +\nLawrence Mitchell +\nLevi Ob +\nLoic Diridollou\nLorenzo Vainigli +\nLuca Pizzini +\nLucas Damo +\nLuke Manley\nMadhuri Patil +\nMarc Garcia\nMarco Edward Gorelli\nMarco Gorelli\nMarcoGorelli\nMaren Westermann +\nMaria Stazherova +\nMarie K +\nMarielle +\nMark Harfouche +\nMarko Pacak +\nMartin +\nMatheus Cerqueira +\nMatheus Pedroni +\nMatteo Raso +\nMatthew Roeschke\nMeeseeksMachine +\nMehdi Mohammadi +\nMichael Harris +\nMichael Mior +\nNatalia Mokeeva +\nNeal Muppidi +\nNick Crews\nNishu Choudhary +\nNoa Tamir\nNoritada Kobayashi\nOmkar Yadav +\nP. Talley +\nPablo +\nPandas Development Team\nParfait Gasana\nPatrick Hoefler\nPedro Nacht +\nPhilip +\nPietro Battiston\nPooja Subramaniam +\nPranav Saibhushan Ravuri +\nPranav. P. A +\nRalf Gommers +\nRaphSku +\nRichard Shadrach\nRobsdedude +\nRoger\nRoger Thomas\nRogerThomas +\nSFuller4 +\nSalahuddin +\nSam Rao\nSean Patrick Malloy +\nSebastian Roll +\nShantanu\nShashwat +\nShashwat Agrawal +\nShiko Wamwea +\nShoham Debnath\nShubhankar Lohani +\nSiddhartha Gandhi +\nSimon Hawkins\nSoumik Dutta +\nSowrov Talukder +\nStefanie Molin\nStefanie Senger +\nStepfen Shawn +\nSteven Rotondo\nStijn Van Hoey\nSudhansu +\nSven\nSylvain MARIE\nSylvain Mari漏\nTabea Kossen +\nTaylor Packard\nTerji Petersen\nThierry Moisan\nThomas H +\nThomas Li\nTorsten W露rtwein\nTsvika S +\nTsvika Shapira +\nVamsi Verma +\nVinicius Akira +\nWilliam Andrea\nWilliam Ayd\nWilliam Blum +\nWilson Xing +\nXiao Yuan +\nXnot +\nYasin Tatar +\nYuanhao Geng\nYvan Cywan +\nZachary Moon +\nZhengbo Wang +\nabonte +\nadrienpacifico +\nalm\namotzop +\nandyjessen +\nanonmouse1 +\nbang128 +\nbishwas jha +\ncalhockemeyer +\ncarla-alves-24 +\ncarlotta +\ncasadipietra +\ncatmar22 +\ncfabian +\ncodamuse +\ndataxerik\ndavidleon123 +\ndependabot[bot] +\nfdrocha +\ngithub-actions[bot]\nhimanshu_wagh +\niofall +\njakirkham +\njbrockmendel\njnclt +\njoelchen +\njoelsonoda +\njoshuabello2550\njoycewamwea +\nkathleenhang +\nkrasch +\nltoniazzi +\nluke396 +\nmilosz-martynow +\nminat-hub +\nmliu08 +\nmonosans +\nnealxm\nnikitaved +\nparadox-lab +\npartev\nraisadz +\nram vikram singh +\nrebecca-palmer\nsarvaSanjay +\nseljaks +\nsilviaovo +\nsmij720 +\nsoumilbaldota +\nstellalin7 +\nstrawberry beach sandals +\ntmoschou +\nuzzell +\nyqyqyq-W +\nyun +\nd隆m Lippai\n锚鹿毛铆 (Daniel Donghyun Kim) +\nprevious\nWhat芒s new in 2.0.1 (April 24, 2023)\nnext\nWhat芒s new in 1.5.3 (January 18, 2023)\nOn this page\nEnhancements\nInstalling optional dependencies with pip extras\nIndex\ncan now hold numpy numeric dtypes\nArgument\ndtype_backend\n, to return pyarrow-backed or numpy-backed nullable dtypes\nCopy-on-Write improvements\nOther enhancements\nNotable bug fixes\nDataFrameGroupBy.cumsum()\nand\nDataFrameGroupBy.cumprod()\noverflow instead of lossy casting to float\nDataFrameGroupBy.nth()\nand\nSeriesGroupBy.nth()\nnow behave as filtrations\nBackwards incompatible API changes\nConstruction with datetime64 or timedelta64 dtype with unsupported resolution\nValue counts sets the resulting name to\ncount\nDisallow astype conversion to non-supported datetime64/timedelta64 dtypes\nUTC and fixed-offset timezones default to standard-library tzinfo objects\nEmpty DataFrames/Series will now default to have a\nRangeIndex\nDataFrame to LaTeX has a new render engine\nIncreased minimum versions for dependencies\nDatetimes are now parsed with a consistent format\nOther API changes\nDeprecations\nRemoval of prior version deprecations/changes\nPerformance improvements\nBug fixes\nCategorical\nDatetimelike\nTimedelta\nTimezones\nNumeric\nConversion\nStrings\nInterval\nIndexing\nMissing\nMultiIndex\nI/O\nPeriod\nPlotting\nGroupby/resample/rolling\nReshaping\nSparse\nExtensionArray\nStyler\nMetadata\nOther\nContributors\nShow Source",
    "crawl_status": "success"
  }
]